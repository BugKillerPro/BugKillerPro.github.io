<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Go语言高级编程</title>
    <url>/2021/10/24/uncatalog/read_note_Advanced_Go_Programming_01/</url>
    <content><![CDATA[<p>读书笔记之《Go语言高级编程(Advanced Go Programming)》</p>
<span id="more"></span>  

<p><img src="/2021/10/24/uncatalog/read_note_Advanced_Go_Programming_01/1.png"><br>&ensp;&ensp;最近组里的<code>Python</code>小伙伴们都开始学GO了,找我推荐下教程,对于有其他语言基础的人来说,<br>有两本书非常适合作为<code>GO</code>的入门教程:  </p>
<ul>
<li><a href="https://chai2010.cn/advanced-go-programming-book/" title="Markdown">Go语言高级编程(Advanced Go Programming)</a></li>
<li><a href="https://www.kancloud.cn/kancloud/web-application-with-golang/44105" title="Markdown">Go Web 编程</a>  </li>
</ul>
<p>&ensp;&ensp;作者分别是曹春晖和谢孟军,两位都是<code>GO</code>中国的布道师。<br>借着这次推荐的机会,我又把《Go语言高级编程》读了一遍,以免小伙伴们来问我的时候,还有不太熟悉的地方。😁  </p>
<p>&ensp;&ensp;语法基础章节,讲的比较浅显,毕竟作者再序言里面也说了:  </p>
<pre><code class="text">本书针对有一定Go语言经验，想深入了解Go语言各种高级用法的开发人员。  
对于Go语言新手，在阅读本书前建议先熟读D&amp;K的《The Go Programming Language》。  
</code></pre>
<p>&ensp;&ensp;除此之外,后续的章节,就比较符合书名里的<code>advenced</code>这个中心思想了.<br>&ensp;&ensp;具体的内容方面,作者结合实战场景,通过循序渐进的方式给出了一些解决方案,但是具体到代码落地,还是需要读者自己去思考和实现,这一点对于编程经验不够丰富的新手可能不太友好.但是多动手、多动脑总是没错的.<br>&ensp;&ensp;阅读技巧方面,如果对语言底层的东西不是特别感兴趣或者没时间的话,第二章 CGO编程 和 第三章 汇编语言<br>是可以直接跳过的,剩下的其他章节对于偏业务开发的同学来说就全是干货了.<br>&ensp;&ensp;两年前,刚从<code>java</code>转<code>go</code>的时候,就选了这本书作为入门书籍,而且当时项目很急,几乎是一边学一边开发.特别是第五章 GO和Web<br>当时项目组刚刚全员转<code>go</code>,对于<code>go</code>语言方面的轮子积累为空,当时的<code>leader</code>又比较固执,不打算用包括<code>gin</code>在内的任何开源框架,<br>而自研<code>web</code>框架的任务又落在了我的肩上,当时,对于还没入门<code>go</code>的我,确实有点慌🤣.所以当看到该书得第五章的时候,我就像高原反应患者<br>突然得到了不限量氧气瓶一样,兴奋和激动的加持下,边搬砖边读这本书,仅用了3天左右就把这本书吸收了,当然,第二章和第三章跳过了.😂<br>看完之后,还没来得及看一看<code>gin</code>的源码,就开始自己手撸<code>web</code>框架了,好在是基于<code>httprouter</code>做路由管理开发的,上线之后,边维护边迭代,<br>可用性和性能方面还没有出过明显的问题.感谢这本书,扮演了救火的角色.<br>&ensp;&ensp;最近再次拿起这本书,看完之后,天空飘来五个字…,不好意思,重来,脑海里只有四个字:开卷有益.差不多快有一年没有读过完整的一本书了,<br>理由和大家一样–没时间🤣.而且最近半年状态也不太好,自我反思了一下,主要原因就是股票;3月份开发了一个选股系统,刚上线时,效果非常凶猛.经过系统和我个人的<br>两层筛选之后,选出的股票成功率几乎100%,而且涨幅也不小,通常2周左右,30%左右的涨幅.所以刚开始小仓位试水,效果非常理想.所以个人心态就变了,<br>很难再静下来心继续提高自己了.可惜,到了8月份,系统似乎不灵了,导致截止到现在,还是亏损状态.所以这次读完这本书之后,心理平静了不少,感谢这本书,再次扮演了救火的角色,<br>让我平静了下来.<br>&ensp;&ensp;当然了,这本书也有不少的缺陷,比如在实践方面,每每讲到痛点就突然峰回路转另起一章,没有具体的落地方案,不禁让人有些失望.但是对于鱼龙混杂的<br><code>go</code>教程来说,这本书至少做到了言之有物,非常值得一读.</p>
]]></content>
      <tags>
        <tag>读书笔记</tag>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title>article_name.md</title>
    <url>/2021/03/22/uncatalog/ckv998l900007v0r7ex2x5g2g/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>git工作实践</title>
    <url>/2021/06/03/git%E5%9B%9E%E5%BF%86%E5%BD%95/git_practice01/</url>
    <content><![CDATA[<p>从gitea切换到gitLab快一年了,而且又是独立开发维护一个项目,很多git命令都有些模糊了,重新整理记录一下;</p>
<span id="more"></span>
<p><img src="/2021/06/03/git%E5%9B%9E%E5%BF%86%E5%BD%95/git_practice01/0.png"></p>
<h1 id="git实践"><a href="#git实践" class="headerlink" title="git实践"></a>git实践</h1><h3 id="1-修改上次的提交"><a href="#1-修改上次的提交" class="headerlink" title="1 修改上次的提交"></a>1 修改上次的提交</h3><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">git add </span><br><span class="line">git commit --amend --no-edit</span><br><span class="line">git push</span><br></pre></td></tr></table></figure></div>
<h3 id="2-分支合并前，合并多次提交"><a href="#2-分支合并前，合并多次提交" class="headerlink" title="2 分支合并前，合并多次提交"></a>2 分支合并前，合并多次提交</h3><h4 id="2-1-应用场景"><a href="#2-1-应用场景" class="headerlink" title="2.1 应用场景"></a>2.1 应用场景</h4><p>对于一个项目，你可能会多次提交代码，每次提交都对应一个<code>commit sha</code></p>
<p><img src="/2021/06/03/git%E5%9B%9E%E5%BF%86%E5%BD%95/git_practice01/1.jpg" alt="avatar"></p>
<p>当完成项目，要进行分支合并的时候，只想保留一个或某几个<code>commit</code>，这时候就需要合并<code>commit</code>了。</p>
<h4 id="2-2-如何合并"><a href="#2-2-如何合并" class="headerlink" title="2.2 如何合并"></a>2.2 如何合并</h4><p>这里介绍两种方式，第一种是<code>git rebase</code>，第二种是<code>git rebase --autosquash</code>，后者在<code>git commit</code>时是有条件的。</p>
<p>1） <code>git rebase</code><br>第一步，开启交互模式</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">// 注意,这里的&lt;commit_sha&gt;是你针对此项目第一个提交的前一个提交的commit。</span><br><span class="line">git rebase -i &lt;commit_sha&gt;</span><br></pre></td></tr></table></figure></div>

<p>举个例子：</p>
<p>下面是工作中的提交记录：</p>
<p><img src="/2021/06/03/git%E5%9B%9E%E5%BF%86%E5%BD%95/git_practice01/2.jpg" alt="avatar"></p>
<p>这时我们想要把前七个<code>commit</code>合并成一个，即：<br><img src="/2021/06/03/git%E5%9B%9E%E5%BF%86%E5%BD%95/git_practice01/3.jpg" alt="avatar"></p>
<p>其中<code>commit_sha</code>是第一个提交的前一个提交的哈希。 因此，在我的示例中，命令为：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">git rebase -i 6394dc</span><br></pre></td></tr></table></figure></div>
<p>第二步，再去合并</p>
<p>这时候会弹出一个框，列出了你想要合并的所有<code>commit</code>。注意列出的顺序是从老到新的。</p>
<p><img src="/2021/06/03/git%E5%9B%9E%E5%BF%86%E5%BD%95/git_practice01/4.jpg" alt="avatar"></p>
<p>更改<code>commit_sha</code>最前面的单词，我们打算把这七个合并成一个<code>commit</code>，那么更改如下：<br><img src="/2021/06/03/git%E5%9B%9E%E5%BF%86%E5%BD%95/git_practice01/5.jpg" alt="avatar"></p>
<p>保存退出后，又弹出一个新的框，让我们更改<code>commit</code>信息，编辑完后退出就好了。<br>最后执行:</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">git push -f</span><br></pre></td></tr></table></figure></div>
<p>最后完成的效果如下：</p>
<p><img src="/2021/06/03/git%E5%9B%9E%E5%BF%86%E5%BD%95/git_practice01/6.png" alt="avatar"></p>
<ol start="2">
<li><code>git rebase --autosquash</code></li>
</ol>
<p>顾名思义，就是会自动帮你压缩<code>commit</code>。但是你在<code>git commit</code>的时候需要使用特殊命令：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">git commit --fixup=&lt;commit_sha&gt;</span><br></pre></td></tr></table></figure></div>
<p>这里的<code>commit_sha</code>是指你对哪个<code>commit</code>进行了更改，所以必须先至少存在一个对该项目的提交。</p>
<p>举个例子：</p>
<p>下面是工作中的提交记录：</p>
<p><img src="/2021/06/03/git%E5%9B%9E%E5%BF%86%E5%BD%95/git_practice01/7.png" alt="avatar"></p>
<p>我现在有有了一个新的改动，那么在提交时，就需要用如下命令表明我是对上一个<code>commit</code>进行了更改：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">git commit --fixup=d94e78</span><br></pre></td></tr></table></figure></div>
<p>产生的效果是这样的：</p>
<p><img src="/2021/06/03/git%E5%9B%9E%E5%BF%86%E5%BD%95/git_practice01/8.png" alt="avatar"></p>
<p>这时候又有了一个新的改动，那么提交时的命令不变：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">git commit --fixup=d94e78</span><br></pre></td></tr></table></figure></div>

<p>产生的效果：</p>
<p><img src="/2021/06/03/git%E5%9B%9E%E5%BF%86%E5%BD%95/git_practice01/9.jpg" alt="avatar"></p>
<p>接下来我们进行合并操作：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">git rebase --autosquash -i &lt;commit_sha&gt;</span><br></pre></td></tr></table></figure></div>

<p>注意，这里的<code>commit_sha</code>是<code>older commit6394dc</code>。</p>
<p>Git这时会很机智的补全单词，不需要手动输入了。</p>
<p><img src="/2021/06/03/git%E5%9B%9E%E5%BF%86%E5%BD%95/git_practice01/10.png" alt="avatar"></p>
<p>直接保存退出，重新编辑提交信息即可。</p>
<p>以上两种方式，一种是提交时轻松，合并时麻烦，另外一种相反。可以根据喜好来选择使用。</p>
<h3 id="3-对特定项目设置用户名-邮箱-密码的方法"><a href="#3-对特定项目设置用户名-邮箱-密码的方法" class="headerlink" title="3 对特定项目设置用户名/邮箱/密码的方法"></a>3 对特定项目设置用户名/邮箱/密码的方法</h3><h4 id="3-1-找到项目所在目录下的-git，进入-git文件夹，然后执行如下命令分别设置用户名和邮箱"><a href="#3-1-找到项目所在目录下的-git，进入-git文件夹，然后执行如下命令分别设置用户名和邮箱" class="headerlink" title="3.1.找到项目所在目录下的.git，进入.git文件夹，然后执行如下命令分别设置用户名和邮箱"></a>3.1.找到项目所在目录下的.git，进入.git文件夹，然后执行如下命令分别设置用户名和邮箱</h4><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">git config user.name &quot;BugKillerPro&quot;</span><br><span class="line">git config user.email &quot;511808895@qq.com&quot;</span><br></pre></td></tr></table></figure></div>
<p>然后执行命令查看config文件：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">cat config</span><br></pre></td></tr></table></figure></div>
<p>发现里面多了刚才配置的用户名和邮箱信息user，即成功为该项目单独设置了用户名和邮箱</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line">[branch &quot;master&quot;]</span><br><span class="line">    remote = origin</span><br><span class="line">    merge = refs/heads/master</span><br><span class="line">[user]</span><br><span class="line">    name = BugKillerPro</span><br><span class="line">    email = 511808895@qq.com</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>

<p>2.如果<code>git pull</code> 每次都要求输入用户名和密码，则可以执行如下配置</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">git config credential.helper store</span><br></pre></td></tr></table></figure></div>
<p>执行后,<code> cat config</code>查看，则多了credential的内容：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">[user]</span><br><span class="line">    name = BugKillerPro</span><br><span class="line">    email = 511808895@qq.com</span><br><span class="line">[credential]</span><br><span class="line">        helper = store</span><br></pre></td></tr></table></figure></div>

<p>然后再回到项目目录下执行<code>git pull/push</code>，根据提示输入用户名和密码，输入正确后，以后再执行<code>git pull/push</code> 就不用输入用户名和密码了</p>
<h3 id="4-合作开发同一个分支-提交本地修改流程"><a href="#4-合作开发同一个分支-提交本地修改流程" class="headerlink" title="4 合作开发同一个分支,提交本地修改流程"></a>4 合作开发同一个分支,提交本地修改流程</h3><h4 id="第一种："><a href="#第一种：" class="headerlink" title="第一种："></a>第一种：</h4><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">git add -A</span><br><span class="line">git commit -m &quot;www&quot;</span><br><span class="line">git push</span><br><span class="line"><span class="meta">#</span><span class="bash"> 无冲突,则结束,有冲突,则继续执行下面的操作</span></span><br><span class="line">git pull --rebase</span><br><span class="line"><span class="meta">#</span><span class="bash"> 解决本地文件冲突</span></span><br><span class="line">git add -A</span><br><span class="line">git commit --amend</span><br><span class="line">git rebase --continue</span><br><span class="line">git push</span><br></pre></td></tr></table></figure></div>

<h4 id="第二种："><a href="#第二种：" class="headerlink" title="第二种："></a>第二种：</h4><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">git stash     # 暂存</span><br><span class="line">git pull      # 本地文件会变得和最新远程仓库一致</span><br><span class="line">git stash pop # 暂存内容恢复</span><br><span class="line"><span class="meta">#</span><span class="bash"> 无冲突,则push,有冲突,则继续执行下面的操作</span></span><br><span class="line">git add -A</span><br><span class="line">git commit -m &quot;www&quot;</span><br><span class="line">git push </span><br></pre></td></tr></table></figure></div>
<p><em><strong>参考</strong></em></p>
<blockquote>
<p><a href="https://zhuanlan.zhihu.com/p/139321091" title="Markdown">知乎</a></p>
<p><a href="https://www.jianshu.com/p/bac094fb0222" title="Markdown">简书</a></p>
</blockquote>
]]></content>
      <categories>
        <category>git回忆录</category>
      </categories>
      <tags>
        <tag>git回忆录</tag>
      </tags>
  </entry>
  <entry>
    <title>go协程泄露 goroutine leak</title>
    <url>/2021/10/27/uncatalog/ckv998l94000av0r75cugcz8d/</url>
    <content><![CDATA[<p>goroutine leak</p>
<span id="more"></span>
<p><img src="/2021/10/27/uncatalog/ckv998l94000av0r75cugcz8d/1.png"></p>
<h1 id="什么是泄露？"><a href="#什么是泄露？" class="headerlink" title="什么是泄露？"></a>什么是泄露？</h1><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="TEXT"><figure class="iseeu highlight /text"><table><tr><td class="code"><pre><span class="line">不好的事情流传出去让别人知道了</span><br></pre></td></tr></table></figure></div>
<p>额……,这个解释对程序员来说好像不太贴近生活,那我们换一个  </p>
<h3 id="内存泄露-Memory-Leak"><a href="#内存泄露-Memory-Leak" class="headerlink" title="内存泄露(Memory Leak)"></a>内存泄露(Memory Leak)</h3><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="TEXT"><figure class="iseeu highlight /text"><table><tr><td class="code"><pre><span class="line">对于java程序员来说,这个词汇肯定不陌生.</span><br><span class="line">内存泄露本意是申请的内存空间没有被正确释放,  </span><br><span class="line">导致后续程序里这块内存被永远占用（不可达）,  </span><br><span class="line">而且指向这块内存空间的指针不再存在时,  </span><br><span class="line">这块内存也就永远不可达了,内存空间就这么一点点被蚕食.  </span><br><span class="line">借用别人的比喻就是:  </span><br><span class="line">比如有10张纸,本来一人一张,画完自己擦了还回去,别人可以继续画,现在有个坏蛋要了纸不擦不还,然后还跑了找不到人了,如此就只剩下9张纸给别人用了,这样的人多起来后,最后大家一张纸都没有了;</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>

<h1 id="go协程泄露-goroutine-leak"><a href="#go协程泄露-goroutine-leak" class="headerlink" title="go协程泄露(goroutine leak)"></a>go协程泄露(goroutine leak)</h1><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="TEXT"><figure class="iseeu highlight /text"><table><tr><td class="code"><pre><span class="line">在Go中,goroutine很轻量级,随便创建成千上万个goroutine不是问题,  </span><br><span class="line">但要注意,要是这么多的goroutine一致递增,而不退出,不释放资源,也会造成资源耗尽、服务不可达的情况;</span><br></pre></td></tr></table></figure></div>

<h3 id="如何发现"><a href="#如何发现" class="headerlink" title="如何发现"></a>如何发现</h3><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// NumGoroutine returns the number of goroutines that currently exist.</span></span><br><span class="line">  runtime.NumGoroutine()</span><br></pre></td></tr></table></figure></div>
<p>我们可以把这个数据封装成一个服务,通过查看每次的协程数量的变化和增减,我们可以判断是否有goroutine泄露发生</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">	<span class="string">&quot;fmt&quot;</span></span><br><span class="line">	<span class="string">&quot;log&quot;</span></span><br><span class="line">	<span class="string">&quot;net/http&quot;</span></span><br><span class="line">	<span class="string">&quot;runtime&quot;</span></span><br><span class="line">	<span class="string">&quot;strconv&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">//func getStackTraceHandler(w http.ResponseWriter, r *http.Request) &#123;</span></span><br><span class="line"><span class="comment">//	stack := debug.Stack()</span></span><br><span class="line"><span class="comment">//	w.Write(stack)</span></span><br><span class="line"><span class="comment">//	pprof.Lookup(&quot;goroutine&quot;).WriteTo(w, 2)</span></span><br><span class="line"><span class="comment">//&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">getGCntHandler</span><span class="params">(w http.ResponseWriter, r *http.Request)</span></span> &#123;</span><br><span class="line">	cnt := runtime.NumGoroutine()</span><br><span class="line">	fmt.Fprintf(w, strconv.Itoa(cnt))</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">	<span class="comment">//http.HandleFunc(&quot;/_stack&quot;, getStackTraceHandler)</span></span><br><span class="line">	http.HandleFunc(<span class="string">&quot;/_gc&quot;</span>, getGCntHandler)</span><br><span class="line">	err := http.ListenAndServe(<span class="string">&quot;:8080&quot;</span>, <span class="literal">nil</span>)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		log.Fatal(<span class="string">&quot;ListenAndServe: &quot;</span>, err)</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure></div>

<h3 id="如何确认泄露处"><a href="#如何确认泄露处" class="headerlink" title="如何确认泄露处"></a>如何确认泄露处</h3><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">	<span class="string">&quot;fmt&quot;</span></span><br><span class="line">	<span class="string">&quot;log&quot;</span></span><br><span class="line">	<span class="string">&quot;net/http&quot;</span></span><br><span class="line">	<span class="string">&quot;runtime&quot;</span></span><br><span class="line">	<span class="string">&quot;runtime/debug&quot;</span></span><br><span class="line">	<span class="string">&quot;runtime/pprof&quot;</span></span><br><span class="line">	<span class="string">&quot;strconv&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">getStackTraceHandler</span><span class="params">(w http.ResponseWriter, r *http.Request)</span></span> &#123;</span><br><span class="line">	stack := debug.Stack()</span><br><span class="line">	w.Write(stack)</span><br><span class="line">	pprof.Lookup(<span class="string">&quot;goroutine&quot;</span>).WriteTo(w, <span class="number">2</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">getGCntHandler</span><span class="params">(w http.ResponseWriter, r *http.Request)</span></span> &#123;</span><br><span class="line">	cnt := runtime.NumGoroutine()</span><br><span class="line">	fmt.Fprintf(w, strconv.Itoa(cnt))</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">	http.HandleFunc(<span class="string">&quot;/_stack&quot;</span>, getStackTraceHandler)</span><br><span class="line">	http.HandleFunc(<span class="string">&quot;/_gc&quot;</span>, getGCntHandler)</span><br><span class="line">	err := http.ListenAndServe(<span class="string">&quot;:8080&quot;</span>, <span class="literal">nil</span>)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		log.Fatal(<span class="string">&quot;ListenAndServe: &quot;</span>, err)</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>

<h3 id="常见的产生原因"><a href="#常见的产生原因" class="headerlink" title="常见的产生原因"></a>常见的产生原因</h3><ul>
<li>由于channel的读/写端退出,导致channel的写/读端goroutine一直阻塞,而无法退出</li>
<li>goroutine内部进入死循环,导致资源一直无法释放</li>
</ul>
<h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><p>基于以上原因,开发时需要重点注意以下几点:</p>
<ul>
<li>创建goroutine时就要想好该goroutine该如何结束.<br>比如：  <ul>
<li>goroutine完成它的工作,正常return</li>
<li>由于发生了没有处理的错误,运行时异常  </li>
<li>有其他的协程告诉它终止</li>
</ul>
</li>
<li>使用channel时,要考虑到channel阻塞时协程可能的行为 </li>
<li>在做 master-worker模式、producer-consumer模式等的开发时</li>
</ul>
]]></content>
      <tags>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title>go的*和&amp;</title>
    <url>/2021/06/03/go-practice/go_practice_01/</url>
    <content><![CDATA[<p>go的*和&amp;的区别</p>
<span id="more"></span>
<p><img src="/2021/06/03/go-practice/go_practice_01/1.png"></p>
<h3 id="和-amp-的区别"><a href="#和-amp-的区别" class="headerlink" title="*和&amp;的区别"></a>*和&amp;的区别</h3><blockquote>
<p>&amp;是取地址符号,即取得某个变量的地址;如&amp;a<br>*是指针运算符,可以表示一个变量是指针类型,也可以表示一个指针变量所指向的存储单元,也就是这个地址所存储的值,即指针取值或者.</p>
</blockquote>
]]></content>
      <categories>
        <category>GO实践</category>
      </categories>
      <tags>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title>go自定义json</title>
    <url>/2021/04/18/go-practice/json_practice01/</url>
    <content><![CDATA[<h5 id="go自定义json-CustomMarshalJSON"><a href="#go自定义json-CustomMarshalJSON" class="headerlink" title="go自定义json,CustomMarshalJSON"></a>go自定义json,CustomMarshalJSON</h5><blockquote>
<p>需求描述: golang 的原生 json package 有时会有一些与预期不符合的情况,<br>例如对接编码(json.Marshal) golang 会默认 “整型浮点数” 如: 1.00 转换为json 的整型 1, 但有时并不希望这种转换.<br>所以就有了CustomMarshalJSON,即自定义json</p>
</blockquote>
<hr>
<span id="more"></span>

<p><img src="/2021/04/18/go-practice/json_practice01/1.png"></p>
<blockquote>
<p><a href="https://pkg.go.dev/encoding/json#ex-package--CustomMarshalJSON" title="Markdown">官方例子</a></p>
</blockquote>
<h6 id="Marshaler-和-Unmarshaler-源码"><a href="#Marshaler-和-Unmarshaler-源码" class="headerlink" title="Marshaler 和 Unmarshaler 源码"></a>Marshaler 和 Unmarshaler 源码</h6><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// </span></span><br><span class="line"><span class="comment">// Marshaler is the interface implemented by types that</span></span><br><span class="line"><span class="comment">// can marshal themselves into valid JSON.</span></span><br><span class="line"><span class="keyword">type</span> Marshaler <span class="keyword">interface</span> &#123;</span><br><span class="line">	MarshalJSON() ([]<span class="keyword">byte</span>, error)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Unmarshaler is the interface implemented by types</span></span><br><span class="line"><span class="comment">// that can unmarshal a JSON description of themselves.</span></span><br><span class="line"><span class="comment">// The input can be assumed to be a valid encoding of</span></span><br><span class="line"><span class="comment">// a JSON value. UnmarshalJSON must copy the JSON data</span></span><br><span class="line"><span class="comment">// if it wishes to retain the data after returning.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// By convention, to approximate the behavior of Unmarshal itself,</span></span><br><span class="line"><span class="comment">// Unmarshalers implement UnmarshalJSON([]byte(&quot;null&quot;)) as a no-op.</span></span><br><span class="line"><span class="keyword">type</span> Unmarshaler <span class="keyword">interface</span> &#123;</span><br><span class="line">	UnmarshalJSON([]<span class="keyword">byte</span>) error</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>
<h2 id="你只要能看懂一个单词themselves，你就明白该怎么解决上面需求描述里的问题了。"><a href="#你只要能看懂一个单词themselves，你就明白该怎么解决上面需求描述里的问题了。" class="headerlink" title="你只要能看懂一个单词themselves，你就明白该怎么解决上面需求描述里的问题了。"></a>你只要能看懂一个单词<code>themselves</code>，你就明白该怎么解决上面需求描述里的问题了。</h2><h6 id="例1："><a href="#例1：" class="headerlink" title="例1："></a>例1：</h6><blockquote>
<p>解决浮点数据类型编码小数位丢失的问题</p>
</blockquote>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> (</span><br><span class="line">	<span class="string">&quot;bytes&quot;</span></span><br><span class="line">	<span class="string">&quot;encoding/json&quot;</span></span><br><span class="line">	<span class="string">&quot;fmt&quot;</span></span><br><span class="line">	<span class="string">&quot;strconv&quot;</span></span><br><span class="line">	<span class="string">&quot;time&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Person <span class="keyword">struct</span> &#123;</span><br><span class="line">	Name <span class="keyword">string</span></span><br><span class="line">	Util <span class="keyword">float64</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> StrictFloat64 <span class="keyword">float64</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 自定义类型上实现 Marshaler 的接口, 在进行 Marshal 时就会使用此除的实现来进行 json 编码</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(f StrictFloat64)</span> <span class="title">MarshalJSON</span><span class="params">()</span> <span class="params">([]<span class="keyword">byte</span>, error)</span></span> &#123;</span><br><span class="line">	<span class="keyword">if</span> <span class="keyword">float64</span>(f) == <span class="keyword">float64</span>(<span class="keyword">int</span>(f)) &#123;</span><br><span class="line">		<span class="keyword">return</span> []<span class="keyword">byte</span>(strconv.FormatFloat(<span class="keyword">float64</span>(f), <span class="string">&#x27;f&#x27;</span>, <span class="number">-1</span>, <span class="number">64</span>)), <span class="literal">nil</span> <span class="comment">// 可以自由调整精度</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> []<span class="keyword">byte</span>(strconv.FormatFloat(<span class="keyword">float64</span>(f), <span class="string">&#x27;f&#x27;</span>, <span class="number">-1</span>, <span class="number">64</span>)), <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> StrictPerson <span class="keyword">struct</span> &#123;</span><br><span class="line">	Name <span class="keyword">string</span></span><br><span class="line">	Util StrictFloat64</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">	p1 := Person&#123;<span class="string">&quot;ross&quot;</span>, <span class="number">1.01</span>&#125;</span><br><span class="line">	p2 := Person&#123;<span class="string">&quot;jack&quot;</span>, <span class="number">1.00</span>&#125; </span><br><span class="line">	p1Json, _ := json.Marshal(p1)</span><br><span class="line">	fmt.Println(<span class="string">&quot;\&quot;ross\&quot;, 1.01 --&gt; &quot;</span> + <span class="keyword">string</span>(p1Json))</span><br><span class="line">	p2Json, _ := json.Marshal(p2)</span><br><span class="line">	fmt.Println(<span class="string">&quot;\&quot;ross\&quot;, 1.00 --&gt; &quot;</span> + <span class="keyword">string</span>(p2Json))</span><br><span class="line"></span><br><span class="line">	sp1 := StrictPerson&#123;<span class="string">&quot;ross&quot;</span>, <span class="number">1.01</span>&#125;</span><br><span class="line">	sp2 := StrictPerson&#123;<span class="string">&quot;jack&quot;</span>, <span class="number">1.00001</span>&#125; </span><br><span class="line">	sp1Json, _ := json.Marshal(sp1)</span><br><span class="line">	fmt.Println(<span class="string">&quot;\&quot;ross\&quot;, 1.01 (自定义 StrictFloat64 类型)--&gt; &quot;</span> + <span class="keyword">string</span>(sp1Json))</span><br><span class="line">	sp2Json, _ := json.Marshal(sp2)</span><br><span class="line">	fmt.Println(<span class="string">&quot;\&quot;ross\&quot;, 1.00 (自定义 StrictFloat64 类型) --&gt; &quot;</span> + <span class="keyword">string</span>(sp2Json))</span><br><span class="line"></span><br><span class="line">	p_Demo := &amp;StrictPerson&#123;&#125;</span><br><span class="line">	json.Unmarshal(sp2Json, p_Demo)</span><br><span class="line">	fmt.Printf(<span class="string">&quot;%#v&quot;</span>, p_Demo)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 输出:</span></span><br><span class="line"><span class="comment">//&quot;ross&quot;, 1.01 --&gt; &#123;&quot;Name&quot;:&quot;ross&quot;,&quot;Util&quot;:1.01&#125;</span></span><br><span class="line"><span class="comment">//&quot;ross&quot;, 1.00 --&gt; &#123;&quot;Name&quot;:&quot;jack&quot;,&quot;Util&quot;:1&#125;</span></span><br><span class="line"><span class="comment">//&quot;ross&quot;, 1.01 (自定义 StrictFloat64 类型)--&gt; &#123;&quot;Name&quot;:&quot;ross&quot;,&quot;Util&quot;:1.01&#125;</span></span><br><span class="line"><span class="comment">//&quot;ross&quot;, 1.00 (自定义 StrictFloat64 类型) --&gt; &#123;&quot;Name&quot;:&quot;jack&quot;,&quot;Util&quot;:1.00001&#125;</span></span><br><span class="line"><span class="comment">//&amp;main.StrictPerson&#123;Name:&quot;jack&quot;, Util:1.00001&#125;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></div>
<h6 id="例2："><a href="#例2：" class="headerlink" title="例2："></a>例2：</h6><blockquote>
<p>解决非2 RFC3339 标准格式时间转换问题</p>
</blockquote>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> ExTime <span class="keyword">struct</span> &#123;</span><br><span class="line">	time.Time</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(t *ExTime)</span> <span class="title">UnmarshalJSON</span><span class="params">(b []<span class="keyword">byte</span>)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	b = bytes.Trim(b, <span class="string">&quot;\&quot;&quot;</span>)  <span class="comment">// 此除需要去掉传入的数据的两端的 &quot;&quot;</span></span><br><span class="line">	ext, err := time.Parse(ExTimeUnmarshalTimeFormat, <span class="keyword">string</span>(b))</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="comment">// do something</span></span><br><span class="line">	&#125;</span><br><span class="line">	*t = ExTime&#123;ext&#125;</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(t ExTime)</span> <span class="title">MarshalJSON</span><span class="params">()</span> <span class="params">([]<span class="keyword">byte</span>, error)</span></span> &#123;</span><br><span class="line">	<span class="keyword">var</span> stamp = fmt.Sprintf(<span class="string">&quot;\&quot;%s\&quot;&quot;</span>, time.Time(t.Time).Format(ExTimeMarshalTimeFormat))</span><br><span class="line">	<span class="keyword">return</span> []<span class="keyword">byte</span>(stamp), <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> ExTimeUnmarshalTimeFormat = <span class="string">&quot;2006-01-02 15:04:05&quot;</span></span><br><span class="line"><span class="keyword">var</span> ExTimeMarshalTimeFormat = <span class="string">&quot;2006-01-02 15:04:05&quot;</span></span><br></pre></td></tr></table></figure></div>

<h6 id="例3："><a href="#例3：" class="headerlink" title="例3："></a>例3：</h6><blockquote>
<p>解决内嵌结构体序列化问题</p>
</blockquote>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> Message <span class="keyword">struct</span> &#123;</span><br><span class="line">    From <span class="keyword">string</span>     <span class="string">`json:&quot;from&quot;`</span></span><br><span class="line">    To   <span class="keyword">string</span>     <span class="string">`json:&quot;to&quot;`</span></span><br><span class="line">    Data <span class="keyword">string</span> <span class="string">`json:&quot;data&quot;`</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    msg := Message&#123;</span><br><span class="line">        From: <span class="string">&quot;XiaoMing&quot;</span>,</span><br><span class="line">        To:   <span class="string">&quot;LiGang&quot;</span>,</span><br><span class="line">        Data: <span class="string">`&#123;&quot;title&quot;:&quot;test&quot;,&quot;body&quot;:&quot;something&quot;&#125;`</span>,</span><br><span class="line">    &#125;</span><br><span class="line">    jsonData, err := json.Marshal(msg)</span><br><span class="line">    <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">        <span class="built_in">panic</span>(err)</span><br><span class="line">    &#125;</span><br><span class="line">    fmt.Println(<span class="keyword">string</span>(jsonData))</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 在上面的例子中，Data字段是string类型，但是保存的内容是json格式的数据，这个时候，程序输出：</span></span><br><span class="line"><span class="comment">// &#123;&quot;from&quot;:&quot;XiaoMing&quot;,&quot;to&quot;:&quot;LiGang&quot;,&quot;data&quot;:&quot;&#123;\&quot;title\&quot;:\&quot;test\&quot;,\&quot;body\&quot;:\&quot;something\&quot;&#125;&quot;&#125;</span></span><br><span class="line"><span class="comment">// 序列化之后的data是一个字符串,而不是我们想要的json结构的字符串</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 解决办法：</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> JsonString <span class="keyword">string</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(j JsonString)</span> <span class="title">MarshalJSON</span><span class="params">()</span> <span class="params">([]<span class="keyword">byte</span>, error)</span></span> &#123;</span><br><span class="line">    fmt.Println(<span class="string">&quot;marshal...&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> []<span class="keyword">byte</span>(j), <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Message2 <span class="keyword">struct</span> &#123;</span><br><span class="line">    From <span class="keyword">string</span>     <span class="string">`json:&quot;from&quot;`</span></span><br><span class="line">    To   <span class="keyword">string</span>     <span class="string">`json:&quot;to&quot;`</span></span><br><span class="line">    Data JsonString <span class="string">`json:&quot;data&quot;`</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>]]></content>
      <categories>
        <category>GO实践</category>
      </categories>
      <tags>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title>shell回忆录</title>
    <url>/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/</url>
    <content><![CDATA[<p>从java切换到go之后,就很少登到服务器上排查问题了,加之CICD顺利上线和应用工程师的配备,在服务器上敲命令和写shell脚本的机会就更少了。<br>但是,这门传统手艺咱不能落下,遂写下该回忆录,想到哪写到哪吧.见谅！</p>
<span id="more"></span>

<p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/0.png"></p>
<h3 id="1-什么是shell"><a href="#1-什么是shell" class="headerlink" title="1,什么是shell"></a>1,什么是<code>shell</code></h3><p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/1.png"></p>
<h3 id="2-linux-的启动过程"><a href="#2-linux-的启动过程" class="headerlink" title="2,linux 的启动过程"></a>2,<code>linux</code> 的启动过程</h3><p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/2.png"></p>
<h3 id="3-shell-脚本"><a href="#3-shell-脚本" class="headerlink" title="3,shell 脚本"></a>3,<code>shell</code> 脚本</h3><p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/3.png">  </p>
<p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/4.png"></p>
<h3 id="3-1-管道"><a href="#3-1-管道" class="headerlink" title="3.1,管道"></a>3.1,管道</h3><p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/5.png"></p>
<h3 id="3-2-重定向"><a href="#3-2-重定向" class="headerlink" title="3.2,重定向"></a>3.2,重定向</h3><p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/6.png"></p>
<h3 id="3-3-变量"><a href="#3-3-变量" class="headerlink" title="3.3,变量"></a>3.3,变量</h3><p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/7.png">  </p>
<p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/8.png">  </p>
<p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/9.png">  </p>
<p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/10.png"></p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> <span class="variable">$n</span> :第n个参数,如果n&gt;=10,需要写为<span class="variable">$&#123;10&#125;</span>的格式;</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> <span class="variable">$&#123;n-_&#125;</span> :第n个参数如果为空,则设置为_,_也可以用其他字符替换;</span></span><br></pre></td></tr></table></figure></div>

<p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/11.png"><br><a href="https://blog.csdn.net/smile_from_2015/article/details/80058351">详解</a></p>
<p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/12.png"></p>
<h3 id="3-4-转义与引用"><a href="#3-4-转义与引用" class="headerlink" title="3.4,转义与引用"></a>3.4,转义与引用</h3><p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/13.png"></p>
<h3 id="3-5-运算符"><a href="#3-5-运算符" class="headerlink" title="3.5,运算符"></a>3.5,运算符</h3><p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/14.png">  </p>
<p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/15.png"></p>
<p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/16.png"></p>
<p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/17.png"></p>
<p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/18.png"></p>
<p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/20.png">  </p>
<p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/21.png"></p>
<p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/22.png">  </p>
<p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/23.png"></p>
<p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/24.png">  </p>
<p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/25.png">  </p>
<p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/26.png">  </p>
<p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/27.png">  </p>
<h3 id="3-6-shell-脚本的测试和判断"><a href="#3-6-shell-脚本的测试和判断" class="headerlink" title="3.6,```shell``脚本的测试和判断"></a>3.6,```shell``脚本的测试和判断</h3><p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/28.png">  </p>
<p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/29.png"></p>
<p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/30.png">  </p>
<p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/31.png">  </p>
<p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/32.png">  </p>
<p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/33.png">  </p>
<p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/34.png">  </p>
<p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/35.png">  </p>
<p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/36.png"> </p>
<p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/37.png">  </p>
<p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/38.png">  </p>
<p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/39.png">  </p>
<p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/40.png"></p>
<p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/41.png">  </p>
<p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/42.png"></p>
<p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/43.png">  </p>
<p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/44.png">  </p>
<p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/45.png">  </p>
<p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/46.png"></p>
<p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/48.png"></p>
<p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/47.png">  </p>
<p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/49.png">  </p>
<p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/50.png">  </p>
<p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/51.png">  </p>
<p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/52.png">  </p>
<p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/53.png">  </p>
<h3 id="3-6-函数"><a href="#3-6-函数" class="headerlink" title="3.6,函数"></a>3.6,函数</h3><p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/54.png"></p>
<p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/55.png">  </p>
<p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/56.png">  </p>
<p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/57.png">  </p>
<p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/58.png">  </p>
<p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/59.png">  </p>
<p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/60.png"> </p>
<p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/61.png">  </p>
<h3 id="3-6-信号"><a href="#3-6-信号" class="headerlink" title="3.6,信号"></a>3.6,信号</h3><p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/62.png">  </p>
<p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/63.png"> </p>
<p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/64.png"> </p>
<h3 id="3-6-计划任务"><a href="#3-6-计划任务" class="headerlink" title="3.6,计划任务"></a>3.6,计划任务</h3><p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/65.png"></p>
<p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/66.png"></p>
<p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/67.png"> </p>
<p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/68.png"> </p>
<p><img src="/2021/07/01/uncatalog/ckv998l99000kv0r7d8izhbnp/69.png"> </p>
]]></content>
      <tags>
        <tag>linux回忆录</tag>
      </tags>
  </entry>
  <entry>
    <title>linux回忆录</title>
    <url>/2021/07/01/uncatalog/ckv998l9b000mv0r7fcfrav6u/</url>
    <content><![CDATA[<p>从java切换到go之后,就很少登到服务器上排查问题了,加之CICD顺利上线和应用工程师的配备,在服务器上敲命令和写shell脚本的机会就更少了。<br>但是,这门传统手艺咱不能落下,遂写下该回忆录,想到哪写到哪吧.见谅！</p>
<span id="more"></span>

<p><img src="/2021/07/01/uncatalog/ckv998l9b000mv0r7fcfrav6u/0.png"></p>
<h3 id="1-基础"><a href="#1-基础" class="headerlink" title="1,基础"></a>1,基础</h3><h4 id="1-1-万能man命令"><a href="#1-1-万能man命令" class="headerlink" title="1.1 万能man命令"></a>1.1 万能<code>man</code>命令</h4><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 功能：格式化并显示在线帮助手册页面.(也就是查看命令的帮助信息)</span></span><br><span class="line">man ls</span><br><span class="line"><span class="meta">#</span><span class="bash"> 输出:</span></span><br><span class="line">LS(1)                         General Commands Manual                         LS(1)</span><br><span class="line"></span><br><span class="line">NAME</span><br><span class="line">       ls, dir, vdir - 列目录内容</span><br><span class="line"></span><br><span class="line">提要</span><br><span class="line">       ls [选项] [文件名...]</span><br><span class="line"></span><br><span class="line">       POSIX 标准选项: [-CFRacdilqrtu1]</span><br><span class="line"></span><br><span class="line">GNU 选项 (短格式):</span><br><span class="line">       [-1abcdfgiklmnopqrstuxABCDFGLNQRSUX]   [-w  cols]  [-T  cols]  [-I  pattern]</span><br><span class="line">       [--full-time] [--format=&#123;long,verbose,commas,across,vertical,single-column&#125;]</span><br><span class="line">       [--sort=&#123;none,time,size,extension&#125;] [--time=&#123;atime,access,use,ctime,status&#125;]</span><br><span class="line">       [--color[=&#123;none,auto,always&#125;]] [--help] [--version] [--]</span><br><span class="line"></span><br><span class="line">描述（ DESCRIPTION ）</span><br><span class="line">       程序ls先列出非目录的文件项，然后是每一个目录中的“可显示”文件。如果</span><br><span class="line">       没有选项之外的参数【译注：即文件名部分为空】出现，缺省为  &quot;.&quot; （当前目录）。</span><br><span class="line">       选项“    -d    ”使得目录与非目录项同样对待。除非“    -a    ”    选项出现，文</span><br><span class="line">       件名以“.”开始的文件不属“可显示”文件。</span><br><span class="line"></span><br><span class="line">       以当前目录为准，每一组文件（包括非目录文件项，以及每一内含文件的目录）分</span><br><span class="line">       别按文件名比较顺序排序。如果“     -l      ”选项存在，每组文件前显示一摘要行:</span><br><span class="line">       给出该组文件长度之和（以 512 字节为单位）。</span><br><span class="line"></span><br><span class="line">       输出是到标准输出（    stdout    ）。除非以“   -C   ”选项要求按多列输出，输出</span><br><span class="line">       将是一行一个。然而，输出到终端时，单列输出或多列输出是不确定的。可以分别</span><br><span class="line">       用选项“ -1 ” 或“ -C ”来强制按单列或多列输出。</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>
<h4 id="1-2-ls命令"><a href="#1-2-ls命令" class="headerlink" title="1.2 ls命令"></a>1.2 <code>ls</code>命令</h4><p><a href="https://blog.csdn.net/sjzs5590/article/details/8254527b"><code>ls -l</code>输出字段详解</a></p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 1,查看目录内容</span></span><br><span class="line">ls [dir_name]</span><br><span class="line"><span class="meta">#</span><span class="bash"> 2,长格式显示目录内容</span></span><br><span class="line">ls -l [dir_name]</span><br><span class="line"><span class="meta">#</span><span class="bash"> 输出</span></span><br><span class="line">drwxr-xr-x 2 root root         6 7月   1 19:31 linux_demo</span><br><span class="line">-rwxr-xr-x 1 root root   2008912 1月  26 17:16 main</span><br><span class="line"></span><br><span class="line">ls -lh [dir_name] # 转为M或者G显示大小</span><br><span class="line"><span class="meta">#</span><span class="bash"> 3,显示当前目录下的所有文件及文件夹包括隐藏的.和..</span></span><br><span class="line">ls -a [dir_name]</span><br><span class="line"><span class="meta">#</span><span class="bash"> 4,递归显示,连同子目录一同显示出来，也就所说该目录下所有文件都会显示出来</span></span><br><span class="line">ls -R [dir_name]</span><br></pre></td></tr></table></figure></div>


<h4 id="1-3-cd命令"><a href="#1-3-cd命令" class="headerlink" title="1.3 cd命令"></a>1.3 <code>cd</code>命令</h4><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 返回到刚才的目录</span></span><br><span class="line">cd -</span><br></pre></td></tr></table></figure></div>

<h4 id="1-4-midir命令"><a href="#1-4-midir命令" class="headerlink" title="1.4 midir命令"></a>1.4 <code>midir</code>命令</h4><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 递归创建目录,即使上级目录不存在,会按目录层级自动创建目录</span></span><br><span class="line">mkdir -p  a/b/c</span><br></pre></td></tr></table></figure></div>

<h4 id="1-5-cp命令"><a href="#1-5-cp命令" class="headerlink" title="1.5 cp命令"></a>1.5 <code>cp</code>命令</h4><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 1,复制目录/文件到指定位置</span></span><br><span class="line">cp source_file/source_dir  target_dir</span><br><span class="line"><span class="meta">#</span><span class="bash"> 2,复制目录/文件到指定位置,保留原有文件/文件夹的时间、属主和权限</span></span><br><span class="line">cp -p source_file/source_dir  target_dir</span><br></pre></td></tr></table></figure></div>

<h4 id="1-6-mv命令"><a href="#1-6-mv命令" class="headerlink" title="1.6 mv命令"></a>1.6 <code>mv</code>命令</h4><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 移动/重命名 文件/文件夹</span></span><br><span class="line">mv source_file/source_dir   target_file/source_dir</span><br></pre></td></tr></table></figure></div>

<h4 id="1-7-通配符"><a href="#1-7-通配符" class="headerlink" title="1.7 通配符"></a>1.7 通配符</h4><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> ?匹配一个</span></span><br><span class="line">mv file?  /root/tmp #当前目录下的filea将会被移动到/root/tmp目录下,fileaa将不会被移动</span><br><span class="line"><span class="meta">#</span><span class="bash"> *匹配所有</span></span><br><span class="line">mv file*  /root/tmp #当前目录下的filea和fileaa将会被移动到/root/tmp目录下</span><br></pre></td></tr></table></figure></div>

<h4 id="1-8-cat命令"><a href="#1-8-cat命令" class="headerlink" title="1.8 cat命令"></a>1.8 <code>cat</code>命令</h4><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 文本内容显示到终端</span></span><br><span class="line">cat file_name</span><br></pre></td></tr></table></figure></div>

<h4 id="1-9-head命令"><a href="#1-9-head命令" class="headerlink" title="1.9 head命令"></a>1.9 <code>head</code>命令</h4><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 查看文件开头(n行)</span></span><br><span class="line">head [-n] file_name</span><br></pre></td></tr></table></figure></div>

<h4 id="1-10-tail命令"><a href="#1-10-tail命令" class="headerlink" title="1.10 tail命令"></a>1.10 <code>tail</code>命令</h4><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 1,查看文件结尾(n行)</span></span><br><span class="line">tail [-n] file_name</span><br><span class="line"><span class="meta">#</span><span class="bash"> 2,查看文件结尾,同步跟新显示</span></span><br><span class="line">tail -f file_name</span><br></pre></td></tr></table></figure></div>

<h4 id="1-11-wc命令"><a href="#1-11-wc命令" class="headerlink" title="1.11 wc命令"></a>1.11 <code>wc</code>命令</h4><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 1,查看文件内容行数</span></span><br><span class="line">wc -l file_name</span><br></pre></td></tr></table></figure></div>

<h4 id="1-12-tail命令"><a href="#1-12-tail命令" class="headerlink" title="1.12 tail命令"></a>1.12 <code>tail</code>命令</h4><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 1,查看文件结尾</span></span><br><span class="line">tail file_name</span><br><span class="line"><span class="meta">#</span><span class="bash"> 2,查看文件结尾,同步跟新显示</span></span><br><span class="line">tail -f file_name</span><br></pre></td></tr></table></figure></div>

<h4 id="1-13-打包压缩和解压缩命令"><a href="#1-13-打包压缩和解压缩命令" class="headerlink" title="1.13 打包压缩和解压缩命令"></a>1.13 打包压缩和解压缩命令</h4><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 1,打包/备份文件夹</span></span><br><span class="line">tar cf dest_file_name.tar target_dir</span><br><span class="line">tar cf /tmp/etc-backup.tar /etc/</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 2,解包文件</span></span><br><span class="line">tar xf dest_file_name.tar -C target_dir</span><br><span class="line">tar xf /tmp/etc-backup.tar -C /root</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 3,打包/备份,并压缩文件夹;gzip压缩方式,压缩速度更快</span></span><br><span class="line">tar zcf dest_file_name.tar.gz target_dir</span><br><span class="line">tar zcf /tmp/etc-backup.tar.gz /etc/</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 4,解压缩文件;gzip压缩方式</span></span><br><span class="line">tar zxf dest_file_name.tar.gz -C target_dir</span><br><span class="line">tar zxf /tmp/etc-backup.tar.gz -C /etc/</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 5,打包/备份,并压缩文件夹;bzip2压缩方式,压缩文件更小</span></span><br><span class="line">tar jcf dest_file_name.tar.bz2 target_dir</span><br><span class="line">tar jcf /tmp/etc-backup.tar.bz2 /etc/</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 6,解压缩文件;bzip2压缩方式</span></span><br><span class="line">tar jxf dest_file_name.tar.bz2 -C target_dir</span><br><span class="line">tar jxf /tmp/etc-backup.tar.bz2 -C /etc/</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>
<h3 id="2-多模式文本编辑器vim"><a href="#2-多模式文本编辑器vim" class="headerlink" title="2,多模式文本编辑器vim"></a>2,多模式文本编辑器<code>vim</code></h3><ul>
<li>正常模式</li>
<li>插入模式</li>
<li>命令模式</li>
<li>可视模式<br><img src="/2021/07/01/uncatalog/ckv998l9b000mv0r7fcfrav6u/vim_op.png"></li>
</ul>
<h4 id="2-1-正常模式下的操作"><a href="#2-1-正常模式下的操作" class="headerlink" title="2.1 正常模式下的操作"></a>2.1 正常模式下的操作</h4><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="TEXT"><figure class="iseeu highlight /text"><table><tr><td class="code"><pre><span class="line"># 复制</span><br><span class="line">单行复制:在正常模式下输入yy即可复制当前行,输入p即可粘贴刚才的复制</span><br><span class="line">多行复制:在正常模式下输入要复制的行数n+yy即可复制n行,输入p即可粘贴刚才的复制</span><br><span class="line">行内复制:在正常模式下输入y$即可复制从当前位置到行末的数据,输入p即可粘贴刚才的复制</span><br><span class="line"></span><br><span class="line"># 剪切</span><br><span class="line">单行剪切:在正常模式下输入dd即可剪切当前行,输入p即可粘贴刚才的剪切</span><br><span class="line">多行复制:在正常模式下输入要剪切的行数n+dd即可剪切n行,输入p即可粘贴刚才的剪切</span><br><span class="line">行内剪切:在正常模式下输入d$即可剪切从当前位置到行末的数据,输入p即可粘贴刚才的剪切</span><br><span class="line"></span><br><span class="line"># 撤销</span><br><span class="line">单次撤销:单输u</span><br><span class="line">多次撤销:多次输入u</span><br><span class="line">撤销撤销操作:ctrl + r</span><br><span class="line"></span><br><span class="line"># 光标移动</span><br><span class="line">显示行号: 冒号+set nu</span><br><span class="line">移动到第n行: n + shift + g</span><br><span class="line">移动到行首: ^</span><br><span class="line">移动到行末尾: $ </span><br><span class="line"></span><br><span class="line"># 删除</span><br><span class="line">删除: x</span><br><span class="line">替换: r</span><br></pre></td></tr></table></figure></div>

<h4 id="2-2-命令模式下的操作"><a href="#2-2-命令模式下的操作" class="headerlink" title="2.2 命令模式下的操作"></a>2.2 命令模式下的操作</h4><table>
<thead>
<tr>
<th>命令</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>:w</td>
<td>保存编辑后的文件内容，但不退出vim编辑器。这个命令的作用是把内存缓冲区中的数据写到启动vim时指定的文件中。</td>
</tr>
<tr>
<td>:w!</td>
<td>强制写文件，即强制覆盖原有文件。如果原有文件的访问权限不允许写入文件，例如，原有的文件为只读文件，则可使用这个命令强制写入。但是，这种命令用法仅当用户是文件的属主时才适用，而超级用户则不受此限制。</td>
</tr>
<tr>
<td>:wq</td>
<td>保存文件内容后退出vim编辑器。这个命令的作用是把内存缓冲区中的数据写到启动vim时指定的文件中，然后退出vim编辑器。另外一种替代的方法是用ZZ命令。</td>
</tr>
<tr>
<td>:wq!</td>
<td>强制保存文件内容后退出vim编辑器。这个命令的作用是把内存缓冲区中的数据强制写到启动vim时指定的文件中，然后退出vim编辑器。</td>
</tr>
<tr>
<td>:q</td>
<td>在未做任何编辑处理而准备退出vim时，可以使用此命令。如果已做过编辑处理，则vim不允许用户使用“:q”命令退出，同时还会输出下列警告信息：No write since last change (:quit! overrides)</td>
</tr>
<tr>
<td>:q!</td>
<td>强制退出vim编辑器，放弃编辑处理的结果。如果确实不需要保存修改后的文件内容，可输入“:q!”命令，强行退出vim编辑器。</td>
</tr>
<tr>
<td>:s/old/new</td>
<td>将当前行的字符old替换为new</td>
</tr>
<tr>
<td>:%s/old/new/g</td>
<td>全局的字符old替换为new</td>
</tr>
<tr>
<td>:n,m%s/old/new/g</td>
<td>第n行到第m的字符old替换为new</td>
</tr>
<tr>
<td>vim /etc/vimrc</td>
<td>修改vim配置</td>
</tr>
</tbody></table>
<h4 id="2-3-可视模式下的操作"><a href="#2-3-可视模式下的操作" class="headerlink" title="2.3 可视模式下的操作"></a>2.3 可视模式下的操作</h4><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">进入可视模式: v</span><br></pre></td></tr></table></figure></div>

<h3 id="3-用户与权限管理"><a href="#3-用户与权限管理" class="headerlink" title="3,用户与权限管理"></a>3,用户与权限管理</h3><h4 id="3-1-用户管理"><a href="#3-1-用户管理" class="headerlink" title="3.1 用户管理"></a>3.1 用户管理</h4><table>
<thead>
<tr>
<th>命令</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>useradd user_name</td>
<td>新建用户</td>
</tr>
<tr>
<td>id user_name</td>
<td>查看用户</td>
</tr>
<tr>
<td>userdel user_name</td>
<td>删除用户</td>
</tr>
<tr>
<td>passwd user_name</td>
<td>设置/修改用户密码</td>
</tr>
<tr>
<td>usermod user_name</td>
<td>修改用户属性,用户组等</td>
</tr>
<tr>
<td>chage user_name</td>
<td>修改用户属性,密码过期时间等</td>
</tr>
<tr>
<td>groupadd group_name</td>
<td>添加用户组</td>
</tr>
<tr>
<td>groupdel group_name</td>
<td>删除用户组</td>
</tr>
<tr>
<td>su - user_name</td>
<td>切换用户</td>
</tr>
<tr>
<td>exit</td>
<td>退回刚才的用户</td>
</tr>
</tbody></table>
<h4 id="3-2-用户切换"><a href="#3-2-用户切换" class="headerlink" title="3.2 用户切换"></a>3.2 用户切换</h4><table>
<thead>
<tr>
<th>命令</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>su - user_name</td>
<td>切换用户</td>
</tr>
<tr>
<td>sudo command</td>
<td>以系统管理者的身份执行指令，也就是说，经由 sudo 所执行的指令就好像是 root 亲自执行</td>
</tr>
</tbody></table>
<h4 id="3-3-用户和用户组的配置文件"><a href="#3-3-用户和用户组的配置文件" class="headerlink" title="3.3 用户和用户组的配置文件"></a>3.3 用户和用户组的配置文件</h4><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="TEXT"><figure class="iseeu highlight /text"><table><tr><td class="code"><pre><span class="line">三个配置文件：</span><br><span class="line">/etc/passwd</span><br><span class="line">/etc/shadow</span><br><span class="line">/etc/group</span><br></pre></td></tr></table></figure></div>

<h4 id="3-3-文件-夹-权限"><a href="#3-3-文件-夹-权限" class="headerlink" title="3.3 文件(夹)权限"></a>3.3 文件(夹)权限</h4><p><img src="/2021/07/01/uncatalog/ckv998l9b000mv0r7fcfrav6u/1.png">  </p>
<p><img src="/2021/07/01/uncatalog/ckv998l9b000mv0r7fcfrav6u/2.png">  </p>
<p><img src="/2021/07/01/uncatalog/ckv998l9b000mv0r7fcfrav6u/3.png">  </p>
<p><img src="/2021/07/01/uncatalog/ckv998l9b000mv0r7fcfrav6u/4.png">  </p>
<p><img src="/2021/07/01/uncatalog/ckv998l9b000mv0r7fcfrav6u/5.png">   </p>
<h4 id="3-3-文件-夹-权限修改"><a href="#3-3-文件-夹-权限修改" class="headerlink" title="3.3 文件(夹)权限修改"></a>3.3 文件(夹)权限修改</h4><p><img src="/2021/07/01/uncatalog/ckv998l9b000mv0r7fcfrav6u/6.png">   </p>
<p>字母方式修改权限<br><img src="/2021/07/01/uncatalog/ckv998l9b000mv0r7fcfrav6u/7.png"><br>数字方式修改权限<br><img src="/2021/07/01/uncatalog/ckv998l9b000mv0r7fcfrav6u/8.png"> </p>
<h3 id="4-网络管理"><a href="#4-网络管理" class="headerlink" title="4,网络管理"></a>4,网络管理</h3><h4 id="4-1-网络状态查看"><a href="#4-1-网络状态查看" class="headerlink" title="4.1,网络状态查看"></a>4.1,网络状态查看</h4><p><img src="/2021/07/01/uncatalog/ckv998l9b000mv0r7fcfrav6u/9.png"></p>
<p><img src="/2021/07/01/uncatalog/ckv998l9b000mv0r7fcfrav6u/10.png">  </p>
<p><img src="/2021/07/01/uncatalog/ckv998l9b000mv0r7fcfrav6u/11.png">  </p>
<p><img src="/2021/07/01/uncatalog/ckv998l9b000mv0r7fcfrav6u/12.png"></p>
<h4 id="4-2-网络配置-可以跳过"><a href="#4-2-网络配置-可以跳过" class="headerlink" title="4.2,网络配置(可以跳过)"></a>4.2,网络配置(可以跳过)</h4><p><img src="/2021/07/01/uncatalog/ckv998l9b000mv0r7fcfrav6u/13.png">  </p>
<p><img src="/2021/07/01/uncatalog/ckv998l9b000mv0r7fcfrav6u/14.png"></p>
<h4 id="4-3-网络故障排查"><a href="#4-3-网络故障排查" class="headerlink" title="4.3,网络故障排查"></a>4.3,网络故障排查</h4><p><img src="/2021/07/01/uncatalog/ckv998l9b000mv0r7fcfrav6u/15.png"></p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 到目标主机(ip/域名)是否畅通</span></span><br><span class="line">ping ip/domain</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 检测发出数据包的主机到目标主机之间所经过的网关数量</span></span><br><span class="line">traceroute -w 1 </span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> mtr 是一个集合 ping 和 traceroute 功能并能直观显示结果的网络诊断工具</span></span><br><span class="line">mtr</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 把域名解析成ip</span></span><br><span class="line">nslookup www.baidu.com</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 端口通畅情况</span></span><br><span class="line">telnet ip/domian + export </span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 抓包(后文详讲)</span></span><br><span class="line">tcpdump</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看服务监听地址</span></span><br><span class="line">netstat -ntpl</span><br><span class="line">ss -ntpl</span><br></pre></td></tr></table></figure></div>

<h4 id="4-3-网络服务管理-跳过"><a href="#4-3-网络服务管理-跳过" class="headerlink" title="4.3,网络服务管理(跳过)"></a>4.3,网络服务管理(跳过)</h4><p><img src="/2021/07/01/uncatalog/ckv998l9b000mv0r7fcfrav6u/16.png"></p>
<h3 id="5-软件包管理器"><a href="#5-软件包管理器" class="headerlink" title="5,软件包管理器"></a>5,软件包管理器</h3><p><img src="/2021/07/01/uncatalog/ckv998l9b000mv0r7fcfrav6u/17.png">  </p>
<p><img src="/2021/07/01/uncatalog/ckv998l9b000mv0r7fcfrav6u/18.png">   </p>
<h4 id="5-1-rpm包"><a href="#5-1-rpm包" class="headerlink" title="5.1,rpm包"></a>5.1,rpm包</h4><p><img src="/2021/07/01/uncatalog/ckv998l9b000mv0r7fcfrav6u/19.png">  </p>
<p><img src="/2021/07/01/uncatalog/ckv998l9b000mv0r7fcfrav6u/20.png">   </p>
<h4 id="5-2-yum包"><a href="#5-2-yum包" class="headerlink" title="5.2,yum包"></a>5.2,yum包</h4><p><img src="/2021/07/01/uncatalog/ckv998l9b000mv0r7fcfrav6u/21.png">  </p>
<p><img src="/2021/07/01/uncatalog/ckv998l9b000mv0r7fcfrav6u/22.png">    </p>
<p><img src="/2021/07/01/uncatalog/ckv998l9b000mv0r7fcfrav6u/23.png">  </p>
<h4 id="5-2-通过源代码编译安装软件-跳过"><a href="#5-2-通过源代码编译安装软件-跳过" class="headerlink" title="5.2,通过源代码编译安装软件(跳过)"></a>5.2,通过源代码编译安装软件(跳过)</h4><h3 id="6-进程管理"><a href="#6-进程管理" class="headerlink" title="6,进程管理"></a>6,进程管理</h3><p><img src="/2021/07/01/uncatalog/ckv998l9b000mv0r7fcfrav6u/24.png">   </p>
<p><img src="/2021/07/01/uncatalog/ckv998l9b000mv0r7fcfrav6u/25.png">   </p>
<p><img src="/2021/07/01/uncatalog/ckv998l9b000mv0r7fcfrav6u/26.png">  </p>
<p><img src="/2021/07/01/uncatalog/ckv998l9b000mv0r7fcfrav6u/27.png">  </p>
]]></content>
      <tags>
        <tag>linux回忆录</tag>
      </tags>
  </entry>
  <entry>
    <title>node_exporter源码阅读</title>
    <url>/2021/10/27/uncatalog/ckv998l9f000qv0r7bn48dbig/</url>
    <content><![CDATA[<h2 id="node-exporter源码阅读"><a href="#node-exporter源码阅读" class="headerlink" title="node_exporter源码阅读"></a>node_exporter源码阅读</h2><span id="more"></span>
<p><img src="/2021/10/27/uncatalog/ckv998l9f000qv0r7bn48dbig/1.png"></p>
<p>基于prometheus的监控系统搭建起来之后,对于多样化的业务线来说,<br>定制化的采集监控指标必将是业务线产品经理的又一个需求方向,所以,作为平台开发者来说,<br>预判产品经理的预判也是一项基本的职业技能🤣,即:think deeper<br>基于此,先把node_exporter的源码一窥究竟.</p>
<blockquote>
<p>本篇文章主要是源码阅读,概念和指标相关的介绍需要读者自行去了解,不过不了解也不影响本篇文章的阅读</p>
</blockquote>
<blockquote>
<p>附上<a href="https://github.com/prometheus/node_exporter" title="Markdown">node_exporter源码地址</a></p>
</blockquote>
<h1 id="1-目录结构"><a href="#1-目录结构" class="headerlink" title="1.目录结构"></a>1.目录结构</h1><p>总的来说,node_exporter的目录结构还是非常简单的：</p>
<ul>
<li><code>node_exporter.go</code>文件即项目的主入口</li>
<li><code>collector</code>文件夹即存放各种采集指标的文件夹<br>其余的就是一些文档和辅助脚本,源码阅读时可以忽略;</li>
</ul>
<h1 id="2-项目主入口-–-node-exporter-go"><a href="#2-项目主入口-–-node-exporter-go" class="headerlink" title="2.项目主入口 – node_exporter.go"></a>2.项目主入口 – <code>node_exporter.go</code></h1><h3 id="2-1定义了一个结构体–handler"><a href="#2-1定义了一个结构体–handler" class="headerlink" title="2.1定义了一个结构体–handler"></a>2.1定义了一个结构体–<code>handler</code></h3><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// handler的实例由newHandler来创建</span></span><br><span class="line"><span class="comment">// handler封装了一个http.Handler</span></span><br><span class="line"><span class="comment">// 对于带filters参数的请求,会动态创建一个http.Handler</span></span><br><span class="line"><span class="comment">// filters参数是针对采集指标的,如果不需要那么多采集指标,可以通过filters参数指定过滤掉,</span></span><br><span class="line"><span class="comment">// 那么创建出来的http.Handler也就是一个filtered http.Handler</span></span><br><span class="line"><span class="comment">// 这个创建出来的http.Handler会赋值给unfilteredHandler</span></span><br><span class="line"><span class="keyword">type</span> handler <span class="keyword">struct</span> &#123;</span><br><span class="line">	unfilteredHandler http.Handler</span><br><span class="line">	<span class="comment">// node_exporter本身的指标也要采集的话,就会用到这个单独的registry</span></span><br><span class="line">	exporterMetricsRegistry *prometheus.Registry</span><br><span class="line">	<span class="comment">// 是否要采集node_exporter本身的指标</span></span><br><span class="line">	includeExporterMetrics  <span class="keyword">bool</span></span><br><span class="line">	<span class="comment">// 最大并发请求数,默认40,可通过命令行传入</span></span><br><span class="line">	maxRequests             <span class="keyword">int</span></span><br><span class="line">	logger                  log.Logger</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<p><code>prometheus</code>对于<code>node_exporter</code>采集数据的获取是通过向<code>node_exporter</code>发送拉取请求来实现的,<br>而这个拉取请求就是通过http协议来交互的.所以这个<code>handler</code>和我们<code>web</code>项目中的<code>handler</code>是一个概念,<br>即都实现了<code>http.Handler</code>接口:</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// ServeHTTP implements http.Handler.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(h *handler)</span> <span class="title">ServeHTTP</span><span class="params">(w http.ResponseWriter, r *http.Request)</span></span> &#123;</span><br><span class="line">	filters := r.URL.Query()[<span class="string">&quot;collect[]&quot;</span>]</span><br><span class="line">	level.Debug(h.logger).Log(<span class="string">&quot;msg&quot;</span>, <span class="string">&quot;collect query:&quot;</span>, <span class="string">&quot;filters&quot;</span>, filters)</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span> <span class="built_in">len</span>(filters) == <span class="number">0</span> &#123;</span><br><span class="line">		<span class="comment">// No filters, use the prepared unfiltered handler.</span></span><br><span class="line">		h.unfilteredHandler.ServeHTTP(w, r)</span><br><span class="line">		<span class="keyword">return</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 这里会调用innerHandler来创建上面讲到的handler</span></span><br><span class="line">	filteredHandler, err := h.innerHandler(filters...)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		level.Warn(h.logger).Log(<span class="string">&quot;msg&quot;</span>, <span class="string">&quot;Couldn&#x27;t create filtered metrics handler:&quot;</span>, <span class="string">&quot;err&quot;</span>, err)</span><br><span class="line">		w.WriteHeader(http.StatusBadRequest)</span><br><span class="line">		w.Write([]<span class="keyword">byte</span>(fmt.Sprintf(<span class="string">&quot;Couldn&#x27;t create filtered metrics handler: %s&quot;</span>, err)))</span><br><span class="line">		<span class="keyword">return</span></span><br><span class="line">	&#125;</span><br><span class="line">	filteredHandler.ServeHTTP(w, r)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h3 id="2-2从主入口函数main开始"><a href="#2-2从主入口函数main开始" class="headerlink" title="2.2从主入口函数main开始"></a>2.2从主入口函数<code>main</code>开始</h3><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">	<span class="comment">// 命令行参数处理</span></span><br><span class="line">	<span class="keyword">var</span> (</span><br><span class="line">		listenAddress = kingpin.Flag(</span><br><span class="line">			<span class="string">&quot;web.listen-address&quot;</span>,</span><br><span class="line">			<span class="string">&quot;Address on which to expose metrics and web interface.&quot;</span>,</span><br><span class="line">		).Default(<span class="string">&quot;:9100&quot;</span>).String()</span><br><span class="line">		metricsPath = kingpin.Flag(</span><br><span class="line">			<span class="string">&quot;web.telemetry-path&quot;</span>,</span><br><span class="line">			<span class="string">&quot;Path under which to expose metrics.&quot;</span>,</span><br><span class="line">		).Default(<span class="string">&quot;/metrics&quot;</span>).String()</span><br><span class="line">		disableExporterMetrics = kingpin.Flag(</span><br><span class="line">			<span class="string">&quot;web.disable-exporter-metrics&quot;</span>,</span><br><span class="line">			<span class="string">&quot;Exclude metrics about the exporter itself (promhttp_*, process_*, go_*).&quot;</span>,</span><br><span class="line">		).Bool()</span><br><span class="line">		maxRequests = kingpin.Flag(</span><br><span class="line">			<span class="string">&quot;web.max-requests&quot;</span>,</span><br><span class="line">			<span class="string">&quot;Maximum number of parallel scrape requests. Use 0 to disable.&quot;</span>,</span><br><span class="line">		).Default(<span class="string">&quot;40&quot;</span>).Int()</span><br><span class="line">		disableDefaultCollectors = kingpin.Flag(</span><br><span class="line">			<span class="string">&quot;collector.disable-defaults&quot;</span>,</span><br><span class="line">			<span class="string">&quot;Set all collectors to disabled by default.&quot;</span>,</span><br><span class="line">		).Default(<span class="string">&quot;false&quot;</span>).Bool()</span><br><span class="line">		configFile = kingpin.Flag(</span><br><span class="line">			<span class="string">&quot;web.config&quot;</span>,</span><br><span class="line">			<span class="string">&quot;[EXPERIMENTAL] Path to config yaml file that can enable TLS or authentication.&quot;</span>,</span><br><span class="line">		).Default(<span class="string">&quot;&quot;</span>).String()</span><br><span class="line">	)</span><br><span class="line"></span><br><span class="line">	promlogConfig := &amp;promlog.Config&#123;&#125;</span><br><span class="line">	flag.AddFlags(kingpin.CommandLine, promlogConfig)</span><br><span class="line">	kingpin.Version(version.Print(<span class="string">&quot;node_exporter&quot;</span>))</span><br><span class="line">	kingpin.CommandLine.UsageWriter(os.Stdout)</span><br><span class="line">	kingpin.HelpFlag.Short(<span class="string">&#x27;h&#x27;</span>)</span><br><span class="line">	kingpin.Parse()</span><br><span class="line">	logger := promlog.New(promlogConfig)</span><br><span class="line">	<span class="comment">// 命令行参数处理结束</span></span><br><span class="line">	</span><br><span class="line">	<span class="comment">// 如果设置disableDefaultCollectors为true,将把除了显式从命令行传入的采集指标之外的所有指标采集器设置为不采集</span></span><br><span class="line">	<span class="keyword">if</span> *disableDefaultCollectors &#123;</span><br><span class="line">		collector.DisableDefaultCollectors()</span><br><span class="line">	&#125;</span><br><span class="line">	level.Info(logger).Log(<span class="string">&quot;msg&quot;</span>, <span class="string">&quot;Starting node_exporter&quot;</span>, <span class="string">&quot;version&quot;</span>, version.Info())</span><br><span class="line">	level.Info(logger).Log(<span class="string">&quot;msg&quot;</span>, <span class="string">&quot;Build context&quot;</span>, <span class="string">&quot;build_context&quot;</span>, version.BuildContext())</span><br><span class="line">	<span class="comment">// 用户</span></span><br><span class="line">	<span class="keyword">if</span> user, err := user.Current(); err == <span class="literal">nil</span> &amp;&amp; user.Uid == <span class="string">&quot;0&quot;</span> &#123;</span><br><span class="line">		level.Warn(logger).Log(<span class="string">&quot;msg&quot;</span>, <span class="string">&quot;Node Exporter is running as root user. This exporter is designed to run as unpriviledged user, root is not required.&quot;</span>)</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// newHandler是重点,后面会讲到</span></span><br><span class="line">	http.Handle(*metricsPath, newHandler(!*disableExporterMetrics, *maxRequests, logger))</span><br><span class="line">	http.HandleFunc(<span class="string">&quot;/&quot;</span>, <span class="function"><span class="keyword">func</span><span class="params">(w http.ResponseWriter, r *http.Request)</span></span> &#123;</span><br><span class="line">		w.Write([]<span class="keyword">byte</span>(<span class="string">`&lt;html&gt;</span></span><br><span class="line"><span class="string">			&lt;head&gt;&lt;title&gt;Node Exporter&lt;/title&gt;&lt;/head&gt;</span></span><br><span class="line"><span class="string">			&lt;body&gt;</span></span><br><span class="line"><span class="string">			&lt;h1&gt;Node Exporter&lt;/h1&gt;</span></span><br><span class="line"><span class="string">			&lt;p&gt;&lt;a href=&quot;`</span> + *metricsPath + <span class="string">`&quot;&gt;Metrics&lt;/a&gt;&lt;/p&gt;</span></span><br><span class="line"><span class="string">			&lt;/body&gt;</span></span><br><span class="line"><span class="string">			&lt;/html&gt;`</span>))</span><br><span class="line">	&#125;)</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 开启http服务,等待prometheus来抓取数据</span></span><br><span class="line">	level.Info(logger).Log(<span class="string">&quot;msg&quot;</span>, <span class="string">&quot;Listening on&quot;</span>, <span class="string">&quot;address&quot;</span>, *listenAddress)</span><br><span class="line">	server := &amp;http.Server&#123;Addr: *listenAddress&#125;</span><br><span class="line">	<span class="keyword">if</span> err := web.ListenAndServe(server, *configFile, logger); err != <span class="literal">nil</span> &#123;</span><br><span class="line">		level.Error(logger).Log(<span class="string">&quot;err&quot;</span>, err)</span><br><span class="line">		os.Exit(<span class="number">1</span>)</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>

<h3 id="2-3handler的创建者–newHandler"><a href="#2-3handler的创建者–newHandler" class="headerlink" title="2.3handler的创建者–newHandler"></a>2.3<code>handler</code>的创建者–<code>newHandler</code></h3><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">newHandler</span><span class="params">(includeExporterMetrics <span class="keyword">bool</span>, maxRequests <span class="keyword">int</span>, logger log.Logger)</span> *<span class="title">handler</span></span> &#123;</span><br><span class="line">	<span class="comment">// handler的结构体成员赋值</span></span><br><span class="line">	h := &amp;handler&#123;</span><br><span class="line">		exporterMetricsRegistry: prometheus.NewRegistry(),</span><br><span class="line">		includeExporterMetrics:  includeExporterMetrics,</span><br><span class="line">		maxRequests:             maxRequests,</span><br><span class="line">		logger:                  logger,</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">if</span> h.includeExporterMetrics &#123;</span><br><span class="line">		h.exporterMetricsRegistry.MustRegister(</span><br><span class="line">			promcollectors.NewProcessCollector(promcollectors.ProcessCollectorOpts&#123;&#125;),</span><br><span class="line">			promcollectors.NewGoCollector(),</span><br><span class="line">		)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// innerHandler真正创建handler的地方</span></span><br><span class="line">	<span class="keyword">if</span> innerHandler, err := h.innerHandler(); err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="built_in">panic</span>(fmt.Sprintf(<span class="string">&quot;Couldn&#x27;t create metrics handler: %s&quot;</span>, err))</span><br><span class="line">	&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">		h.unfilteredHandler = innerHandler</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> h</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>

<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 根据filters入参创建对应的http.Handler</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(h *handler)</span> <span class="title">innerHandler</span><span class="params">(filters ...<span class="keyword">string</span>)</span> <span class="params">(http.Handler, error)</span></span> &#123;</span><br><span class="line">	<span class="comment">// 根据filters情况创建NodeCollector,后面会讲这个NodeCollector</span></span><br><span class="line">	nc, err := collector.NewNodeCollector(h.logger, filters...)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, fmt.Errorf(<span class="string">&quot;couldn&#x27;t create collector: %s&quot;</span>, err)</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// Only log the creation of an unfiltered handler, which should happen</span></span><br><span class="line">	<span class="comment">// only once upon startup.</span></span><br><span class="line">	<span class="keyword">if</span> <span class="built_in">len</span>(filters) == <span class="number">0</span> &#123;</span><br><span class="line">		level.Info(h.logger).Log(<span class="string">&quot;msg&quot;</span>, <span class="string">&quot;Enabled collectors&quot;</span>)</span><br><span class="line">		collectors := []<span class="keyword">string</span>&#123;&#125;</span><br><span class="line">		<span class="keyword">for</span> n := <span class="keyword">range</span> nc.Collectors &#123;</span><br><span class="line">			collectors = <span class="built_in">append</span>(collectors, n)</span><br><span class="line">		&#125;</span><br><span class="line">		sort.Strings(collectors)</span><br><span class="line">		<span class="keyword">for</span> _, c := <span class="keyword">range</span> collectors &#123;</span><br><span class="line">			level.Info(h.logger).Log(<span class="string">&quot;collector&quot;</span>, c)</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 下面就是注册实现了prometheus.Collector接口的node_exporter/自研exporter的通用流程</span></span><br><span class="line">	<span class="comment">// 在node_exporter这里,由NodeCollector实现prometheus.Collector接口</span></span><br><span class="line">	r := prometheus.NewRegistry()</span><br><span class="line">	r.MustRegister(version.NewCollector(<span class="string">&quot;node_exporter&quot;</span>))</span><br><span class="line">	<span class="keyword">if</span> err := r.Register(nc); err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, fmt.Errorf(<span class="string">&quot;couldn&#x27;t register node collector: %s&quot;</span>, err)</span><br><span class="line">	&#125;</span><br><span class="line">	handler := promhttp.HandlerFor(</span><br><span class="line">		prometheus.Gatherers&#123;h.exporterMetricsRegistry, r&#125;,</span><br><span class="line">		promhttp.HandlerOpts&#123;</span><br><span class="line">			ErrorLog:            stdlog.New(log.NewStdlibAdapter(level.Error(h.logger)), <span class="string">&quot;&quot;</span>, <span class="number">0</span>),</span><br><span class="line">			ErrorHandling:       promhttp.ContinueOnError,</span><br><span class="line">			MaxRequestsInFlight: h.maxRequests,</span><br><span class="line">			Registry:            h.exporterMetricsRegistry,</span><br><span class="line">		&#125;,</span><br><span class="line">	)</span><br><span class="line">	<span class="keyword">if</span> h.includeExporterMetrics &#123;</span><br><span class="line">		<span class="comment">// Note that we have to use h.exporterMetricsRegistry here to</span></span><br><span class="line">		<span class="comment">// use the same promhttp metrics for all expositions.</span></span><br><span class="line">		handler = promhttp.InstrumentMetricHandler(</span><br><span class="line">			h.exporterMetricsRegistry, handler,</span><br><span class="line">		)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> handler, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<h1 id="3-node-exporter-自研exporter必须要实现的一个接口–prometheus-Collector"><a href="#3-node-exporter-自研exporter必须要实现的一个接口–prometheus-Collector" class="headerlink" title="3.node_exporter/自研exporter必须要实现的一个接口–prometheus.Collector"></a>3.<code>node_exporter</code>/自研<code>exporter</code>必须要实现的一个接口–<code>prometheus.Collector</code></h1><p>这里涉及到<code>github.com/prometheus/client_golang/prometheus</code>的源码,留到讲自研exporter的时候会剖析,<br>client_golang是prometheus的官方go库,既可以用于集成现有应用,也可以作为连接Prometheus HTTP API的基础库</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Collector is the interface implemented by anything that can be used by</span></span><br><span class="line"><span class="comment">// Prometheus to collect metrics. A Collector has to be registered for</span></span><br><span class="line"><span class="comment">// collection. See Registerer.Register.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// The stock metrics provided by this package (Gauge, Counter, Summary,</span></span><br><span class="line"><span class="comment">// Histogram, Untyped) are also Collectors (which only ever collect one metric,</span></span><br><span class="line"><span class="comment">// namely itself). An implementer of Collector may, however, collect multiple</span></span><br><span class="line"><span class="comment">// metrics in a coordinated fashion and/or create metrics on the fly. Examples</span></span><br><span class="line"><span class="comment">// for collectors already implemented in this library are the metric vectors</span></span><br><span class="line"><span class="comment">// (i.e. collection of multiple instances of the same Metric but with different</span></span><br><span class="line"><span class="comment">// label values) like GaugeVec or SummaryVec, and the ExpvarCollector.</span></span><br><span class="line"><span class="keyword">type</span> Collector <span class="keyword">interface</span> &#123;</span><br><span class="line">	<span class="comment">// Describe sends the super-set of all possible descriptors of metrics</span></span><br><span class="line">	<span class="comment">// collected by this Collector to the provided channel and returns once</span></span><br><span class="line">	<span class="comment">// the last descriptor has been sent. The sent descriptors fulfill the</span></span><br><span class="line">	<span class="comment">// consistency and uniqueness requirements described in the Desc</span></span><br><span class="line">	<span class="comment">// documentation.</span></span><br><span class="line">	<span class="comment">//</span></span><br><span class="line">	<span class="comment">// It is valid if one and the same Collector sends duplicate</span></span><br><span class="line">	<span class="comment">// descriptors. Those duplicates are simply ignored. However, two</span></span><br><span class="line">	<span class="comment">// different Collectors must not send duplicate descriptors.</span></span><br><span class="line">	<span class="comment">//</span></span><br><span class="line">	<span class="comment">// Sending no descriptor at all marks the Collector as “unchecked”,</span></span><br><span class="line">	<span class="comment">// i.e. no checks will be performed at registration time, and the</span></span><br><span class="line">	<span class="comment">// Collector may yield any Metric it sees fit in its Collect method.</span></span><br><span class="line">	<span class="comment">//</span></span><br><span class="line">	<span class="comment">// This method idempotently sends the same descriptors throughout the</span></span><br><span class="line">	<span class="comment">// lifetime of the Collector. It may be called concurrently and</span></span><br><span class="line">	<span class="comment">// therefore must be implemented in a concurrency safe way.</span></span><br><span class="line">	<span class="comment">//</span></span><br><span class="line">	<span class="comment">// If a Collector encounters an error while executing this method, it</span></span><br><span class="line">	<span class="comment">// must send an invalid descriptor (created with NewInvalidDesc) to</span></span><br><span class="line">	<span class="comment">// signal the error to the registry.</span></span><br><span class="line">	Describe(<span class="keyword">chan</span>&lt;- *Desc)</span><br><span class="line">	<span class="comment">// Collect is called by the Prometheus registry when collecting</span></span><br><span class="line">	<span class="comment">// metrics. The implementation sends each collected metric via the</span></span><br><span class="line">	<span class="comment">// provided channel and returns once the last metric has been sent. The</span></span><br><span class="line">	<span class="comment">// descriptor of each sent metric is one of those returned by Describe</span></span><br><span class="line">	<span class="comment">// (unless the Collector is unchecked, see above). Returned metrics that</span></span><br><span class="line">	<span class="comment">// share the same descriptor must differ in their variable label</span></span><br><span class="line">	<span class="comment">// values.</span></span><br><span class="line">	<span class="comment">//</span></span><br><span class="line">	<span class="comment">// This method may be called concurrently and must therefore be</span></span><br><span class="line">	<span class="comment">// implemented in a concurrency safe way. Blocking occurs at the expense</span></span><br><span class="line">	<span class="comment">// of total performance of rendering all registered metrics. Ideally,</span></span><br><span class="line">	<span class="comment">// Collector implementations support concurrent readers.</span></span><br><span class="line">	Collect(<span class="keyword">chan</span>&lt;- Metric)</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>

<h3 id="3-1node-exporter中prometheus-Collector接口的实现者–NodeCollector"><a href="#3-1node-exporter中prometheus-Collector接口的实现者–NodeCollector" class="headerlink" title="3.1node_exporter中prometheus.Collector接口的实现者–NodeCollector"></a>3.1<code>node_exporter</code>中<code>prometheus.Collector</code>接口的实现者–<code>NodeCollector</code></h3><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">// NodeCollector implements the prometheus.Collector interface.</span></span><br><span class="line"><span class="keyword">type</span> NodeCollector <span class="keyword">struct</span> &#123;</span><br><span class="line">	Collectors <span class="keyword">map</span>[<span class="keyword">string</span>]Collector</span><br><span class="line">	logger     log.Logger</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Describe implements the prometheus.Collector interface.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(n NodeCollector)</span> <span class="title">Describe</span><span class="params">(ch <span class="keyword">chan</span>&lt;- *prometheus.Desc)</span></span> &#123;</span><br><span class="line">    ch &lt;- scrapeDurationDesc</span><br><span class="line">    ch &lt;- scrapeSuccessDesc</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Collect implements the prometheus.Collector interface.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(n NodeCollector)</span> <span class="title">Collect</span><span class="params">(ch <span class="keyword">chan</span>&lt;- prometheus.Metric)</span></span> &#123;</span><br><span class="line">    wg := sync.WaitGroup&#123;&#125;</span><br><span class="line">    wg.Add(<span class="built_in">len</span>(n.Collectors))</span><br><span class="line">    <span class="keyword">for</span> name, c := <span class="keyword">range</span> n.Collectors &#123;</span><br><span class="line">        <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">(name <span class="keyword">string</span>, c Collector)</span></span> &#123;</span><br><span class="line">        	<span class="comment">// 执行各个采集指标的采集方法</span></span><br><span class="line">            execute(name, c, ch, n.logger)</span><br><span class="line">            wg.Done()</span><br><span class="line">        &#125;(name, c)</span><br><span class="line">    &#125;</span><br><span class="line">    wg.Wait()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<h1 id="4-结束语"><a href="#4-结束语" class="headerlink" title="4.结束语"></a>4.结束语</h1><p>整体来看<code>node_exporter</code>的源码可阅读性还是非常高的.接下来将会写一篇自研<code>exporter</code>的实践；</p>
]]></content>
      <tags>
        <tag>prometheus</tag>
        <tag>源码阅读</tag>
        <tag>node_exporter</tag>
      </tags>
  </entry>
  <entry>
    <title>一次slice bug</title>
    <url>/2021/03/22/uncatalog/slice_practice01/</url>
    <content><![CDATA[<hr>
<span id="more"></span>



<hr>
<p><img src="/2021/03/22/uncatalog/slice_practice01/1.png"></p>
<h5 id="一次slice-bug"><a href="#一次slice-bug" class="headerlink" title="一次slice bug"></a>一次slice bug</h5><blockquote>
<p>bug源：今天重构前同事的遗留代码,在review过程中,有段代码看起来有些别扭,有几分线程不安全的味道<br>bug描述：多个协程往同一个slice里追加操作需要开发者保证线程安全<br>bug修复： 详见代码  </p>
</blockquote>
<hr>
<h6 id="bug源"><a href="#bug源" class="headerlink" title="bug源"></a>bug源</h6><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 简化版bug复现</span></span><br><span class="line">    <span class="keyword">var</span> arr []<span class="keyword">string</span></span><br><span class="line">	<span class="keyword">var</span> wg sync.WaitGroup</span><br><span class="line">	wg.Add(<span class="number">10</span>)</span><br><span class="line">	<span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">10</span>; i++ &#123;</span><br><span class="line">		<span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">			<span class="keyword">defer</span> wg.Done()</span><br><span class="line">			str := getStr()</span><br><span class="line">			arr = <span class="built_in">append</span>(arr, str)</span><br><span class="line">		&#125;()</span><br><span class="line">	&#125;</span><br><span class="line">	wg.Wait()</span><br><span class="line">	calculate(arr)</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>
<hr>
<h6 id="疑问：slice的append操作是否是线程安全的？"><a href="#疑问：slice的append操作是否是线程安全的？" class="headerlink" title="疑问：slice的append操作是否是线程安全的？"></a>疑问：slice的append操作是否是线程安全的？</h6><blockquote>
<p>结论：append操作并不能保证线程安全</p>
</blockquote>
<p>我们看一看下面的两个例子(例子转自<a href="https://studygolang.com/articles/13662" title="Markdown">studygolang</a> 仅为了证明结论)：  </p>
<ul>
<li>例1:<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">    <span class="string">&quot;sync&quot;</span></span><br><span class="line">    <span class="string">&quot;testing&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">TestAppend</span><span class="params">(t *testing.T)</span></span> &#123;</span><br><span class="line">    x := []<span class="keyword">string</span>&#123;<span class="string">&quot;start&quot;</span>&#125;</span><br><span class="line"></span><br><span class="line">    wg := sync.WaitGroup&#123;&#125;</span><br><span class="line">    wg.Add(<span class="number">2</span>)</span><br><span class="line">    <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">        <span class="keyword">defer</span> wg.Done()</span><br><span class="line">        y := <span class="built_in">append</span>(x, <span class="string">&quot;hello&quot;</span>, <span class="string">&quot;world&quot;</span>)</span><br><span class="line">        t.Log(<span class="built_in">cap</span>(y), <span class="built_in">len</span>(y))</span><br><span class="line">    &#125;()</span><br><span class="line">    <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">        <span class="keyword">defer</span> wg.Done()</span><br><span class="line">        z := <span class="built_in">append</span>(x, <span class="string">&quot;goodbye&quot;</span>, <span class="string">&quot;bob&quot;</span>)</span><br><span class="line">        t.Log(<span class="built_in">cap</span>(z), <span class="built_in">len</span>(z))</span><br><span class="line">    &#125;()</span><br><span class="line">    wg.Wait()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div></li>
<li>例2:<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">    <span class="string">&quot;testing&quot;</span></span><br><span class="line">    <span class="string">&quot;sync&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">TestAppend</span><span class="params">(t *testing.T)</span></span> &#123;</span><br><span class="line">	<span class="comment">//以给这个名为 x 的 slice 在创建是预留一些容量.这是较例1唯一改动的地方</span></span><br><span class="line">    x := <span class="built_in">make</span>([]<span class="keyword">string</span>, <span class="number">0</span>, <span class="number">6</span>)</span><br><span class="line"></span><br><span class="line">    wg := sync.WaitGroup&#123;&#125;</span><br><span class="line">    wg.Add(<span class="number">2</span>)</span><br><span class="line">    <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">        <span class="keyword">defer</span> wg.Done()</span><br><span class="line">        y := <span class="built_in">append</span>(x, <span class="string">&quot;hello&quot;</span>, <span class="string">&quot;world&quot;</span>)</span><br><span class="line">        t.Log(<span class="built_in">len</span>(y))</span><br><span class="line">    &#125;()</span><br><span class="line">    <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">        <span class="keyword">defer</span> wg.Done()</span><br><span class="line">        z := <span class="built_in">append</span>(x, <span class="string">&quot;goodbye&quot;</span>, <span class="string">&quot;bob&quot;</span>)</span><br><span class="line">        t.Log(<span class="built_in">len</span>(z))</span><br><span class="line">    &#125;()</span><br><span class="line">    wg.Wait()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
如果我们执行这个测试时带上 <code>-race</code>,发现出现了<code>DATA RACE</code><blockquote>
<p>解释为什么测试失败  </p>
</blockquote>
</li>
</ul>
<p>理解为什么这个失败会发生，请看看这个旧例子的 x 的内存布局<br><img src="/2021/03/22/uncatalog/slice_practice01/5.png">  </p>
<p>x 没有足够的容量进行修改</p>
<p>Go 语言发现没有足够的内存空间来存储 <em>hello</em>,<em>world</em> 和　<em>goodbye</em>, <em>bob</em>,  </p>
<p>于是分配的新的内存给 <em>y</em> 与 <em>z</em>。   </p>
<p>数据竞争不会在多进程读取内存时发生，<em>x</em> 没有被修改。  </p>
<p>这里没有冲突，也就没有竞争。  </p>
<p><img src="/2021/03/22/uncatalog/slice_practice01/2.png">  </p>
<p> <em>z</em> 与 <em>y</em> 获取新的内存空间  </p>
<p>在新的代码里，事情不一样了<br><img src="/2021/03/22/uncatalog/slice_practice01/3.png"><br><em>x</em> 有更多的容量</p>
<p>在这里，go 注意到有足够的内存存放 <em>hello</em>, <em>world</em>，<br>另一个协程也发现有足够的空间存放 <em>goodbye</em>, <em>bob</em>，<br>这个竞争的发生是因为这两个协程都尝试往同一个内存空间写入，<br>谁也不知道谁是赢家。<br><img src="/2021/03/22/uncatalog/slice_practice01/4.png"><br>这是 Go 语言的一个特性而非 bug ，append 不会强制每一次调用它都申请新的内存。<br>它允许用户在循环内进行 append 操作时不会破坏垃圾回收机制。<br>缺点是你必须清楚知道在多个协程对 slice 的操作。</p>
<h6 id="疑问：slice的append操作如何保证线程安全？"><a href="#疑问：slice的append操作如何保证线程安全？" class="headerlink" title="疑问：slice的append操作如何保证线程安全？"></a>疑问：slice的append操作如何保证线程安全？</h6><blockquote>
<p>最简单的解决方法是不使用共享状态的第一个变量来进行 append 。<br>   相反，根据你的需要来 make 一个新的 slice ，<br>   使用这个新的 slice 作为 append 的第一个变量。<br>   下面是失败的测试示例的修正版，这里的替代方法是使用 copy </p>
</blockquote>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">    <span class="string">&quot;sync&quot;</span></span><br><span class="line">    <span class="string">&quot;testing&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">TestAppend</span><span class="params">(t *testing.T)</span></span> &#123;</span><br><span class="line">    x := <span class="built_in">make</span>([]<span class="keyword">string</span>, <span class="number">0</span>, <span class="number">6</span>)</span><br><span class="line">    x = <span class="built_in">append</span>(x, <span class="string">&quot;start&quot;</span>)</span><br><span class="line"></span><br><span class="line">    wg := sync.WaitGroup&#123;&#125;</span><br><span class="line">    wg.Add(<span class="number">2</span>)</span><br><span class="line">    <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">        <span class="keyword">defer</span> wg.Done()</span><br><span class="line">        y := <span class="built_in">make</span>([]<span class="keyword">string</span>, <span class="number">0</span>, <span class="built_in">len</span>(x)+<span class="number">2</span>)</span><br><span class="line">        y = <span class="built_in">append</span>(y, x...)</span><br><span class="line">        y = <span class="built_in">append</span>(y, <span class="string">&quot;hello&quot;</span>, <span class="string">&quot;world&quot;</span>)</span><br><span class="line">        t.Log(<span class="built_in">cap</span>(y), <span class="built_in">len</span>(y), y[<span class="number">0</span>])</span><br><span class="line">    &#125;()</span><br><span class="line">    <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">        <span class="keyword">defer</span> wg.Done()</span><br><span class="line">        z := <span class="built_in">make</span>([]<span class="keyword">string</span>, <span class="number">0</span>, <span class="built_in">len</span>(x)+<span class="number">2</span>)</span><br><span class="line">        z = <span class="built_in">append</span>(z, x...)</span><br><span class="line">        z = <span class="built_in">append</span>(z, <span class="string">&quot;goodbye&quot;</span>, <span class="string">&quot;bob&quot;</span>)</span><br><span class="line">        t.Log(<span class="built_in">cap</span>(z), <span class="built_in">len</span>(z), z[<span class="number">0</span>])</span><br><span class="line">    &#125;()</span><br><span class="line">    wg.Wait()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<hr>
<h6 id="疑问：文章开头的问题该如何解决呢？"><a href="#疑问：文章开头的问题该如何解决呢？" class="headerlink" title="疑问：文章开头的问题该如何解决呢？"></a>疑问：文章开头的问题该如何解决呢？</h6><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 简化版bug复现</span></span><br><span class="line">    <span class="keyword">var</span> arr []<span class="keyword">string</span></span><br><span class="line">	<span class="keyword">var</span> wg sync.WaitGroup</span><br><span class="line">	wg.Add(<span class="number">10</span>)</span><br><span class="line">	<span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">10</span>; i++ &#123;</span><br><span class="line">		<span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">			<span class="keyword">defer</span> wg.Done()</span><br><span class="line">			str := getStr()</span><br><span class="line">			arr = <span class="built_in">append</span>(arr, str)</span><br><span class="line">		&#125;()</span><br><span class="line">	&#125;</span><br><span class="line">	wg.Wait()</span><br><span class="line">	calculate(arr)</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>
<blockquote>
<p>解决方案：引入<strong>channel</strong>机制，将<strong>消费者</strong>和<strong>生产者</strong>解耦</p>
</blockquote>
<ul>
<li><p>解决方案1：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line">   ch := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">string</span>, n)</span><br><span class="line">   <span class="keyword">var</span> arr []<span class="keyword">string</span></span><br><span class="line">   <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">	<span class="keyword">for</span> i := <span class="keyword">range</span> ch &#123;</span><br><span class="line">		arr = <span class="built_in">append</span>(arr, i)</span><br><span class="line">	&#125;</span><br><span class="line">&#125;()</span><br><span class="line"><span class="keyword">var</span> wg sync.WaitGroup</span><br><span class="line">wg.Add(<span class="number">10</span>)</span><br><span class="line"><span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">10</span>; i++ &#123;</span><br><span class="line">	<span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">		<span class="keyword">defer</span> wg.Done()</span><br><span class="line">		str := getStr()</span><br><span class="line">		ch &lt;- str</span><br><span class="line">	&#125;()</span><br><span class="line">&#125;</span><br><span class="line">wg.Wait()</span><br><span class="line">   <span class="built_in">close</span>(ch)</span><br><span class="line">calculate(arr)</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>
<p>问题解决了吗？<br>slice的append操作的线程安全有保障了,但是又引入了新问题： </p>
<blockquote>
<p>如何保证传递给<code>calculate()</code>的<code>arr</code>取尽了<code>ch</code>呢？  </p>
</blockquote>
</li>
<li><p>终极方案</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line">   ch := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">string</span>, n)</span><br><span class="line">   <span class="keyword">var</span> arr []<span class="keyword">string</span></span><br><span class="line">   <span class="keyword">var</span> wg0 sync.WaitGroup</span><br><span class="line">   <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">       wg0.Add(<span class="number">1</span>)</span><br><span class="line">	<span class="keyword">for</span> i := <span class="keyword">range</span> ch &#123;</span><br><span class="line">		arr = <span class="built_in">append</span>(arr, i)</span><br><span class="line">	&#125;</span><br><span class="line">       wg0.Done()</span><br><span class="line">&#125;()</span><br><span class="line"><span class="keyword">var</span> wg sync.WaitGroup</span><br><span class="line">wg.Add(<span class="number">10</span>)</span><br><span class="line"><span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">10</span>; i++ &#123;</span><br><span class="line">	<span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">		<span class="keyword">defer</span> wg.Done()</span><br><span class="line">		str := getStr()</span><br><span class="line">		ch &lt;- str</span><br><span class="line">	&#125;()</span><br><span class="line">&#125;</span><br><span class="line">wg.Wait()</span><br><span class="line">   <span class="built_in">close</span>(ch)</span><br><span class="line">   wg0.Wait()</span><br><span class="line">calculate(arr)</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>
<p><code>wg</code>保证<code>str</code>都发送到了<code>ch</code><br><code>wg0</code>保证<code>ch</code>都被取出放到了<code>arr</code> </p>
</li>
</ul>
]]></content>
      <tags>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title>一个容易被忽略的数据库Bug</title>
    <url>/2021/05/10/go-practice/mysql_bug_practice01/</url>
    <content><![CDATA[<p>今天review小组内其他几个成员的代码，发现了一个大家都在写的bug，向各位分享一下；</p>
<span id="more"></span>

<p><img src="/2021/05/10/go-practice/mysql_bug_practice01/1.png"></p>
<h5 id="直接上代码："><a href="#直接上代码：" class="headerlink" title="直接上代码："></a>直接上代码：</h5><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> sql_demo</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">	<span class="string">&quot;database/sql&quot;</span></span><br><span class="line">	<span class="string">&quot;fmt&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">sql_demo</span><span class="params">()</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	db, err := sql.Open(<span class="string">&quot;mysql&quot;</span>, <span class="string">&quot;xxxx:xxxx@tcp(localhost:3306)/xxxx?charset=utf8&quot;</span>)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		fmt.Println(err)</span><br><span class="line">		<span class="keyword">return</span> err</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">defer</span> db.Close()</span><br><span class="line">	rows, err := db.Query(<span class="string">&quot;select id,name from sql_demo&quot;</span>)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		fmt.Println(err)</span><br><span class="line">		<span class="keyword">return</span> err</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">defer</span> rows.Close()</span><br><span class="line">	<span class="keyword">var</span> id <span class="keyword">int</span></span><br><span class="line">	<span class="keyword">var</span> name <span class="keyword">string</span></span><br><span class="line">	<span class="keyword">for</span> rows.Next() &#123;</span><br><span class="line">		rerr := rows.Scan(&amp;id, &amp;name)</span><br><span class="line">		<span class="keyword">if</span> rerr == <span class="literal">nil</span> &#123;</span><br><span class="line">			<span class="keyword">return</span> rerr</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>

<h5 id="找bug："><a href="#找bug：" class="headerlink" title="找bug："></a>找bug：</h5><p>是不是没找到？没关系，我们看下源码:</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> sql_demo</span><br><span class="line"></span><br><span class="line"><span class="comment">// Next prepares the next result row for reading with the Scan method. It</span></span><br><span class="line"><span class="comment">// returns true on success, or false if there is no next result row or an error</span></span><br><span class="line"><span class="comment">// happened while preparing it. Err should be consulted to distinguish between</span></span><br><span class="line"><span class="comment">// the two cases.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// Every call to Scan, even the first one, must be preceded by a call to Next.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(rs *Rows)</span> <span class="title">Next</span><span class="params">()</span> <span class="title">bool</span></span> &#123;</span><br><span class="line">	<span class="keyword">var</span> doClose, ok <span class="keyword">bool</span></span><br><span class="line">	withLock(rs.closemu.RLocker(), <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">		doClose, ok = rs.nextLocked()</span><br><span class="line">	&#125;)</span><br><span class="line">	<span class="keyword">if</span> doClose &#123;</span><br><span class="line">		rs.Close()</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> ok</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<p>简单翻译一下：当 <code>no next result row</code>或者遇到 <code>error</code>的时候,<code>Next()</code>都会返回<code>false</code>,<br>我们需要调用<code>Err</code>来区分这两种情况;<br>所以bug找到了，迭代过程中，当遇到<code>error</code>时,比如网络异常等等，此时数据可能只读到了一部分，<code>rows.Next()</code>会返回<code>false</code>,<br>直接<code>return nil</code>,会把异常遗漏掉,造成一个隐形<code>bug</code>;<br>正确做法：<br>把<code>return nil</code>改为<code>rows.Err()</code>即可;</p>
]]></content>
      <categories>
        <category>GO实践</category>
      </categories>
      <tags>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title>单例模式.md</title>
    <url>/2021/03/22/design/single01/</url>
    <content><![CDATA[<h4 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h4><blockquote>
<p>单例模式(<strong>Singleton Design Pattern</strong>):一个类只允许创建一个对象（或者实例）  </p>
</blockquote>
<hr>
<h4 id="要解决的问题-用途"><a href="#要解决的问题-用途" class="headerlink" title="要解决的问题/用途"></a>要解决的问题/用途</h4><ul>
<li>资源访问冲突</li>
<li>表示全局唯一类,如<em>配置信息类</em>、<em>连接池类</em>、<em>ID生成器类</em>等</li>
</ul>
<hr>
<span id="more"></span>

<p><img src="/2021/03/22/design/single01/1.png"></p>
<h4 id="如何实现"><a href="#如何实现" class="headerlink" title="如何实现"></a>如何实现</h4><table>
<thead>
<tr>
<th>实现方式</th>
<th>概念</th>
<th>是否线程安全</th>
<th>是否支持延迟加载</th>
<th>适用场景</th>
</tr>
</thead>
<tbody><tr>
<td>饿汉式</td>
<td>单例实例在类加载的时候<br>instance静态实例就已经创建并初始化好了</td>
<td>是</td>
<td>否</td>
<td>详见代码</td>
</tr>
<tr>
<td>懒汉式</td>
<td>单例实例在第一次被使用时构建</td>
<td>可以加锁实现线程安全</td>
<td>是</td>
<td>详见代码</td>
</tr>
<tr>
<td>双重检测</td>
<td>只要instance被创建之后，即便再调用getInstance()函数也不会再进入到加锁逻辑中了。<br>所以，这种实现方式解决了懒汉式并发度低的问题</td>
<td>是</td>
<td>是</td>
<td>详见代码</td>
</tr>
<tr>
<td>静态内部类</td>
<td>java特有,在此不做讲解</td>
<td>-</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>枚举</td>
<td>java特有,在此不做讲解</td>
<td>-</td>
<td>-</td>
<td>-</td>
</tr>
</tbody></table>
<hr>
<h5 id="1-饿汉式"><a href="#1-饿汉式" class="headerlink" title="1.饿汉式"></a>1.饿汉式</h5><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">饿汉模式适用场景：</span></span><br><span class="line"><span class="comment">如果初始化耗时长，那我们最好不要等到真正要用它的时候，</span></span><br><span class="line"><span class="comment">才去执行这个耗时长的初始化过程，这会影响到系统的性能</span></span><br><span class="line"><span class="comment">（比如，在响应客户端接口请求的时候，做这个初始化操作，</span></span><br><span class="line"><span class="comment">会导致此请求的响应时间变长，甚至超时）。</span></span><br><span class="line"><span class="comment">采用饿汉式实现方式，将耗时的初始化操作，</span></span><br><span class="line"><span class="comment">提前到程序启动的时候完成，这样就能避免在程序运行的时候，</span></span><br><span class="line"><span class="comment">再去初始化导致的性能问题。</span></span><br><span class="line"><span class="comment">如果实例占用资源多，按照fail-fast的设计原则（有问题及早暴露），</span></span><br><span class="line"><span class="comment">那我们也希望在程序启动时就将这个实例初始化好。</span></span><br><span class="line"><span class="comment">如果资源不够，就会在程序启动的时候触发报错（比如Java中的 PermGen Space OOM），</span></span><br><span class="line"><span class="comment">我们可以立即去修复。这样也能避免在程序运行一段时间后，</span></span><br><span class="line"><span class="comment">突然因为初始化这个实例占用资源过多，导致系统崩溃，影响系统的可用性。</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">var</span> es = &amp;EagerSingleton&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//func init() &#123;</span></span><br><span class="line"><span class="comment">//	如果EagerSingleton有属性需要初始化,可以在init内进行</span></span><br><span class="line"><span class="comment">//&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">GetEsInstance</span><span class="params">()</span> *<span class="title">EagerSingleton</span></span>  &#123;</span><br><span class="line">	<span class="keyword">return</span> es</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> EagerSingleton <span class="keyword">struct</span> &#123;</span><br><span class="line">	</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<hr>
<h5 id="2-懒汉式"><a href="#2-懒汉式" class="headerlink" title="2.懒汉式"></a>2.懒汉式</h5><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="string">&quot;sync&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">懒汉模式适用场景：</span></span><br><span class="line"><span class="comment">懒汉式相对于饿汉式的优势是支持延迟加载。</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> lz *LazySingleton</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> LazySingleton <span class="keyword">struct</span> &#123;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 第一种：非线程安全</span></span><br><span class="line"><span class="comment">//func GetLzInstance() *LazySingleton  &#123;</span></span><br><span class="line"><span class="comment">//	if lz == nil&#123;</span></span><br><span class="line"><span class="comment">//		lz = &amp;LazySingleton&#123;&#125;</span></span><br><span class="line"><span class="comment">//	&#125;</span></span><br><span class="line"><span class="comment">//	return lz</span></span><br><span class="line"><span class="comment">//&#125;</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 第二种：加锁，并发性能最差</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//var mu sync.Mutex</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//func GetLzInstance() *LazySingleton &#123;</span></span><br><span class="line"><span class="comment">//	mu.Lock()</span></span><br><span class="line"><span class="comment">//	defer mu.Unlock()</span></span><br><span class="line"><span class="comment">//	if lz == nil &#123;</span></span><br><span class="line"><span class="comment">//		lz = &amp;LazySingleton&#123;&#125;</span></span><br><span class="line"><span class="comment">//	&#125;</span></span><br><span class="line"><span class="comment">//	return lz</span></span><br><span class="line"><span class="comment">//&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 第三种：锁+双重检查，并发性较第二种稍好一点</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//var mu sync.Mutex</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">//func GetLzInstance() *LazySingleton &#123;</span></span><br><span class="line"><span class="comment">//	if lz == nil &#123;</span></span><br><span class="line"><span class="comment">//		mu.Lock()</span></span><br><span class="line"><span class="comment">//		defer mu.Unlock()</span></span><br><span class="line"><span class="comment">//		if lz == nil &#123;</span></span><br><span class="line"><span class="comment">//			lz = &amp;LazySingleton&#123;&#125;</span></span><br><span class="line"><span class="comment">//		&#125;</span></span><br><span class="line"><span class="comment">//	&#125;</span></span><br><span class="line"><span class="comment">//	return lz</span></span><br><span class="line"><span class="comment">//&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 第四种：懒汉式最优实现,通过golang特有的sync.Once来实现</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> once sync.Once</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">GetLzInstance</span><span class="params">()</span> *<span class="title">LazySingleton</span></span> &#123;</span><br><span class="line">	once.Do(<span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">		lz = &amp;LazySingleton&#123;&#125;</span><br><span class="line">	&#125;)</span><br><span class="line">	<span class="keyword">return</span> lz</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title>分布式事务的点点滴滴--概念概览</title>
    <url>/2021/05/18/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/dtp01/</url>
    <content><![CDATA[<h4 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h4><blockquote>
<p>最近着手把微服务项目的数据库进行分库分表，不可避免的要增加分布式事务的考虑，所以在此把相关知识点梳理一下。<br>本专题将会分为三篇,从分布式事务的概念到各种理论和协议。</p>
</blockquote>
<span id="more"></span>

<p><img src="/2021/05/18/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/dtp01/1.png"><br>讲分布式事务之前先做个扫盲，了解几个概念：</p>
<h3 id="1-微服务"><a href="#1-微服务" class="headerlink" title="1.微服务"></a>1.微服务</h3><blockquote>
<p>以下内容来自维基百科</p>
</blockquote>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="TEXT"><figure class="iseeu highlight /text"><table><tr><td class="code"><pre><span class="line">微服务（英语：Microservices）是一种软件架构风格，</span><br><span class="line">它是以专注于单一责任与功能的小型功能区块 (Small Building Blocks) 为基础，</span><br><span class="line">利用模块化的方式组合出复杂的大型应用程序，</span><br><span class="line">各功能区块使用与语言无关 (Language-Independent/Language agnostic）</span><br><span class="line">的API集相互通信。</span><br><span class="line">微服务的起源是由 Peter Rodgers 博士于 2005 年度云计算博览会</span><br><span class="line">提出的微 Web 服务（Micro-Web-Service）开始，</span><br><span class="line">Juval Löwy 则是与他有类似的前导想法，</span><br><span class="line">将类别变成细粒服务（granular services），以作为微软下一阶段的软件架构，</span><br><span class="line">其核心想法是让服务是由类似 Unix 管道的访问方式使用，</span><br><span class="line">而且复杂的服务背后是使用简单 URI 来开放接口，任何服务，</span><br><span class="line">任何细粒都能被开放（exposed）。这个设计在 HP 的实验室被实现，</span><br><span class="line">具有改变复杂软件系统的强大力量。</span><br></pre></td></tr></table></figure></div>

<h3 id="2-分布式"><a href="#2-分布式" class="headerlink" title="2.分布式"></a>2.分布式</h3><blockquote>
<p>以下内容来自维基百科</p>
</blockquote>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="TEXT"><figure class="iseeu highlight /text"><table><tr><td class="code"><pre><span class="line">分布式系统有很多不同的定义，</span><br><span class="line">一般认为：“一个分布式系统是一些独立的计算机集合，</span><br><span class="line">但是对这个系统的用户来说，系统就像一台计算机一样。”</span><br><span class="line">这个定义有两方面的含义：</span><br><span class="line">第一，从硬件角度来讲，每台计算机都是自主的；</span><br><span class="line">第二，从软件角度来讲，用户将整个系统看做是一台计算机。</span><br><span class="line">这两者都是必需的，缺一不可</span><br></pre></td></tr></table></figure></div>

<h3 id="3-事务"><a href="#3-事务" class="headerlink" title="3.事务"></a>3.事务</h3><blockquote>
<p>以下内容来自维基百科</p>
</blockquote>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="TEXT"><figure class="iseeu highlight /text"><table><tr><td class="code"><pre><span class="line">数据库事务（简称：事务）是数据库管理系统执行过程中的一个逻辑单位，</span><br><span class="line">由一个有限的数据库操作序列构成。</span><br><span class="line">数据库事务通常包含了一个序列的对数据库的读/写操作。</span><br><span class="line">包含有以下两个目的：</span><br><span class="line">为数据库操作序列提供了一个从失败中恢复到正常状态的方法，</span><br><span class="line">同时提供了数据库即使在异常状态下仍能保持一致性的方法。</span><br><span class="line">当多个应用程序在并发访问数据库时，可以在这些应用程序之间提供一个隔离方法，</span><br><span class="line">以防止彼此的操作互相干扰。</span><br><span class="line">通俗点讲就是：数据库事务可以确保该事务范围内的所有操作都可以全部成功或者全部失败。  </span><br><span class="line">如果事务失败，那么效果就和没有执行这些SQL一样，不会对数据库数据有任何改动。</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>
<h4 id="3-1-分布式事务的起源："><a href="#3-1-分布式事务的起源：" class="headerlink" title="3.1 分布式事务的起源："></a>3.1 分布式事务的起源：</h4><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="TEXT"><figure class="iseeu highlight /text"><table><tr><td class="code"><pre><span class="line">在单体架构中，我们可以通过数据库层面对事务的支持来保证业务上的事务操作。  </span><br><span class="line">但是随着微服务架构的普及，一个大型业务系统往往由若干个子系统构成，  </span><br><span class="line">这些子系统又拥有各自独立的数据库。往往一个业务流程需要由多个子系统共同完成，  </span><br><span class="line">而且这些操作可能需要在一个事务中完成。此时，我们就需要在数据库之上通过某种手段，  </span><br><span class="line">实现跨数据库的事务支持，这也就是大家常说的“分布式事务”。</span><br><span class="line">分布式事务涉及到操作多个数据库的事务，分布式事务的参与者、支持事务的服务器、  </span><br><span class="line">资源服务器以及事务管理器分别位于分布式系统的不同节点上。  </span><br><span class="line">一个分布式事务可以看作是由多个分布式的操作序列组成的，通常可以把这一系列分布式的操作序列称为子事务，  </span><br><span class="line">但由于在分布式事务中，各个子事务的执行是分布式的，因此要实现一种能够保证 ACID 特性的分布式事务处理系统就显得格外复杂。</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>

<h4 id="3-2-分布式事务的两个典型应用场景："><a href="#3-2-分布式事务的两个典型应用场景：" class="headerlink" title="3.2 分布式事务的两个典型应用场景："></a>3.2 分布式事务的两个典型应用场景：</h4><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="TEXT"><figure class="iseeu highlight /text"><table><tr><td class="code"><pre><span class="line">1.数据库分库分表：</span><br><span class="line">在单库单表场景下，当业务数据量达到单库单表的极限时，就需要考虑分库分表，  </span><br><span class="line">将之前的单库单表拆分成多库多表；分库分表之后，原来在单个数据库上的事务操作，  </span><br><span class="line">可能就变成跨多个数据库的操作，此时就需要使用分布式事务。</span><br><span class="line"></span><br><span class="line">2.业务服务化</span><br><span class="line">业务服务化即业务按照面向服务（SOA）的架构拆分整个网站系统，所有的业务操作都以服务的方式对外发布，  </span><br><span class="line">跨应用、跨服务的操作需要使用分布式事务才能保证数据的一致性。</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>
<h4 id="3-3-分布式事务涉及到的几个理论："><a href="#3-3-分布式事务涉及到的几个理论：" class="headerlink" title="3.3 分布式事务涉及到的几个理论："></a>3.3 分布式事务涉及到的几个理论：</h4><h5 id="3-3-1-CAP："><a href="#3-3-1-CAP：" class="headerlink" title="3.3.1.CAP："></a>3.3.1.CAP：</h5><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="TEXT"><figure class="iseeu highlight /text"><table><tr><td class="code"><pre><span class="line">分布式系统不可能同时满足</span><br><span class="line">一致性（C：Consistency）、</span><br><span class="line">可用性（A：Availability）、</span><br><span class="line">分区容忍性（P：Partition Tolerance）、</span><br><span class="line">最多只能同时满足其中两项。</span><br><span class="line"></span><br><span class="line">Consistency 一致性:一致性指的是多个数据副本是否能保持一致的特性，  </span><br><span class="line">在一致性的条件下，系统在执行数据更新操作之后能够从一致性状态转移到另一个一致性状态。  </span><br><span class="line">对系统的一个数据更新成功之后，如果所有用户都能够读取到最新的值，该系统就被认为具有强一致性。  </span><br><span class="line"></span><br><span class="line">Availability 可用性:可用性指分布式系统在面对各种异常时可以提供正常服务的能力，  </span><br><span class="line">可以用系统可用时间占总时间的比值来衡量，4 个 9 的可用性表示系统 99.99% 的时间是可用的。  </span><br><span class="line">在可用性条件下，要求系统提供的服务一直处于可用的状态，对于用户的每一个操作请求总是能够在有限的时间内返回结果。</span><br><span class="line"></span><br><span class="line">Parttition Tolerance 分区容忍性:网络分区指分布式系统中的节点被划分为多个区域，每个区域内部可以通信，  </span><br><span class="line">但是区域之间无法通信。在分区容忍性条件下，分布式系统在遇到任何网络分区故障的时候，  </span><br><span class="line">仍然需要能对外提供一致性和可用性的服务，除非是整个网络环境都发生了故障。  </span><br></pre></td></tr></table></figure></div>
<p>关于CAP的知乎高赞解释：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="TEXT"><figure class="iseeu highlight /text"><table><tr><td class="code"><pre><span class="line">一个分布式系统里面，节点组成的网络本来应该是连通的。然而可能因为一些故障，使得有些节点之间不连通了，  </span><br><span class="line">整个网络就分成了几块区域。数据就散布在了这些不连通的区域中。这就叫分区。</span><br><span class="line">当你一个数据项只在一个节点中保存，那么分区出现后，和这个节点不连通的部分就访问不到这个数据了。这时分区就是无法容忍的。</span><br><span class="line">提高分区容忍性的办法就是一个数据项复制到多个节点上，那么出现分区之后，这一数据项就可能分布到各个区里。容忍性就提高了。</span><br><span class="line">然而，要把数据复制到多个节点，就会带来一致性的问题，就是多个节点上面的数据可能是不一致的。  </span><br><span class="line">要保证一致，每次写操作就都要等待全部节点写成功，而这等待又会带来可用性的问题。</span><br><span class="line">总的来说就是，数据存在的节点越多，分区容忍性越高，但要复制更新的数据就越多，一致性就越难保证。  </span><br><span class="line">为了保证一致性，更新所有节点数据所需要的时间就越长，可用性就会降低。</span><br><span class="line"></span><br><span class="line">综上，CAP 理论实际上是要在可用性和一致性之间做权衡。  </span><br><span class="line">可用性和一致性往往是冲突的，很难使它们同时满足。在多个节点之间进行数据同步时，</span><br><span class="line">为了保证一致性（CP），不能访问未同步完成的节点，也就失去了部分可用性；</span><br><span class="line">为了保证可用性（AP），允许读取所有节点的数据，但是数据可能不一致。</span><br><span class="line">通常采取的策略是保证可用性，牺牲部分一致性，只确保最终一致性。</span><br><span class="line">当然，牺牲一致性，并不是完全不管数据的一致性，否则数据是混乱的，那么系统可用性再高分布式再好也没有了价值。  </span><br><span class="line">牺牲一致性，只是不再要求关系型数据库中的强一致性，而是只要系统能达到最终一致性即可，考虑到客户体验，  </span><br><span class="line">这个最终一致的时间窗口，要尽可能的对用户透明，也就是需要保障“用户感知到的一致性”。  </span><br><span class="line">通常是通过数据的多份异步复制来实现系统的高可用和数据的最终一致性的，“用户感知到的一致性”的时间窗口则取决于数据复制到一致状态的时间。</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>

<h5 id="3-3-2-BASE："><a href="#3-3-2-BASE：" class="headerlink" title="3.3.2.BASE："></a>3.3.2.BASE：</h5><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="TEXT"><figure class="iseeu highlight /text"><table><tr><td class="code"><pre><span class="line">BASE理论是指，Basically Available（基本可用）、Soft-state（ 软状态/柔性事务）、Eventual Consistency（最终一致性）。  </span><br><span class="line">是基于CAP定理演化而来，是对CAP中一致性和可用性权衡的结果。  </span><br><span class="line">核心思想：即使无法做到强一致性，但每个业务根据自身的特点，采用适当的方式来使系统达到最终一致性。</span><br><span class="line"></span><br><span class="line"> 基本可用BA：（Basically Available ）：指分布式系统在出现故障的时候，允许损失部分可用性，保证核心可用。  </span><br><span class="line"> 但不等价于不可用。比如：搜索引擎0.5秒返回查询结果，但由于故障，2秒响应查询结果；  </span><br><span class="line"> 网页访问过大时，部分用户提供降级服务等。简单来说就是基本可用。</span><br><span class="line"> </span><br><span class="line">软状态S:(Soft State)：软状态是指允许系统存在中间状态，并且该中间状态不会影响系统整体可用性。  </span><br><span class="line">即允许系统在不同节点间副本同步的时候存在延时。简单来说就是状态可以在一段时间内不同            步。</span><br><span class="line"></span><br><span class="line">最终一致性E：(Eventually Consistent)：系统中的所有数据副本经过一定时间后，最终能够达到一致的状态，不需要实时保证系统数据的强一致性。  </span><br><span class="line">最终一致性是弱一致性的一种特殊情况。  </span><br><span class="line"></span><br><span class="line">BASE理论面向的是大型高可用可扩展的分布式系统，通过牺牲强一致性来获得可用性。  </span><br><span class="line">ACID是传统数据库常用的概念设计，追求强一致性模型。  </span><br><span class="line">简单来说就是在一定的时间窗口内， 最终数据达成一致即可。  </span><br></pre></td></tr></table></figure></div>


<h5 id="3-3-3-柔性事务和刚性事务："><a href="#3-3-3-柔性事务和刚性事务：" class="headerlink" title="3.3.3.柔性事务和刚性事务："></a>3.3.3.柔性事务和刚性事务：</h5><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="TEXT"><figure class="iseeu highlight /text"><table><tr><td class="code"><pre><span class="line">刚性事务满足ACID理论</span><br><span class="line">ACID能够保证事务的强一致性，即数据是实时一致的。</span><br><span class="line">这在本地事务中是没有问题的，在分布式事务中，</span><br><span class="line">强一致性会极大影响分布式系统的性能，因此分布式系统中遵循BASE理论即可。</span><br><span class="line">但分布式系统的不同业务场景对一致性的要求也不同。</span><br><span class="line">如交易场景下，就要求强一致性，此时就需要遵循ACID理论，</span><br><span class="line">而在注册成功后发送短信验证码等场景下，并不需要实时一致，</span><br><span class="line">因此遵循BASE理论即可。</span><br><span class="line">因此要根据具体业务场景，在ACID和BASE之间寻求平衡。</span><br><span class="line">柔性事务满足BASE理论（基本可用，最终一致）</span><br><span class="line"></span><br><span class="line">柔性事务分为：</span><br><span class="line">两阶段型 2PC(two phase commitment)</span><br><span class="line">补偿型TCC (try confirn/caclen</span><br><span class="line">异步确保型 (通过信息中间件)</span><br><span class="line">最大努力通知型。</span><br></pre></td></tr></table></figure></div>
<blockquote>
<p>分布式事务涉及到的概念讲完了，接下来两篇将分别讲下分布式事务的一些指导理论和协议。</p>
</blockquote>
]]></content>
      <categories>
        <category>架构设计</category>
      </categories>
      <tags>
        <tag>架构设计</tag>
      </tags>
  </entry>
  <entry>
    <title>工厂模式</title>
    <url>/2021/03/23/design/factory01/</url>
    <content><![CDATA[<hr>
<h4 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h4><blockquote>
<p>简单工厂模式(Simple Factory Pattern)<br>工厂方法模式(Factory Method)：定义了一个创建对象的接口，但由子类决定要实例化的类是哪一个。工厂方法让类把实例化推迟到子类<br>抽象工厂模式：提供一个接口，用于创建相关或依赖对象的家族，而不需要明确指定具体类   </p>
</blockquote>
<hr>
<span id="more"></span>

<p><img src="/2021/03/23/design/factory01/1.png"></p>
<h4 id="要解决的问题-用途"><a href="#要解决的问题-用途" class="headerlink" title="要解决的问题/用途"></a>要解决的问题/用途</h4><ul>
<li>当创建逻辑比较复杂，是一个“大工程”的时候，我们就考虑使用<em>工厂模式</em></li>
<li>封装对象的创建过程，将对象的创建和使用相分离</li>
<li>代码中存在<code>if-else</code>分支判断，动态地根据不同的类型创建不同的对象。将这一大坨<code>if-else</code>创建对象的代码抽离出来，放到工厂类中.</li>
<li>尽管我们不需要根据不同的类型创建不同的对象，但是，单个对象本身的创建过程比较复杂，<br>比如要组合其他类对象，做各种初始化操作。在这种情况下，我们也可以考虑使用<em>工厂模式</em>，将对象的创建过程封装到工厂类中</li>
</ul>
<hr>
<h4 id="如何实现"><a href="#如何实现" class="headerlink" title="如何实现"></a>如何实现</h4><h5 id="1-简单工厂模式-Simple-Factory-Pattern"><a href="#1-简单工厂模式-Simple-Factory-Pattern" class="headerlink" title="1,简单工厂模式(Simple Factory Pattern)"></a>1,简单工厂模式(Simple Factory Pattern)</h5> <div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">简单工厂模式1(Simple Factory Pattern)</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="string">&quot;errors&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">简单工厂模式1(Simple Factory Pattern)</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> rcpFactory1 *RuleConfigParserFactory1</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Load1</span><span class="params">(configFormat <span class="keyword">string</span>)</span> <span class="params">(RuleConfig, error)</span></span> &#123;</span><br><span class="line">	parser, err := rcpFactory1.createParser(configFormat)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">var</span> text <span class="keyword">string</span></span><br><span class="line">	<span class="comment">// load form config file</span></span><br><span class="line">	<span class="keyword">return</span> parser.Parse(text)</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 简单工厂模式1</span></span><br><span class="line"><span class="keyword">type</span> RuleConfigParserFactory1 <span class="keyword">struct</span> &#123;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(r *RuleConfigParserFactory1)</span> <span class="title">createParser</span><span class="params">(configFormat <span class="keyword">string</span>)</span> <span class="params">(IRuleConfigParser, error)</span></span> &#123;</span><br><span class="line">	<span class="keyword">var</span> parser IRuleConfigParser</span><br><span class="line">	<span class="keyword">if</span> configFormat == <span class="string">&quot;json&quot;</span> &#123;</span><br><span class="line">		parser = &amp;JsonRuleConfigParser&#123;&#125;</span><br><span class="line">	&#125; <span class="keyword">else</span> <span class="keyword">if</span> configFormat == <span class="string">&quot;xml&quot;</span> &#123;</span><br><span class="line">		parser = &amp;XmlRuleConfigParser&#123;&#125;</span><br><span class="line">	&#125; <span class="keyword">else</span> <span class="keyword">if</span> configFormat == <span class="string">&quot;yml&quot;</span> &#123;</span><br><span class="line">		parser = &amp;YamlRuleConfigParser&#123;&#125;</span><br><span class="line">	&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, errors.New(<span class="string">&quot;configFormat invalid&quot;</span>)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> parser, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> IRuleConfigParser <span class="keyword">interface</span> &#123;</span><br><span class="line">	Parse(text <span class="keyword">string</span>) (RuleConfig, error)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> JsonRuleConfigParser <span class="keyword">struct</span> &#123;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(j *JsonRuleConfigParser)</span> <span class="title">Parse</span><span class="params">(text <span class="keyword">string</span>)</span> <span class="params">(RuleConfig, error)</span></span> &#123;</span><br><span class="line">	<span class="built_in">panic</span>(<span class="string">&quot;implement me&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> YamlRuleConfigParser <span class="keyword">struct</span> &#123;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(y *YamlRuleConfigParser)</span> <span class="title">Parse</span><span class="params">(text <span class="keyword">string</span>)</span> <span class="params">(RuleConfig, error)</span></span> &#123;</span><br><span class="line">	<span class="built_in">panic</span>(<span class="string">&quot;implement me&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> XmlRuleConfigParser <span class="keyword">struct</span> &#123;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(x *XmlRuleConfigParser)</span> <span class="title">Parse</span><span class="params">(text <span class="keyword">string</span>)</span> <span class="params">(RuleConfig, error)</span></span> &#123;</span><br><span class="line">	<span class="built_in">panic</span>(<span class="string">&quot;implement me&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> RuleConfig <span class="keyword">interface</span> &#123;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure></div>
<p>还有一种简单工厂模式的实现,和单例模式相结合</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">	<span class="string">&quot;errors&quot;</span></span><br><span class="line">	<span class="string">&quot;strings&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">简单工厂模式2(Simple Factory Pattern)</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> rcpFactory2 = &amp;RuleConfigParserFactory2&#123;</span><br><span class="line">	cacheParsers: <span class="keyword">map</span>[<span class="keyword">string</span>]IRuleConfigParser&#123;</span><br><span class="line">		<span class="string">&quot;json&quot;</span>: &amp;JsonRuleConfigParser&#123;&#125;,</span><br><span class="line">		<span class="string">&quot;xml&quot;</span>:  &amp;XmlRuleConfigParser&#123;&#125;,</span><br><span class="line">		<span class="string">&quot;yaml&quot;</span>: &amp;YamlRuleConfigParser&#123;&#125;,</span><br><span class="line">	&#125;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Load2</span><span class="params">(configFormat <span class="keyword">string</span>)</span> <span class="params">(RuleConfig, error)</span></span> &#123;</span><br><span class="line">	parser, err := rcpFactory2.createParser(configFormat)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">var</span> text <span class="keyword">string</span></span><br><span class="line">	<span class="comment">// load form config file</span></span><br><span class="line">	<span class="keyword">return</span> parser.Parse(text)</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 简单工厂模式2</span></span><br><span class="line"><span class="keyword">type</span> RuleConfigParserFactory2 <span class="keyword">struct</span> &#123;</span><br><span class="line">	cacheParsers <span class="keyword">map</span>[<span class="keyword">string</span>]IRuleConfigParser</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(r *RuleConfigParserFactory2)</span> <span class="title">createParser</span><span class="params">(configFormat <span class="keyword">string</span>)</span> <span class="params">(IRuleConfigParser, error)</span></span> &#123;</span><br><span class="line">	configFormat = strings.ToLower(configFormat)</span><br><span class="line">	parser, ok := r.cacheParsers[configFormat]</span><br><span class="line">	<span class="keyword">if</span> !ok &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, errors.New(<span class="string">&quot;configFormat invalid&quot;</span>)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> parser, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure></div>
<blockquote>
<p>简单工厂模式总结：尽管简单工厂模式的代码实现中，有多处if分支判断逻辑，违背开闭原则，<br>  但权衡扩展性和可读性，这样的代码实现在大多数情况下（比如，不需要频繁地添加parser，也没有太多的parser）<br>  是没有问题的</p>
</blockquote>
<h5 id="2-工厂方法（Factory-Method）"><a href="#2-工厂方法（Factory-Method）" class="headerlink" title="2,工厂方法（Factory Method）"></a>2,工厂方法（Factory Method）</h5><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="string">&quot;errors&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">工厂方法1（Factory Method）,这种设计可以在当我们新增一种parser的时候，只需要新增一个实现了IRuleConfigParserFactory接口的Factory类即可。</span></span><br><span class="line"><span class="comment"> 所以，工厂方法模式比起简单工厂模式更加符合开闭原则</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">var</span> rcpFactory1 *RuleConfigParserFactory1</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Load1</span><span class="params">(configFormat <span class="keyword">string</span>)</span> <span class="params">(RuleConfig, error)</span></span> &#123;</span><br><span class="line">	factory, err := rcpFactory1.getFactory(configFormat)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">	&#125;</span><br><span class="line">	parser := factory.CreateParser()</span><br><span class="line">	<span class="keyword">var</span> text <span class="keyword">string</span></span><br><span class="line">	<span class="comment">// load form config file</span></span><br><span class="line">	<span class="keyword">return</span> parser.Parse(text)</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 简单工厂模式1</span></span><br><span class="line"><span class="keyword">type</span> RuleConfigParserFactory1 <span class="keyword">struct</span> &#123;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(r *RuleConfigParserFactory1)</span> <span class="title">getFactory</span><span class="params">(configFormat <span class="keyword">string</span>)</span> <span class="params">(IRuleConfigParserFactory, error)</span></span> &#123;</span><br><span class="line">	<span class="keyword">var</span> factory RuleConfigParseFactory</span><br><span class="line">	<span class="keyword">if</span> configFormat == <span class="string">&quot;json&quot;</span> &#123;</span><br><span class="line">		factory = &amp;JsonRuleConfigParserFactory&#123;&#125;</span><br><span class="line">	&#125; <span class="keyword">else</span> <span class="keyword">if</span> configFormat == <span class="string">&quot;xml&quot;</span> &#123;</span><br><span class="line">		factory = &amp;XmlRuleConfigParserFactory&#123;&#125;</span><br><span class="line">	&#125; <span class="keyword">else</span> <span class="keyword">if</span> configFormat == <span class="string">&quot;yml&quot;</span> &#123;</span><br><span class="line">		factory = &amp;YamlRuleConfigParserFactory&#123;&#125;</span><br><span class="line">	&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, errors.New(<span class="string">&quot;configFormat invalid&quot;</span>)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> factory, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> IRuleConfigParserFactory <span class="keyword">interface</span> &#123;</span><br><span class="line">	CreateParser() IRuleConfigParser</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> JsonRuleConfigParserFactory <span class="keyword">struct</span> &#123;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(j *JsonRuleConfigParserFactory)</span> <span class="title">CreateParser</span><span class="params">()</span> <span class="title">IRuleConfigParser</span></span> &#123;</span><br><span class="line">	<span class="keyword">return</span> &amp;JsonRuleConfigParser&#123;&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> YamlRuleConfigParserFactory <span class="keyword">struct</span> &#123;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(j *YamlRuleConfigParserFactory)</span> <span class="title">CreateParser</span><span class="params">()</span> <span class="title">IRuleConfigParser</span></span> &#123;</span><br><span class="line">	<span class="keyword">return</span> &amp;YamlRuleConfigParser&#123;&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> XmlRuleConfigParserFactory <span class="keyword">struct</span> &#123;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(j *XmlRuleConfigParserFactory)</span> <span class="title">CreateParser</span><span class="params">()</span> <span class="title">IRuleConfigParser</span></span> &#123;</span><br><span class="line">	<span class="keyword">return</span> &amp;XmlRuleConfigParser&#123;&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> IRuleConfigParser <span class="keyword">interface</span> &#123;</span><br><span class="line">	Parse(text <span class="keyword">string</span>) (RuleConfig, error)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> JsonRuleConfigParser <span class="keyword">struct</span> &#123;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(j *JsonRuleConfigParser)</span> <span class="title">Parse</span><span class="params">(text <span class="keyword">string</span>)</span> <span class="params">(RuleConfig, error)</span></span> &#123;</span><br><span class="line">	<span class="built_in">panic</span>(<span class="string">&quot;implement me&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> YamlRuleConfigParser <span class="keyword">struct</span> &#123;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(y *YamlRuleConfigParser)</span> <span class="title">Parse</span><span class="params">(text <span class="keyword">string</span>)</span> <span class="params">(RuleConfig, error)</span></span> &#123;</span><br><span class="line">	<span class="built_in">panic</span>(<span class="string">&quot;implement me&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> XmlRuleConfigParser <span class="keyword">struct</span> &#123;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(x *XmlRuleConfigParser)</span> <span class="title">Parse</span><span class="params">(text <span class="keyword">string</span>)</span> <span class="params">(RuleConfig, error)</span></span> &#123;</span><br><span class="line">	<span class="built_in">panic</span>(<span class="string">&quot;implement me&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> RuleConfig <span class="keyword">interface</span> &#123;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>
<p>考虑到工厂类只包含方法，不包含成员变量，所以完全可以复用，于是有了工厂方法模式的另外一种实现：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">	<span class="string">&quot;errors&quot;</span></span><br><span class="line">	<span class="string">&quot;strings&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> 工厂方法2（Factory Method）</span></span><br><span class="line"><span class="comment"> 工厂方法1中,工厂类对象的创建逻辑又耦合进了load()函数中，</span></span><br><span class="line"><span class="comment"> 跟我们最初的简单工厂模式1非常相似，引入工厂方法非但没有解决问题，反倒让设计变得更加复杂了</span></span><br><span class="line"><span class="comment"> 解决办法：</span></span><br><span class="line"><span class="comment"> 我们可以为工厂类再创建一个简单工厂，也就是工厂的工厂，用来创建工厂类对象。</span></span><br><span class="line"><span class="comment"> RuleConfigParserFactory2，</span></span><br><span class="line"><span class="comment"> getFactory()返回的是缓存好的单例工厂对象</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">var</span> rcpFactory2 = &amp;RuleConfigParserFactory2&#123;</span><br><span class="line">	m: <span class="keyword">map</span>[<span class="keyword">string</span>]RuleConfigParseFactory&#123;</span><br><span class="line">		<span class="string">&quot;json&quot;</span>: &amp;JsonRuleConfigParserFactory&#123;&#125;,</span><br><span class="line">		<span class="string">&quot;xml&quot;</span>:  &amp;XmlRuleConfigParserFactory&#123;&#125;,</span><br><span class="line">		<span class="string">&quot;yaml&quot;</span>: &amp;YamlRuleConfigParserFactory&#123;&#125;,</span><br><span class="line">	&#125;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Load2</span><span class="params">(configFormat <span class="keyword">string</span>)</span> <span class="params">(RuleConfig, error)</span></span> &#123;</span><br><span class="line">	factory, err := rcpFactory2.getFactory(configFormat)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">	&#125;</span><br><span class="line">	parser := factory.CreateParser()</span><br><span class="line">	<span class="keyword">var</span> text <span class="keyword">string</span></span><br><span class="line">	<span class="comment">// load form config file</span></span><br><span class="line">	<span class="keyword">return</span> parser.Parse(text)</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 简单工厂模式2</span></span><br><span class="line"><span class="keyword">type</span> RuleConfigParserFactory2 <span class="keyword">struct</span> &#123;</span><br><span class="line">	m <span class="keyword">map</span>[<span class="keyword">string</span>]RuleConfigParseFactory</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(r *RuleConfigParserFactory2)</span> <span class="title">getFactory</span><span class="params">(configFormat <span class="keyword">string</span>)</span> <span class="params">(RuleConfigParseFactory, error)</span></span> &#123;</span><br><span class="line">	configFormat = strings.ToLower(configFormat)</span><br><span class="line">	factory, ok := r.m[configFormat]</span><br><span class="line">	<span class="keyword">if</span> !ok &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, errors.New(<span class="string">&quot;configFormat invalid&quot;</span>)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> factory, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>
<blockquote>
<p>工厂方法模式总结:对于规则配置文件解析这个应用场景来说，工厂模式需要额外创建诸多Factory类，<br>  也会增加代码的复杂性，而且，每个Factory类只是做简单的new操作，功能非常单薄（只有一行代码），<br>  也没必要设计成独立的类，所以，在这个应用场景下，简单工厂模式简单好用，比工厂方法模式更加合适</p>
</blockquote>
<h4 id="抽象工厂（Abstract-Factory）"><a href="#抽象工厂（Abstract-Factory）" class="headerlink" title="抽象工厂（Abstract Factory）"></a>抽象工厂（Abstract Factory）</h4><blockquote>
<p>一个factory接口创建多个parser<br> <div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">抽象工厂（Abstract Factory）</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">type</span> IconfigParserFactory <span class="keyword">interface</span> &#123;</span><br><span class="line">	CreateRuleParser()</span><br><span class="line">	CreateSystemParser()</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></div></p>
</blockquote>
]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title>常用限流算法介绍及源码分析</title>
    <url>/2021/05/26/uncatalog/ckv998l9x001mv0r7ggr51u53/</url>
    <content><![CDATA[<p>漏桶和令牌桶<br><a href="https://zhuanlan.zhihu.com/p/197402205">https://zhuanlan.zhihu.com/p/197402205</a></p>
<p>过载保护<br><img src="/2021/05/26/uncatalog/ckv998l9x001mv0r7ggr51u53/img.png" alt="img.png"></p>
]]></content>
      <tags>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title>非对称加密</title>
    <url>/2021/05/06/go-practice/Asymmetric_Encryption_practice01/</url>
    <content><![CDATA[<h5 id="从一个故事开始："><a href="#从一个故事开始：" class="headerlink" title="从一个故事开始："></a>从一个<a href="http://www.youdzone.com/signature.html" title="Markdown">故事</a>开始：</h5><p>我来翻译一下这个故事：</p>
<span id="more"></span>
<p><img src="/2021/05/06/go-practice/Asymmetric_Encryption_practice01/1.png"><br>故事的主人公是 Bob，他有三个好朋友 Pat、Doug 和 Susan。<br>Bob 经常跟他们写信，因为他的信是明文传输的，在传递过程可能被人截获偷窥，<br>也可能被人截获然后又篡改了，更有可能别人伪装成 Bob 本人跟他的好朋友通信，<br>总之是不安全的。他很苦恼，经过一番苦苦探索，诶，他发现计算机安全学里有一种叫非对称加密算法的东东，<br>好像可以帮助他解决这个问题</p>
<p>说明：非对称加密算法（RSA）是内容加密的一类算法，<br>它有两个秘钥：公钥与私钥。公钥是公开的钥匙，所有人都可以知道，<br>私钥是保密的，只有持有者知道。通过公钥加密的内容，只能通过私钥解开。<br>非对称加密算法的安全性很高，但是因为计算量庞大，比较消耗性能。 好了，来看看 Bob 是怎么应用非对称加密算法与他的好朋友通信的： 1、首先 Bob 弄到了两把钥匙：公钥和私钥；<br><img src="/2021/05/06/go-practice/Asymmetric_Encryption_practice01/01.png"><br>2、Bob 自己保留下了私钥，把公钥复制成三份送给了他的三个好朋友 Pat、Doug 和 Susan；<br><img src="/2021/05/06/go-practice/Asymmetric_Encryption_practice01/2.png"><br>3、此时，Bob 总算可以安心地和他的好朋友愉快地通信了。<br>比如 Susan 要和他讨论关于去哪吃午饭的事情，<br>Susan 就可以先把自己的内容（明文）首先用 Bob 送给他的公钥做一次加密，然后把加密的内容传送给 Bob。<br>Bob 收到信后，再用自己的私钥解开信的内容；<br><img src="/2021/05/06/go-practice/Asymmetric_Encryption_practice01/3.png"><br>说明：这其实是计算机安全学里加密的概念，加密的目的是为了不让别人看到传送的内容，<br>加密的手段是通过一定的加密算法及约定的密钥进行的（比如上述用了非对称加密算法以及 Bob 的公钥），<br>而解密则需要相关的解密算法及约定的秘钥（如上述用了非对称加密算法和 Bob 自己的私钥），<br>可以看出加密是可逆的（可解密的）。</p>
<p>4、Bob 看完信后，决定给 Susan 回一封信。<br>为了防止信的内容被篡改（或者别人伪装成他的身份跟 Susan 通信），<br>他决定先对信的内容用 hash 算法做一次处理，得到一个字符串哈希值，<br>Bob 又用自己的私钥对哈希值做了一次加密得到一个签名，<br>然后把签名和信（明文的）一起发送给 Susan；<br><img src="/2021/05/06/go-practice/Asymmetric_Encryption_practice01/4.png"><br><img src="/2021/05/06/go-practice/Asymmetric_Encryption_practice01/5.png"><br><img src="/2021/05/06/go-practice/Asymmetric_Encryption_practice01/6.png"><br>说明 2：Bob 的内容实质是明文传输的，所以这个过程是可以被人截获和窥探的，<br>但是 Bob 不担心被人窥探，他担心的是内容被人篡改或者有人冒充自己跟 Susan 通信。<br>这里其实涉及到了计算机安全学中的认证概念，Bob 要向 Susan 证明通信的对方是 Bob 本人，<br>另外也需要确保自己的内容是完整的。<br>5、Susan 接收到了 Bob 的信，首先用 Bob 给的公钥对签名作了解密处理，<br>得到了哈希值 A，然后 Susan 用了同样的 Hash 算法对信的内容作了一次哈希处理，<br>得到另外一个哈希值 B，对比 A 和 B，如果这两个值是相同的，那么可以确认信就是 Bob 本人写的，并且内容没有被篡改过；<br><img src="/2021/05/06/go-practice/Asymmetric_Encryption_practice01/7.png"><br>说明：4 跟 5 其实构成了一次完整的通过数字签名进行认证的过程。<br>数字签名的过程简述为：发送方通过不可逆算法对内容 text1 进行处理（哈希），<br>得到的结果值 hash1，然后用私钥加密 hash1 得到结果值 encry1。<br>对方接收 text1 和 encry1，用公钥解密 encry1 得到 hash1，<br>然后用 text1 进行同等的不可逆处理得到 hash2，对 hash1 和 hash2 进行对比即可认证发送方。<br>6、此时，另外一种比较复杂出现了，Bob 是通过网络把公钥寄送给他的三个好朋友的，<br>有一个不怀好意的家伙 Jerry 截获了 Bob 给 Doug 的公钥。<br>Jerry 开始伪装成 Bob 跟 Doug 通信，Doug 感觉通信的对象不像是 Bob，但是他又无法确认；<br><img src="/2021/05/06/go-practice/Asymmetric_Encryption_practice01/8.png"><br>7、Bob 最终发现了自己的公钥被 Jerry 截获了，<br>他感觉自己的公钥通过网络传输给自己的小伙伴似乎也是不安全的，<br>不怀好意的家伙可以截获这个明文传输的公钥。<br>为此他想到了去第三方权威机构”证书中心”（certificate authority，简称 CA）做认证。<br>证书中心用自己的私钥对 Bob 的公钥和其它信息做了一次加密。<br>这样 Bob 通过网络将数字证书传递给他的小伙伴后，小伙伴们先用 CA 给的公钥解密证书，这样就可以安全获取 Bob 的公钥了。<br><img src="/2021/05/06/go-practice/Asymmetric_Encryption_practice01/9.png">  </p>
<h5 id="非对称加密容易误解的一个点–公钥和私钥到底哪个才是用来加密和哪个用来解密："><a href="#非对称加密容易误解的一个点–公钥和私钥到底哪个才是用来加密和哪个用来解密：" class="headerlink" title="非对称加密容易误解的一个点–公钥和私钥到底哪个才是用来加密和哪个用来解密："></a>非对称加密容易误解的一个点–<a href="https://www.zhihu.com/question/25912483" title="Markdown">公钥和私钥到底哪个才是用来加密和哪个用来解密</a>：</h5><blockquote>
<p>其中一个高赞回答：<br>不要去硬记。<br>你只要想：既然是加密，那肯定是不希望别人知道我的消息，所以只有我才能解密，所以可得出公钥负责加密，私钥负责解密；<br>同理，既然是签名，那肯定是不希望有人冒充我发消息，只有我才能发布这个签名，所以可得出私钥负责签名，公钥负责验证。</p>
</blockquote>
<h5 id="非对称加密的一个实现–RSA算法："><a href="#非对称加密的一个实现–RSA算法：" class="headerlink" title="非对称加密的一个实现–RSA算法："></a>非对称加密的一个实现–RSA算法：</h5><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> rsa_algorithm</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">	<span class="string">&quot;bytes&quot;</span></span><br><span class="line">	<span class="string">&quot;crypto/rand&quot;</span></span><br><span class="line">	<span class="string">&quot;crypto/rsa&quot;</span></span><br><span class="line">	<span class="string">&quot;crypto/x509&quot;</span></span><br><span class="line">	<span class="string">&quot;encoding/pem&quot;</span></span><br><span class="line">	<span class="string">&quot;errors&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">GenPair</span><span class="params">(bits <span class="keyword">int</span>, passwd <span class="keyword">string</span>)</span> <span class="params">(priKey, pubKey []<span class="keyword">byte</span>, err error)</span></span> &#123;</span><br><span class="line">	<span class="comment">// 生成私钥</span></span><br><span class="line">	<span class="keyword">var</span> privateKey *rsa.PrivateKey</span><br><span class="line">	<span class="keyword">if</span> privateKey, err = rsa.GenerateKey(rand.Reader, bits); err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span></span><br><span class="line">	&#125;</span><br><span class="line">	priStream := x509.MarshalPKCS1PrivateKey(privateKey)</span><br><span class="line">	block := &amp;pem.Block&#123;Type: passwd, Bytes: priStream&#125;</span><br><span class="line">	priKey = pem.EncodeToMemory(block)</span><br><span class="line">	<span class="comment">// 生成公钥</span></span><br><span class="line">	publicKey := &amp;privateKey.PublicKey</span><br><span class="line">	<span class="keyword">var</span> pubStream []<span class="keyword">byte</span></span><br><span class="line">	<span class="keyword">if</span> pubStream, err = x509.MarshalPKIXPublicKey(publicKey); err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span></span><br><span class="line">	&#125;</span><br><span class="line">	block = &amp;pem.Block&#123;Type: passwd, Bytes: pubStream&#125;</span><br><span class="line">	pubKey = pem.EncodeToMemory(block)</span><br><span class="line">	<span class="keyword">return</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Encrypt</span><span class="params">(pubKey, origData []<span class="keyword">byte</span>)</span> <span class="params">([]<span class="keyword">byte</span>, error)</span></span> &#123;</span><br><span class="line">	block, _ := pem.Decode(pubKey)</span><br><span class="line">	<span class="keyword">if</span> block == <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, errors.New(<span class="string">&quot;public key error&quot;</span>)</span><br><span class="line">	&#125;</span><br><span class="line">	publicKey, err := x509.ParsePKIXPublicKey(block.Bytes)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">	&#125;</span><br><span class="line">	pub := publicKey.(*rsa.PublicKey)</span><br><span class="line">	k := (pub.N.BitLen() + <span class="number">7</span>) / <span class="number">8</span></span><br><span class="line">	partLen := k - <span class="number">11</span></span><br><span class="line">	chunks := split(origData, partLen)</span><br><span class="line">	buf := bytes.NewBuffer(<span class="built_in">make</span>([]<span class="keyword">byte</span>, <span class="number">0</span>, k))</span><br><span class="line">	<span class="keyword">for</span> _, chunk := <span class="keyword">range</span> chunks &#123;</span><br><span class="line">		bytes, err := rsa.EncryptPKCS1v15(rand.Reader, pub, chunk)</span><br><span class="line">		<span class="comment">// fmt.Println(&quot;out chunk len:&quot;, len(bytes))</span></span><br><span class="line">		<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">			<span class="keyword">return</span> []<span class="keyword">byte</span>&#123;&#125;, err</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">if</span> _, err = buf.Write(bytes); err != <span class="literal">nil</span> &#123;</span><br><span class="line">			<span class="keyword">return</span> []<span class="keyword">byte</span>&#123;&#125;, err</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> buf.Bytes(), <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Decrypt</span><span class="params">(priKey, ciphertext []<span class="keyword">byte</span>)</span> <span class="params">([]<span class="keyword">byte</span>, error)</span></span> &#123;</span><br><span class="line">	block, _ := pem.Decode(priKey)</span><br><span class="line">	<span class="keyword">if</span> block == <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, errors.New(<span class="string">&quot;private key error!&quot;</span>)</span><br><span class="line">	&#125;</span><br><span class="line">	privateKey, err := x509.ParsePKCS1PrivateKey(block.Bytes)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">	&#125;</span><br><span class="line">	partLen := (privateKey.N.BitLen() + <span class="number">7</span>) / <span class="number">8</span></span><br><span class="line">	chunks := split([]<span class="keyword">byte</span>(ciphertext), partLen)</span><br><span class="line">	buf := bytes.NewBuffer(<span class="built_in">make</span>([]<span class="keyword">byte</span>, <span class="number">0</span>, partLen))</span><br><span class="line">	<span class="keyword">for</span> _, chunk := <span class="keyword">range</span> chunks &#123;</span><br><span class="line">		bytes, err := rsa.DecryptPKCS1v15(rand.Reader, privateKey, chunk)</span><br><span class="line">		<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">			<span class="keyword">return</span> []<span class="keyword">byte</span>&#123;&#125;, err</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">if</span> _, err = buf.Write(bytes); err != <span class="literal">nil</span> &#123;</span><br><span class="line">			<span class="keyword">return</span> []<span class="keyword">byte</span>&#123;&#125;, err</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> buf.Bytes(), <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">split</span><span class="params">(buf []<span class="keyword">byte</span>, lim <span class="keyword">int</span>)</span> [][]<span class="title">byte</span></span> &#123;</span><br><span class="line">	<span class="keyword">var</span> chunk []<span class="keyword">byte</span></span><br><span class="line">	chunks := <span class="built_in">make</span>([][]<span class="keyword">byte</span>, <span class="number">0</span>, <span class="built_in">len</span>(buf)/lim+<span class="number">1</span>)</span><br><span class="line">	<span class="keyword">for</span> <span class="built_in">len</span>(buf) &gt;= lim &#123;</span><br><span class="line">		chunk, buf = buf[:lim], buf[lim:]</span><br><span class="line">		chunks = <span class="built_in">append</span>(chunks, chunk)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">if</span> <span class="built_in">len</span>(buf) &gt; <span class="number">0</span> &#123;</span><br><span class="line">		chunks = <span class="built_in">append</span>(chunks, buf)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> chunks</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>

<h5 id="非对称加密的一个应用–https："><a href="#非对称加密的一个应用–https：" class="headerlink" title="非对称加密的一个应用–https："></a>非对称加密的一个应用–https：</h5><p>通过 Bob 与他的小伙伴的通信，我们已经可以大致了解一个安全通信的过程，<br>也可以了解基本的加密、解密、认证等概念。HTTPS 就是基于这样一个逻辑设计的。<br>首先看看组成 HTTPS 的协议：HTTP 协议和 SSL/TSL 协议。<br>HTTP 协议就不用讲了，而 SSL/TSL 就是负责加密解密等安全处理的模块，<br>所以 HTTPS 的核心在 SSL/TSL 上面。整个通信如下：   </p>
<ul>
<li>1、浏览器发起往服务器的 443 端口发起请求，请求携带了浏览器支持的加密算法和哈希算法。   </li>
<li>2、服务器收到请求，选择浏览器支持的加密算法和哈希算法。   </li>
<li>3、服务器下将数字证书返回给浏览器，这里的数字证书可以是向某个可靠机构申请的，也可以是自制的。   </li>
<li>4、浏览器进入数字证书认证环节，这一部分是浏览器内置的 TSL 完成的：  <ul>
<li>4.1 首先浏览器会从内置的证书列表中索引，找到服务器下发证书对应的机构，如果没有找到，此时就会提示用户该证书是不是由权威机构颁发，是不可信任的。如果查到了对应的机构，则取出该机构颁发的公钥.</li>
<li>4.2 用机构的证书公钥解密得到证书的内容和证书签名，内容包括网站的网址、网站的公钥、证书的有效期等。浏览器会先验证证书签名的合法性（验证过程类似上面 Bob 和 Susan 的通信）。签名通过后，浏览器验证证书记录的网址是否和当前网址是一致的，不一致会提示用户。如果网址一致会检查证书有效期，证书过期了也会提示用户。这些都通过认证时，浏览器就可以安全使用证书中的网站公钥了。</li>
<li>4.3 浏览器生成一个随机数 R，并使用网站公钥对 R 进行加密。</li>
</ul>
</li>
<li>5、浏览器将加密的 R 传送给服务器。   </li>
<li>6、服务器用自己的私钥解密得到 R。</li>
<li>7、服务器以 R 为密钥使用了对称加密算法加密网页内容并传输给浏览器。</li>
<li>8、浏览器以 R 为密钥使用之前约定好的解密算法获取网页内容。<br><img src="/2021/05/06/go-practice/Asymmetric_Encryption_practice01/10.png"><blockquote>
<p>备注 1：前 5 步其实就是 HTTPS 的握手过程，这个过程主要是认证服务端证书（内置的公钥）的合法性。<br>因为非对称加密计算量较大，整个通信过程只会用到一次非对称加密算法（主要是用来保护传输客户端生成的用于对称加密的随机数私钥）。<br>后续内容的加解密都是通过一开始约定好的对称加密算法进行的。</p>
<p>备注 2：SSL/TLS 是 HTTPS 安全性的核心模块，TLS 的前身是 SSL，TLS1.0 就是 SSL3.1，<br>TLS1.1 是 SSL3.2，TLS1.2 则是 SSL3.3。 SSL/TLS 是建立在 TCP 协议之上，因而也是应用层级别的协议。<br>其包括 TLS Record Protocol 和 TLS Handshaking Protocols 两个模块，<br>后者负责握手过程中的身份认证，前者则保证数据传输过程中的完整性和私密性</p>
</blockquote>
</li>
</ul>
]]></content>
      <categories>
        <category>GO实践</category>
      </categories>
      <tags>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title>exporter开发(上篇)</title>
    <url>/2021/10/29/uncatalog/ckvcbok080000j0r7d9f9gqjj/</url>
    <content><![CDATA[<hr>
<span id="more"></span>
<p><img src="/2021/10/29/uncatalog/ckvcbok080000j0r7d9f9gqjj/1.png"></p>
<h1 id="exporter开发-上篇"><a href="#exporter开发-上篇" class="headerlink" title="exporter开发(上篇)"></a>exporter开发(上篇)</h1><p>  上篇文章剖析了<a href="https://bugkillerpro.github.io/2021/10/27/uncatalog/ckv998l9f000qv0r7bn48dbig/" title="Markdown">node_exporter源码</a>，接下来就要自己实践下<code>exporter</code>的开发了。</p>
<h2 id="1，一个”hello-world”demo版的exporter"><a href="#1，一个”hello-world”demo版的exporter" class="headerlink" title="1，一个”hello world”demo版的exporter"></a>1，一个”hello world”demo版的exporter</h2><p>  正式开启<code>exporter</code>开发之前，我们先来个<code>exporter</code>开发的<code>hello world</code></p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">	<span class="string">&quot;fmt&quot;</span></span><br><span class="line">	<span class="string">&quot;net/http&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">HelloWorldHandler</span><span class="params">(w http.ResponseWriter, r *http.Request)</span></span> &#123;</span><br><span class="line">	fmt.Fprintf(w, <span class="string">`metric_name&#123;label_name=&quot;label_value&quot;&#125; 80`</span> )</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span> <span class="params">()</span></span> &#123;</span><br><span class="line">	http.HandleFunc(<span class="string">&quot;/metrics&quot;</span>, HelloWorldHandler)</span><br><span class="line">	http.ListenAndServe(<span class="string">&quot;:8080&quot;</span>, <span class="literal">nil</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<p>  启动起来之后，我们把它加入到prometheus的配置文件里:</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">scrape_configs:</span></span><br><span class="line">  <span class="comment"># The job name is added as a label `job=&lt;job_name&gt;` to any timeseries scraped from this config.</span></span><br><span class="line">  <span class="comment"># metrics_path defaults to &#x27;/metrics&#x27;</span></span><br><span class="line">  <span class="comment"># scheme defaults to &#x27;http&#x27;.</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;hello_world&#x27;</span></span><br><span class="line">    <span class="attr">static_configs:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">targets:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">localhost:8080</span></span><br></pre></td></tr></table></figure></div>
<p>  然后把它和prometheus都启动起来，我们看一下prometheus的采集结果：  </p>
<p>  <img src="/2021/10/29/uncatalog/ckvcbok080000j0r7d9f9gqjj/2.png"></p>
<p>  <img src="/2021/10/29/uncatalog/ckvcbok080000j0r7d9f9gqjj/3.png"></p>
<p>  到此，我们已经完成了一个简易版的自研<code>exporter</code>的<code>Demo</code>。</p>
<h2 id="2，开发exporter需要遵循的规范"><a href="#2，开发exporter需要遵循的规范" class="headerlink" title="2，开发exporter需要遵循的规范"></a>2，开发<code>exporter</code>需要遵循的规范</h2><p>  作为一个优秀的开源监控项目，Prometheus的可扩展性是非常强大的，所以才出现了各种强大的中间相关<code>exporter</code>。但是，无规矩不成方圆，<br>要接入Prometheus就要遵循它的规范，了解了这些之后，你的<code>exporter</code>开发之路将会非常顺利，因为这个规范很简单，就只有一个<code>interface</code>:  </p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> prometheus</span><br><span class="line"></span><br><span class="line"><span class="comment">// Collector is the interface implemented by anything that can be used by</span></span><br><span class="line"><span class="comment">// Prometheus to collect metrics. A Collector has to be registered for</span></span><br><span class="line"><span class="comment">// collection. See Registerer.Register.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// The stock metrics provided by this package (Gauge, Counter, Summary,</span></span><br><span class="line"><span class="comment">// Histogram, Untyped) are also Collectors (which only ever collect one metric,</span></span><br><span class="line"><span class="comment">// namely itself). An implementer of Collector may, however, collect multiple</span></span><br><span class="line"><span class="comment">// metrics in a coordinated fashion and/or create metrics on the fly. Examples</span></span><br><span class="line"><span class="comment">// for collectors already implemented in this library are the metric vectors</span></span><br><span class="line"><span class="comment">// (i.e. collection of multiple instances of the same Metric but with different</span></span><br><span class="line"><span class="comment">// label values) like GaugeVec or SummaryVec, and the ExpvarCollector.</span></span><br><span class="line"><span class="keyword">type</span> Collector <span class="keyword">interface</span> &#123;</span><br><span class="line">	<span class="comment">// Describe sends the super-set of all possible descriptors of metrics</span></span><br><span class="line">	<span class="comment">// collected by this Collector to the provided channel and returns once</span></span><br><span class="line">	<span class="comment">// the last descriptor has been sent. The sent descriptors fulfill the</span></span><br><span class="line">	<span class="comment">// consistency and uniqueness requirements described in the Desc</span></span><br><span class="line">	<span class="comment">// documentation.</span></span><br><span class="line">	<span class="comment">//</span></span><br><span class="line">	<span class="comment">// It is valid if one and the same Collector sends duplicate</span></span><br><span class="line">	<span class="comment">// descriptors. Those duplicates are simply ignored. However, two</span></span><br><span class="line">	<span class="comment">// different Collectors must not send duplicate descriptors.</span></span><br><span class="line">	<span class="comment">//</span></span><br><span class="line">	<span class="comment">// Sending no descriptor at all marks the Collector as “unchecked”,</span></span><br><span class="line">	<span class="comment">// i.e. no checks will be performed at registration time, and the</span></span><br><span class="line">	<span class="comment">// Collector may yield any Metric it sees fit in its Collect method.</span></span><br><span class="line">	<span class="comment">//</span></span><br><span class="line">	<span class="comment">// This method idempotently sends the same descriptors throughout the</span></span><br><span class="line">	<span class="comment">// lifetime of the Collector. It may be called concurrently and</span></span><br><span class="line">	<span class="comment">// therefore must be implemented in a concurrency safe way.</span></span><br><span class="line">	<span class="comment">//</span></span><br><span class="line">	<span class="comment">// If a Collector encounters an error while executing this method, it</span></span><br><span class="line">	<span class="comment">// must send an invalid descriptor (created with NewInvalidDesc) to</span></span><br><span class="line">	<span class="comment">// signal the error to the registry.</span></span><br><span class="line">	Describe(<span class="keyword">chan</span>&lt;- *Desc)</span><br><span class="line">	<span class="comment">// Collect is called by the Prometheus registry when collecting</span></span><br><span class="line">	<span class="comment">// metrics. The implementation sends each collected metric via the</span></span><br><span class="line">	<span class="comment">// provided channel and returns once the last metric has been sent. The</span></span><br><span class="line">	<span class="comment">// descriptor of each sent metric is one of those returned by Describe</span></span><br><span class="line">	<span class="comment">// (unless the Collector is unchecked, see above). Returned metrics that</span></span><br><span class="line">	<span class="comment">// share the same descriptor must differ in their variable label</span></span><br><span class="line">	<span class="comment">// values.</span></span><br><span class="line">	<span class="comment">//</span></span><br><span class="line">	<span class="comment">// This method may be called concurrently and must therefore be</span></span><br><span class="line">	<span class="comment">// implemented in a concurrency safe way. Blocking occurs at the expense</span></span><br><span class="line">	<span class="comment">// of total performance of rendering all registered metrics. Ideally,</span></span><br><span class="line">	<span class="comment">// Collector implementations support concurrent readers.</span></span><br><span class="line">	Collect(<span class="keyword">chan</span>&lt;- Metric)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<p>  这个<code>interface</code>定义在<a href="github.com/prometheus/client_golang/prometheus" title="Markdown">client_golang</a>中，<code>client_golang</code>是<code>prometheus</code>的官方<code>go</code>库,<br>既可以用于集成现有应用,也可以作为连接<code>Prometheus HTTP API</code>的基础库。<br>  <code>Collector</code>这个接口里的每个字段我都会给出详细的解析，在此之前，我们先了解几个和本章内容相关的基本概念，关于prometheus的详细内容，还需要读者自己去学习； </p>
<h3 id="2-1-Prometheus监控系统的架构图"><a href="#2-1-Prometheus监控系统的架构图" class="headerlink" title="2.1 Prometheus监控系统的架构图"></a>2.1 Prometheus监控系统的架构图</h3><p>  <img src="/2021/10/29/uncatalog/ckvcbok080000j0r7d9f9gqjj/4.png"><br>  和本篇相关的就是左下角的部分，<code>Prometheus targets</code>也就是各种的<code>exporter</code>。<br>  <code>Prometheus server</code>从各个<code>target</code>上获取采集数据的方式是<code>pull</code>，也就是通过 <code>http</code>协议向各个<code>exporter</code>发送<code>GET</code>请求，默认的路径就是<code>/metrics</code>，所以就像上面我们的<code>hello world</code>版的<code>Demo</code>一样，遵循这种规范就可以被<code>Prometheus server</code>采集到。</p>
<h3 id="2-2-数据结构"><a href="#2-2-数据结构" class="headerlink" title="2.2 数据结构"></a>2.2 数据结构</h3><p>  数据已经采集到了，但是<code>Prometheus server</code>怎么能正确的领会到我的意图呢？也就是说它怎么能正确解析出我的数据呢？<br>  那就需要我们发送的数据遵循<a href="github.com/prometheus/client_golang/prometheus" title="Markdown">client_golang</a>里定义的的数据结构的规范了。<br>  <code>Prometheus client libraries</code> 提供了四种核心的 <code>metric types</code> ，我在这里简要列举一下:</p>
<table>
<thead>
<tr>
<th>metric types</th>
<th>概念</th>
<th>用途</th>
</tr>
</thead>
<tbody><tr>
<td>Counter</td>
<td>收集的数据是按照某个趋势（增加／减少）一直变化的</td>
<td>服务请求总量、错误总数等</td>
</tr>
<tr>
<td>Gauge</td>
<td>收集的数据是一个瞬时的值，与时间没有关系，可以任意变高变低</td>
<td>当前 goroutines 的数量、内存使用率、磁盘使用率等</td>
</tr>
<tr>
<td>Histogram</td>
<td>表示一段时间范围内对数据进行采样（通常是请求持续时间或响应大小），并能够对其指定区间以及总数进行统计，通常它采集的数据展示为直方图</td>
<td>计算数据的分位数</td>
</tr>
<tr>
<td>Summary</td>
<td>和 Histogram 类似</td>
<td>同上</td>
</tr>
</tbody></table>
<p>  这里要讲一下<code>Histogram</code>和<code>Summary</code>的区别:  </p>
<ul>
<li><code>Histogram</code>，将时间范围内的数据划分成不同的时间段，并各自评估其样本个数及样本值之和，因而可以在<code>server</code>端计算出分位数;</li>
<li><code>Summary</code>，直接在客户端，也就是采集端，上报计算好的分位数；</li>
</ul>
<p>  所以，重点就在于<code>2.1</code>和<code>2.2</code>，一个定义了怎么给，另一个定义了给什么样的数据。</p>
<h2 id="3，Collector接口详解"><a href="#3，Collector接口详解" class="headerlink" title="3，Collector接口详解"></a>3，<code>Collector</code>接口详解</h2><h2 id="3-1，Collector相关的重点struct关系图"><a href="#3-1，Collector相关的重点struct关系图" class="headerlink" title="3.1，Collector相关的重点struct关系图"></a>3.1，<code>Collector</code>相关的重点<code>struct</code>关系图</h2><p><img src="/2021/10/29/uncatalog/ckvcbok080000j0r7d9f9gqjj/5.jpg"></p>
<h3 id="3-1-1，Metric"><a href="#3-1-1，Metric" class="headerlink" title="3.1.1，Metric"></a>3.1.1，<code>Metric</code></h3><p>  指标，即对单个值进行建模的结果，上面讲到的四种<code>metric types</code>都是它的具体实现，即包括我们自定义开发在内的所有<code>exporter</code>上定义的采集数据，其类型，都是<code>Metric</code>的具体实现;</p>
<ul>
<li>接口 Desc() *Desc : 返回关于Metric的描述符。</li>
<li>接口 Write(*dto.Metric) error : 将Metric编码为Protocol Buffer传输对象</li>
</ul>
<h3 id="3-1-2，Collector"><a href="#3-1-2，Collector" class="headerlink" title="3.1.2，Collector"></a>3.1.2，<code>Collector</code></h3><p> 各种<code>exporter</code>上的主要<code>struct</code>都是<code>Collector</code>的具体实现，如<a href="https://bugkillerpro.github.io/2021/10/27/uncatalog/ckv998l9f000qv0r7bn48dbig/" title="Markdown">node_exporter源码</a>中的<code>NodeCollector</code>  </p>
<ul>
<li>接口 Describe(chan&lt;- *Desc) ：传递指标描述符到 channel</li>
<li>接口 Collect(chan&lt;- Metric) : 执⾏抓取函数并返回数据，返回的数据传递到 channel 中</li>
</ul>
<h3 id="3-1-3，MetricVec"><a href="#3-1-3，MetricVec" class="headerlink" title="3.1.3，MetricVec"></a>3.1.3，<code>MetricVec</code></h3><p>用来做为‘相同指标名，不同标签值的’<code>Collector</code>，比如 采集指标名为<code>number of HTTP requests</code>的数据，可以根据<code>response code</code>和<code>method</code>来区分不同的标签值。<code>MetricVec</code>也有四种具体的实现：  </p>
<ul>
<li>GaugeVec</li>
<li>CounterVec</li>
<li>SummaryVec</li>
<li>HistogramVec</li>
</ul>
<p>下一篇文章，将通过具体的<code>exporter</code>开发代码讲述下相关的实践。</p>
]]></content>
      <tags>
        <tag>prometheus</tag>
        <tag>源码阅读</tag>
        <tag>exporter开发</tag>
      </tags>
  </entry>
  <entry>
    <title>exporter开发(下篇)</title>
    <url>/2021/10/31/uncatalog/ckveojmmm000058r7hcfo45uz/</url>
    <content><![CDATA[<hr>
<span id="more"></span>
<p><img src="/2021/10/31/uncatalog/ckveojmmm000058r7hcfo45uz/1.png"></p>
<h1 id="exporter开发-下篇"><a href="#exporter开发-下篇" class="headerlink" title="exporter开发(下篇)"></a>exporter开发(下篇)</h1><p>  准备工作已经在上篇讲过了，这里我们就直接开始撸代码</p>
<h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><p>  目录结构：<br>  .<br>  ├── collector<br>  │   └── pid.go<br>  └── main.go</p>
<p>  main.go</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">	<span class="string">&quot;custom_exporters/demo_04/collector&quot;</span></span><br><span class="line">	<span class="string">&quot;fmt&quot;</span></span><br><span class="line">	<span class="string">&quot;github.com/prometheus/client_golang/prometheus&quot;</span></span><br><span class="line">	<span class="string">&quot;github.com/prometheus/client_golang/prometheus/promhttp&quot;</span></span><br><span class="line">	<span class="string">&quot;net/http&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">	prometheus.MustRegister(collector.NewPidCollector())</span><br><span class="line">	http.Handle(<span class="string">&quot;/metrics&quot;</span>, promhttp.Handler())</span><br><span class="line">	<span class="keyword">if</span> err := http.ListenAndServe(<span class="string">&quot;:8080&quot;</span>, <span class="literal">nil</span>); err != <span class="literal">nil</span> &#123;</span><br><span class="line">		fmt.Printf(<span class="string">&quot;Error occur when start server %v&quot;</span>, err)</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>  pid.go  </p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> collector</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">  <span class="string">&quot;github.com/prometheus/client_golang/prometheus&quot;</span></span><br><span class="line">  <span class="string">&quot;github.com/shirou/gopsutil/host&quot;</span></span><br><span class="line">  <span class="string">&quot;os&quot;</span></span><br><span class="line">  <span class="string">&quot;sync&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> PidCollector <span class="keyword">struct</span> &#123;</span><br><span class="line">  pidDesc    *prometheus.Desc   <span class="comment">//当前collector的pid</span></span><br><span class="line">  mutex          sync.Mutex</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">NewPidCollector</span><span class="params">()</span><span class="title">PidCollector</span></span>  &#123;</span><br><span class="line">  <span class="keyword">return</span> PidCollector&#123;pidDesc:  prometheus.NewDesc(</span><br><span class="line">    <span class="string">&quot;cur_collector_pid&quot;</span>,</span><br><span class="line">    <span class="string">&quot;当前collector的pid&quot;</span>,</span><br><span class="line">    []<span class="keyword">string</span>&#123;<span class="string">&quot;HOST_NAME&quot;</span>&#125;,</span><br><span class="line">    <span class="literal">nil</span>)&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// Describe implements the prometheus.Collector interface.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p PidCollector)</span> <span class="title">Describe</span><span class="params">(ch <span class="keyword">chan</span>&lt;- *prometheus.Desc)</span></span> &#123;</span><br><span class="line">  ch &lt;- p.pidDesc</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Collect implements the prometheus.Collector interface.This method may be called concurrently and must therefore be</span></span><br><span class="line"><span class="comment">// implemented in a concurrency safe way</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p PidCollector)</span> <span class="title">Collect</span><span class="params">(ch <span class="keyword">chan</span>&lt;- prometheus.Metric)</span></span> &#123;</span><br><span class="line">  p.mutex.Lock()</span><br><span class="line">  <span class="keyword">defer</span> p.mutex.Unlock()</span><br><span class="line">  host,_:= host.Info()</span><br><span class="line">  ch &lt;- prometheus.MustNewConstMetric(</span><br><span class="line">    p.pidDesc,</span><br><span class="line">    prometheus.GaugeValue,</span><br><span class="line">    <span class="keyword">float64</span>(os.Getpid()),</span><br><span class="line">    host.Hostname,</span><br><span class="line">  )</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h2 id="prometheus配置"><a href="#prometheus配置" class="headerlink" title="prometheus配置"></a>prometheus配置</h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">scrape_configs:</span></span><br><span class="line">  <span class="comment"># The job name is added as a label `job=&lt;job_name&gt;` to any timeseries scraped from this config.</span></span><br><span class="line">  <span class="comment"># metrics_path defaults to &#x27;/metrics&#x27;</span></span><br><span class="line">  <span class="comment"># scheme defaults to &#x27;http&#x27;.</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;pid collector&#x27;</span></span><br><span class="line">    <span class="attr">static_configs:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">targets:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">localhost:8080</span></span><br></pre></td></tr></table></figure></div>

<h2 id="效果"><a href="#效果" class="headerlink" title="效果"></a>效果</h2><p><img src="/2021/10/31/uncatalog/ckveojmmm000058r7hcfo45uz/2.png"></p>
<p><img src="/2021/10/31/uncatalog/ckveojmmm000058r7hcfo45uz/3.png"></p>
<h2 id="结尾"><a href="#结尾" class="headerlink" title="结尾"></a>结尾</h2><p>  这只是一个简单的<code>collector</code>实践，如果有多个指标需要采集，我们就可以在 <code>XXXCollector</code>结构体里面定义多个<code>Desc</code>，具体指标值的获取，需要根据具体场景来实现。</p>
]]></content>
      <tags>
        <tag>prometheus</tag>
        <tag>源码阅读</tag>
        <tag>exporter开发</tag>
      </tags>
  </entry>
  <entry>
    <title>golang的几种协程终止方法和区别</title>
    <url>/2022/02/16/uncatalog/ckzpbwxd00000ecr7802m1nw2/</url>
    <content><![CDATA[<hr>
<span id="more"></span>
<p><img src="/2022/02/16/uncatalog/ckzpbwxd00000ecr7802m1nw2/1.png"></p>
<h1 id="return"><a href="#return" class="headerlink" title="return"></a>return</h1><p>结束当前函数,并返回指定值,defer调用会执行;</p>
<h3 id="这里需要引申出来一个知识点–return和defer的执行顺序问题-先看一段代码："><a href="#这里需要引申出来一个知识点–return和defer的执行顺序问题-先看一段代码：" class="headerlink" title="这里需要引申出来一个知识点–return和defer的执行顺序问题,先看一段代码："></a>这里需要引申出来一个知识点–return和defer的执行顺序问题,先看一段代码：</h3><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="string">&quot;fmt&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">	fmt.Println(<span class="string">&quot;f1 result: &quot;</span>, f1())</span><br><span class="line">	fmt.Println(<span class="string">&quot;------&quot;</span>)</span><br><span class="line">	fmt.Println(<span class="string">&quot;f2 result: &quot;</span>, f2())</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">f1</span><span class="params">()</span> <span class="title">int</span></span> &#123;</span><br><span class="line">	<span class="keyword">var</span> i <span class="keyword">int</span></span><br><span class="line">	<span class="keyword">defer</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">		i++</span><br><span class="line">		fmt.Println(<span class="string">&quot;f11: &quot;</span>, i)</span><br><span class="line">	&#125;()</span><br><span class="line"></span><br><span class="line">	<span class="keyword">defer</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">		i++</span><br><span class="line">		fmt.Println(<span class="string">&quot;f12: &quot;</span>, i)</span><br><span class="line">	&#125;()</span><br><span class="line"></span><br><span class="line">	i = <span class="number">1000</span></span><br><span class="line">	<span class="keyword">return</span> i</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">f2</span><span class="params">()</span> <span class="params">(i <span class="keyword">int</span>)</span></span> &#123;</span><br><span class="line">	<span class="keyword">defer</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">		i++</span><br><span class="line">		fmt.Println(<span class="string">&quot;f21: &quot;</span>, i)</span><br><span class="line">	&#125;()</span><br><span class="line"></span><br><span class="line">	<span class="keyword">defer</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">		i++</span><br><span class="line">		fmt.Println(<span class="string">&quot;f22: &quot;</span>, i)</span><br><span class="line">	&#125;()</span><br><span class="line"></span><br><span class="line">	i = <span class="number">1000</span></span><br><span class="line">	<span class="keyword">return</span> i</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<h3 id="输出"><a href="#输出" class="headerlink" title="输出:"></a>输出:</h3><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">f12:  1001</span><br><span class="line">f11:  1002</span><br><span class="line">f1 result:  1000</span><br><span class="line">------</span><br><span class="line">f22:  1001</span><br><span class="line">f21:  1002</span><br><span class="line">f2 result:  1002</span><br></pre></td></tr></table></figure></div>
<h3 id="原因"><a href="#原因" class="headerlink" title="原因:"></a>原因:</h3><ul>
<li>多个defer的执行顺序为“后进先出”</li>
<li>defer、return、返回值三者的执行逻辑应该是：<br>return最先执行，return负责将结果写入返回值中<br>接着defer开始执行一些收尾工作<br>最后函数携带当前返回值退出</li>
<li>如果函数的返回值是无名的（不带命名返回值,如上面例子中的<code>f1</code>）<br>则go语言会在执行return的时候会执行一个类似创建一个临时变量作为保存return值的动作  </li>
<li>而有名返回值的函数（如上面例子中的<code>f2</code>），由于返回值在函数定义的时候已经将该变量进行定义，<br>在执行return的时候会先执行返回值保存操作，而后续的defer函数会改变这个返回值，<br>但是由于使用的函数定义的变量，所以执行defer操作后对该变量的修改会影响到return的值</li>
</ul>
<p>针对后面两条，我们可以通过<code>go tool compile </code>工具来进行验证:</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">go tool compile -S -N -l main.go &gt; main.s //  -N -l两个命令行选项用于关闭Go编译器的优化,优化后的代码会掩盖实现细节</span><br></pre></td></tr></table></figure></div>
<p>查看<code>main.s</code>文件,重点查看一下几行:</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tr><td class="code"><pre><span class="line">0x00af 00175 (main.go:23)	MOVQ	$1000, &quot;&quot;.i+8(SP)</span><br><span class="line">0x00b8 00184 (main.go:24)	MOVQ	$1000, &quot;&quot;.~r0+144(SP) &#x2F;&#x2F; 这里就是上面所说的创建一个临时变量作为保存return值的动作</span><br><span class="line">0x00c4 00196 (main.go:24)	XCHGL	AX, AX</span><br><span class="line">0x00c5 00197 (main.go:24)	CALL	runtime.deferreturn(SB)</span><br><span class="line">0x00ca 00202 (main.go:24)	MOVQ	128(SP), BP</span><br><span class="line">0x00d2 00210 (main.go:24)	ADDQ	$136, SP</span><br><span class="line">0x00d9 00217 (main.go:24)	RET</span><br></pre></td></tr></table></figure></div>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tr><td class="code"><pre><span class="line">0x009e 00158 (main.go:38)	MOVQ	$1000, &quot;&quot;.i+136(SP)</span><br><span class="line">0x00aa 00170 (main.go:39)	XCHGL	AX, AX</span><br><span class="line">0x00ab 00171 (main.go:39)	CALL	runtime.deferreturn(SB)</span><br><span class="line">0x00b0 00176 (main.go:39)	MOVQ	120(SP), BP</span><br><span class="line">0x00b5 00181 (main.go:39)	SUBQ	$-128, SP</span><br><span class="line">0x00b9 00185 (main.go:39)	RET</span><br></pre></td></tr></table></figure></div>
<h3 id="代码解读"><a href="#代码解读" class="headerlink" title="代码解读:"></a>代码解读:</h3><p>为了弄清上述两种情况的区别，我们首先要理解return 返回值的运行机制:<br>return 并非原子操作，分为赋值，和返回值两步操作<br>f1 : 实际上return 执行了两步操作，因为返回值没有命名，<br>所以return 默认指定了一个临时变量（假设为s），首先将i赋值给s,<br>后续的操作因为是针对i,进行的，所以不会影响s, 此后因为s不会更新，<br>所以return s 不会改变，相当于：<br>var i int<br>s := i<br>return s<br>f2 : 同上，s 就相当于命名的变量i, 因为所有的操作都是基于命名变量i(s),返回值也是i,<br>所以每一次defer操作，都会更新返回值i</p>
<h1 id="runtime-Goexit"><a href="#runtime-Goexit" class="headerlink" title="runtime.Goexit()"></a>runtime.Goexit()</h1><p>结束当前<code>goroutine</code>,其他的<code>goroutine</code>不受影响,主程序也一样继续运行,<code>defer</code>会被调用;<br>如果在<code>main</code>函数中调用,则<code>main goroutine</code>终止,由于<code>main</code>函数没有<code>return</code>,则其他<code>groutine</code>会继续执行;(<code>main groutine</code>正常退出,则其他<code>groutine</code>都会退出)</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 源码注释在此</span></span><br><span class="line"><span class="comment">// Goexit terminates the goroutine that calls it. No other goroutine is affected.</span></span><br><span class="line"><span class="comment">// Goexit runs all deferred calls before terminating the goroutine. Because Goexit</span></span><br><span class="line"><span class="comment">// is not a panic, any recover calls in those deferred functions will return nil.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// Calling Goexit from the main goroutine terminates that goroutine</span></span><br><span class="line"><span class="comment">// without func main returning. Since func main has not returned,</span></span><br><span class="line"><span class="comment">// the program continues execution of other goroutines.</span></span><br><span class="line"><span class="comment">// If all other goroutines exit, the program crashes.</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></div>

<h1 id="os-Exit-code-int"><a href="#os-Exit-code-int" class="headerlink" title="os.Exit(code int)"></a>os.Exit(code int)</h1><p>会结束当前程序,不管你三七二十一。几乎不会用到</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 源码注释在此</span></span><br><span class="line"><span class="comment">// Exit causes the current program to exit with the given status code.</span></span><br><span class="line"><span class="comment">// Conventionally, code zero indicates success, non-zero an error.</span></span><br><span class="line"><span class="comment">// The program terminates immediately; deferred functions are not run.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// For portability, the status code should be in the range [0, 125].</span></span><br></pre></td></tr></table></figure></div>

<h1 id="panic-v-interface"><a href="#panic-v-interface" class="headerlink" title="panic(v interface{})"></a>panic(v interface{})</h1><p>停止当前<code>goroutine</code>的正常执行,<code>defer</code>会执行,<code>panic</code>会一直向上传递.</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 源码注释在此</span></span><br><span class="line"><span class="comment">// The panic built-in function stops normal execution of the current</span></span><br><span class="line"><span class="comment">// goroutine. When a function F calls panic, normal execution of F stops</span></span><br><span class="line"><span class="comment">// immediately. Any functions whose execution was deferred by F are run in</span></span><br><span class="line"><span class="comment">// the usual way, and then F returns to its caller. To the caller G, the</span></span><br><span class="line"><span class="comment">// invocation of F then behaves like a call to panic, terminating G&#x27;s</span></span><br><span class="line"><span class="comment">// execution and running any deferred functions. This continues until all</span></span><br><span class="line"><span class="comment">// functions in the executing goroutine have stopped, in reverse order. At</span></span><br><span class="line"><span class="comment">// that point, the program is terminated with a non-zero exit code. This</span></span><br><span class="line"><span class="comment">// termination sequence is called panicking and can be controlled by the</span></span><br><span class="line"><span class="comment">// built-in function recover.</span></span><br></pre></td></tr></table></figure></div>
<h1 id="结尾"><a href="#结尾" class="headerlink" title="结尾"></a>结尾</h1><p>多看源码，多实验，好记性不如烂笔头。</p>
]]></content>
      <tags>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title>k8s集群搭建</title>
    <url>/2022/02/17/uncatalog/ckzqm8tm30000dwr70rq7714w/</url>
    <content><![CDATA[<blockquote>
<p>网络上的教程在安装网络插件的时候,总会出问题,遂出此手把手教程.</p>
</blockquote>
<span id="more"></span>
<p><img src="/2022/02/17/uncatalog/ckzqm8tm30000dwr70rq7714w/1.png"></p>
<h1 id="k8s集群搭建-k8s安装安装网络插件"><a href="#k8s集群搭建-k8s安装安装网络插件" class="headerlink" title="k8s集群搭建/k8s安装安装网络插件"></a>k8s集群搭建/k8s安装安装网络插件</h1><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tr><td class="code"><pre><span class="line">Kubernetes 简称 k8s，是用 8 来代替 8 个字符 “ubernete” 的缩写</span><br></pre></td></tr></table></figure></div>
<p>k8s 集群大体上分为两大类：</p>
<ul>
<li>一主多从：一台 master 节点和多台 node 节点，搭建比较简单，但是有可能出现 master 单机故障</li>
<li>多主多从： 多台 master 节点和多台 node 节点，搭建比较麻烦，但是安全性高<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="TEXT"><figure class="iseeu highlight /text"><table><tr><td class="code"><pre><span class="line">不管是 一主多从 异或者是 多主多从 ，这里至少都是需要三台服务器，而且每台服务器的规格至少得在 2G内存 2颗CPU 配置起步;  </span><br></pre></td></tr></table></figure></div></li>
</ul>
<p>手把手开始搭建:</p>
<h2 id="1-环境配置"><a href="#1-环境配置" class="headerlink" title="1,环境配置"></a>1,环境配置</h2><h3 id="1-1-主机名解析"><a href="#1-1-主机名解析" class="headerlink" title="1.1 主机名解析"></a>1.1 主机名解析</h3><p>我这里有三台服务器,ip和角色分配如下：  </p>
<table>
<thead>
<tr>
<th>序号</th>
<th>ip</th>
<th>角色</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>192.168.161.111</td>
<td>master</td>
</tr>
<tr>
<td>2</td>
<td>192.168.209.156</td>
<td>node1</td>
</tr>
<tr>
<td>3</td>
<td>192.168.209.157</td>
<td>node2</td>
</tr>
</tbody></table>
<hr>
<p>为了集群节点间的直接调用，我们需要配置一下主机名解析，分别在三台服务器上编辑 <code>/etc/hosts</code>,添加一下内容:  </p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">192.168.161.111 master</span><br><span class="line">192.168.209.156 node1</span><br><span class="line">192.168.209.157 node2</span><br></pre></td></tr></table></figure></div>

<h3 id="1-2-同步时间"><a href="#1-2-同步时间" class="headerlink" title="1.2 同步时间"></a>1.2 同步时间</h3><p>集群中的时间必须要精确一致，我们可以直接使用<code>chronyd</code>服务从网络同步时间，三台服务器需做同样的操作  </p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">systemctl start chroynd </span><br><span class="line">systemctl enable chroynd</span><br></pre></td></tr></table></figure></div>

<h3 id="1-3-禁用iptables和firewalld服务"><a href="#1-3-禁用iptables和firewalld服务" class="headerlink" title="1.3 禁用iptables和firewalld服务"></a>1.3 禁用iptables和firewalld服务</h3><p>kubernetes和docker在运行中会产生大量的iptables规则，为了不让系统规则跟它们混淆，直接关闭系统的规则。三台虚拟机需做同样操作</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 关闭firewalld服务</span></span><br><span class="line">systemctl stop firewalld </span><br><span class="line">systemctl disable firewallld</span><br><span class="line"><span class="meta">#</span><span class="bash"> 关闭iptables服务</span></span><br><span class="line">systemctl stop iptables</span><br><span class="line">systemctl disable iptables</span><br></pre></td></tr></table></figure></div>

<h3 id="1-4-禁用selinux"><a href="#1-4-禁用selinux" class="headerlink" title="1.4 禁用selinux"></a>1.4 禁用selinux</h3><p>selinux是linux系统下的一个安全服务，如果不关闭它，在安装集群中会产生各种各样的奇葩问题</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 永久关闭</span></span><br><span class="line">sed -i &#x27;s/enforcing/disabled/&#x27; /etc/selinux/config</span><br><span class="line"><span class="meta">#</span><span class="bash"> 临时关闭</span></span><br><span class="line">setenforce 0</span><br></pre></td></tr></table></figure></div>

<h3 id="1-5-禁用swap分区"><a href="#1-5-禁用swap分区" class="headerlink" title="1.5 禁用swap分区"></a>1.5 禁用swap分区</h3><p>swap分区指的是虚拟内存分区，它的作用是在物理内存使用完之后，将磁盘空间虚拟成内存来使用启用swap设备会对系统的性能产生非常负面的影响，<br>因此kubernetes要求每个节点都要禁用swap设备但是如果因为某些原因确实不能关闭swap分区，就需要在集群安装过程中通过明确的参数进行配置说明</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 永久关闭 ,注释掉swap那一行</span></span><br><span class="line">vim /etc/fstab</span><br><span class="line"><span class="meta">#</span><span class="bash"> 临时关闭</span></span><br><span class="line">swapoff -a</span><br></pre></td></tr></table></figure></div>
<h3 id="1-6-修改Linux的内核参数"><a href="#1-6-修改Linux的内核参数" class="headerlink" title="1.6 修改Linux的内核参数"></a>1.6 修改Linux的内核参数</h3><p>我们需要修改linux的内核参数，添加网桥过滤和地址转发功能，<br>编辑<code>/etc/sysctl.d/kubernetes.conf</code>文件，添加如下配置</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1</span><br><span class="line">net.ipv4.ip_forward = 1</span><br></pre></td></tr></table></figure></div>
<p>添加后进行以下操作：<br> <div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 重新加载配置</span></span><br><span class="line">sysctl -p</span><br><span class="line"><span class="meta">#</span><span class="bash"> 加载网桥过滤模块</span></span><br><span class="line">modprobe br_netfilter</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看网桥过滤模块是否加载成功</span></span><br><span class="line">lsmod | grep br_netfilter</span><br></pre></td></tr></table></figure></div></p>
<h3 id="1-7-配置-ipvs-功能"><a href="#1-7-配置-ipvs-功能" class="headerlink" title="1.7 配置 ipvs 功能"></a>1.7 配置 ipvs 功能</h3><p>在kubernetes中service有两种代理模型，一种是基于iptables的，一种是基于ipvs的 相比较的话，<br>ipvs的性能明显要高一些，但是如果要使用它，需要手动载入ipvs模块</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 安装ipset和ipvsadm</span></span><br><span class="line">yum install ipset ipvsadmin -y</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 添加需要加载的模块写入脚本文件</span></span><br><span class="line">cat &lt;&lt;EOF &gt; /etc/sysconfig/modules/ipvs.modules</span><br><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line">modprobe -- ip_vs</span><br><span class="line">modprobe -- ip_vs_rr</span><br><span class="line">modprobe -- ip_vs_wrr</span><br><span class="line">modprobe -- ip_vs_sh</span><br><span class="line">modprobe -- nf_conntrack_ipv4</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 为脚本文件添加执行权限</span></span><br><span class="line">chmod +x /etc/sysconfig/modules/ipvs.modules</span><br><span class="line"> /bin/bash /etc/sysconfig/modules/ipvs.modules</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看对应的模块是否加载成功</span></span><br><span class="line"> lsmod | grep -e ip_vs -e nf_conntrack_ipv4</span><br></pre></td></tr></table></figure></div>
<p>完成以上配置后重启服务器 ：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">reboot</span><br></pre></td></tr></table></figure></div>

<h2 id="2-docker安装"><a href="#2-docker安装" class="headerlink" title="2,docker安装"></a>2,docker安装</h2><ul>
<li>1.Linux要求内核3.0以上</li>
<li>2.CentOS 7</li>
</ul>
<h3 id="2-1-环境查看"><a href="#2-1-环境查看" class="headerlink" title="2.1 环境查看"></a>2.1 环境查看</h3><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">系统内核要求3.0以上</span></span><br><span class="line">[root@localhost ~]# uname -r</span><br><span class="line">3.10.0-1062.el7.x86_64</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">系统版本</span></span><br><span class="line">[root@localhost ~]# cat /etc/os-release </span><br><span class="line">NAME=&quot;CentOS Linux&quot;</span><br><span class="line">VERSION=&quot;7 (Core)&quot;</span><br><span class="line">ID=&quot;centos&quot;</span><br><span class="line">ID_LIKE=&quot;rhel fedora&quot;</span><br><span class="line">VERSION_ID=&quot;7&quot;</span><br><span class="line">PRETTY_NAME=&quot;CentOS Linux 7 (Core)&quot;</span><br><span class="line">ANSI_COLOR=&quot;0;31&quot;</span><br><span class="line">CPE_NAME=&quot;cpe:/o:centos:centos:7&quot;</span><br><span class="line">HOME_URL=&quot;https://www.centos.org/&quot;</span><br><span class="line">BUG_REPORT_URL=&quot;https://bugs.centos.org/&quot;</span><br><span class="line"></span><br><span class="line">CENTOS_MANTISBT_PROJECT=&quot;CentOS-7&quot;</span><br><span class="line">CENTOS_MANTISBT_PROJECT_VERSION=&quot;7&quot;</span><br><span class="line">REDHAT_SUPPORT_PRODUCT=&quot;centos&quot;</span><br><span class="line">REDHAT_SUPPORT_PRODUCT_VERSION=&quot;7&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>

<h3 id="2-2-安装"><a href="#2-2-安装" class="headerlink" title="2.2 安装"></a>2.2 安装</h3><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">1.卸载旧版本</span></span><br><span class="line"> yum remove docker \</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">                   docker-client \</span></span><br><span class="line"><span class="bash">&gt;                   docker-client-latest \</span></span><br><span class="line"><span class="bash">&gt;                   docker-common \</span></span><br><span class="line"><span class="bash">&gt;                   docker-latest \</span></span><br><span class="line"><span class="bash">&gt;                   docker-latest-logrotate \</span></span><br><span class="line"><span class="bash">&gt;                   docker-logrotate \</span></span><br><span class="line"><span class="bash">&gt;                   docker-engine</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">2.需要的安装包</span></span><br><span class="line">yum install -y yum-utils</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">3.设置镜像的仓库</span></span><br><span class="line">yum-config-manager \</span><br><span class="line">    --add-repo \</span><br><span class="line">    https://download.docker.com/linux/centos/docker-ce.repo</span><br><span class="line"><span class="meta">#</span><span class="bash">上述方法默认是从国外的，不推荐</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">推荐使用国内的</span></span><br><span class="line">yum-config-manager \</span><br><span class="line">    --add-repo \</span><br><span class="line">    https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</span><br><span class="line">  </span><br><span class="line"><span class="meta">#</span><span class="bash">更新软件包索引</span></span><br><span class="line">yum makecache fast</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">4.安装docker docker-ce 社区版 而ee是企业版</span></span><br><span class="line">yum install docker-ce docker-ce-cli containerd.io # 这里我们使用社区版即可</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">5.启动docker</span></span><br><span class="line">systemctl start docker</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">6.使用docker version 查看是否安装成功</span></span><br><span class="line">docker version</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">7.测试</span></span><br><span class="line">docker run hello-world</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">8.查看一下下载的hello-world镜像</span></span><br><span class="line">[root@localhost /]# docker images</span><br><span class="line">REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">hello-world         latest              bf756fb1ae65        5 months ago        13.3kB</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>

<h2 id="3-k8s集群初始化"><a href="#3-k8s集群初始化" class="headerlink" title="3,k8s集群初始化"></a>3,k8s集群初始化</h2><h3 id="3-1-由于-kubernetes-的镜像源在国外，速度比较慢，因此我们需要切换成国内的镜像源"><a href="#3-1-由于-kubernetes-的镜像源在国外，速度比较慢，因此我们需要切换成国内的镜像源" class="headerlink" title="3.1 由于 kubernetes 的镜像源在国外，速度比较慢，因此我们需要切换成国内的镜像源"></a>3.1 由于 <code>kubernetes</code> 的镜像源在国外，速度比较慢，因此我们需要切换成国内的镜像源</h3><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 编辑 /etc/yum.repos.d/kubernetes.repo 添加一下配置</span></span><br><span class="line">vim /etc/yum.repos.d/kubernetes.repo</span><br><span class="line">[kubernetes]</span><br><span class="line">name=Kubernetes</span><br><span class="line">baseurl=http://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=0</span><br><span class="line">repo_gpgcheck=0</span><br><span class="line">gpgkey=http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg</span><br><span class="line">http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg</span><br></pre></td></tr></table></figure></div>

<h3 id="3-2-然后安装kubeadm、kubelet和kubectl-三个组件"><a href="#3-2-然后安装kubeadm、kubelet和kubectl-三个组件" class="headerlink" title="3.2 然后安装kubeadm、kubelet和kubectl 三个组件"></a>3.2 然后安装<code>kubeadm</code>、<code>kubelet</code>和<code>kubectl</code> 三个组件</h3><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">yum install --setopt=obsoletes=0 kubeadm-1.17.4-0 kubelet-1.17.4-0 kubectl-1.17.4-0 -y</span><br></pre></td></tr></table></figure></div>
<h3 id="3-3-配置-kubelet-的group"><a href="#3-3-配置-kubelet-的group" class="headerlink" title="3.3 配置 kubelet 的group"></a>3.3 配置 kubelet 的group</h3><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 编辑 /etc/sysconfig/kubelet，添加下面的配置</span></span><br><span class="line">KUBELET_CGROUP_ARGS=&quot;--cgroup-driver=systemd&quot;</span><br><span class="line">KUBE_PROXY_MODE=&quot;ipvs&quot;</span><br></pre></td></tr></table></figure></div>

<h3 id="3-4-初始化集群，仅在master上执行此步骤"><a href="#3-4-初始化集群，仅在master上执行此步骤" class="headerlink" title="3.4 初始化集群，仅在master上执行此步骤"></a>3.4 初始化集群，仅在<code>master</code>上执行此步骤</h3><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建集群</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 由于默认拉取镜像地址 k8s.gcr.io 国内无法访问，这里指定阿里云镜像仓库地址</span></span><br><span class="line">[root@master ~]# kubeadm init \</span><br><span class="line">--apiserver-advertise-address=192.168.161.1111 \</span><br><span class="line">--image-repository registry.aliyuncs.com/google_containers \</span><br><span class="line">--kubernetes-version=v1.17.4 \</span><br><span class="line">--pod-network-cidr=10.244.0.0/16 \</span><br><span class="line">--service-cidr=10.96.0.0/12 </span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">使用 kubectl 工具</span></span><br><span class="line">[root@master ~]# mkdir -p $HOME/.kube</span><br><span class="line">[root@master ~]# sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">[root@master ~]# sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br></pre></td></tr></table></figure></div>

<h3 id="3-5-把node节点加入集群"><a href="#3-5-把node节点加入集群" class="headerlink" title="3.5 把node节点加入集群"></a>3.5 把<code>node</code>节点加入集群</h3><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> token 在上一步的结果中</span></span><br><span class="line">kubeadm join 192.168.108.100:6443 --token xxx \ </span><br><span class="line">--discovery-token-ca-cert-hash sha256:xxx</span><br></pre></td></tr></table></figure></div>
<h3 id="3-6-安装网络插件，这一步也是很多教程都会出错的地方"><a href="#3-6-安装网络插件，这一步也是很多教程都会出错的地方" class="headerlink" title="3.6 安装网络插件，这一步也是很多教程都会出错的地方"></a>3.6 安装网络插件，这一步也是很多教程都会出错的地方</h3><p>kubernetes支持多种网络插件，比如flannel、calico、canal等等，这里选择使用flanne<br>下载 flanneld-v0.13.0-amd64.docker ：<a href="https://github.com/flannel-io/flannel/releases/" title="Markdown">下载地址</a><br>下载完成后，上传至 master 服务器 执行以下命令</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">docker load &lt; flanneld-v0.13.0-amd64.docker</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看镜像，flannel</span></span><br><span class="line">docker images</span><br></pre></td></tr></table></figure></div>
<p>然后我们需要获取flannel的配置文件来部署 flannel 服务</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 这里往往会失败，往下看</span></span><br><span class="line">wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml</span><br></pre></td></tr></table></figure></div>
<p>但是由于众所周知的网络的原因，这个文件并不能保证网络插件安装成功，所以我在这里准备了一个文件，镜像地址已经更换阿里数据源；</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">wget https://github.com/BugKillerPro/blog_config_files/blob/main/kube-flannel.yml</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 使用配置文件启动fannel</span></span><br><span class="line">kubectl apply -f kube-flannel.yml</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看集群节点的状态</span></span><br><span class="line">kubectl get nodes</span><br></pre></td></tr></table></figure></div>
<p><img src="/2022/02/17/uncatalog/ckzqm8tm30000dwr70rq7714w/img_1.png" alt="img_1.png"></p>
<p>STATUS全部Ready就成功了，网上的其他教程，问题大都无法全部Ready.</p>
<h2 id="3-k8s集群测试"><a href="#3-k8s集群测试" class="headerlink" title="3,k8s集群测试"></a>3,k8s集群测试</h2><p>集群已搭建完成，我们再创建一个Nginx服务测试下</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">创建一个nginx服务</span></span><br><span class="line">kubectl create deployment nginx  --image=nginx:1.14-alpine</span><br><span class="line"><span class="meta">#</span><span class="bash">暴露端口</span></span><br><span class="line">kubectl expose deploy nginx  --port=80 --target-port=80  --type=NodePort</span><br><span class="line"><span class="meta">#</span><span class="bash">查看服务</span></span><br><span class="line">kubectl get pod,svc</span><br></pre></td></tr></table></figure></div>
<p><img src="/2022/02/17/uncatalog/ckzqm8tm30000dwr70rq7714w/img_2.png" alt="img_2.png"></p>
<p><img src="/2022/02/17/uncatalog/ckzqm8tm30000dwr70rq7714w/img_3.png" alt="img_3.png"></p>
]]></content>
      <tags>
        <tag>云原生基础系列</tag>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>云原生基础系列之Kubernetes(三)资源管理</title>
    <url>/2022/06/09/uncatalog/cl46zbaxk00017or7fpbp30br/</url>
    <content><![CDATA[<hr>
<span id="more"></span>



<hr>
<h3 id="3-资源管理"><a href="#3-资源管理" class="headerlink" title="3. 资源管理"></a>3. 资源管理</h3><h4 id="3-1-资源管理介绍"><a href="#3-1-资源管理介绍" class="headerlink" title="3.1 资源管理介绍"></a>3.1 资源管理介绍</h4><p>在kubernetes中，所有的内容都抽象为资源，用户需要通过操作资源来管理kubernetes。</p>
<blockquote>
<p>kubernetes的本质上就是一个集群系统，用户可以在集群中部署各种服务，所谓的部署服务，其实就是在kubernetes集群中运行一个个的容器，并将指定的程序跑在容器中。</p>
<p>kubernetes的最小管理单元是pod而不是容器，所以只能将容器放在<code>Pod</code>中，而kubernetes一般也不会直接管理Pod，而是通过<code>Pod控制器</code>来管理Pod的。</p>
<p>Pod可以提供服务之后，就要考虑如何访问Pod中服务，kubernetes提供了<code>Service</code>资源实现这个功能。</p>
<p>当然，如果Pod中程序的数据需要持久化，kubernetes还提供了各种<code>存储</code>系统。</p>
</blockquote>
<p><img src="/2022/06/09/uncatalog/cl46zbaxk00017or7fpbp30br/image-20200406225334627.png" alt="image-20200406225334627"></p>
<blockquote>
<p>学习kubernetes的核心，就是学习如何对集群上的<code>Pod、Pod控制器、Service、存储</code>等各种资源进行操作</p>
</blockquote>
<h4 id="3-2-YAML语言介绍"><a href="#3-2-YAML语言介绍" class="headerlink" title="3.2 YAML语言介绍"></a>3.2 YAML语言介绍</h4><p>YAML是一个类似 XML、JSON 的标记性语言。它强调以<strong>数据</strong>为中心，并不是以标识语言为重点。因而YAML本身的定义比较简单，号称”一种人性化的数据格式语言”。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tr><td class="code"><pre><span class="line">&lt;heima&gt;</span><br><span class="line">    &lt;age&gt;15&lt;&#x2F;age&gt;</span><br><span class="line">    &lt;address&gt;Beijing&lt;&#x2F;address&gt;</span><br><span class="line">&lt;&#x2F;heima&gt;</span><br></pre></td></tr></table></figure></div>

<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tr><td class="code"><pre><span class="line">heima:</span><br><span class="line">  age: 15</span><br><span class="line">  address: Beijing</span><br></pre></td></tr></table></figure></div>

<p>YAML的语法比较简单，主要有下面几个：</p>
<ul>
<li>大小写敏感</li>
<li>使用缩进表示层级关系</li>
<li>缩进不允许使用tab，只允许空格( 低版本限制 )</li>
<li>缩进的空格数不重要，只要相同层级的元素左对齐即可</li>
<li>‘#’表示注释</li>
</ul>
<p>YAML支持以下几种数据类型：</p>
<ul>
<li>纯量：单个的、不可再分的值</li>
<li>对象：键值对的集合，又称为映射（mapping）/ 哈希（hash） / 字典（dictionary）</li>
<li>数组：一组按次序排列的值，又称为序列（sequence） / 列表（list）</li>
</ul>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YML"><figure class="iseeu highlight /yml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 纯量, 就是指的一个简单的值，字符串、布尔值、整数、浮点数、Null、时间、日期</span></span><br><span class="line"><span class="comment"># 1 布尔类型</span></span><br><span class="line"><span class="attr">c1:</span> <span class="literal">true</span> <span class="string">(或者True)</span></span><br><span class="line"><span class="comment"># 2 整型</span></span><br><span class="line"><span class="attr">c2:</span> <span class="number">234</span></span><br><span class="line"><span class="comment"># 3 浮点型</span></span><br><span class="line"><span class="attr">c3:</span> <span class="number">3.14</span></span><br><span class="line"><span class="comment"># 4 null类型 </span></span><br><span class="line"><span class="attr">c4:</span> <span class="string">~</span>  <span class="comment"># 使用~表示null</span></span><br><span class="line"><span class="comment"># 5 日期类型</span></span><br><span class="line"><span class="attr">c5:</span> <span class="number">2018-02-17</span>    <span class="comment"># 日期必须使用ISO 8601格式，即yyyy-MM-dd</span></span><br><span class="line"><span class="comment"># 6 时间类型</span></span><br><span class="line"><span class="attr">c6:</span> <span class="number">2018-02-17T15:02:31+08:00</span>  <span class="comment"># 时间使用ISO 8601格式，时间和日期之间使用T连接，最后使用+代表时区</span></span><br><span class="line"><span class="comment"># 7 字符串类型</span></span><br><span class="line"><span class="attr">c7:</span> <span class="string">heima</span>     <span class="comment"># 简单写法，直接写值 , 如果字符串中间有特殊字符，必须使用双引号或者单引号包裹 </span></span><br><span class="line"><span class="attr">c8:</span> <span class="string">line1</span></span><br><span class="line">    <span class="string">line2</span>     <span class="comment"># 字符串过多的情况可以拆成多行，每一行会被转化成一个空格</span></span><br></pre></td></tr></table></figure></div>



<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 对象</span></span><br><span class="line"><span class="comment"># 形式一(推荐):</span></span><br><span class="line"><span class="attr">heima:</span></span><br><span class="line">  <span class="attr">age:</span> <span class="number">15</span></span><br><span class="line">  <span class="attr">address:</span> <span class="string">Beijing</span></span><br><span class="line"><span class="comment"># 形式二(了解):</span></span><br><span class="line"><span class="attr">heima:</span> &#123;<span class="attr">age:</span> <span class="number">15</span>,<span class="attr">address:</span> <span class="string">Beijing</span>&#125;</span><br></pre></td></tr></table></figure></div>

<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 数组</span></span><br><span class="line"><span class="comment"># 形式一(推荐):</span></span><br><span class="line"><span class="attr">address:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">顺义</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">昌平</span>  </span><br><span class="line"><span class="comment"># 形式二(了解):</span></span><br><span class="line"><span class="attr">address:</span> [<span class="string">顺义</span>,<span class="string">昌平</span>]</span><br></pre></td></tr></table></figure></div>

<blockquote>
<p>小提示：</p>
<p>1 书写yaml切记<code>:</code> 后面要加一个空格</p>
<p>2 如果需要将多段yaml配置放在一个文件中，中间要使用<code>---</code>分隔</p>
<p>3 下面是一个yaml转json的网站，可以通过它验证yaml是否书写正确</p>
<p><a href="https://www.json2yaml.com/convert-yaml-to-json">https://www.json2yaml.com/convert-yaml-to-json</a></p>
</blockquote>
<h4 id="3-3-资源管理方式"><a href="#3-3-资源管理方式" class="headerlink" title="3.3 资源管理方式"></a>3.3 资源管理方式</h4><ul>
<li><p>命令式对象管理：直接使用命令去操作kubernetes资源</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="POWERSHELL"><figure class="iseeu highlight /powershell"><table><tr><td class="code"><pre><span class="line">kubectl run nginx<span class="literal">-pod</span> -<span class="literal">-image</span>=nginx:<span class="number">1.17</span>.<span class="number">1</span> -<span class="literal">-port</span>=<span class="number">80</span></span><br></pre></td></tr></table></figure></div></li>
<li><p>命令式对象配置：通过命令配置和配置文件去操作kubernetes资源</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="POWERSHELL"><figure class="iseeu highlight /powershell"><table><tr><td class="code"><pre><span class="line">kubectl create/patch <span class="operator">-f</span> nginx<span class="literal">-pod</span>.yaml</span><br></pre></td></tr></table></figure></div></li>
<li><p>声明式对象配置：通过apply命令和配置文件去操作kubernetes资源</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="POWERSHELL"><figure class="iseeu highlight /powershell"><table><tr><td class="code"><pre><span class="line">kubectl apply <span class="operator">-f</span> nginx<span class="literal">-pod</span>.yaml</span><br></pre></td></tr></table></figure></div></li>
</ul>
<table>
<thead>
<tr>
<th align="left">类型</th>
<th align="left">操作对象</th>
<th align="left">适用环境</th>
<th align="left">优点</th>
<th align="left">缺点</th>
</tr>
</thead>
<tbody><tr>
<td align="left">命令式对象管理</td>
<td align="left">对象</td>
<td align="left">测试</td>
<td align="left">简单</td>
<td align="left">只能操作活动对象，无法审计、跟踪</td>
</tr>
<tr>
<td align="left">命令式对象配置</td>
<td align="left">文件</td>
<td align="left">开发</td>
<td align="left">可以审计、跟踪</td>
<td align="left">项目大时，配置文件多，操作麻烦</td>
</tr>
<tr>
<td align="left">声明式对象配置</td>
<td align="left">目录</td>
<td align="left">开发</td>
<td align="left">支持目录操作</td>
<td align="left">意外情况下难以调试</td>
</tr>
</tbody></table>
<h5 id="3-3-1-命令式对象管理"><a href="#3-3-1-命令式对象管理" class="headerlink" title="3.3.1 命令式对象管理"></a>3.3.1 命令式对象管理</h5><p><strong>kubectl命令</strong></p>
<p>kubectl是kubernetes集群的命令行工具，通过它能够对集群本身进行管理，并能够在集群上进行容器化应用的安装部署。kubectl命令的语法如下：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tr><td class="code"><pre><span class="line">kubectl [command] [type] [name] [flags]</span><br></pre></td></tr></table></figure></div>

<p><strong>comand</strong>：指定要对资源执行的操作，例如create、get、delete</p>
<p><strong>type</strong>：指定资源类型，比如deployment、pod、service</p>
<p><strong>name</strong>：指定资源的名称，名称大小写敏感</p>
<p><strong>flags</strong>：指定额外的可选参数</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 查看所有pod</span></span><br><span class="line">kubectl get pod </span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看某个pod</span></span><br><span class="line">kubectl get pod pod_name</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看某个pod,以yaml格式展示结果</span></span><br><span class="line">kubectl get pod pod_name -o yaml</span><br></pre></td></tr></table></figure></div>

<p><strong>资源类型</strong></p>
<p>kubernetes中所有的内容都抽象为资源，可以通过下面的命令进行查看:</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tr><td class="code"><pre><span class="line">kubectl api-resources</span><br></pre></td></tr></table></figure></div>

<p>经常使用的资源有下面这些：</p>
<table>
<thead>
<tr>
<th align="left">资源分类</th>
<th align="left">资源名称</th>
<th align="left">缩写</th>
<th align="left">资源作用</th>
</tr>
</thead>
<tbody><tr>
<td align="left">集群级别资源</td>
<td align="left">nodes</td>
<td align="left">no</td>
<td align="left">集群组成部分</td>
</tr>
<tr>
<td align="left">namespaces</td>
<td align="left">ns</td>
<td align="left">隔离Pod</td>
<td align="left"></td>
</tr>
<tr>
<td align="left">pod资源</td>
<td align="left">pods</td>
<td align="left">po</td>
<td align="left">装载容器</td>
</tr>
<tr>
<td align="left">pod资源控制器</td>
<td align="left">replicationcontrollers</td>
<td align="left">rc</td>
<td align="left">控制pod资源</td>
</tr>
<tr>
<td align="left"></td>
<td align="left">replicasets</td>
<td align="left">rs</td>
<td align="left">控制pod资源</td>
</tr>
<tr>
<td align="left"></td>
<td align="left">deployments</td>
<td align="left">deploy</td>
<td align="left">控制pod资源</td>
</tr>
<tr>
<td align="left"></td>
<td align="left">daemonsets</td>
<td align="left">ds</td>
<td align="left">控制pod资源</td>
</tr>
<tr>
<td align="left"></td>
<td align="left">jobs</td>
<td align="left"></td>
<td align="left">控制pod资源</td>
</tr>
<tr>
<td align="left"></td>
<td align="left">cronjobs</td>
<td align="left">cj</td>
<td align="left">控制pod资源</td>
</tr>
<tr>
<td align="left"></td>
<td align="left">horizontalpodautoscalers</td>
<td align="left">hpa</td>
<td align="left">控制pod资源</td>
</tr>
<tr>
<td align="left"></td>
<td align="left">statefulsets</td>
<td align="left">sts</td>
<td align="left">控制pod资源</td>
</tr>
<tr>
<td align="left">服务发现资源</td>
<td align="left">services</td>
<td align="left">svc</td>
<td align="left">统一pod对外接口</td>
</tr>
<tr>
<td align="left"></td>
<td align="left">ingress</td>
<td align="left">ing</td>
<td align="left">统一pod对外接口</td>
</tr>
<tr>
<td align="left">存储资源</td>
<td align="left">volumeattachments</td>
<td align="left"></td>
<td align="left">存储</td>
</tr>
<tr>
<td align="left"></td>
<td align="left">persistentvolumes</td>
<td align="left">pv</td>
<td align="left">存储</td>
</tr>
<tr>
<td align="left"></td>
<td align="left">persistentvolumeclaims</td>
<td align="left">pvc</td>
<td align="left">存储</td>
</tr>
<tr>
<td align="left">配置资源</td>
<td align="left">configmaps</td>
<td align="left">cm</td>
<td align="left">配置</td>
</tr>
<tr>
<td align="left"></td>
<td align="left">secrets</td>
<td align="left"></td>
<td align="left">配置</td>
</tr>
</tbody></table>
<p><strong>操作</strong></p>
<p>kubernetes允许对资源进行多种操作，可以通过–help查看详细的操作命令</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tr><td class="code"><pre><span class="line">kubectl --help</span><br></pre></td></tr></table></figure></div>

<p>经常使用的操作有下面这些：</p>
<table>
<thead>
<tr>
<th align="left">命令分类</th>
<th align="left">命令</th>
<th align="left">翻译</th>
<th align="left">命令作用</th>
</tr>
</thead>
<tbody><tr>
<td align="left">基本命令</td>
<td align="left">create</td>
<td align="left">创建</td>
<td align="left">创建一个资源</td>
</tr>
<tr>
<td align="left"></td>
<td align="left">edit</td>
<td align="left">编辑</td>
<td align="left">编辑一个资源</td>
</tr>
<tr>
<td align="left"></td>
<td align="left">get</td>
<td align="left">获取</td>
<td align="left">获取一个资源</td>
</tr>
<tr>
<td align="left"></td>
<td align="left">patch</td>
<td align="left">更新</td>
<td align="left">更新一个资源</td>
</tr>
<tr>
<td align="left"></td>
<td align="left">delete</td>
<td align="left">删除</td>
<td align="left">删除一个资源</td>
</tr>
<tr>
<td align="left"></td>
<td align="left">explain</td>
<td align="left">解释</td>
<td align="left">展示资源文档</td>
</tr>
<tr>
<td align="left">运行和调试</td>
<td align="left">run</td>
<td align="left">运行</td>
<td align="left">在集群中运行一个指定的镜像</td>
</tr>
<tr>
<td align="left"></td>
<td align="left">expose</td>
<td align="left">暴露</td>
<td align="left">暴露资源为Service</td>
</tr>
<tr>
<td align="left"></td>
<td align="left">describe</td>
<td align="left">描述</td>
<td align="left">显示资源内部信息</td>
</tr>
<tr>
<td align="left"></td>
<td align="left">logs</td>
<td align="left">日志输出容器在 pod 中的日志</td>
<td align="left">输出容器在 pod 中的日志</td>
</tr>
<tr>
<td align="left"></td>
<td align="left">attach</td>
<td align="left">缠绕进入运行中的容器</td>
<td align="left">进入运行中的容器</td>
</tr>
<tr>
<td align="left"></td>
<td align="left">exec</td>
<td align="left">执行容器中的一个命令</td>
<td align="left">执行容器中的一个命令</td>
</tr>
<tr>
<td align="left"></td>
<td align="left">cp</td>
<td align="left">复制</td>
<td align="left">在Pod内外复制文件</td>
</tr>
<tr>
<td align="left"></td>
<td align="left">rollout</td>
<td align="left">首次展示</td>
<td align="left">管理资源的发布</td>
</tr>
<tr>
<td align="left"></td>
<td align="left">scale</td>
<td align="left">规模</td>
<td align="left">扩(缩)容Pod的数量</td>
</tr>
<tr>
<td align="left"></td>
<td align="left">autoscale</td>
<td align="left">自动调整</td>
<td align="left">自动调整Pod的数量</td>
</tr>
<tr>
<td align="left">高级命令</td>
<td align="left">apply</td>
<td align="left">rc</td>
<td align="left">通过文件对资源进行配置</td>
</tr>
<tr>
<td align="left"></td>
<td align="left">label</td>
<td align="left">标签</td>
<td align="left">更新资源上的标签</td>
</tr>
<tr>
<td align="left">其他命令</td>
<td align="left">cluster-info</td>
<td align="left">集群信息</td>
<td align="left">显示集群信息</td>
</tr>
<tr>
<td align="left"></td>
<td align="left">version</td>
<td align="left">版本</td>
<td align="left">显示当前Server和Client的版本</td>
</tr>
</tbody></table>
<p>下面以一个namespace / pod的创建和删除简单演示下命令的使用：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建一个namespace</span></span><br><span class="line">[root@master ~]# kubectl create namespace dev</span><br><span class="line">namespace/dev created</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 获取namespace</span></span><br><span class="line">[root@master ~]# kubectl get ns</span><br><span class="line">NAME              STATUS   AGE</span><br><span class="line">default           Active   21h</span><br><span class="line">dev               Active   21s</span><br><span class="line">kube-node-lease   Active   21h</span><br><span class="line">kube-public       Active   21h</span><br><span class="line">kube-system       Active   21h</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 在此namespace下创建并运行一个nginx的Pod</span></span><br><span class="line">[root@master ~]# kubectl run pod --image=nginx:latest -n dev</span><br><span class="line">kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.</span><br><span class="line">deployment.apps/pod created</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看新创建的pod</span></span><br><span class="line">[root@master ~]# kubectl get pod -n dev</span><br><span class="line">NAME  READY   STATUS    RESTARTS   AGE</span><br><span class="line">pod   1/1     Running   0          21s</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 删除指定的pod</span></span><br><span class="line">[root@master ~]# kubectl delete pod pod-864f9875b9-pcw7x</span><br><span class="line">pod &quot;pod&quot; deleted</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 删除指定的namespace</span></span><br><span class="line">[root@master ~]# kubectl delete ns dev</span><br><span class="line">namespace &quot;dev&quot; deleted</span><br></pre></td></tr></table></figure></div>

<h5 id="3-3-2-命令式对象配置"><a href="#3-3-2-命令式对象配置" class="headerlink" title="3.3.2 命令式对象配置"></a>3.3.2 命令式对象配置</h5><p>命令式对象配置就是使用命令配合配置文件一起来操作kubernetes资源。</p>
<p>1） 创建一个nginxpod.yaml，内容如下：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Namespace</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">dev</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginxpod</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx-containers</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx:latest</span></span><br></pre></td></tr></table></figure></div>

<p>2）执行create命令，创建资源：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="POWERSHELL"><figure class="iseeu highlight /powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl create -f nginxpod.yaml</span></span><br><span class="line">namespace/dev created</span><br><span class="line">pod/nginxpod created</span><br></pre></td></tr></table></figure></div>

<p>此时发现创建了两个资源对象，分别是namespace和pod</p>
<p>3）执行get命令，查看资源：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">[root@master ~]#  kubectl get -f nginxpod.yaml</span><br><span class="line">NAME            STATUS   AGE</span><br><span class="line">namespace/dev   Active   18s</span><br><span class="line"></span><br><span class="line">NAME            READY   STATUS    RESTARTS   AGE</span><br><span class="line">pod/nginxpod    1/1     Running   0          17s</span><br></pre></td></tr></table></figure></div>

<p>这样就显示了两个资源对象的信息</p>
<p>4）执行delete命令，删除资源：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">[root@master ~]# kubectl delete -f nginxpod.yaml</span><br><span class="line">namespace &quot;dev&quot; deleted</span><br><span class="line">pod &quot;nginxpod&quot; deleted</span><br></pre></td></tr></table></figure></div>

<p>此时发现两个资源对象被删除了</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tr><td class="code"><pre><span class="line">总结:</span><br><span class="line">    命令式对象配置的方式操作资源，可以简单的认为：命令  +  yaml配置文件（里面是命令需要的各种参数）</span><br></pre></td></tr></table></figure></div>

<h5 id="3-3-3-声明式对象配置"><a href="#3-3-3-声明式对象配置" class="headerlink" title="3.3.3 声明式对象配置"></a>3.3.3 声明式对象配置</h5><p>声明式对象配置跟命令式对象配置很相似，但是它只有一个命令apply。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 首先执行一次kubectl apply -f yaml文件，发现创建了资源</span></span><br><span class="line">[root@master ~]#  kubectl apply -f nginxpod.yaml</span><br><span class="line">namespace/dev created</span><br><span class="line">pod/nginxpod created</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 再次执行一次kubectl apply -f yaml文件，发现说资源没有变动</span></span><br><span class="line">[root@master ~]#  kubectl apply -f nginxpod.yaml</span><br><span class="line">namespace/dev unchanged</span><br><span class="line">pod/nginxpod unchanged</span><br></pre></td></tr></table></figure></div>

<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="POWERSHELL"><figure class="iseeu highlight /powershell"><table><tr><td class="code"><pre><span class="line">总结:</span><br><span class="line">    其实声明式对象配置就是使用apply描述一个资源最终的状态（在yaml中定义状态）</span><br><span class="line">    使用apply操作资源：</span><br><span class="line">        如果资源不存在，就创建，相当于 kubectl create</span><br><span class="line">        如果资源已存在，就更新，相当于 kubectl patch</span><br></pre></td></tr></table></figure></div>

<blockquote>
<p>扩展：kubectl可以在node节点上运行吗 ?</p>
</blockquote>
<p>kubectl的运行是需要进行配置的，它的配置文件是$HOME/.kube，如果想要在node节点运行此命令，需要将master上的.kube文件复制到node节点上，即在master节点上执行下面操作：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">scp  -r  HOME/.kube   node1: HOME/</span><br></pre></td></tr></table></figure></div>

<blockquote>
<p>使用推荐: 三种方式应该怎么用 ?</p>
</blockquote>
<p>创建/更新资源 使用声明式对象配置 kubectl apply -f XXX.yaml</p>
<p>删除资源 使用命令式对象配置 kubectl delete -f XXX.yaml</p>
<p>查询资源 使用命令式对象管理 kubectl get(describe) 资源名称</p>
]]></content>
      <tags>
        <tag>云原生基础系列</tag>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>云原生基础系列之Kubernetes(九)安全认证</title>
    <url>/2022/06/09/uncatalog/cl46zbaxw00037or72v2f9efa/</url>
    <content><![CDATA[<hr>
<span id="more"></span>



<hr>
<h3 id="9-安全认证"><a href="#9-安全认证" class="headerlink" title="9. 安全认证"></a>9. 安全认证</h3><h4 id="9-1-访问控制概述"><a href="#9-1-访问控制概述" class="headerlink" title="9.1 访问控制概述"></a>9.1 访问控制概述</h4><p>Kubernetes作为一个分布式集群的管理工具，保证集群的安全性是其一个重要的任务。所谓的安全性其实就是保证对Kubernetes的各种<strong>客户端</strong>进行<strong>认证和鉴权</strong>操作。</p>
<p><strong>客户端</strong></p>
<p>在Kubernetes集群中，客户端通常有两类：</p>
<ul>
<li><strong>User Account</strong>：一般是独立于kubernetes之外的其他服务管理的用户账号。</li>
<li><strong>Service Account</strong>：kubernetes管理的账号，用于为Pod中的服务进程在访问Kubernetes时提供身份标识。</li>
</ul>
<p><img src="/2022/06/09/uncatalog/cl46zbaxw00037or72v2f9efa/image-20200520102949189.png" alt="img"></p>
<p><strong>认证、授权与准入控制</strong></p>
<p>ApiServer是访问及管理资源对象的唯一入口。任何一个请求访问ApiServer，都要经过下面三个流程：</p>
<ul>
<li>Authentication（认证）：身份鉴别，只有正确的账号才能够通过认证</li>
<li>Authorization（授权）： 判断用户是否有权限对访问的资源执行特定的动作</li>
<li>Admission Control（准入控制）：用于补充授权机制以实现更加精细的访问控制功能。</li>
</ul>
<p><img src="/2022/06/09/uncatalog/cl46zbaxw00037or72v2f9efa/image-20200520103942580.png" alt="img"></p>
<h4 id="9-2-认证管理"><a href="#9-2-认证管理" class="headerlink" title="9.2 认证管理"></a>9.2 认证管理</h4><p>Kubernetes集群安全的最关键点在于如何识别并认证客户端身份，它提供了3种客户端身份认证方式：</p>
<ul>
<li><p>HTTP Base认证：通过用户名+密码的方式认证</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tr><td class="code"><pre><span class="line">这种认证方式是把“用户名:密码”用BASE64算法进行编码后的字符串放在HTTP请求中的Header Authorization域里发送给服务端。服务端收到后进行解码，获取用户名及密码，然后进行用户身份认证的过程。</span><br></pre></td></tr></table></figure></div></li>
<li><p>HTTP Token认证：通过一个Token来识别合法用户</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tr><td class="code"><pre><span class="line">这种认证方式是用一个很长的难以被模仿的字符串--Token来表明客户身份的一种方式。每个Token对应一个用户名，当客户端发起API调用请求时，需要在HTTP Header里放入Token，API Server接到Token后会跟服务器中保存的token进行比对，然后进行用户身份认证的过程。</span><br></pre></td></tr></table></figure></div></li>
<li><p>HTTPS证书认证：基于CA根证书签名的双向数字证书认证方式</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tr><td class="code"><pre><span class="line">这种认证方式是安全性最高的一种方式，但是同时也是操作起来最麻烦的一种方式。</span><br></pre></td></tr></table></figure></div></li>
</ul>
<p><img src="/2022/06/09/uncatalog/cl46zbaxw00037or72v2f9efa/image-20200518211037434.png" alt="img"></p>
<p><strong>HTTPS认证大体分为3个过程：</strong></p>
<ol>
<li><p>证书申请和下发</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tr><td class="code"><pre><span class="line">HTTPS通信双方的服务器向CA机构申请证书，CA机构下发根证书、服务端证书及私钥给申请者</span><br></pre></td></tr></table></figure></div></li>
<li><p>客户端和服务端的双向认证</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tr><td class="code"><pre><span class="line">1&gt; 客户端向服务器端发起请求，服务端下发自己的证书给客户端，</span><br><span class="line">   客户端接收到证书后，通过私钥解密证书，在证书中获得服务端的公钥，</span><br><span class="line">   客户端利用服务器端的公钥认证证书中的信息，如果一致，则认可这个服务器</span><br><span class="line">2&gt; 客户端发送自己的证书给服务器端，服务端接收到证书后，通过私钥解密证书，</span><br><span class="line">   在证书中获得客户端的公钥，并用该公钥认证证书信息，确认客户端是否合法</span><br></pre></td></tr></table></figure></div></li>
<li><p>服务器端和客户端进行通信</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tr><td class="code"><pre><span class="line">服务器端和客户端协商好加密方案后，客户端会产生一个随机的秘钥并加密，然后发送到服务器端。</span><br><span class="line">服务器端接收这个秘钥后，双方接下来通信的所有内容都通过该随机秘钥加密</span><br></pre></td></tr></table></figure></div></li>
</ol>
<blockquote>
<p>注意: Kubernetes允许同时配置多种认证方式，只要其中任意一个方式认证通过即可</p>
</blockquote>
<h4 id="9-3-授权管理"><a href="#9-3-授权管理" class="headerlink" title="9.3 授权管理"></a>9.3 授权管理</h4><p>授权发生在认证成功之后，通过认证就可以知道请求用户是谁， 然后Kubernetes会根据事先定义的授权策略来决定用户是否有权限访问，这个过程就称为授权。</p>
<p>每个发送到ApiServer的请求都带上了用户和资源的信息：比如发送请求的用户、请求的路径、请求的动作等，授权就是根据这些信息和授权策略进行比较，如果符合策略，则认为授权通过，否则会返回错误。</p>
<p>API Server目前支持以下几种授权策略：</p>
<ul>
<li>AlwaysDeny：表示拒绝所有请求，一般用于测试</li>
<li>AlwaysAllow：允许接收所有请求，相当于集群不需要授权流程（Kubernetes默认的策略）</li>
<li>ABAC：基于属性的访问控制，表示使用用户配置的授权规则对用户请求进行匹配和控制</li>
<li>Webhook：通过调用外部REST服务对用户进行授权</li>
<li>Node：是一种专用模式，用于对kubelet发出的请求进行访问控制</li>
<li>RBAC：基于角色的访问控制（kubeadm安装方式下的默认选项）</li>
</ul>
<p>RBAC(Role-Based Access Control) 基于角色的访问控制，主要是在描述一件事情：<strong>给哪些对象授予了哪些权限</strong></p>
<p>其中涉及到了下面几个概念：</p>
<ul>
<li>对象：User、Groups、ServiceAccount</li>
<li>角色：代表着一组定义在资源上的可操作动作(权限)的集合</li>
<li>绑定：将定义好的角色跟用户绑定在一起</li>
</ul>
<p><img src="/2022/06/09/uncatalog/cl46zbaxw00037or72v2f9efa/image-20200519181209566.png" alt="img"></p>
<p>RBAC引入了4个顶级资源对象：</p>
<ul>
<li>Role、ClusterRole：角色，用于指定一组权限</li>
<li>RoleBinding、ClusterRoleBinding：角色绑定，用于将角色（权限）赋予给对象</li>
</ul>
<p><strong>Role、ClusterRole</strong></p>
<p>一个角色就是一组权限的集合，这里的权限都是许可形式的（白名单）。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Role只能对命名空间内的资源进行授权，需要指定nameapce</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Role</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1beta1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">authorization-role</span></span><br><span class="line"><span class="attr">rules:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>]  <span class="comment"># 支持的API组列表,&quot;&quot; 空字符串，表示核心API群</span></span><br><span class="line">  <span class="attr">resources:</span> [<span class="string">&quot;pods&quot;</span>] <span class="comment"># 支持的资源对象列表</span></span><br><span class="line">  <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;watch&quot;</span>, <span class="string">&quot;list&quot;</span>] <span class="comment"># 允许的对资源对象的操作方法列表</span></span><br></pre></td></tr></table></figure></div>

<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ClusterRole可以对集群范围内资源、跨namespaces的范围资源、非资源类型进行授权</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1beta1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"> <span class="attr">name:</span> <span class="string">authorization-clusterrole</span></span><br><span class="line"><span class="attr">rules:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>]</span><br><span class="line">  <span class="attr">resources:</span> [<span class="string">&quot;pods&quot;</span>]</span><br><span class="line">  <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;watch&quot;</span>, <span class="string">&quot;list&quot;</span>]</span><br></pre></td></tr></table></figure></div>

<p>需要详细说明的是，rules中的参数：</p>
<ul>
<li><p>apiGroups: 支持的API组列表</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;</span>,<span class="string">&quot;apps&quot;</span>, <span class="string">&quot;autoscaling&quot;</span>, <span class="string">&quot;batch&quot;</span></span><br></pre></td></tr></table></figure></div></li>
<li><p>resources：支持的资源对象列表</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;services&quot;</span>, <span class="string">&quot;endpoints&quot;</span>, <span class="string">&quot;pods&quot;</span>,<span class="string">&quot;secrets&quot;</span>,<span class="string">&quot;configmaps&quot;</span>,<span class="string">&quot;crontabs&quot;</span>,<span class="string">&quot;deployments&quot;</span>,<span class="string">&quot;jobs&quot;</span>,</span><br><span class="line"><span class="string">&quot;nodes&quot;</span>,<span class="string">&quot;rolebindings&quot;</span>,<span class="string">&quot;clusterroles&quot;</span>,<span class="string">&quot;daemonsets&quot;</span>,<span class="string">&quot;replicasets&quot;</span>,<span class="string">&quot;statefulsets&quot;</span>,</span><br><span class="line"><span class="string">&quot;horizontalpodautoscalers&quot;</span>,<span class="string">&quot;replicationcontrollers&quot;</span>,<span class="string">&quot;cronjobs&quot;</span></span><br></pre></td></tr></table></figure></div></li>
<li><p>verbs：对资源对象的操作方法列表</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>, <span class="string">&quot;create&quot;</span>, <span class="string">&quot;update&quot;</span>, <span class="string">&quot;patch&quot;</span>, <span class="string">&quot;delete&quot;</span>, <span class="string">&quot;exec&quot;</span></span><br></pre></td></tr></table></figure></div></li>
</ul>
<p><strong>RoleBinding、ClusterRoleBinding</strong></p>
<p>角色绑定用来把一个角色绑定到一个目标对象上，绑定目标可以是User、Group或者ServiceAccount。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># RoleBinding可以将同一namespace中的subject绑定到某个Role下，则此subject即具有该Role定义的权限</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">RoleBinding</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1beta1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">authorization-role-binding</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">User</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">heima</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line">  <span class="attr">kind:</span> <span class="string">Role</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">authorization-role</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br></pre></td></tr></table></figure></div>

<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ClusterRoleBinding在整个集群级别和所有namespaces将特定的subject与ClusterRole绑定，授予权限</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1beta1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"> <span class="attr">name:</span> <span class="string">authorization-clusterrole-binding</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">User</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">heima</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line">  <span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">authorization-clusterrole</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br></pre></td></tr></table></figure></div>

<p><strong>RoleBinding引用ClusterRole进行授权</strong></p>
<p>RoleBinding可以引用ClusterRole，对属于同一命名空间内ClusterRole定义的资源主体进行授权。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tr><td class="code"><pre><span class="line">一种很常用的做法就是，集群管理员为集群范围预定义好一组角色（ClusterRole），然后在多个命名空间中重复使用这些ClusterRole。这样可以大幅提高授权管理工作效率，也使得各个命名空间下的基础性授权规则与使用体验保持一致。</span><br></pre></td></tr></table></figure></div>

<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 虽然authorization-clusterrole是一个集群角色，但是因为使用了RoleBinding</span></span><br><span class="line"><span class="comment"># 所以heima只能读取dev命名空间中的资源</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">RoleBinding</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1beta1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">authorization-role-binding-ns</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">User</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">heima</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line">  <span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">authorization-clusterrole</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br></pre></td></tr></table></figure></div>

<p><strong>实战：创建一个只能管理dev空间下Pods资源的账号</strong></p>
<ol>
<li>创建账号</li>
</ol>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 1) 创建证书</span></span><br><span class="line">[root@k8s-master01 pki]# cd /etc/kubernetes/pki/</span><br><span class="line">[root@k8s-master01 pki]# (umask 077;openssl genrsa -out devman.key 2048)</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 2) 用apiserver的证书去签署</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 2-1) 签名申请，申请的用户是devman,组是devgroup</span></span><br><span class="line">[root@k8s-master01 pki]# openssl req -new -key devman.key -out devman.csr -subj &quot;/CN=devman/O=devgroup&quot;     </span><br><span class="line"><span class="meta">#</span><span class="bash"> 2-2) 签署证书</span></span><br><span class="line">[root@k8s-master01 pki]# openssl x509 -req -in devman.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out devman.crt -days 3650</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 3) 设置集群、用户、上下文信息</span></span><br><span class="line">[root@k8s-master01 pki]# kubectl config set-cluster kubernetes --embed-certs=true --certificate-authority=/etc/kubernetes/pki/ca.crt --server=https://192.168.109.100:6443</span><br><span class="line"></span><br><span class="line">[root@k8s-master01 pki]# kubectl config set-credentials devman --embed-certs=true --client-certificate=/etc/kubernetes/pki/devman.crt --client-key=/etc/kubernetes/pki/devman.key</span><br><span class="line"></span><br><span class="line">[root@k8s-master01 pki]# kubectl config set-context devman@kubernetes --cluster=kubernetes --user=devman</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 切换账户到devman</span></span><br><span class="line">[root@k8s-master01 pki]# kubectl config use-context devman@kubernetes</span><br><span class="line">Switched to context &quot;devman@kubernetes&quot;.</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看dev下pod，发现没有权限</span></span><br><span class="line">[root@k8s-master01 pki]# kubectl get pods -n dev</span><br><span class="line">Error from server (Forbidden): pods is forbidden: User &quot;devman&quot; cannot list resource &quot;pods&quot; in API group &quot;&quot; in the namespace &quot;dev&quot;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 切换到admin账户</span></span><br><span class="line">[root@k8s-master01 pki]# kubectl config use-context kubernetes-admin@kubernetes</span><br><span class="line">Switched to context &quot;kubernetes-admin@kubernetes&quot;.</span><br></pre></td></tr></table></figure></div>

<p>2） 创建Role和RoleBinding，为devman用户授权</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">Role</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1beta1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">dev-role</span></span><br><span class="line"><span class="attr">rules:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>]</span><br><span class="line">  <span class="attr">resources:</span> [<span class="string">&quot;pods&quot;</span>]</span><br><span class="line">  <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;watch&quot;</span>, <span class="string">&quot;list&quot;</span>]</span><br><span class="line">  </span><br><span class="line"><span class="meta">---</span></span><br><span class="line"></span><br><span class="line"><span class="attr">kind:</span> <span class="string">RoleBinding</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1beta1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">authorization-role-binding</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">User</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">devman</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line">  <span class="attr">kind:</span> <span class="string">Role</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">dev-role</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br></pre></td></tr></table></figure></div>

<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master01 pki]# kubectl create -f dev-role.yaml</span><br><span class="line">role.rbac.authorization.k8s.io/dev-role created</span><br><span class="line">rolebinding.rbac.authorization.k8s.io/authorization-role-binding created</span><br></pre></td></tr></table></figure></div>

<ol start="3">
<li>切换账户，再次验证</li>
</ol>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 切换账户到devman</span></span><br><span class="line">[root@k8s-master01 pki]# kubectl config use-context devman@kubernetes</span><br><span class="line">Switched to context &quot;devman@kubernetes&quot;.</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 再次查看</span></span><br><span class="line">[root@k8s-master01 pki]# kubectl get pods -n dev</span><br><span class="line">NAME                                 READY   STATUS             RESTARTS   AGE</span><br><span class="line">nginx-deployment-66cb59b984-8wp2k    1/1     Running            0          4d1h</span><br><span class="line">nginx-deployment-66cb59b984-dc46j    1/1     Running            0          4d1h</span><br><span class="line">nginx-deployment-66cb59b984-thfck    1/1     Running            0          4d1h</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 为了不影响后面的学习,切回admin账户</span></span><br><span class="line">[root@k8s-master01 pki]# kubectl config use-context kubernetes-admin@kubernetes</span><br><span class="line">Switched to context &quot;kubernetes-admin@kubernetes&quot;.</span><br></pre></td></tr></table></figure></div>

<h4 id="9-4-准入控制"><a href="#9-4-准入控制" class="headerlink" title="9.4 准入控制"></a>9.4 准入控制</h4><p>通过了前面的认证和授权之后，还需要经过准入控制处理通过之后，apiserver才会处理这个请求。</p>
<p>准入控制是一个可配置的控制器列表，可以通过在Api-Server上通过命令行设置选择执行哪些准入控制器：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tr><td class="code"><pre><span class="line">--admission-control&#x3D;NamespaceLifecycle,LimitRanger,ServiceAccount,PersistentVolumeLabel,</span><br><span class="line">                      DefaultStorageClass,ResourceQuota,DefaultTolerationSeconds</span><br></pre></td></tr></table></figure></div>

<p>只有当所有的准入控制器都检查通过之后，apiserver才执行该请求，否则返回拒绝。</p>
<p>当前可配置的Admission Control准入控制如下：</p>
<ul>
<li>AlwaysAdmit：允许所有请求</li>
<li>AlwaysDeny：禁止所有请求，一般用于测试</li>
<li>AlwaysPullImages：在启动容器之前总去下载镜像</li>
<li>DenyExecOnPrivileged：它会拦截所有想在Privileged Container上执行命令的请求</li>
<li>ImagePolicyWebhook：这个插件将允许后端的一个Webhook程序来完成admission controller的功能。</li>
<li>Service Account：实现ServiceAccount实现了自动化</li>
<li>SecurityContextDeny：这个插件将使用SecurityContext的Pod中的定义全部失效</li>
<li>ResourceQuota：用于资源配额管理目的，观察所有请求，确保在namespace上的配额不会超标</li>
<li>LimitRanger：用于资源限制管理，作用于namespace上，确保对Pod进行资源限制</li>
<li>InitialResources：为未设置资源请求与限制的Pod，根据其镜像的历史资源的使用情况进行设置</li>
<li>NamespaceLifecycle：如果尝试在一个不存在的namespace中创建资源对象，则该创建请求将被拒绝。当删除一个namespace时，系统将会删除该namespace中所有对象。</li>
<li>DefaultStorageClass：为了实现共享存储的动态供应，为未指定StorageClass或PV的PVC尝试匹配默认的StorageClass，尽可能减少用户在申请PVC时所需了解的后端存储细节</li>
<li>DefaultTolerationSeconds：这个插件为那些没有设置forgiveness tolerations并具有notready:NoExecute和unreachable:NoExecute两种taints的Pod设置默认的“容忍”时间，为5min</li>
<li>PodSecurityPolicy：这个插件用于在创建或修改Pod时决定是否根据Pod的security context和可用的PodSecurityPolicy对Pod的安全策略进行控制</li>
</ul>
]]></content>
      <tags>
        <tag>云原生基础系列</tag>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>云原生基础系列之Kubernetes(十)DashBoard</title>
    <url>/2022/06/09/uncatalog/cl46zbaxy00047or77oe22gjt/</url>
    <content><![CDATA[<hr>
<span id="more"></span>



<hr>
<h3 id="10-DashBoard"><a href="#10-DashBoard" class="headerlink" title="10. DashBoard"></a>10. DashBoard</h3><p>之前在kubernetes中完成的所有操作都是通过命令行工具kubectl完成的。其实，为了提供更丰富的用户体验，kubernetes还开发了一个基于web的用户界面（Dashboard）。用户可以使用Dashboard部署容器化的应用，还可以监控应用的状态，执行故障排查以及管理kubernetes中各种资源。</p>
<h4 id="10-1-部署Dashboard"><a href="#10-1-部署Dashboard" class="headerlink" title="10.1 部署Dashboard"></a>10.1 部署Dashboard</h4><ol>
<li>下载yaml，并运行Dashboard</li>
</ol>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 下载yaml</span></span><br><span class="line">[root@k8s-master01 ~]# wget  https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.0/aio/deploy/recommended.yaml</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 修改kubernetes-dashboard的Service类型</span></span><br><span class="line">kind: Service</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br><span class="line">  name: kubernetes-dashboard</span><br><span class="line">  namespace: kubernetes-dashboard</span><br><span class="line">spec:</span><br><span class="line">  type: NodePort  # 新增</span><br><span class="line">  ports:</span><br><span class="line">    - port: 443</span><br><span class="line">      targetPort: 8443</span><br><span class="line">      nodePort: 30009  # 新增</span><br><span class="line">  selector:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 部署</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl create -f recommended.yaml</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看namespace下的kubernetes-dashboard下的资源</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl get pod,svc -n kubernetes-dashboard</span><br><span class="line">NAME                                            READY   STATUS    RESTARTS   AGE</span><br><span class="line">pod/dashboard-metrics-scraper-c79c65bb7-zwfvw   1/1     Running   0          111s</span><br><span class="line">pod/kubernetes-dashboard-56484d4c5-z95z5        1/1     Running   0          111s</span><br><span class="line"></span><br><span class="line">NAME                               TYPE       CLUSTER-IP      EXTERNAL-IP  PORT(S)         AGE</span><br><span class="line">service/dashboard-metrics-scraper  ClusterIP  10.96.89.218    &lt;none&gt;       8000/TCP        111s</span><br><span class="line">service/kubernetes-dashboard       NodePort   10.104.178.171  &lt;none&gt;       443:30009/TCP   111s</span><br></pre></td></tr></table></figure></div>

<p>2）创建访问账户，获取token</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建账号</span></span><br><span class="line">[root@k8s-master01-1 ~]# kubectl create serviceaccount dashboard-admin -n kubernetes-dashboard</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 授权</span></span><br><span class="line">[root@k8s-master01-1 ~]# kubectl create clusterrolebinding dashboard-admin-rb --clusterrole=cluster-admin --serviceaccount=kubernetes-dashboard:dashboard-admin</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 获取账号token</span></span><br><span class="line">[root@k8s-master01 ~]#  kubectl get secrets -n kubernetes-dashboard | grep dashboard-admin</span><br><span class="line">dashboard-admin-token-xbqhh        kubernetes.io/service-account-token   3      2m35s</span><br><span class="line"></span><br><span class="line">[root@k8s-master01 ~]# kubectl describe secrets dashboard-admin-token-xbqhh -n kubernetes-dashboard</span><br><span class="line">Name:         dashboard-admin-token-xbqhh</span><br><span class="line">Namespace:    kubernetes-dashboard</span><br><span class="line">Labels:       &lt;none&gt;</span><br><span class="line">Annotations:  kubernetes.io/service-account.name: dashboard-admin</span><br><span class="line">              kubernetes.io/service-account.uid: 95d84d80-be7a-4d10-a2e0-68f90222d039</span><br><span class="line"></span><br><span class="line">Type:  kubernetes.io/service-account-token</span><br><span class="line"></span><br><span class="line">Data</span><br><span class="line">====</span><br><span class="line">namespace:  20 bytes</span><br><span class="line">token:      eyJhbGciOiJSUzI1NiIsImtpZCI6ImJrYkF4bW5XcDhWcmNGUGJtek5NODFuSXl1aWptMmU2M3o4LTY5a2FKS2cifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlcm5ldGVzLWRhc2hib2FyZCIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJkYXNoYm9hcmQtYWRtaW4tdG9rZW4teGJxaGgiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoiZGFzaGJvYXJkLWFkbWluIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiOTVkODRkODAtYmU3YS00ZDEwLWEyZTAtNjhmOTAyMjJkMDM5Iiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmVybmV0ZXMtZGFzaGJvYXJkOmRhc2hib2FyZC1hZG1pbiJ9.NAl7e8ZfWWdDoPxkqzJzTB46sK9E8iuJYnUI9vnBaY3Jts7T1g1msjsBnbxzQSYgAG--cV0WYxjndzJY_UWCwaGPrQrt_GunxmOK9AUnzURqm55GR2RXIZtjsWVP2EBatsDgHRmuUbQvTFOvdJB4x3nXcYLN2opAaMqg3rnU2rr-A8zCrIuX_eca12wIp_QiuP3SF-tzpdLpsyRfegTJZl6YnSGyaVkC9id-cxZRb307qdCfXPfCHR_2rt5FVfxARgg_C0e3eFHaaYQO7CitxsnIoIXpOFNAR8aUrmopJyODQIPqBWUehb7FhlU1DCduHnIIXVC_UICZ-MKYewBDLw</span><br><span class="line">ca.crt:     1025 bytes</span><br></pre></td></tr></table></figure></div>

<p>3）通过浏览器访问Dashboard的UI</p>
<p>在登录页面上输入上面的token</p>
<p><img src="/2022/06/09/uncatalog/cl46zbaxy00047or77oe22gjt/image-20200520144548997.png" alt="image-20200520144548997"></p>
<p>出现下面的页面代表成功</p>
<p><img src="/2022/06/09/uncatalog/cl46zbaxy00047or77oe22gjt/image-20200520144959353.png" alt="image-20200520144959353"></p>
<h4 id="10-2-使用DashBoard"><a href="#10-2-使用DashBoard" class="headerlink" title="10.2 使用DashBoard"></a>10.2 使用DashBoard</h4><p>本章节以Deployment为例演示DashBoard的使用</p>
<p><strong>查看</strong></p>
<p>选择指定的命名空间<code>dev</code>，然后点击<code>Deployments</code>，查看dev空间下的所有deployment</p>
<p><img src="/2022/06/09/uncatalog/cl46zbaxy00047or77oe22gjt/image-20200520154628679.png" alt="img"></p>
<p><strong>扩缩容</strong></p>
<p>在<code>Deployment</code>上点击<code>规模</code>，然后指定<code>目标副本数量</code>，点击确定</p>
<p><img src="/2022/06/09/uncatalog/cl46zbaxy00047or77oe22gjt/image-20200520162605102.png" alt="img"></p>
<p><strong>编辑</strong></p>
<p>在<code>Deployment</code>上点击<code>编辑</code>，然后修改<code>yaml文件</code>，点击确定</p>
<p><img src="/2022/06/09/uncatalog/cl46zbaxy00047or77oe22gjt/image-20200520163253644.png" alt="image-20200520163253644"></p>
<p><strong>查看Pod</strong></p>
<p>点击<code>Pods</code>, 查看pods列表</p>
<p><img src="/2022/06/09/uncatalog/cl46zbaxy00047or77oe22gjt/image-20200520163552110.png" alt="img"></p>
<p><strong>操作Pod</strong></p>
<p>选中某个Pod，可以对其执行日志（logs）、进入执行（exec）、编辑、删除操作</p>
<p><img src="/2022/06/09/uncatalog/cl46zbaxy00047or77oe22gjt/image-20200520163832827.png" alt="img"></p>
<blockquote>
<p>Dashboard提供了kubectl的绝大部分功能，这里不再一一演示</p>
</blockquote>
]]></content>
      <tags>
        <tag>云原生基础系列</tag>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>云原生基础系列之Kubernetes(七)Service详解</title>
    <url>/2022/06/09/uncatalog/cl46zbay9000j7or7b2e4b2pr/</url>
    <content><![CDATA[<hr>
<span id="more"></span>
<hr>
<h4 id="7-1-Service介绍"><a href="#7-1-Service介绍" class="headerlink" title="7.1 Service介绍"></a>7.1 Service介绍</h4><p>在kubernetes中，pod是应用程序的载体，我们可以通过pod的ip来访问应用程序，但是pod的ip地址不是固定的，这也就意味着不方便直接采用pod的ip对服务进行访问。</p>
<p>为了解决这个问题，kubernetes提供了Service资源，Service会对提供同一个服务的多个pod进行聚合，并且提供一个统一的入口地址。通过访问Service的入口地址就能访问到后面的pod服务。</p>
<p><img src="/2022/06/09/uncatalog/cl46zbay9000j7or7b2e4b2pr/image-20200408194716912-1626783758946.png" alt="img"></p>
<p>Service在很多情况下只是一个概念，真正起作用的其实是kube-proxy服务进程，每个Node节点上都运行着一个kube-proxy服务进程。当创建Service的时候会通过api-server向etcd写入创建的service的信息，而kube-proxy会基于监听的机制发现这种Service的变动，然后<strong>它会将最新的Service信息转换成对应的访问规则</strong>。</p>
<p><img src="/2022/06/09/uncatalog/cl46zbay9000j7or7b2e4b2pr/image-20200509121254425.png" alt="img"></p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tr><td class="code"><pre><span class="line"># 10.97.97.97:80 是service提供的访问入口</span><br><span class="line"># 当访问这个入口的时候，可以发现后面有三个pod的服务在等待调用，</span><br><span class="line"># kube-proxy会基于rr（轮询）的策略，将请求分发到其中一个pod上去</span><br><span class="line"># 这个规则会同时在集群内的所有节点上都生成，所以在任何一个节点，访问都可以。</span><br><span class="line">[root@node1 ~]# ipvsadm -Ln</span><br><span class="line">IP Virtual Server version 1.2.1 (size&#x3D;4096)</span><br><span class="line">Prot LocalAddress:Port Scheduler Flags</span><br><span class="line">  -&gt; RemoteAddress:Port           Forward Weight ActiveConn InActConn</span><br><span class="line">TCP  10.97.97.97:80 rr</span><br><span class="line">  -&gt; 10.244.1.39:80               Masq    1      0          0</span><br><span class="line">  -&gt; 10.244.1.40:80               Masq    1      0          0</span><br><span class="line">  -&gt; 10.244.2.33:80               Masq    1      0          0</span><br></pre></td></tr></table></figure></div>

<p>kube-proxy目前支持三种工作模式:</p>
<p>kube-proxy目前支持三种工作模式:</p>
<h5 id="7-1-1-userspace-模式"><a href="#7-1-1-userspace-模式" class="headerlink" title="7.1.1 userspace 模式"></a>7.1.1 userspace 模式</h5><p>userspace模式下，kube-proxy会为每一个Service创建一个监听端口，发向Cluster IP的请求被Iptables规则重定向到kube-proxy监听的端口上，kube-proxy根据LB算法选择一个提供服务的Pod并和其建立链接，以将请求转发到Pod上。  该模式下，kube-proxy充当了一个四层负责均衡器的角色。由于kube-proxy运行在userspace中，在进行转发处理时会增加内核和用户空间之间的数据拷贝，虽然比较稳定，但是效率比较低。</p>
<p><img src="/2022/06/09/uncatalog/cl46zbay9000j7or7b2e4b2pr/image-20200509151424280.png" alt="img"></p>
<h5 id="7-1-2-iptables-模式"><a href="#7-1-2-iptables-模式" class="headerlink" title="7.1.2 iptables 模式"></a>7.1.2 iptables 模式</h5><p>iptables模式下，kube-proxy为service后端的每个Pod创建对应的iptables规则，直接将发向Cluster IP的请求重定向到一个Pod IP。  该模式下kube-proxy不承担四层负责均衡器的角色，只负责创建iptables规则。该模式的优点是较userspace模式效率更高，但不能提供灵活的LB策略，当后端Pod不可用时也无法进行重试。</p>
<p><img src="/2022/06/09/uncatalog/cl46zbay9000j7or7b2e4b2pr/image-20200509152947714.png" alt="img"></p>
<h5 id="7-1-3-ipvs-模式"><a href="#7-1-3-ipvs-模式" class="headerlink" title="7.1.3 ipvs 模式"></a>7.1.3 ipvs 模式</h5><p>ipvs模式和iptables类似，kube-proxy监控Pod的变化并创建相应的ipvs规则。ipvs相对iptables转发效率更高。除此以外，ipvs支持更多的LB算法。</p>
<p><img src="/2022/06/09/uncatalog/cl46zbay9000j7or7b2e4b2pr/image-20200509153731363.png" alt="img"></p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 此模式必须安装ipvs内核模块，否则会降级为iptables</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 开启ipvs</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl edit cm kube-proxy -n kube-system</span><br><span class="line"><span class="meta">#</span><span class="bash"> 修改mode: <span class="string">&quot;ipvs&quot;</span></span></span><br><span class="line">[root@k8s-master01 ~]# kubectl delete pod -l k8s-app=kube-proxy -n kube-system</span><br><span class="line">[root@node1 ~]# ipvsadm -Ln</span><br><span class="line">IP Virtual Server version 1.2.1 (size=4096)</span><br><span class="line">Prot LocalAddress:Port Scheduler Flags</span><br><span class="line"><span class="meta">  -&gt;</span><span class="bash"> RemoteAddress:Port           Forward Weight ActiveConn InActConn</span></span><br><span class="line">TCP  10.97.97.97:80 rr</span><br><span class="line"><span class="meta">  -&gt;</span><span class="bash"> 10.244.1.39:80               Masq    1      0          0</span></span><br><span class="line"><span class="meta">  -&gt;</span><span class="bash"> 10.244.1.40:80               Masq    1      0          0</span></span><br><span class="line"><span class="meta">  -&gt;</span><span class="bash"> 10.244.2.33:80               Masq    1      0          0</span></span><br></pre></td></tr></table></figure></div>

<h4 id="7-2-Service类型"><a href="#7-2-Service类型" class="headerlink" title="7.2 Service类型"></a>7.2 Service类型</h4><p>Service的资源清单文件：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">Service</span>  <span class="comment"># 资源类型</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span>  <span class="comment"># 资源版本</span></span><br><span class="line"><span class="attr">metadata:</span> <span class="comment"># 元数据</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">service</span> <span class="comment"># 资源名称</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span> <span class="comment"># 命名空间</span></span><br><span class="line"><span class="attr">spec:</span> <span class="comment"># 描述</span></span><br><span class="line">  <span class="attr">selector:</span> <span class="comment"># 标签选择器，用于确定当前service代理哪些pod</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">type:</span> <span class="comment"># Service类型，指定service的访问方式</span></span><br><span class="line">  <span class="attr">clusterIP:</span>  <span class="comment"># 虚拟服务的ip地址</span></span><br><span class="line">  <span class="attr">sessionAffinity:</span> <span class="comment"># session亲和性，支持ClientIP、None两个选项</span></span><br><span class="line">  <span class="attr">ports:</span> <span class="comment"># 端口信息</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">protocol:</span> <span class="string">TCP</span> </span><br><span class="line">      <span class="attr">port:</span> <span class="number">3017</span>  <span class="comment"># service端口</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">5003</span> <span class="comment"># pod端口</span></span><br><span class="line">      <span class="attr">nodePort:</span> <span class="number">31122</span> <span class="comment"># 主机端口</span></span><br></pre></td></tr></table></figure></div>

<ul>
<li>ClusterIP：默认值，它是Kubernetes系统自动分配的虚拟IP，只能在集群内部访问</li>
<li>NodePort：将Service通过指定的Node上的端口暴露给外部，通过此方法，就可以在集群外部访问服务</li>
<li>LoadBalancer：使用外接负载均衡器完成到服务的负载分发，注意此模式需要外部云环境支持</li>
<li>ExternalName： 把集群外部的服务引入集群内部，直接使用</li>
</ul>
<h4 id="7-3-Service使用"><a href="#7-3-Service使用" class="headerlink" title="7.3 Service使用"></a>7.3 Service使用</h4><h5 id="7-3-1-实验环境准备"><a href="#7-3-1-实验环境准备" class="headerlink" title="7.3.1 实验环境准备"></a>7.3.1 实验环境准备</h5><p>在使用service之前，首先利用Deployment创建出3个pod，注意要为pod设置<code>app=nginx-pod</code>的标签</p>
<p>创建deployment.yaml，内容如下：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span>      </span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pc-deployment</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span> </span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">3</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">nginx-pod</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">nginx-pod</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure></div>

<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master01 ~]# kubectl create -f deployment.yaml</span><br><span class="line">deployment.apps/pc-deployment created</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看pod详情</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl get pods -n dev -o wide --show-labels</span><br><span class="line">NAME                             READY   STATUS     IP            NODE     LABELS</span><br><span class="line">pc-deployment-66cb59b984-8p84h   1/1     Running    10.244.1.39   node1    app=nginx-pod</span><br><span class="line">pc-deployment-66cb59b984-vx8vx   1/1     Running    10.244.2.33   node2    app=nginx-pod</span><br><span class="line">pc-deployment-66cb59b984-wnncx   1/1     Running    10.244.1.40   node1    app=nginx-pod</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 为了方便后面的测试，修改下三台nginx的index.html页面（三台修改的IP地址不一致）</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> kubectl <span class="built_in">exec</span> -it pc-deployment-66cb59b984-8p84h -n dev /bin/sh</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> <span class="built_in">echo</span> <span class="string">&quot;10.244.1.39&quot;</span> &gt; /usr/share/nginx/html/index.html</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">修改完毕之后，访问测试</span></span><br><span class="line">[root@k8s-master01 ~]# curl 10.244.1.39</span><br><span class="line">10.244.1.39</span><br><span class="line">[root@k8s-master01 ~]# curl 10.244.2.33</span><br><span class="line">10.244.2.33</span><br><span class="line">[root@k8s-master01 ~]# curl 10.244.1.40</span><br><span class="line">10.244.1.40</span><br></pre></td></tr></table></figure></div>

<h5 id="7-3-2-ClusterIP类型的Service"><a href="#7-3-2-ClusterIP类型的Service" class="headerlink" title="7.3.2 ClusterIP类型的Service"></a>7.3.2 ClusterIP类型的Service</h5><p>创建service-clusterip.yaml文件</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">service-clusterip</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nginx-pod</span></span><br><span class="line">  <span class="attr">clusterIP:</span> <span class="number">10.97</span><span class="number">.97</span><span class="number">.97</span> <span class="comment"># service的ip地址，如果不写，默认会生成一个</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">ClusterIP</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span>  <span class="comment"># Service端口       </span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">80</span> <span class="comment"># pod端口</span></span><br></pre></td></tr></table></figure></div>

<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建service</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl create -f service-clusterip.yaml</span><br><span class="line">service/service-clusterip created</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看service</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl get svc -n dev -o wide</span><br><span class="line">NAME                TYPE        CLUSTER-IP    EXTERNAL-IP   PORT(S)   AGE   SELECTOR</span><br><span class="line">service-clusterip   ClusterIP   10.97.97.97   &lt;none&gt;        80/TCP    13s   app=nginx-pod</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看service的详细信息</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 在这里有一个Endpoints列表，里面就是当前service可以负载到的服务入口</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl describe svc service-clusterip -n dev</span><br><span class="line">Name:              service-clusterip</span><br><span class="line">Namespace:         dev</span><br><span class="line">Labels:            &lt;none&gt;</span><br><span class="line">Annotations:       &lt;none&gt;</span><br><span class="line">Selector:          app=nginx-pod</span><br><span class="line">Type:              ClusterIP</span><br><span class="line">IP:                10.97.97.97</span><br><span class="line">Port:              &lt;unset&gt;  80/TCP</span><br><span class="line">TargetPort:        80/TCP</span><br><span class="line">Endpoints:         10.244.1.39:80,10.244.1.40:80,10.244.2.33:80</span><br><span class="line">Session Affinity:  None</span><br><span class="line">Events:            &lt;none&gt;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看ipvs的映射规则</span></span><br><span class="line">[root@k8s-master01 ~]# ipvsadm -Ln</span><br><span class="line">TCP  10.97.97.97:80 rr</span><br><span class="line"><span class="meta">  -&gt;</span><span class="bash"> 10.244.1.39:80               Masq    1      0          0</span></span><br><span class="line"><span class="meta">  -&gt;</span><span class="bash"> 10.244.1.40:80               Masq    1      0          0</span></span><br><span class="line"><span class="meta">  -&gt;</span><span class="bash"> 10.244.2.33:80               Masq    1      0          0</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 访问10.97.97.97:80观察效果</span></span><br><span class="line">[root@k8s-master01 ~]# curl 10.97.97.97:80</span><br><span class="line">10.244.2.33</span><br></pre></td></tr></table></figure></div>

<h5 id="7-3-3-Endpoint"><a href="#7-3-3-Endpoint" class="headerlink" title="7.3.3 Endpoint"></a>7.3.3 Endpoint</h5><p>Endpoint是kubernetes中的一个资源对象，存储在etcd中，用来记录一个service对应的所有pod的访问地址，它是根据service配置文件中selector描述产生的。</p>
<p>一个Service由一组Pod组成，这些Pod通过Endpoints暴露出来，<strong>Endpoints是实现实际服务的端点集合</strong>。换句话说，service和pod之间的联系是通过endpoints实现的。</p>
<p><img src="/2022/06/09/uncatalog/cl46zbay9000j7or7b2e4b2pr/image-20200509191917069.png" alt="image-20200509191917069"></p>
<p><strong>负载分发策略</strong></p>
<p>对Service的访问被分发到了后端的Pod上去，目前kubernetes提供了两种负载分发策略：</p>
<ul>
<li><p>如果不定义，默认使用kube-proxy的策略，比如随机、轮询</p>
</li>
<li><p>基于客户端地址的会话保持模式，即来自同一个客户端发起的所有请求都会转发到固定的一个Pod上</p>
<p>此模式可以使在spec中添加<code>sessionAffinity:ClientIP</code>选项</p>
</li>
</ul>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 查看ipvs的映射规则【rr 轮询】</span></span><br><span class="line">[root@k8s-master01 ~]# ipvsadm -Ln</span><br><span class="line">TCP  10.97.97.97:80 rr</span><br><span class="line"><span class="meta">  -&gt;</span><span class="bash"> 10.244.1.39:80               Masq    1      0          0</span></span><br><span class="line"><span class="meta">  -&gt;</span><span class="bash"> 10.244.1.40:80               Masq    1      0          0</span></span><br><span class="line"><span class="meta">  -&gt;</span><span class="bash"> 10.244.2.33:80               Masq    1      0          0</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 循环访问测试</span></span><br><span class="line">[root@k8s-master01 ~]# while true;do curl 10.97.97.97:80; sleep 5; done;</span><br><span class="line">10.244.1.40</span><br><span class="line">10.244.1.39</span><br><span class="line">10.244.2.33</span><br><span class="line">10.244.1.40</span><br><span class="line">10.244.1.39</span><br><span class="line">10.244.2.33</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 修改分发策略----sessionAffinity:ClientIP</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看ipvs规则【persistent 代表持久】</span></span><br><span class="line">[root@k8s-master01 ~]# ipvsadm -Ln</span><br><span class="line">TCP  10.97.97.97:80 rr persistent 10800</span><br><span class="line"><span class="meta">  -&gt;</span><span class="bash"> 10.244.1.39:80               Masq    1      0          0</span></span><br><span class="line"><span class="meta">  -&gt;</span><span class="bash"> 10.244.1.40:80               Masq    1      0          0</span></span><br><span class="line"><span class="meta">  -&gt;</span><span class="bash"> 10.244.2.33:80               Masq    1      0          0</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 循环访问测试</span></span><br><span class="line">[root@k8s-master01 ~]# while true;do curl 10.97.97.97; sleep 5; done;</span><br><span class="line">10.244.2.33</span><br><span class="line">10.244.2.33</span><br><span class="line">10.244.2.33</span><br><span class="line">  </span><br><span class="line"><span class="meta">#</span><span class="bash"> 删除service</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl delete -f service-clusterip.yaml</span><br><span class="line">service &quot;service-clusterip&quot; deleted</span><br></pre></td></tr></table></figure></div>

<h5 id="7-3-4-HeadLiness类型的Service"><a href="#7-3-4-HeadLiness类型的Service" class="headerlink" title="7.3.4 HeadLiness类型的Service"></a>7.3.4 HeadLiness类型的Service</h5><p>在某些场景中，开发人员可能不想使用Service提供的负载均衡功能，而希望自己来控制负载均衡策略，针对这种情况，kubernetes提供了HeadLiness Service，这类Service不会分配Cluster IP，如果想要访问service，只能通过service的域名进行查询。</p>
<p>创建service-headliness.yaml</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">service-headliness</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nginx-pod</span></span><br><span class="line">  <span class="attr">clusterIP:</span> <span class="string">None</span> <span class="comment"># 将clusterIP设置为None，即可创建headliness Service</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">ClusterIP</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span>    </span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure></div>

<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建service</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl create -f service-headliness.yaml</span><br><span class="line">service/service-headliness created</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 获取service， 发现CLUSTER-IP未分配</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl get svc service-headliness -n dev -o wide</span><br><span class="line">NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE   SELECTOR</span><br><span class="line">service-headliness   ClusterIP   None         &lt;none&gt;        80/TCP    11s   app=nginx-pod</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看service详情</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl describe svc service-headliness  -n dev</span><br><span class="line">Name:              service-headliness</span><br><span class="line">Namespace:         dev</span><br><span class="line">Labels:            &lt;none&gt;</span><br><span class="line">Annotations:       &lt;none&gt;</span><br><span class="line">Selector:          app=nginx-pod</span><br><span class="line">Type:              ClusterIP</span><br><span class="line">IP:                None</span><br><span class="line">Port:              &lt;unset&gt;  80/TCP</span><br><span class="line">TargetPort:        80/TCP</span><br><span class="line">Endpoints:         10.244.1.39:80,10.244.1.40:80,10.244.2.33:80</span><br><span class="line">Session Affinity:  None</span><br><span class="line">Events:            &lt;none&gt;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看域名的解析情况</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl exec -it pc-deployment-66cb59b984-8p84h -n dev /bin/sh</span><br><span class="line">/ # cat /etc/resolv.conf</span><br><span class="line">nameserver 10.96.0.10</span><br><span class="line">search dev.svc.cluster.local svc.cluster.local cluster.local</span><br><span class="line"></span><br><span class="line">[root@k8s-master01 ~]# dig @10.96.0.10 service-headliness.dev.svc.cluster.local</span><br><span class="line">service-headliness.dev.svc.cluster.local. 30 IN A 10.244.1.40</span><br><span class="line">service-headliness.dev.svc.cluster.local. 30 IN A 10.244.1.39</span><br><span class="line">service-headliness.dev.svc.cluster.local. 30 IN A 10.244.2.33</span><br></pre></td></tr></table></figure></div>

<h5 id="7-3-5-NodePort类型的Service"><a href="#7-3-5-NodePort类型的Service" class="headerlink" title="7.3.5 NodePort类型的Service"></a>7.3.5 NodePort类型的Service</h5><p>在之前的样例中，创建的Service的ip地址只有集群内部才可以访问，如果希望将Service暴露给集群外部使用，那么就要使用到另外一种类型的Service，称为NodePort类型。NodePort的工作原理其实就是<strong>将service的端口映射到Node的一个端口上</strong>，然后就可以通过<code>NodeIp:NodePort</code>来访问service了。</p>
<p><img src="/2022/06/09/uncatalog/cl46zbay9000j7or7b2e4b2pr/image-20200620175731338.png" alt="img"></p>
<p>创建service-nodeport.yaml</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">service-nodeport</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nginx-pod</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">NodePort</span> <span class="comment"># service类型</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">nodePort:</span> <span class="number">30002</span> <span class="comment"># 指定绑定的node的端口(默认的取值范围是：30000-32767), 如果不指定，会默认分配</span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure></div>

<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建service</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl create -f service-nodeport.yaml</span><br><span class="line">service/service-nodeport created</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看service</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl get svc -n dev -o wide</span><br><span class="line">NAME               TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)       SELECTOR</span><br><span class="line">service-nodeport   NodePort   10.105.64.191   &lt;none&gt;        80:30002/TCP  app=nginx-pod</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 接下来可以通过电脑主机的浏览器去访问集群中任意一个nodeip的30002端口，即可访问到pod</span></span><br></pre></td></tr></table></figure></div>

<h5 id="7-3-6-LoadBalancer类型的Service"><a href="#7-3-6-LoadBalancer类型的Service" class="headerlink" title="7.3.6 LoadBalancer类型的Service"></a>7.3.6 LoadBalancer类型的Service</h5><p>LoadBalancer和NodePort很相似，目的都是向外部暴露一个端口，区别在于LoadBalancer会在集群的外部再来做一个负载均衡设备，而这个设备需要外部环境支持的，外部服务发送到这个设备上的请求，会被设备负载之后转发到集群中。</p>
<p><img src="/2022/06/09/uncatalog/cl46zbay9000j7or7b2e4b2pr/image-20200510103945494.png" alt="img"></p>
<h5 id="7-3-7-ExternalName类型的Service"><a href="#7-3-7-ExternalName类型的Service" class="headerlink" title="7.3.7 ExternalName类型的Service"></a>7.3.7 ExternalName类型的Service</h5><p>ExternalName类型的Service用于引入集群外部的服务，它通过<code>externalName</code>属性指定外部一个服务的地址，然后在集群内部访问此service就可以访问到外部的服务了。</p>
<p><img src="/2022/06/09/uncatalog/cl46zbay9000j7or7b2e4b2pr/image-20200510113311209.png" alt="img"></p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: service-externalname</span><br><span class="line">  namespace: dev</span><br><span class="line">spec:</span><br><span class="line">  type: ExternalName # service类型</span><br><span class="line">  externalName: www.baidu.com  #改成ip地址也可以</span><br></pre></td></tr></table></figure></div>

<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建service</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl  create -f service-externalname.yaml</span><br><span class="line">service/service-externalname created</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 域名解析</span></span><br><span class="line">[root@k8s-master01 ~]# dig @10.96.0.10 service-externalname.dev.svc.cluster.local</span><br><span class="line">service-externalname.dev.svc.cluster.local. 30 IN CNAME www.baidu.com.</span><br><span class="line">www.baidu.com.          30      IN      CNAME   www.a.shifen.com.</span><br><span class="line">www.a.shifen.com.       30      IN      A       39.156.66.18</span><br><span class="line">www.a.shifen.com.       30      IN      A       39.156.66.14</span><br></pre></td></tr></table></figure></div>

<h4 id="7-4-Ingress介绍"><a href="#7-4-Ingress介绍" class="headerlink" title="7.4 Ingress介绍"></a>7.4 Ingress介绍</h4><p>在前面课程中已经提到，Service对集群之外暴露服务的主要方式有两种：NotePort和LoadBalancer，但是这两种方式，都有一定的缺点：</p>
<ul>
<li>NodePort方式的缺点是会占用很多集群机器的端口，那么当集群服务变多的时候，这个缺点就愈发明显</li>
<li>LB方式的缺点是每个service需要一个LB，浪费、麻烦，并且需要kubernetes之外设备的支持</li>
</ul>
<p>基于这种现状，kubernetes提供了Ingress资源对象，Ingress只需要一个NodePort或者一个LB就可以满足暴露多个Service的需求。工作机制大致如下图表示：</p>
<p><img src="/2022/06/09/uncatalog/cl46zbay9000j7or7b2e4b2pr/image-20200623092808049.png" alt="img"></p>
<p>实际上，Ingress相当于一个7层的负载均衡器，是kubernetes对反向代理的一个抽象，它的工作原理类似于Nginx，可以理解成在<strong>Ingress里建立诸多映射规则，Ingress Controller通过监听这些配置规则并转化成Nginx的反向代理配置 , 然后对外部提供服务</strong>。在这里有两个核心概念：</p>
<ul>
<li>ingress：kubernetes中的一个对象，作用是定义请求如何转发到service的规则</li>
<li>ingress controller：具体实现反向代理及负载均衡的程序，对ingress定义的规则进行解析，根据配置的规则来实现请求转发，实现方式有很多，比如Nginx, Contour, Haproxy等等</li>
</ul>
<p>Ingress（以Nginx为例）的工作原理如下：</p>
<ol>
<li>用户编写Ingress规则，说明哪个域名对应kubernetes集群中的哪个Service</li>
<li>Ingress控制器动态感知Ingress服务规则的变化，然后生成一段对应的Nginx反向代理配置</li>
<li>Ingress控制器会将生成的Nginx配置写入到一个运行着的Nginx服务中，并动态更新</li>
<li>到此为止，其实真正在工作的就是一个Nginx了，内部配置了用户定义的请求转发规则</li>
</ol>
<p><img src="/2022/06/09/uncatalog/cl46zbay9000j7or7b2e4b2pr/image-20200516112704764.png" alt="img"></p>
<h4 id="7-5-Ingress使用"><a href="#7-5-Ingress使用" class="headerlink" title="7.5 Ingress使用"></a>7.5 Ingress使用</h4><h5 id="7-5-1-环境准备-搭建ingress环境"><a href="#7-5-1-环境准备-搭建ingress环境" class="headerlink" title="7.5.1 环境准备 搭建ingress环境"></a>7.5.1 环境准备 搭建ingress环境</h5><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="MAKEFILE"><figure class="iseeu highlight /makefile"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建文件夹</span></span><br><span class="line">[root@k8s-master01 ~]<span class="comment"># mkdir ingress-controller</span></span><br><span class="line">[root@k8s-master01 ~]<span class="comment"># cd ingress-controller/</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取ingress-nginx，本次案例使用的是0.30版本</span></span><br><span class="line">[root@k8s-master01 ingress-controller]<span class="comment"># wget https://raw.githubusercontent.com/kubernetes/ingress-nginx/nginx-0.30.0/deploy/static/mandatory.yaml</span></span><br><span class="line">[root@k8s-master01 ingress-controller]<span class="comment"># wget https://raw.githubusercontent.com/kubernetes/ingress-nginx/nginx-0.30.0/deploy/static/provider/baremetal/service-nodeport.yaml</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改mandatory.yaml文件中的仓库</span></span><br><span class="line"><span class="comment"># 修改quay.io/kubernetes-ingress-controller/nginx-ingress-controller:0.30.0</span></span><br><span class="line"><span class="comment"># 为quay-mirror.qiniu.com/kubernetes-ingress-controller/nginx-ingress-controller:0.30.0</span></span><br><span class="line"><span class="comment"># 创建ingress-nginx</span></span><br><span class="line">[root@k8s-master01 ingress-controller]<span class="comment"># kubectl apply -f ./</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看ingress-nginx</span></span><br><span class="line">[root@k8s-master01 ingress-controller]<span class="comment"># kubectl get pod -n ingress-nginx</span></span><br><span class="line">NAME                                           READY   STATUS    RESTARTS   AGE</span><br><span class="line">pod/nginx-ingress-controller-fbf967dd5-4qpbp   1/1     Running   0          12h</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看service</span></span><br><span class="line">[root@k8s-master01 ingress-controller]<span class="comment"># kubectl get svc -n ingress-nginx</span></span><br><span class="line">NAME            TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)                      AGE</span><br><span class="line">ingress-nginx   NodePort   10.98.75.163   &lt;none&gt;        80:32240/TCP,443:31335/TCP   11h</span><br></pre></td></tr></table></figure></div>

<h5 id="7-5-2-准备service和pod"><a href="#7-5-2-准备service和pod" class="headerlink" title="7.5.2 准备service和pod"></a>7.5.2 准备service和pod</h5><p>为了后面的实验比较方便，创建如下图所示的模型</p>
<p><img src="/2022/06/09/uncatalog/cl46zbay9000j7or7b2e4b2pr/image-20200516102419998.png" alt="img"></p>
<p>创建tomcat-nginx.yaml</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx-deployment</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">3</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">nginx-pod</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">nginx-pod</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">tomcat-deployment</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">3</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">tomcat-pod</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">tomcat-pod</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">tomcat</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">tomcat:8.5-jre10-slim</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">8080</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx-service</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nginx-pod</span></span><br><span class="line">  <span class="attr">clusterIP:</span> <span class="string">None</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">ClusterIP</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">80</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">tomcat-service</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">tomcat-pod</span></span><br><span class="line">  <span class="attr">clusterIP:</span> <span class="string">None</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">ClusterIP</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">8080</span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">8080</span></span><br></pre></td></tr></table></figure></div>

<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl create -f tomcat-nginx.yaml</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl get svc -n dev</span><br><span class="line">NAME             TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)    AGE</span><br><span class="line">nginx-service    ClusterIP   None         &lt;none&gt;        80/TCP     48s</span><br><span class="line">tomcat-service   ClusterIP   None         &lt;none&gt;        8080/TCP   48s</span><br></pre></td></tr></table></figure></div>

<h5 id="7-5-3-Http代理"><a href="#7-5-3-Http代理" class="headerlink" title="7.5.3 Http代理"></a>7.5.3 Http代理</h5><p>创建ingress-http.yaml</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Ingress</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ingress-http</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">nginx.itheima.com</span></span><br><span class="line">    <span class="attr">http:</span></span><br><span class="line">      <span class="attr">paths:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/</span></span><br><span class="line">        <span class="attr">backend:</span></span><br><span class="line">          <span class="attr">serviceName:</span> <span class="string">nginx-service</span></span><br><span class="line">          <span class="attr">servicePort:</span> <span class="number">80</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">tomcat.itheima.com</span></span><br><span class="line">    <span class="attr">http:</span></span><br><span class="line">      <span class="attr">paths:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/</span></span><br><span class="line">        <span class="attr">backend:</span></span><br><span class="line">          <span class="attr">serviceName:</span> <span class="string">tomcat-service</span></span><br><span class="line">          <span class="attr">servicePort:</span> <span class="number">8080</span></span><br></pre></td></tr></table></figure></div>

<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl create -f ingress-http.yaml</span><br><span class="line">ingress.extensions/ingress-http created</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl get ing ingress-http -n dev</span><br><span class="line">NAME           HOSTS                                  ADDRESS   PORTS   AGE</span><br><span class="line">ingress-http   nginx.itheima.com,tomcat.itheima.com             80      22s</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看详情</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl describe ing ingress-http  -n dev</span><br><span class="line">...</span><br><span class="line">Rules:</span><br><span class="line">Host                Path  Backends</span><br><span class="line">----                ----  --------</span><br><span class="line">nginx.itheima.com   / nginx-service:80 (10.244.1.96:80,10.244.1.97:80,10.244.2.112:80)</span><br><span class="line">tomcat.itheima.com  / tomcat-service:8080(10.244.1.94:8080,10.244.1.95:8080,10.244.2.111:8080)</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 接下来,在本地电脑上配置host文件,解析上面的两个域名到192.168.109.100(master)上</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 然后,就可以分别访问tomcat.itheima.com:32240  和  nginx.itheima.com:32240 查看效果了</span></span><br></pre></td></tr></table></figure></div>

<h5 id="7-5-4-Https代理"><a href="#7-5-4-Https代理" class="headerlink" title="7.5.4 Https代理"></a>7.5.4 Https代理</h5><p>创建证书</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 生成证书</span></span><br><span class="line">openssl req -x509 -sha256 -nodes -days 365 -newkey rsa:2048 -keyout tls.key -out tls.crt -subj &quot;/C=CN/ST=BJ/L=BJ/O=nginx/CN=itheima.com&quot;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建密钥</span></span><br><span class="line">kubectl create secret tls tls-secret --key tls.key --cert tls.crt</span><br></pre></td></tr></table></figure></div>

<p>创建ingress-https.yaml</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Ingress</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ingress-https</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">tls:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">hosts:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">nginx.itheima.com</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">tomcat.itheima.com</span></span><br><span class="line">      <span class="attr">secretName:</span> <span class="string">tls-secret</span> <span class="comment"># 指定秘钥</span></span><br><span class="line">  <span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">nginx.itheima.com</span></span><br><span class="line">    <span class="attr">http:</span></span><br><span class="line">      <span class="attr">paths:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/</span></span><br><span class="line">        <span class="attr">backend:</span></span><br><span class="line">          <span class="attr">serviceName:</span> <span class="string">nginx-service</span></span><br><span class="line">          <span class="attr">servicePort:</span> <span class="number">80</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">tomcat.itheima.com</span></span><br><span class="line">    <span class="attr">http:</span></span><br><span class="line">      <span class="attr">paths:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/</span></span><br><span class="line">        <span class="attr">backend:</span></span><br><span class="line">          <span class="attr">serviceName:</span> <span class="string">tomcat-service</span></span><br><span class="line">          <span class="attr">servicePort:</span> <span class="number">8080</span></span><br></pre></td></tr></table></figure></div>

<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl create -f ingress-https.yaml</span><br><span class="line">ingress.extensions/ingress-https created</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl get ing ingress-https -n dev</span><br><span class="line">NAME            HOSTS                                  ADDRESS         PORTS     AGE</span><br><span class="line">ingress-https   nginx.itheima.com,tomcat.itheima.com   10.104.184.38   80, 443   2m42s</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看详情</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl describe ing ingress-https -n dev</span><br><span class="line">...</span><br><span class="line">TLS:</span><br><span class="line">  tls-secret terminates nginx.itheima.com,tomcat.itheima.com</span><br><span class="line">Rules:</span><br><span class="line">Host              Path Backends</span><br><span class="line">----              ---- --------</span><br><span class="line">nginx.itheima.com  /  nginx-service:80 (10.244.1.97:80,10.244.1.98:80,10.244.2.119:80)</span><br><span class="line">tomcat.itheima.com /  tomcat-service:8080(10.244.1.99:8080,10.244.2.117:8080,10.244.2.120:8080)</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 下面可以通过浏览器访问https://nginx.itheima.com:31335 和 https://tomcat.itheima.com:31335来查看了</span></span><br></pre></td></tr></table></figure></div>
]]></content>
      <tags>
        <tag>云原生基础系列</tag>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>云原生基础系列之Kubernetes(八)数据存储</title>
    <url>/2022/06/09/uncatalog/cl46zbay9000k7or71j4vcb8a/</url>
    <content><![CDATA[<hr>
<span id="more"></span>



<hr>
<h3 id="8-数据存储"><a href="#8-数据存储" class="headerlink" title="8. 数据存储"></a>8. 数据存储</h3><p>在前面已经提到，容器的生命周期可能很短，会被频繁地创建和销毁。那么容器在销毁时，保存在容器中的数据也会被清除。这种结果对用户来说，在某些情况下是不乐意看到的。为了持久化保存容器的数据，kubernetes引入了Volume的概念。</p>
<p>Volume是Pod中能够被多个容器访问的共享目录，它被定义在Pod上，然后被一个Pod里的多个容器挂载到具体的文件目录下，kubernetes通过Volume实现同一个Pod中不同容器之间的数据共享以及数据的持久化存储。Volume的生命容器不与Pod中单个容器的生命周期相关，当容器终止或者重启时，Volume中的数据也不会丢失。</p>
<p>kubernetes的Volume支持多种类型，比较常见的有下面几个：</p>
<ul>
<li>简单存储：EmptyDir、HostPath、NFS</li>
<li>高级存储：PV、PVC</li>
<li>配置存储：ConfigMap、Secret</li>
</ul>
<h4 id="8-1-基本存储"><a href="#8-1-基本存储" class="headerlink" title="8.1 基本存储"></a>8.1 基本存储</h4><h5 id="8-1-1-EmptyDir"><a href="#8-1-1-EmptyDir" class="headerlink" title="8.1.1 EmptyDir"></a>8.1.1 EmptyDir</h5><p>EmptyDir是最基础的Volume类型，一个EmptyDir就是Host上的一个空目录。</p>
<p>EmptyDir是在Pod被分配到Node时创建的，它的初始内容为空，并且无须指定宿主机上对应的目录文件，因为kubernetes会自动分配一个目录，当Pod销毁时， EmptyDir中的数据也会被永久删除。 EmptyDir用途如下：</p>
<ul>
<li>临时空间，例如用于某些应用程序运行时所需的临时目录，且无须永久保留</li>
<li>一个容器需要从另一个容器中获取数据的目录（多容器共享目录）</li>
</ul>
<p>接下来，通过一个容器之间文件共享的案例来使用一下EmptyDir。</p>
<p>在一个Pod中准备两个容器nginx和busybox，然后声明一个Volume分别挂在到两个容器的目录中，然后nginx容器负责向Volume中写日志，busybox中通过命令将日志内容读到控制台。</p>
<p><img src="/2022/06/09/uncatalog/cl46zbay9000k7or71j4vcb8a/image-20200413174713773.png" alt="img"></p>
<p>创建一个volume-emptydir.yaml</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">volume-emptydir</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">volumeMounts:</span>  <span class="comment"># 将logs-volume挂在到nginx容器中，对应的目录为 /var/log/nginx</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">logs-volume</span></span><br><span class="line">      <span class="attr">mountPath:</span> <span class="string">/var/log/nginx</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">busybox</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">busybox:1.30</span></span><br><span class="line">    <span class="attr">command:</span> [<span class="string">&quot;/bin/sh&quot;</span>,<span class="string">&quot;-c&quot;</span>,<span class="string">&quot;tail -f /logs/access.log&quot;</span>] <span class="comment"># 初始命令，动态读取指定文件中内容</span></span><br><span class="line">    <span class="attr">volumeMounts:</span>  <span class="comment"># 将logs-volume 挂在到busybox容器中，对应的目录为 /logs</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">logs-volume</span></span><br><span class="line">      <span class="attr">mountPath:</span> <span class="string">/logs</span></span><br><span class="line">  <span class="attr">volumes:</span> <span class="comment"># 声明volume， name为logs-volume，类型为emptyDir</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">logs-volume</span></span><br><span class="line">    <span class="attr">emptyDir:</span> &#123;&#125;</span><br></pre></td></tr></table></figure></div>

<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建Pod</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl create -f volume-emptydir.yaml</span><br><span class="line">pod/volume-emptydir created</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看pod</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl get pods volume-emptydir -n dev -o wide</span><br><span class="line">NAME                  READY   STATUS    RESTARTS   AGE      IP       NODE   ...... </span><br><span class="line">volume-emptydir       2/2     Running   0          97s   10.42.2.9   node1  ......</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 通过podIp访问nginx</span></span><br><span class="line">[root@k8s-master01 ~]# curl 10.42.2.9</span><br><span class="line">......</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 通过kubectl logs命令查看指定容器的标准输出</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl logs -f volume-emptydir -n dev -c busybox</span><br><span class="line">10.42.1.0 - - [27/Jun/2021:15:08:54 +0000] &quot;GET / HTTP/1.1&quot; 200 612 &quot;-&quot; &quot;curl/7.29.0&quot; &quot;-&quot;</span><br></pre></td></tr></table></figure></div>

<h5 id="8-1-2-HostPath"><a href="#8-1-2-HostPath" class="headerlink" title="8.1.2 HostPath"></a>8.1.2 HostPath</h5><p>上节课提到，EmptyDir中数据不会被持久化，它会随着Pod的结束而销毁，如果想简单的将数据持久化到主机中，可以选择HostPath。</p>
<p>HostPath就是将Node主机中一个实际目录挂在到Pod中，以供容器使用，这样的设计就可以保证Pod销毁了，但是数据依据可以存在于Node主机上。</p>
<p><img src="/2022/06/09/uncatalog/cl46zbay9000k7or71j4vcb8a/image-20200413214031331.png" alt="img"></p>
<p>创建一个volume-hostpath.yaml：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">volume-hostpath</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">volumeMounts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">logs-volume</span></span><br><span class="line">      <span class="attr">mountPath:</span> <span class="string">/var/log/nginx</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">busybox</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">busybox:1.30</span></span><br><span class="line">    <span class="attr">command:</span> [<span class="string">&quot;/bin/sh&quot;</span>,<span class="string">&quot;-c&quot;</span>,<span class="string">&quot;tail -f /logs/access.log&quot;</span>]</span><br><span class="line">    <span class="attr">volumeMounts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">logs-volume</span></span><br><span class="line">      <span class="attr">mountPath:</span> <span class="string">/logs</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">logs-volume</span></span><br><span class="line">    <span class="attr">hostPath:</span> </span><br><span class="line">      <span class="attr">path:</span> <span class="string">/root/logs</span></span><br><span class="line">      <span class="attr">type:</span> <span class="string">DirectoryOrCreate</span>  <span class="comment"># 目录存在就使用，不存在就先创建后使用</span></span><br></pre></td></tr></table></figure></div>

<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tr><td class="code"><pre><span class="line">关于type的值的一点说明：</span><br><span class="line">    DirectoryOrCreate 目录存在就使用，不存在就先创建后使用</span><br><span class="line">    Directory   目录必须存在</span><br><span class="line">    FileOrCreate  文件存在就使用，不存在就先创建后使用</span><br><span class="line">    File 文件必须存在 </span><br><span class="line">    Socket  unix套接字必须存在</span><br><span class="line">    CharDevice  字符设备必须存在</span><br><span class="line">    BlockDevice 块设备必须存在</span><br></pre></td></tr></table></figure></div>

<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建Pod</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl create -f volume-hostpath.yaml</span><br><span class="line">pod/volume-hostpath created</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看Pod</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl get pods volume-hostpath -n dev -o wide</span><br><span class="line">NAME                  READY   STATUS    RESTARTS   AGE   IP             NODE   ......</span><br><span class="line">pod-volume-hostpath   2/2     Running   0          16s   10.42.2.10     node1  ......</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">访问nginx</span></span><br><span class="line">[root@k8s-master01 ~]# curl 10.42.2.10</span><br><span class="line"></span><br><span class="line">[root@k8s-master01 ~]# kubectl logs -f volume-emptydir -n dev -c busybox</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 接下来就可以去host的/root/logs目录下查看存储的文件了</span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">##  注意: 下面的操作需要到Pod所在的节点运行（案例中是node1）</span></span></span><br><span class="line">[root@node1 ~]# ls /root/logs/</span><br><span class="line">access.log  error.log</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 同样的道理，如果在此目录下创建一个文件，到容器中也是可以看到的</span></span><br></pre></td></tr></table></figure></div>

<h5 id="8-1-3-NFS"><a href="#8-1-3-NFS" class="headerlink" title="8.1.3 NFS"></a>8.1.3 NFS</h5><p>HostPath可以解决数据持久化的问题，但是一旦Node节点故障了，Pod如果转移到了别的节点，又会出现问题了，此时需要准备单独的网络存储系统，比较常用的用NFS、CIFS。</p>
<p>NFS是一个网络文件存储系统，可以搭建一台NFS服务器，然后将Pod中的存储直接连接到NFS系统上，这样的话，无论Pod在节点上怎么转移，只要Node跟NFS的对接没问题，数据就可以成功访问。</p>
<p><img src="/2022/06/09/uncatalog/cl46zbay9000k7or71j4vcb8a/image-20200413215133559.png" alt="img"></p>
<p>1）首先要准备nfs的服务器，这里为了简单，直接是master节点做nfs服务器</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 在nfs上安装nfs服务</span></span><br><span class="line">[root@nfs ~]# yum install nfs-utils -y</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 准备一个共享目录</span></span><br><span class="line">[root@nfs ~]# mkdir /root/data/nfs -pv</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 将共享目录以读写权限暴露给192.168.5.0/24网段中的所有主机</span></span><br><span class="line">[root@nfs ~]# vim /etc/exports</span><br><span class="line">[root@nfs ~]# more /etc/exports</span><br><span class="line">/root/data/nfs     192.168.5.0/24(rw,no_root_squash)</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 启动nfs服务</span></span><br><span class="line">[root@nfs ~]# systemctl restart nfs</span><br></pre></td></tr></table></figure></div>

<p>2）接下来，要在的每个node节点上都安装下nfs，这样的目的是为了node节点可以驱动nfs设备</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 在node上安装nfs服务，注意不需要启动</span></span><br><span class="line">[root@k8s-master01 ~]# yum install nfs-utils -y</span><br></pre></td></tr></table></figure></div>

<p>3）接下来，就可以编写pod的配置文件了，创建volume-nfs.yaml</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">volume-nfs</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">volumeMounts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">logs-volume</span></span><br><span class="line">      <span class="attr">mountPath:</span> <span class="string">/var/log/nginx</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">busybox</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">busybox:1.30</span></span><br><span class="line">    <span class="attr">command:</span> [<span class="string">&quot;/bin/sh&quot;</span>,<span class="string">&quot;-c&quot;</span>,<span class="string">&quot;tail -f /logs/access.log&quot;</span>] </span><br><span class="line">    <span class="attr">volumeMounts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">logs-volume</span></span><br><span class="line">      <span class="attr">mountPath:</span> <span class="string">/logs</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">logs-volume</span></span><br><span class="line">    <span class="attr">nfs:</span></span><br><span class="line">      <span class="attr">server:</span> <span class="number">192.168</span><span class="number">.5</span><span class="number">.6</span>  <span class="comment">#nfs服务器地址</span></span><br><span class="line">      <span class="attr">path:</span> <span class="string">/root/data/nfs</span> <span class="comment">#共享文件路径</span></span><br></pre></td></tr></table></figure></div>

<p>4）最后，运行下pod，观察结果</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建pod</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl create -f volume-nfs.yaml</span><br><span class="line">pod/volume-nfs created</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看pod</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl get pods volume-nfs -n dev</span><br><span class="line">NAME                  READY   STATUS    RESTARTS   AGE</span><br><span class="line">volume-nfs        2/2     Running   0          2m9s</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看nfs服务器上的共享目录，发现已经有文件了</span></span><br><span class="line">[root@k8s-master01 ~]# ls /root/data/</span><br><span class="line">access.log  error.log</span><br></pre></td></tr></table></figure></div>

<h4 id="8-2-高级存储"><a href="#8-2-高级存储" class="headerlink" title="8.2 高级存储"></a>8.2 高级存储</h4><p>前面已经学习了使用NFS提供存储，此时就要求用户会搭建NFS系统，并且会在yaml配置nfs。由于kubernetes支持的存储系统有很多，要求客户全都掌握，显然不现实。为了能够屏蔽底层存储实现的细节，方便用户使用， kubernetes引入PV和PVC两种资源对象。</p>
<ul>
<li><p>PV（Persistent Volume）是持久化卷的意思，是对底层的共享存储的一种抽象。一般情况下PV由kubernetes管理员进行创建和配置，它与底层具体的共享存储技术有关，并通过插件完成与共享存储的对接。</p>
</li>
<li><p>PVC（Persistent Volume Claim）是持久卷声明的意思，是用户对于存储需求的一种声明。换句话说，PVC其实就是用户向kubernetes系统发出的一种资源需求申请。</p>
</li>
</ul>
<p><img src="/2022/06/09/uncatalog/cl46zbay9000k7or71j4vcb8a/image-20200514194111567.png" alt="img"></p>
<p>使用了PV和PVC之后，工作可以得到进一步的细分：</p>
<ul>
<li>存储：存储工程师维护</li>
<li>PV： kubernetes管理员维护</li>
<li>PVC：kubernetes用户维护</li>
</ul>
<h5 id="8-2-1-PV"><a href="#8-2-1-PV" class="headerlink" title="8.2.1 PV"></a>8.2.1 PV</h5><p>PV是存储资源的抽象，下面是资源清单文件:</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span>  </span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolume</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pv2</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">nfs:</span> <span class="comment"># 存储类型，与底层真正存储对应</span></span><br><span class="line">  <span class="attr">capacity:</span>  <span class="comment"># 存储能力，目前只支持存储空间的设置</span></span><br><span class="line">    <span class="attr">storage:</span> <span class="string">2Gi</span></span><br><span class="line">  <span class="attr">accessModes:</span>  <span class="comment"># 访问模式</span></span><br><span class="line">  <span class="attr">storageClassName:</span> <span class="comment"># 存储类别</span></span><br><span class="line">  <span class="attr">persistentVolumeReclaimPolicy:</span> <span class="comment"># 回收策略</span></span><br></pre></td></tr></table></figure></div>

<p>PV 的关键配置参数说明：</p>
<ul>
<li><p><strong>存储类型</strong></p>
<p>底层实际存储的类型，kubernetes支持多种存储类型，每种存储类型的配置都有所差异</p>
</li>
<li><p><strong>存储能力（capacity）</strong></p>
</li>
</ul>
<p>目前只支持存储空间的设置( storage=1Gi )，不过未来可能会加入IOPS、吞吐量等指标的配置</p>
<ul>
<li><p><strong>访问模式（accessModes）</strong></p>
<p>用于描述用户应用对存储资源的访问权限，访问权限包括下面几种方式：</p>
<ul>
<li>ReadWriteOnce（RWO）：读写权限，但是只能被单个节点挂载</li>
<li>ReadOnlyMany（ROX）： 只读权限，可以被多个节点挂载</li>
<li>ReadWriteMany（RWX）：读写权限，可以被多个节点挂载</li>
</ul>
<p><code>需要注意的是，底层不同的存储类型可能支持的访问模式不同</code></p>
</li>
<li><p><strong>回收策略（persistentVolumeReclaimPolicy）</strong></p>
<p>当PV不再被使用了之后，对其的处理方式。目前支持三种策略：</p>
<ul>
<li>Retain （保留） 保留数据，需要管理员手工清理数据</li>
<li>Recycle（回收） 清除 PV 中的数据，效果相当于执行 rm -rf /thevolume/*</li>
<li>Delete （删除） 与 PV 相连的后端存储完成 volume 的删除操作，当然这常见于云服务商的存储服务</li>
</ul>
<p><code>需要注意的是，底层不同的存储类型可能支持的回收策略不同</code></p>
</li>
<li><p><strong>存储类别</strong></p>
<p>PV可以通过storageClassName参数指定一个存储类别</p>
<ul>
<li>具有特定类别的PV只能与请求了该类别的PVC进行绑定</li>
<li>未设定类别的PV则只能与不请求任何类别的PVC进行绑定</li>
</ul>
</li>
<li><p><strong>状态（status）</strong></p>
<p>一个 PV 的生命周期中，可能会处于4中不同的阶段：</p>
<ul>
<li>Available（可用）： 表示可用状态，还未被任何 PVC 绑定</li>
<li>Bound（已绑定）： 表示 PV 已经被 PVC 绑定</li>
<li>Released（已释放）： 表示 PVC 被删除，但是资源还未被集群重新声明</li>
<li>Failed（失败）： 表示该 PV 的自动回收失败</li>
</ul>
</li>
</ul>
<p><strong>实验</strong></p>
<p>使用NFS作为存储，来演示PV的使用，创建3个PV，对应NFS中的3个暴露的路径。</p>
<ol>
<li>准备NFS环境</li>
</ol>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建目录</span></span><br><span class="line">[root@nfs ~]# mkdir /root/data/&#123;pv1,pv2,pv3&#125; -pv</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 暴露服务</span></span><br><span class="line">[root@nfs ~]# more /etc/exports</span><br><span class="line">/root/data/pv1     192.168.5.0/24(rw,no_root_squash)</span><br><span class="line">/root/data/pv2     192.168.5.0/24(rw,no_root_squash)</span><br><span class="line">/root/data/pv3     192.168.5.0/24(rw,no_root_squash)</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 重启服务</span></span><br><span class="line">[root@nfs ~]#  systemctl restart nfs</span><br></pre></td></tr></table></figure></div>

<ol start="2">
<li>创建pv.yaml</li>
</ol>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolume</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span>  <span class="string">pv1</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">capacity:</span> </span><br><span class="line">    <span class="attr">storage:</span> <span class="string">1Gi</span></span><br><span class="line">  <span class="attr">accessModes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">ReadWriteMany</span></span><br><span class="line">  <span class="attr">persistentVolumeReclaimPolicy:</span> <span class="string">Retain</span></span><br><span class="line">  <span class="attr">nfs:</span></span><br><span class="line">    <span class="attr">path:</span> <span class="string">/root/data/pv1</span></span><br><span class="line">    <span class="attr">server:</span> <span class="number">192.168</span><span class="number">.5</span><span class="number">.6</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolume</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span>  <span class="string">pv2</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">capacity:</span> </span><br><span class="line">    <span class="attr">storage:</span> <span class="string">2Gi</span></span><br><span class="line">  <span class="attr">accessModes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">ReadWriteMany</span></span><br><span class="line">  <span class="attr">persistentVolumeReclaimPolicy:</span> <span class="string">Retain</span></span><br><span class="line">  <span class="attr">nfs:</span></span><br><span class="line">    <span class="attr">path:</span> <span class="string">/root/data/pv2</span></span><br><span class="line">    <span class="attr">server:</span> <span class="number">192.168</span><span class="number">.5</span><span class="number">.6</span></span><br><span class="line">    </span><br><span class="line"><span class="meta">---</span></span><br><span class="line"></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolume</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span>  <span class="string">pv3</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">capacity:</span> </span><br><span class="line">    <span class="attr">storage:</span> <span class="string">3Gi</span></span><br><span class="line">  <span class="attr">accessModes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">ReadWriteMany</span></span><br><span class="line">  <span class="attr">persistentVolumeReclaimPolicy:</span> <span class="string">Retain</span></span><br><span class="line">  <span class="attr">nfs:</span></span><br><span class="line">    <span class="attr">path:</span> <span class="string">/root/data/pv3</span></span><br><span class="line">    <span class="attr">server:</span> <span class="number">192.168</span><span class="number">.5</span><span class="number">.6</span></span><br></pre></td></tr></table></figure></div>

<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建 pv</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl create -f pv.yaml</span><br><span class="line">persistentvolume/pv1 created</span><br><span class="line">persistentvolume/pv2 created</span><br><span class="line">persistentvolume/pv3 created</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看pv</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl get pv -o wide</span><br><span class="line">NAME   CAPACITY   ACCESS MODES  RECLAIM POLICY  STATUS      AGE   VOLUMEMODE</span><br><span class="line">pv1    1Gi        RWX            Retain        Available    10s   Filesystem</span><br><span class="line">pv2    2Gi        RWX            Retain        Available    10s   Filesystem</span><br><span class="line">pv3    3Gi        RWX            Retain        Available    9s    Filesystem</span><br></pre></td></tr></table></figure></div>

<h5 id="8-2-2-PVC"><a href="#8-2-2-PVC" class="headerlink" title="8.2.2 PVC"></a>8.2.2 PVC</h5><p>PVC是资源的申请，用来声明对存储空间、访问模式、存储类别需求信息。下面是资源清单文件:</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolumeClaim</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pvc</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">accessModes:</span> <span class="comment"># 访问模式</span></span><br><span class="line">  <span class="attr">selector:</span> <span class="comment"># 采用标签对PV选择</span></span><br><span class="line">  <span class="attr">storageClassName:</span> <span class="comment"># 存储类别</span></span><br><span class="line">  <span class="attr">resources:</span> <span class="comment"># 请求空间</span></span><br><span class="line">    <span class="attr">requests:</span></span><br><span class="line">      <span class="attr">storage:</span> <span class="string">5Gi</span></span><br></pre></td></tr></table></figure></div>

<p>PVC 的关键配置参数说明：</p>
<ul>
<li><strong>访问模式（accessModes）</strong></li>
</ul>
<p>用于描述用户应用对存储资源的访问权限</p>
<ul>
<li><p><strong>选择条件（selector）</strong></p>
<p>通过Label Selector的设置，可使PVC对于系统中己存在的PV进行筛选</p>
</li>
<li><p><strong>存储类别（storageClassName）</strong></p>
<p>PVC在定义时可以设定需要的后端存储的类别，只有设置了该class的pv才能被系统选出</p>
</li>
<li><p><strong>资源请求（Resources ）</strong></p>
<p>描述对存储资源的请求</p>
</li>
</ul>
<p><strong>实验</strong></p>
<ol>
<li>创建pvc.yaml，申请pv</li>
</ol>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolumeClaim</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pvc1</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">accessModes:</span> </span><br><span class="line">  <span class="bullet">-</span> <span class="string">ReadWriteMany</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">    <span class="attr">requests:</span></span><br><span class="line">      <span class="attr">storage:</span> <span class="string">1Gi</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolumeClaim</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pvc2</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">accessModes:</span> </span><br><span class="line">  <span class="bullet">-</span> <span class="string">ReadWriteMany</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">    <span class="attr">requests:</span></span><br><span class="line">      <span class="attr">storage:</span> <span class="string">1Gi</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolumeClaim</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pvc3</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">accessModes:</span> </span><br><span class="line">  <span class="bullet">-</span> <span class="string">ReadWriteMany</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">    <span class="attr">requests:</span></span><br><span class="line">      <span class="attr">storage:</span> <span class="string">1Gi</span></span><br></pre></td></tr></table></figure></div>

<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建pvc</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl create -f pvc.yaml</span><br><span class="line">persistentvolumeclaim/pvc1 created</span><br><span class="line">persistentvolumeclaim/pvc2 created</span><br><span class="line">persistentvolumeclaim/pvc3 created</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看pvc</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl get pvc  -n dev -o wide</span><br><span class="line">NAME   STATUS   VOLUME   CAPACITY   ACCESS MODES   STORAGECLASS   AGE   VOLUMEMODE</span><br><span class="line">pvc1   Bound    pv1      1Gi        RWX                           15s   Filesystem</span><br><span class="line">pvc2   Bound    pv2      2Gi        RWX                           15s   Filesystem</span><br><span class="line">pvc3   Bound    pv3      3Gi        RWX                           15s   Filesystem</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看pv</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl get pv -o wide</span><br><span class="line">NAME  CAPACITY ACCESS MODES  RECLAIM POLICY  STATUS    CLAIM       AGE     VOLUMEMODE</span><br><span class="line">pv1    1Gi        RWx        Retain          Bound    dev/pvc1    3h37m    Filesystem</span><br><span class="line">pv2    2Gi        RWX        Retain          Bound    dev/pvc2    3h37m    Filesystem</span><br><span class="line">pv3    3Gi        RWX        Retain          Bound    dev/pvc3    3h37m    Filesystem   </span><br></pre></td></tr></table></figure></div>

<ol start="2">
<li>创建pods.yaml, 使用pv</li>
</ol>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod1</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">busybox</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">busybox:1.30</span></span><br><span class="line">    <span class="attr">command:</span> [<span class="string">&quot;/bin/sh&quot;</span>,<span class="string">&quot;-c&quot;</span>,<span class="string">&quot;while true;do echo pod1 &gt;&gt; /root/out.txt; sleep 10; done;&quot;</span>]</span><br><span class="line">    <span class="attr">volumeMounts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">volume</span></span><br><span class="line">      <span class="attr">mountPath:</span> <span class="string">/root/</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">volume</span></span><br><span class="line">      <span class="attr">persistentVolumeClaim:</span></span><br><span class="line">        <span class="attr">claimName:</span> <span class="string">pvc1</span></span><br><span class="line">        <span class="attr">readOnly:</span> <span class="literal">false</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod2</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">busybox</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">busybox:1.30</span></span><br><span class="line">    <span class="attr">command:</span> [<span class="string">&quot;/bin/sh&quot;</span>,<span class="string">&quot;-c&quot;</span>,<span class="string">&quot;while true;do echo pod2 &gt;&gt; /root/out.txt; sleep 10; done;&quot;</span>]</span><br><span class="line">    <span class="attr">volumeMounts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">volume</span></span><br><span class="line">      <span class="attr">mountPath:</span> <span class="string">/root/</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">volume</span></span><br><span class="line">      <span class="attr">persistentVolumeClaim:</span></span><br><span class="line">        <span class="attr">claimName:</span> <span class="string">pvc2</span></span><br><span class="line">        <span class="attr">readOnly:</span> <span class="literal">false</span></span><br></pre></td></tr></table></figure></div>

<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建pod</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl create -f pods.yaml</span><br><span class="line">pod/pod1 created</span><br><span class="line">pod/pod2 created</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看pod</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl get pods -n dev -o wide</span><br><span class="line">NAME   READY   STATUS    RESTARTS   AGE   IP            NODE   </span><br><span class="line">pod1   1/1     Running   0          14s   10.244.1.69   node1   </span><br><span class="line">pod2   1/1     Running   0          14s   10.244.1.70   node1  </span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看pvc</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl get pvc -n dev -o wide</span><br><span class="line">NAME   STATUS   VOLUME   CAPACITY   ACCESS MODES      AGE   VOLUMEMODE</span><br><span class="line">pvc1   Bound    pv1      1Gi        RWX               94m   Filesystem</span><br><span class="line">pvc2   Bound    pv2      2Gi        RWX               94m   Filesystem</span><br><span class="line">pvc3   Bound    pv3      3Gi        RWX               94m   Filesystem</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看pv</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl get pv -n dev -o wide</span><br><span class="line">NAME   CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM       AGE     VOLUMEMODE</span><br><span class="line">pv1    1Gi        RWX            Retain           Bound    dev/pvc1    5h11m   Filesystem</span><br><span class="line">pv2    2Gi        RWX            Retain           Bound    dev/pvc2    5h11m   Filesystem</span><br><span class="line">pv3    3Gi        RWX            Retain           Bound    dev/pvc3    5h11m   Filesystem</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看nfs中的文件存储</span></span><br><span class="line">[root@nfs ~]# more /root/data/pv1/out.txt</span><br><span class="line">node1</span><br><span class="line">node1</span><br><span class="line">[root@nfs ~]# more /root/data/pv2/out.txt</span><br><span class="line">node2</span><br><span class="line">node2</span><br></pre></td></tr></table></figure></div>

<h5 id="8-2-3-生命周期"><a href="#8-2-3-生命周期" class="headerlink" title="8.2.3 生命周期"></a>8.2.3 生命周期</h5><p>PVC和PV是一一对应的，PV和PVC之间的相互作用遵循以下生命周期：</p>
<ul>
<li><p><strong>资源供应</strong>：管理员手动创建底层存储和PV</p>
</li>
<li><p><strong>资源绑定</strong>：用户创建PVC，kubernetes负责根据PVC的声明去寻找PV，并绑定</p>
<p>在用户定义好PVC之后，系统将根据PVC对存储资源的请求在已存在的PV中选择一个满足条件的</p>
<ul>
<li>一旦找到，就将该PV与用户定义的PVC进行绑定，用户的应用就可以使用这个PVC了</li>
<li>如果找不到，PVC则会无限期处于Pending状态，直到等到系统管理员创建了一个符合其要求的PV</li>
</ul>
<p>PV一旦绑定到某个PVC上，就会被这个PVC独占，不能再与其他PVC进行绑定了</p>
</li>
<li><p><strong>资源使用</strong>：用户可在pod中像volume一样使用pvc</p>
<p>Pod使用Volume的定义，将PVC挂载到容器内的某个路径进行使用。</p>
</li>
<li><p><strong>资源释放</strong>：用户删除pvc来释放pv</p>
<p>当存储资源使用完毕后，用户可以删除PVC，与该PVC绑定的PV将会被标记为“已释放”，但还不能立刻与其他PVC进行绑定。通过之前PVC写入的数据可能还被留在存储设备上，只有在清除之后该PV才能再次使用。</p>
</li>
<li><p><strong>资源回收</strong>：kubernetes根据pv设置的回收策略进行资源的回收</p>
<p>对于PV，管理员可以设定回收策略，用于设置与之绑定的PVC释放资源之后如何处理遗留数据的问题。只有PV的存储空间完成回收，才能供新的PVC绑定和使用</p>
</li>
</ul>
<p><img src="/2022/06/09/uncatalog/cl46zbay9000k7or71j4vcb8a/image-20200515002806726.png" alt="img"></p>
<h4 id="8-3-配置存储"><a href="#8-3-配置存储" class="headerlink" title="8.3 配置存储"></a>8.3 配置存储</h4><h5 id="8-3-1-ConfigMap"><a href="#8-3-1-ConfigMap" class="headerlink" title="8.3.1 ConfigMap"></a>8.3.1 ConfigMap</h5><p>ConfigMap是一种比较特殊的存储卷，它的主要作用是用来存储配置信息的。</p>
<p>创建configmap.yaml，内容如下：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">configmap</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">info:</span> <span class="string">|</span></span><br><span class="line">    <span class="string">username:admin</span></span><br><span class="line">    <span class="string">password:123456</span></span><br></pre></td></tr></table></figure></div>

<p>接下来，使用此配置文件创建configmap</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建configmap</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl create -f configmap.yaml</span><br><span class="line">configmap/configmap created</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看configmap详情</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl describe cm configmap -n dev</span><br><span class="line">Name:         configmap</span><br><span class="line">Namespace:    dev</span><br><span class="line">Labels:       &lt;none&gt;</span><br><span class="line">Annotations:  &lt;none&gt;</span><br><span class="line"></span><br><span class="line">Data</span><br><span class="line">====</span><br><span class="line">info:</span><br><span class="line">----</span><br><span class="line">username:admin</span><br><span class="line">password:123456</span><br><span class="line"></span><br><span class="line">Events:  &lt;none&gt;</span><br></pre></td></tr></table></figure></div>

<p>接下来创建一个pod-configmap.yaml，将上面创建的configmap挂载进去</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-configmap</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br><span class="line">    <span class="attr">volumeMounts:</span> <span class="comment"># 将configmap挂载到目录</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">config</span></span><br><span class="line">      <span class="attr">mountPath:</span> <span class="string">/configmap/config</span></span><br><span class="line">  <span class="attr">volumes:</span> <span class="comment"># 引用configmap</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">config</span></span><br><span class="line">    <span class="attr">configMap:</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">configmap</span></span><br></pre></td></tr></table></figure></div>

<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建pod</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl create -f pod-configmap.yaml</span><br><span class="line">pod/pod-configmap created</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看pod</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl get pod pod-configmap -n dev</span><br><span class="line">NAME            READY   STATUS    RESTARTS   AGE</span><br><span class="line">pod-configmap   1/1     Running   0          6s</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">进入容器</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl exec -it pod-configmap -n dev /bin/sh</span><br><span class="line"><span class="meta">#</span><span class="bash"> <span class="built_in">cd</span> /configmap/config/</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> ls</span></span><br><span class="line">info</span><br><span class="line"><span class="meta">#</span><span class="bash"> more info</span></span><br><span class="line">username:admin</span><br><span class="line">password:123456</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 可以看到映射已经成功，每个configmap都映射成了一个目录</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> key---&gt;文件     value----&gt;文件中的内容</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 此时如果更新configmap的内容, 容器中的值也会动态更新</span></span><br></pre></td></tr></table></figure></div>

<h5 id="8-3-2-Secret"><a href="#8-3-2-Secret" class="headerlink" title="8.3.2 Secret"></a>8.3.2 Secret</h5><p>在kubernetes中，还存在一种和ConfigMap非常类似的对象，称为Secret对象。它主要用于存储敏感信息，例如密码、秘钥、证书等等。</p>
<ol>
<li>首先使用base64对数据进行编码</li>
</ol>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master01 ~]# echo -n &#x27;admin&#x27; | base64 #准备username</span><br><span class="line">YWRtaW4=</span><br><span class="line">[root@k8s-master01 ~]# echo -n &#x27;123456&#x27; | base64 #准备password</span><br><span class="line">MTIzNDU2</span><br></pre></td></tr></table></figure></div>

<ol start="2">
<li>接下来编写secret.yaml，并创建Secret</li>
</ol>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Secret</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">secret</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">type:</span> <span class="string">Opaque</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">username:</span> <span class="string">YWRtaW4=</span></span><br><span class="line">  <span class="attr">password:</span> <span class="string">MTIzNDU2</span></span><br></pre></td></tr></table></figure></div>

<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建secret</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl create -f secret.yaml</span><br><span class="line">secret/secret created</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看secret详情</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl describe secret secret -n dev</span><br><span class="line">Name:         secret</span><br><span class="line">Namespace:    dev</span><br><span class="line">Labels:       &lt;none&gt;</span><br><span class="line">Annotations:  &lt;none&gt;</span><br><span class="line">Type:  Opaque</span><br><span class="line">Data</span><br><span class="line">====</span><br><span class="line">password:  6 bytes</span><br><span class="line">username:  5 bytes</span><br></pre></td></tr></table></figure></div>

<ol start="3">
<li>创建pod-secret.yaml，将上面创建的secret挂载进去：</li>
</ol>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-secret</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br><span class="line">    <span class="attr">volumeMounts:</span> <span class="comment"># 将secret挂载到目录</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">config</span></span><br><span class="line">      <span class="attr">mountPath:</span> <span class="string">/secret/config</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">config</span></span><br><span class="line">    <span class="attr">secret:</span></span><br><span class="line">      <span class="attr">secretName:</span> <span class="string">secret</span></span><br></pre></td></tr></table></figure></div>

<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建pod</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl create -f pod-secret.yaml</span><br><span class="line">pod/pod-secret created</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看pod</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl get pod pod-secret -n dev</span><br><span class="line">NAME            READY   STATUS    RESTARTS   AGE</span><br><span class="line">pod-secret      1/1     Running   0          2m28s</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 进入容器，查看secret信息，发现已经自动解码了</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl exec -it pod-secret /bin/sh -n dev</span><br><span class="line">/ # ls /secret/config/</span><br><span class="line">password  username</span><br><span class="line">/ # more /secret/config/username</span><br><span class="line">admin</span><br><span class="line">/ # more /secret/config/password</span><br><span class="line">123456</span><br></pre></td></tr></table></figure></div>

<p>至此，已经实现了利用secret实现了信息的编码。</p>
]]></content>
      <tags>
        <tag>云原生基础系列</tag>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>云原生基础系列之Kubernetes(四)实战入门</title>
    <url>/2022/06/09/uncatalog/cl46zbayd000p7or77mughk0e/</url>
    <content><![CDATA[<hr>
<span id="more"></span>



<hr>
<h3 id="4-实战入门"><a href="#4-实战入门" class="headerlink" title="4. 实战入门"></a>4. 实战入门</h3><p>本章节将介绍如何在kubernetes集群中部署一个nginx服务，并且能够对其进行访问。</p>
<h4 id="4-1-Namespace"><a href="#4-1-Namespace" class="headerlink" title="4.1 Namespace"></a>4.1 Namespace</h4><p>Namespace是kubernetes系统中的一种非常重要资源，它的主要作用是用来实现<strong>多套环境的资源隔离</strong>或者<strong>多租户的资源隔离</strong>。</p>
<p>默认情况下，kubernetes集群中的所有的Pod都是可以相互访问的。但是在实际中，可能不想让两个Pod之间进行互相的访问，那此时就可以将两个Pod划分到不同的namespace下。kubernetes通过将集群内部的资源分配到不同的Namespace中，可以形成逻辑上的”组”，以方便不同的组的资源进行隔离使用和管理。</p>
<p>可以通过kubernetes的授权机制，将不同的namespace交给不同租户进行管理，这样就实现了多租户的资源隔离。此时还能结合kubernetes的资源配额机制，限定不同租户能占用的资源，例如CPU使用量、内存使用量等等，来实现租户可用资源的管理。</p>
<p><img src="/2022/06/09/uncatalog/cl46zbayd000p7or77mughk0e/image-20200407100850484.png" alt="image-20200407100850484"></p>
<p>kubernetes在集群启动之后，会默认创建几个namespace</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">[root@master ~]# kubectl  get namespace</span><br><span class="line">NAME              STATUS   AGE</span><br><span class="line">default           Active   45h     #  所有未指定Namespace的对象都会被分配在default命名空间</span><br><span class="line">kube-node-lease   Active   45h     #  集群节点之间的心跳维护，v1.13开始引入</span><br><span class="line">kube-public       Active   45h     #  此命名空间下的资源可以被所有人访问（包括未认证用户）</span><br><span class="line">kube-system       Active   45h     #  所有由Kubernetes系统创建的资源都处于这个命名空间</span><br></pre></td></tr></table></figure></div>

<p>下面来看namespace资源的具体操作：</p>
<h5 id="4-1-1-查看"><a href="#4-1-1-查看" class="headerlink" title="4.1.1 查看"></a>4.1.1 <strong>查看</strong></h5><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 1 查看所有的ns  命令：kubectl get ns</span></span><br><span class="line">[root@master ~]# kubectl get ns</span><br><span class="line">NAME              STATUS   AGE</span><br><span class="line">default           Active   45h</span><br><span class="line">kube-node-lease   Active   45h</span><br><span class="line">kube-public       Active   45h     </span><br><span class="line">kube-system       Active   45h     </span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 2 查看指定的ns   命令：kubectl get ns ns名称</span></span><br><span class="line">[root@master ~]# kubectl get ns default</span><br><span class="line">NAME      STATUS   AGE</span><br><span class="line">default   Active   45h</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 3 指定输出格式  命令：kubectl get ns ns名称  -o 格式参数</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> kubernetes支持的格式有很多，比较常见的是wide、json、yaml</span></span><br><span class="line">[root@master ~]# kubectl get ns default -o yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Namespace</span><br><span class="line">metadata:</span><br><span class="line">  creationTimestamp: &quot;2021-05-08T04:44:16Z&quot;</span><br><span class="line">  name: default</span><br><span class="line">  resourceVersion: &quot;151&quot;</span><br><span class="line">  selfLink: /api/v1/namespaces/default</span><br><span class="line">  uid: 7405f73a-e486-43d4-9db6-145f1409f090</span><br><span class="line">spec:</span><br><span class="line">  finalizers:</span><br><span class="line">  - kubernetes</span><br><span class="line">status:</span><br><span class="line">  phase: Active</span><br><span class="line">  </span><br><span class="line"><span class="meta">#</span><span class="bash"> 4 查看ns详情  命令：kubectl describe ns ns名称</span></span><br><span class="line">[root@master ~]# kubectl describe ns default</span><br><span class="line">Name:         default</span><br><span class="line">Labels:       &lt;none&gt;</span><br><span class="line">Annotations:  &lt;none&gt;</span><br><span class="line">Status:       Active  # Active 命名空间正在使用中  Terminating 正在删除命名空间</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> ResourceQuota 针对namespace做的资源限制</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> LimitRange针对namespace中的每个组件做的资源限制</span></span><br><span class="line">No resource quota.</span><br><span class="line">No LimitRange resource.</span><br></pre></td></tr></table></figure></div>

<h5 id="4-1-2-创建"><a href="#4-1-2-创建" class="headerlink" title="4.1.2 创建"></a>4.1.2 <strong>创建</strong></h5><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建namespace</span></span><br><span class="line">[root@master ~]# kubectl create ns dev</span><br><span class="line">namespace/dev created</span><br></pre></td></tr></table></figure></div>

<h5 id="4-1-3-删除"><a href="#4-1-3-删除" class="headerlink" title="4.1.3 删除"></a>4.1.3 <strong>删除</strong></h5><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 删除namespace</span></span><br><span class="line">[root@master ~]# kubectl delete ns dev</span><br><span class="line">namespace &quot;dev&quot; deleted</span><br></pre></td></tr></table></figure></div>

<h5 id="4-1-4-配置方式"><a href="#4-1-4-配置方式" class="headerlink" title="4.1.4 配置方式"></a>4.1.4 <strong>配置方式</strong></h5><p>首先准备一个yaml文件：ns-dev.yaml</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Namespace</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">dev</span></span><br></pre></td></tr></table></figure></div>

<p>然后就可以执行对应的创建和删除命令了：</p>
<p>创建：kubectl create -f ns-dev.yaml</p>
<p>删除：kubectl delete -f ns-dev.yaml</p>
<h4 id="4-2-Pod"><a href="#4-2-Pod" class="headerlink" title="4.2 Pod"></a>4.2 Pod</h4><p>Pod是kubernetes集群进行管理的最小单元，程序要运行必须部署在容器中，而容器必须存在于Pod中。</p>
<p>Pod可以认为是容器的封装，一个Pod中可以存在一个或者多个容器。</p>
<p><img src="/2022/06/09/uncatalog/cl46zbayd000p7or77mughk0e/image-20200407121501907.png" alt="image-20200407121501907"></p>
<p>kubernetes在集群启动之后，集群中的各个组件也都是以Pod方式运行的。可以通过下面命令查看：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">[root@master ~]# kubectl get pod -n kube-system</span><br><span class="line">NAMESPACE     NAME                             READY   STATUS    RESTARTS   AGE</span><br><span class="line">kube-system   coredns-6955765f44-68g6v         1/1     Running   0          2d1h</span><br><span class="line">kube-system   coredns-6955765f44-cs5r8         1/1     Running   0          2d1h</span><br><span class="line">kube-system   etcd-master                      1/1     Running   0          2d1h</span><br><span class="line">kube-system   kube-apiserver-master            1/1     Running   0          2d1h</span><br><span class="line">kube-system   kube-controller-manager-master   1/1     Running   0          2d1h</span><br><span class="line">kube-system   kube-flannel-ds-amd64-47r25      1/1     Running   0          2d1h</span><br><span class="line">kube-system   kube-flannel-ds-amd64-ls5lh      1/1     Running   0          2d1h</span><br><span class="line">kube-system   kube-proxy-685tk                 1/1     Running   0          2d1h</span><br><span class="line">kube-system   kube-proxy-87spt                 1/1     Running   0          2d1h</span><br><span class="line">kube-system   kube-scheduler-master            1/1     Running   0          2d1h</span><br></pre></td></tr></table></figure></div>

<h5 id="4-2-1-创建并运行"><a href="#4-2-1-创建并运行" class="headerlink" title="4.2.1 创建并运行"></a>4.2.1 创建并运行</h5><p>kubernetes没有提供单独运行Pod的命令，都是通过Pod控制器来实现的</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 命令格式： kubectl run (pod控制器名称) [参数]</span> </span><br><span class="line"><span class="meta">#</span><span class="bash"> --image  指定Pod的镜像</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> --port   指定端口</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> --namespace  指定namespace</span></span><br><span class="line">[root@master ~]# kubectl run nginx --image=nginx:latest --port=80 --namespace dev </span><br><span class="line">deployment.apps/nginx created</span><br></pre></td></tr></table></figure></div>

<h5 id="4-2-2-查看pod信息"><a href="#4-2-2-查看pod信息" class="headerlink" title="4.2.2 查看pod信息"></a>4.2.2 查看pod信息</h5><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 查看Pod基本信息</span></span><br><span class="line">[root@master ~]# kubectl get pods -n dev</span><br><span class="line">NAME    READY   STATUS    RESTARTS   AGE</span><br><span class="line">nginx   1/1     Running   0          43s</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看Pod的详细信息</span></span><br><span class="line">[root@master ~]# kubectl describe pod nginx -n dev</span><br><span class="line">Name:         nginx</span><br><span class="line">Namespace:    dev</span><br><span class="line">Priority:     0</span><br><span class="line">Node:         node1/192.168.5.4</span><br><span class="line">Start Time:   Wed, 08 May 2021 09:29:24 +0800</span><br><span class="line">Labels:       pod-template-hash=5ff7956ff6</span><br><span class="line">              run=nginx</span><br><span class="line">Annotations:  &lt;none&gt;</span><br><span class="line">Status:       Running</span><br><span class="line">IP:           10.244.1.23</span><br><span class="line">IPs:</span><br><span class="line">  IP:           10.244.1.23</span><br><span class="line">Controlled By:  ReplicaSet/nginx</span><br><span class="line">Containers:</span><br><span class="line">  nginx:</span><br><span class="line">    Container ID:   docker://4c62b8c0648d2512380f4ffa5da2c99d16e05634979973449c98e9b829f6253c</span><br><span class="line">    Image:          nginx:latest</span><br><span class="line">    Image ID:       docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7</span><br><span class="line">    Port:           80/TCP</span><br><span class="line">    Host Port:      0/TCP</span><br><span class="line">    State:          Running</span><br><span class="line">      Started:      Wed, 08 May 2021 09:30:01 +0800</span><br><span class="line">    Ready:          True</span><br><span class="line">    Restart Count:  0</span><br><span class="line">    Environment:    &lt;none&gt;</span><br><span class="line">    Mounts:</span><br><span class="line">      /var/run/secrets/kubernetes.io/serviceaccount from default-token-hwvvw (ro)</span><br><span class="line">Conditions:</span><br><span class="line">  Type              Status</span><br><span class="line">  Initialized       True</span><br><span class="line">  Ready             True</span><br><span class="line">  ContainersReady   True</span><br><span class="line">  PodScheduled      True</span><br><span class="line">Volumes:</span><br><span class="line">  default-token-hwvvw:</span><br><span class="line">    Type:        Secret (a volume populated by a Secret)</span><br><span class="line">    SecretName:  default-token-hwvvw</span><br><span class="line">    Optional:    false</span><br><span class="line">QoS Class:       BestEffort</span><br><span class="line">Node-Selectors:  &lt;none&gt;</span><br><span class="line">Tolerations:     node.kubernetes.io/not-ready:NoExecute for 300s</span><br><span class="line">                 node.kubernetes.io/unreachable:NoExecute for 300s</span><br><span class="line">Events:</span><br><span class="line">  Type    Reason     Age        From               Message</span><br><span class="line">  ----    ------     ----       ----               -------</span><br><span class="line">  Normal  Scheduled  &lt;unknown&gt;  default-scheduler  Successfully assigned dev/nginx-5ff7956ff6-fg2db to node1</span><br><span class="line">  Normal  Pulling    4m11s      kubelet, node1     Pulling image &quot;nginx:latest&quot;</span><br><span class="line">  Normal  Pulled     3m36s      kubelet, node1     Successfully pulled image &quot;nginx:latest&quot;</span><br><span class="line">  Normal  Created    3m36s      kubelet, node1     Created container nginx</span><br><span class="line">  Normal  Started    3m36s      kubelet, node1     Started container nginx</span><br></pre></td></tr></table></figure></div>

<h5 id="4-2-3-访问Pod"><a href="#4-2-3-访问Pod" class="headerlink" title="4.2.3 访问Pod"></a>4.2.3 访问Pod</h5><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 获取podIP</span></span><br><span class="line">[root@master ~]# kubectl get pods -n dev -o wide</span><br><span class="line">NAME    READY   STATUS    RESTARTS   AGE    IP             NODE    ... </span><br><span class="line">nginx   1/1     Running   0          190s   10.244.1.23   node1   ...</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">访问POD</span></span><br><span class="line">[root@master ~]# curl http://10.244.1.23:80</span><br><span class="line">&lt;!DOCTYPE html&gt;</span><br><span class="line">&lt;html&gt;</span><br><span class="line">&lt;head&gt;</span><br><span class="line">	&lt;title&gt;Welcome to nginx!&lt;/title&gt;</span><br><span class="line">&lt;/head&gt;</span><br><span class="line">&lt;body&gt;</span><br><span class="line">	&lt;p&gt;&lt;em&gt;Thank you for using nginx.&lt;/em&gt;&lt;/p&gt;</span><br><span class="line">&lt;/body&gt;</span><br><span class="line">&lt;/html&gt;</span><br></pre></td></tr></table></figure></div>

<h5 id="4-2-4-删除指定Pod"><a href="#4-2-4-删除指定Pod" class="headerlink" title="4.2.4 删除指定Pod"></a>4.2.4 删除指定Pod</h5><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 删除指定Pod</span></span><br><span class="line">[root@master ~]# kubectl delete pod nginx -n dev</span><br><span class="line">pod &quot;nginx&quot; deleted</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 此时，显示删除Pod成功，但是再查询，发现又新产生了一个</span> </span><br><span class="line">[root@master ~]# kubectl get pods -n dev</span><br><span class="line">NAME    READY   STATUS    RESTARTS   AGE</span><br><span class="line">nginx   1/1     Running   0          21s</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 这是因为当前Pod是由Pod控制器创建的，控制器会监控Pod状况，一旦发现Pod死亡，会立即重建</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 此时要想删除Pod，必须删除Pod控制器</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 先来查询一下当前namespace下的Pod控制器</span></span><br><span class="line">[root@master ~]# kubectl get deploy -n  dev</span><br><span class="line">NAME    READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">nginx   1/1     1            1           9m7s</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 接下来，删除此PodPod控制器</span></span><br><span class="line">[root@master ~]# kubectl delete deploy nginx -n dev</span><br><span class="line">deployment.apps &quot;nginx&quot; deleted</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 稍等片刻，再查询Pod，发现Pod被删除了</span></span><br><span class="line">[root@master ~]# kubectl get pods -n dev</span><br><span class="line">No resources found in dev namespace.</span><br></pre></td></tr></table></figure></div>

<h5 id="4-2-5-配置操作"><a href="#4-2-5-配置操作" class="headerlink" title="4.2.5 配置操作"></a>4.2.5 配置操作</h5><p>创建一个pod-nginx.yaml，内容如下：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">nginx:latest</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">pod</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx-port</span></span><br><span class="line">      <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">      <span class="attr">protocol:</span> <span class="string">TCP</span></span><br></pre></td></tr></table></figure></div>

<p>然后就可以执行对应的创建和删除命令了：</p>
<p>创建：kubectl create -f pod-nginx.yaml</p>
<p>删除：kubectl delete -f pod-nginx.yaml</p>
<h4 id="4-3-Label"><a href="#4-3-Label" class="headerlink" title="4.3 Label"></a>4.3 Label</h4><p>Label是kubernetes系统中的一个重要概念。它的作用就是在资源上添加标识，用来对它们进行区分和选择。</p>
<p>Label的特点：</p>
<ul>
<li>一个Label会以key/value键值对的形式附加到各种对象上，如Node、Pod、Service等等</li>
<li>一个资源对象可以定义任意数量的Label ，同一个Label也可以被添加到任意数量的资源对象上去</li>
<li>Label通常在资源对象定义时确定，当然也可以在对象创建后动态添加或者删除</li>
</ul>
<p>可以通过Label实现资源的多维度分组，以便灵活、方便地进行资源分配、调度、配置、部署等管理工作。</p>
<blockquote>
<p>一些常用的Label 示例如下：</p>
<ul>
<li>版本标签：”version”:”release”, “version”:”stable”……</li>
<li>环境标签：”environment”:”dev”，”environment”:”test”，”environment”:”pro”</li>
<li>架构标签：”tier”:”frontend”，”tier”:”backend”</li>
</ul>
</blockquote>
<p>标签定义完毕之后，还要考虑到标签的选择，这就要使用到Label Selector，即：</p>
<p>Label用于给某个资源对象定义标识</p>
<p>Label Selector用于查询和筛选拥有某些标签的资源对象</p>
<p>当前有两种Label Selector：</p>
<ul>
<li><p>基于等式的Label Selector</p>
<p>name = slave: 选择所有包含Label中key=”name”且value=”slave”的对象</p>
<p>env != production: 选择所有包括Label中的key=”env”且value不等于”production”的对象</p>
</li>
<li><p>基于集合的Label Selector</p>
<p>name in (master, slave): 选择所有包含Label中的key=”name”且value=”master”或”slave”的对象</p>
<p>name not in (frontend): 选择所有包含Label中的key=”name”且value不等于”frontend”的对象</p>
</li>
</ul>
<p>标签的选择条件可以使用多个，此时将多个Label Selector进行组合，使用逗号”,”进行分隔即可。例如：</p>
<p>name=slave，env!=production</p>
<p>name not in (frontend)，env!=production</p>
<h5 id="4-3-1-命令方式"><a href="#4-3-1-命令方式" class="headerlink" title="4.3.1 命令方式"></a>4.3.1 命令方式</h5><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 为pod资源打标签</span></span><br><span class="line">[root@master ~]# kubectl label pod nginx-pod version=1.0 -n dev</span><br><span class="line">pod/nginx-pod labeled</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 为pod资源更新标签</span></span><br><span class="line">[root@master ~]# kubectl label pod nginx-pod version=2.0 -n dev --overwrite</span><br><span class="line">pod/nginx-pod labeled</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看标签</span></span><br><span class="line">[root@master ~]# kubectl get pod nginx-pod  -n dev --show-labels</span><br><span class="line">NAME        READY   STATUS    RESTARTS   AGE   LABELS</span><br><span class="line">nginx-pod   1/1     Running   0          10m   version=2.0</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 筛选标签</span></span><br><span class="line">[root@master ~]# kubectl get pod -n dev -l version=2.0  --show-labels</span><br><span class="line">NAME        READY   STATUS    RESTARTS   AGE   LABELS</span><br><span class="line">nginx-pod   1/1     Running   0          17m   version=2.0</span><br><span class="line">[root@master ~]# kubectl get pod -n dev -l version!=2.0 --show-labels</span><br><span class="line">No resources found in dev namespace.</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">删除标签</span></span><br><span class="line">[root@master ~]# kubectl label pod nginx-pod version- -n dev</span><br><span class="line">pod/nginx-pod labeled</span><br></pre></td></tr></table></figure></div>

<h5 id="4-3-2-配置方式"><a href="#4-3-2-配置方式" class="headerlink" title="4.3.2 配置方式"></a>4.3.2 配置方式</h5><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">version:</span> <span class="string">&quot;3.0&quot;</span> </span><br><span class="line">    <span class="attr">env:</span> <span class="string">&quot;test&quot;</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">nginx:latest</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">pod</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx-port</span></span><br><span class="line">      <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">      <span class="attr">protocol:</span> <span class="string">TCP</span></span><br></pre></td></tr></table></figure></div>

<p>然后就可以执行对应的更新命令了：kubectl apply -f pod-nginx.yaml</p>
<h4 id="4-4-Deployment"><a href="#4-4-Deployment" class="headerlink" title="4.4 Deployment"></a>4.4 Deployment</h4><p>在kubernetes中，Pod是最小的控制单元，但是kubernetes很少直接控制Pod，一般都是通过Pod控制器来完成的。Pod控制器用于pod的管理，确保pod资源符合预期的状态，当pod的资源出现故障时，会尝试进行重启或重建pod。</p>
<p>在kubernetes中Pod控制器的种类有很多，本章节只介绍一种：Deployment。</p>
<p><img src="/2022/06/09/uncatalog/cl46zbayd000p7or77mughk0e/image-20200408193950807.png" alt="image-20200408193950807"></p>
<h5 id="4-4-1待操作。。。。。"><a href="#4-4-1待操作。。。。。" class="headerlink" title="4.4.1待操作。。。。。"></a>4.4.1待操作。。。。。</h5><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 命令格式: kubectl create deployment 名称  [参数] </span></span><br><span class="line"><span class="comment"># --image  指定pod的镜像</span></span><br><span class="line"><span class="comment"># --port   指定端口</span></span><br><span class="line"><span class="comment"># --replicas  指定创建pod数量</span></span><br><span class="line"><span class="comment"># --namespace  指定namespace</span></span><br><span class="line">[<span class="string">root@master</span> <span class="string">~</span>]<span class="comment"># kubectl run nginx --image=nginx:latest --port=80 --replicas=3 -n dev</span></span><br><span class="line"><span class="string">deployment.apps/nginx</span> <span class="string">created</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看创建的Pod</span></span><br><span class="line">[<span class="string">root@master</span> <span class="string">~</span>]<span class="comment"># kubectl get pods -n dev</span></span><br><span class="line"><span class="string">NAME</span>                     <span class="string">READY</span>   <span class="string">STATUS</span>    <span class="string">RESTARTS</span>   <span class="string">AGE</span></span><br><span class="line"><span class="string">nginx-5ff7956ff6-6k8cb</span>   <span class="number">1</span><span class="string">/1</span>     <span class="string">Running</span>   <span class="number">0</span>          <span class="string">19s</span></span><br><span class="line"><span class="string">nginx-5ff7956ff6-jxfjt</span>   <span class="number">1</span><span class="string">/1</span>     <span class="string">Running</span>   <span class="number">0</span>          <span class="string">19s</span></span><br><span class="line"><span class="string">nginx-5ff7956ff6-v6jqw</span>   <span class="number">1</span><span class="string">/1</span>     <span class="string">Running</span>   <span class="number">0</span>          <span class="string">19s</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看deployment的信息</span></span><br><span class="line">[<span class="string">root@master</span> <span class="string">~</span>]<span class="comment"># kubectl get deploy -n dev</span></span><br><span class="line"><span class="string">NAME</span>    <span class="string">READY</span>   <span class="string">UP-TO-DATE</span>   <span class="string">AVAILABLE</span>   <span class="string">AGE</span></span><br><span class="line"><span class="string">nginx</span>   <span class="number">3</span><span class="string">/3</span>     <span class="number">3</span>            <span class="number">3</span>           <span class="string">2m42s</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># UP-TO-DATE：成功升级的副本数量</span></span><br><span class="line"><span class="comment"># AVAILABLE：可用副本的数量</span></span><br><span class="line">[<span class="string">root@master</span> <span class="string">~</span>]<span class="comment"># kubectl get deploy -n dev -o wide</span></span><br><span class="line"><span class="string">NAME</span>    <span class="string">READY</span> <span class="string">UP-TO-DATE</span>  <span class="string">AVAILABLE</span>   <span class="string">AGE</span>     <span class="string">CONTAINERS</span>   <span class="string">IMAGES</span>              <span class="string">SELECTOR</span></span><br><span class="line"><span class="string">nginx</span>   <span class="number">3</span><span class="string">/3</span>     <span class="number">3</span>         <span class="number">3</span>           <span class="string">2m51s</span>   <span class="string">nginx</span>        <span class="string">nginx:latest</span>        <span class="string">run=nginx</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看deployment的详细信息</span></span><br><span class="line">[<span class="string">root@master</span> <span class="string">~</span>]<span class="comment"># kubectl describe deploy nginx -n dev</span></span><br><span class="line"><span class="attr">Name:</span>                   <span class="string">nginx</span></span><br><span class="line"><span class="attr">Namespace:</span>              <span class="string">dev</span></span><br><span class="line"><span class="attr">CreationTimestamp:</span>      <span class="string">Wed,</span> <span class="number">08</span> <span class="string">May</span> <span class="number">2021 11:14:14</span> <span class="string">+0800</span></span><br><span class="line"><span class="attr">Labels:</span>                 <span class="string">run=nginx</span></span><br><span class="line"><span class="attr">Annotations:            deployment.kubernetes.io/revision:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">Selector:</span>               <span class="string">run=nginx</span></span><br><span class="line"><span class="attr">Replicas:</span>               <span class="number">3</span> <span class="string">desired</span> <span class="string">|</span> <span class="number">3</span> <span class="string">updated</span> <span class="string">|</span> <span class="number">3</span> <span class="string">total</span> <span class="string">|</span> <span class="number">3</span> <span class="string">available</span> <span class="string">|</span> <span class="number">0</span> <span class="string">unavailable</span></span><br><span class="line"><span class="attr">StrategyType:</span>           <span class="string">RollingUpdate</span></span><br><span class="line"><span class="attr">MinReadySeconds:</span>        <span class="number">0</span></span><br><span class="line"><span class="attr">RollingUpdateStrategy:</span>  <span class="number">25</span><span class="string">%</span> <span class="string">max</span> <span class="string">unavailable,</span> <span class="number">25</span><span class="string">%</span> <span class="string">max</span> <span class="string">违规词汇</span></span><br><span class="line"><span class="attr">Pod Template:</span></span><br><span class="line">  <span class="attr">Labels:</span>  <span class="string">run=nginx</span></span><br><span class="line">  <span class="attr">Containers:</span></span><br><span class="line">   <span class="attr">nginx:</span></span><br><span class="line">    <span class="attr">Image:</span>        <span class="string">nginx:latest</span></span><br><span class="line">    <span class="attr">Port:</span>         <span class="number">80</span><span class="string">/TCP</span></span><br><span class="line">    <span class="attr">Host Port:</span>    <span class="number">0</span><span class="string">/TCP</span></span><br><span class="line">    <span class="attr">Environment:</span>  <span class="string">&lt;none&gt;</span></span><br><span class="line">    <span class="attr">Mounts:</span>       <span class="string">&lt;none&gt;</span></span><br><span class="line">  <span class="attr">Volumes:</span>        <span class="string">&lt;none&gt;</span></span><br><span class="line"><span class="attr">Conditions:</span></span><br><span class="line">  <span class="string">Type</span>           <span class="string">Status</span>  <span class="string">Reason</span></span><br><span class="line">  <span class="string">----</span>           <span class="string">------</span>  <span class="string">------</span></span><br><span class="line">  <span class="string">Available</span>      <span class="literal">True</span>    <span class="string">MinimumReplicasAvailable</span></span><br><span class="line">  <span class="string">Progressing</span>    <span class="literal">True</span>    <span class="string">NewReplicaSetAvailable</span></span><br><span class="line"><span class="attr">OldReplicaSets:</span>  <span class="string">&lt;none&gt;</span></span><br><span class="line"><span class="attr">NewReplicaSet:</span>   <span class="string">nginx-5ff7956ff6</span> <span class="string">(3/3</span> <span class="string">replicas</span> <span class="string">created)</span></span><br><span class="line"><span class="attr">Events:</span></span><br><span class="line">  <span class="string">Type</span>    <span class="string">Reason</span>             <span class="string">Age</span>    <span class="string">From</span>                   <span class="string">Message</span></span><br><span class="line">  <span class="string">----</span>    <span class="string">------</span>             <span class="string">----</span>   <span class="string">----</span>                   <span class="string">-------</span></span><br><span class="line">  <span class="string">Normal</span>  <span class="string">ScalingReplicaSet</span>  <span class="string">5m43s</span>  <span class="string">deployment-controller</span>  <span class="string">Scaled</span> <span class="string">up</span> <span class="string">replicaset</span> <span class="string">nginx-5ff7956ff6</span> <span class="string">to</span> <span class="number">3</span></span><br><span class="line">  </span><br><span class="line"><span class="comment"># 删除 </span></span><br><span class="line">[<span class="string">root@master</span> <span class="string">~</span>]<span class="comment"># kubectl delete deploy nginx -n dev</span></span><br><span class="line"><span class="string">deployment.apps</span> <span class="string">&quot;nginx&quot;</span> <span class="string">deleted</span></span><br></pre></td></tr></table></figure></div>



<h5 id="4-4-2-配置操作"><a href="#4-4-2-配置操作" class="headerlink" title="4.4.2 配置操作"></a>4.4.2 配置操作</h5><p>创建一个deploy-nginx.yaml，内容如下：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">3</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">run:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">run:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">nginx:latest</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">          <span class="attr">protocol:</span> <span class="string">TCP</span></span><br></pre></td></tr></table></figure></div>

<p>然后就可以执行对应的创建和删除命令了：</p>
<p>创建：kubectl create -f deploy-nginx.yaml</p>
<p>删除：kubectl delete -f deploy-nginx.yaml</p>
<h4 id="4-5-Service"><a href="#4-5-Service" class="headerlink" title="4.5 Service"></a>4.5 Service</h4><p>通过上节课的学习，已经能够利用Deployment来创建一组Pod来提供具有高可用性的服务。</p>
<p>虽然每个Pod都会分配一个单独的Pod IP，然而却存在如下两问题：</p>
<ul>
<li>Pod IP 会随着Pod的重建产生变化</li>
<li>Pod IP 仅仅是集群内可见的虚拟IP，外部无法访问</li>
</ul>
<p>这样对于访问这个服务带来了难度。因此，kubernetes设计了Service来解决这个问题。</p>
<p>Service可以看作是一组同类Pod<strong>对外的访问接口</strong>。借助Service，应用可以方便地实现服务发现和负载均衡。</p>
<p><img src="/2022/06/09/uncatalog/cl46zbayd000p7or77mughk0e/image-20200408194716912.png" alt="image-20200408194716912"></p>
<h5 id="4-5-1-创建集群内部可访问的Service"><a href="#4-5-1-创建集群内部可访问的Service" class="headerlink" title="4.5.1 创建集群内部可访问的Service"></a>4.5.1 创建集群内部可访问的Service</h5><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tr><td class="code"><pre><span class="line"># 暴露Service</span><br><span class="line">[root@master ~]# kubectl expose deploy nginx --name&#x3D;svc-nginx1 --type&#x3D;ClusterIP --port&#x3D;80 --target-port&#x3D;80 -n dev</span><br><span class="line">service&#x2F;svc-nginx1 exposed</span><br><span class="line"></span><br><span class="line"># 查看service</span><br><span class="line">[root@master ~]# kubectl get svc svc-nginx1 -n dev -o wide</span><br><span class="line">NAME         TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)   AGE     SELECTOR</span><br><span class="line">svc-nginx1   ClusterIP   10.109.179.231   &lt;none&gt;        80&#x2F;TCP    3m51s   run&#x3D;nginx</span><br><span class="line"></span><br><span class="line"># 这里产生了一个CLUSTER-IP，这就是service的IP，在Service的生命周期中，这个地址是不会变动的</span><br><span class="line"># 可以通过这个IP访问当前service对应的POD</span><br><span class="line">[root@master ~]# curl 10.109.179.231:80</span><br><span class="line">&lt;!DOCTYPE html&gt;</span><br><span class="line">&lt;html&gt;</span><br><span class="line">&lt;head&gt;</span><br><span class="line">&lt;title&gt;Welcome to nginx!&lt;&#x2F;title&gt;</span><br><span class="line">&lt;&#x2F;head&gt;</span><br><span class="line">&lt;body&gt;</span><br><span class="line">&lt;h1&gt;Welcome to nginx!&lt;&#x2F;h1&gt;</span><br><span class="line">.......</span><br><span class="line">&lt;&#x2F;body&gt;</span><br><span class="line">&lt;&#x2F;html&gt;</span><br></pre></td></tr></table></figure></div>

<h5 id="4-5-2-创建集群外部也可访问的Service"><a href="#4-5-2-创建集群外部也可访问的Service" class="headerlink" title="4.5.2 创建集群外部也可访问的Service"></a>4.5.2 创建集群外部也可访问的Service</h5><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tr><td class="code"><pre><span class="line"># 上面创建的Service的type类型为ClusterIP，这个ip地址只用集群内部可访问</span><br><span class="line"># 如果需要创建外部也可以访问的Service，需要修改type为NodePort</span><br><span class="line">[root@master ~]# kubectl expose deploy nginx --name&#x3D;svc-nginx2 --type&#x3D;NodePort --port&#x3D;80 --target-port&#x3D;80 -n dev</span><br><span class="line">service&#x2F;svc-nginx2 exposed</span><br><span class="line"></span><br><span class="line"># 此时查看，会发现出现了NodePort类型的Service，而且有一对Port（80:31928&#x2F;TC）</span><br><span class="line">[root@master ~]# kubectl get svc  svc-nginx2  -n dev -o wide</span><br><span class="line">NAME          TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGE    SELECTOR</span><br><span class="line">svc-nginx2    NodePort    10.100.94.0      &lt;none&gt;        80:31928&#x2F;TCP   9s     run&#x3D;nginx</span><br><span class="line"></span><br><span class="line"># 接下来就可以通过集群外的主机访问 节点IP:31928访问服务了</span><br><span class="line"># 例如在的电脑主机上通过浏览器访问下面的地址</span><br><span class="line">http:&#x2F;&#x2F;192.168.90.100:31928&#x2F;</span><br></pre></td></tr></table></figure></div>

<h5 id="4-5-3-删除Service"><a href="#4-5-3-删除Service" class="headerlink" title="4.5.3 删除Service"></a>4.5.3 删除Service</h5><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">[root@master ~]# kubectl delete svc svc-nginx-1 -n dev </span><br><span class="line">service &quot;svc-nginx-1&quot; deleted</span><br></pre></td></tr></table></figure></div>

<h5 id="4-5-4-配置方式"><a href="#4-5-4-配置方式" class="headerlink" title="4.5.4 配置方式"></a>4.5.4 配置方式</h5><p>创建一个svc-nginx.yaml，内容如下：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">svc-nginx</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">clusterIP:</span> <span class="number">10.109</span><span class="number">.179</span><span class="number">.231</span> <span class="comment">#固定svc的内网ip</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">80</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">run:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">ClusterIP</span></span><br></pre></td></tr></table></figure></div>

<p>然后就可以执行对应的创建和删除命令了：</p>
<p>创建：kubectl create -f svc-nginx.yaml</p>
<p>删除：kubectl delete -f svc-nginx.yaml</p>
<blockquote>
<p><strong>小结</strong></p>
<p>至此，已经掌握了Namespace、Pod、Deployment、Service资源的基本操作，有了这些操作，就可以在kubernetes集群中实现一个服务的简单部署和访问了，但是如果想要更好的使用kubernetes，就需要深入学习这几种资源的细节和原理。</p>
</blockquote>
]]></content>
      <tags>
        <tag>云原生基础系列</tag>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>云原生基础系列之Kubernetes(六)Pod控制器详解</title>
    <url>/2022/06/09/uncatalog/cl46zbaye000q7or7bx6mhrl3/</url>
    <content><![CDATA[<hr>
<span id="more"></span>



<hr>
<h3 id="6-Pod控制器详解"><a href="#6-Pod控制器详解" class="headerlink" title="6. Pod控制器详解"></a>6. Pod控制器详解</h3><h4 id="6-1-Pod控制器介绍"><a href="#6-1-Pod控制器介绍" class="headerlink" title="6.1 Pod控制器介绍"></a>6.1 Pod控制器介绍</h4><p>Pod是kubernetes的最小管理单元，在kubernetes中，按照pod的创建方式可以将其分为两类：</p>
<ul>
<li>自主式pod：kubernetes直接创建出来的Pod，这种pod删除后就没有了，也不会重建</li>
<li>控制器创建的pod：kubernetes通过控制器创建的pod，这种pod删除了之后还会自动重建</li>
</ul>
<blockquote>
<p><strong><code>什么是Pod控制器</code></strong></p>
<p>Pod控制器是管理pod的中间层，使用Pod控制器之后，只需要告诉Pod控制器，想要多少个什么样的Pod就可以了，它会创建出满足条件的Pod并确保每一个Pod资源处于用户期望的目标状态。如果Pod资源在运行中出现故障，它会基于指定策略重新编排Pod。</p>
</blockquote>
<p>在kubernetes中，有很多类型的pod控制器，每种都有自己的适合的场景，常见的有下面这些：</p>
<ul>
<li>ReplicationController：比较原始的pod控制器，已经被废弃，由ReplicaSet替代</li>
<li>ReplicaSet：保证副本数量一直维持在期望值，并支持pod数量扩缩容，镜像版本升级</li>
<li>Deployment：通过控制ReplicaSet来控制Pod，并支持滚动升级、回退版本</li>
<li>Horizontal Pod Autoscaler：可以根据集群负载自动水平调整Pod的数量，实现削峰填谷</li>
<li>DaemonSet：在集群中的指定Node上运行且仅运行一个副本，一般用于守护进程类的任务</li>
<li>Job：它创建出来的pod只要完成任务就立即退出，不需要重启或重建，用于执行一次性任务</li>
<li>Cronjob：它创建的Pod负责周期性任务控制，不需要持续后台运行</li>
<li>StatefulSet：管理有状态应用</li>
</ul>
<h4 id="6-2-ReplicaSet-RS"><a href="#6-2-ReplicaSet-RS" class="headerlink" title="6.2 ReplicaSet(RS)"></a>6.2 ReplicaSet(RS)</h4><p>ReplicaSet的主要作用是<strong>保证一定数量的pod正常运行</strong>，它会持续监听这些Pod的运行状态，一旦Pod发生故障，就会重启或重建。同时它还支持对pod数量的扩缩容和镜像版本的升降级。</p>
<p><img src="/2022/06/09/uncatalog/cl46zbaye000q7or7bx6mhrl3/image-20200612005334159.png" alt="img"></p>
<p>ReplicaSet的资源清单文件：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span> <span class="comment"># 版本号</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ReplicaSet</span> <span class="comment"># 类型       </span></span><br><span class="line"><span class="attr">metadata:</span> <span class="comment"># 元数据</span></span><br><span class="line">  <span class="attr">name:</span> <span class="comment"># rs名称 </span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="comment"># 所属命名空间 </span></span><br><span class="line">  <span class="attr">labels:</span> <span class="comment">#标签</span></span><br><span class="line">    <span class="attr">controller:</span> <span class="string">rs</span></span><br><span class="line"><span class="attr">spec:</span> <span class="comment"># 详情描述</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">3</span> <span class="comment"># 副本数量</span></span><br><span class="line">  <span class="attr">selector:</span> <span class="comment"># 选择器，通过它指定该控制器管理哪些pod</span></span><br><span class="line">    <span class="attr">matchLabels:</span>      <span class="comment"># Labels匹配规则</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">nginx-pod</span></span><br><span class="line">    <span class="attr">matchExpressions:</span> <span class="comment"># Expressions匹配规则</span></span><br><span class="line">      <span class="bullet">-</span> &#123;<span class="attr">key:</span> <span class="string">app</span>, <span class="attr">operator:</span> <span class="string">In</span>, <span class="attr">values:</span> [<span class="string">nginx-pod</span>]&#125;</span><br><span class="line">  <span class="attr">template:</span> <span class="comment"># 模板，当副本数量不足时，会根据下面的模板创建pod副本</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">nginx-pod</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure></div>

<p>在这里面，需要新了解的配置项就是<code>spec</code>下面几个选项：</p>
<ul>
<li><p>replicas：指定副本数量，其实就是当前rs创建出来的pod的数量，默认为1</p>
</li>
<li><p>selector：选择器，它的作用是建立pod控制器和pod之间的关联关系，采用的Label Selector机制</p>
<p>在pod模板上定义label，在控制器上定义选择器，就可以表明当前控制器能管理哪些pod了</p>
</li>
<li><p>template：模板，就是当前控制器创建pod所使用的模板板，里面其实就是前一章学过的pod的定义</p>
</li>
</ul>
<p><strong>创建ReplicaSet</strong></p>
<p>创建pc-replicaset.yaml文件，内容如下：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ReplicaSet</span>   </span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pc-replicaset</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">3</span></span><br><span class="line">  <span class="attr">selector:</span> </span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">nginx-pod</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">nginx-pod</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br></pre></td></tr></table></figure></div>

<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建rs</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl create -f pc-replicaset.yaml</span><br><span class="line">replicaset.apps/pc-replicaset created</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看rs</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> DESIRED:期望副本数量</span>  </span><br><span class="line"><span class="meta">#</span><span class="bash"> CURRENT:当前副本数量</span>  </span><br><span class="line"><span class="meta">#</span><span class="bash"> READY:已经准备好提供服务的副本数量</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl get rs pc-replicaset -n dev -o wide</span><br><span class="line">NAME          DESIRED   CURRENT READY AGE   CONTAINERS   IMAGES             SELECTOR</span><br><span class="line">pc-replicaset 3         3       3     22s   nginx        nginx:1.17.1       app=nginx-pod</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看当前控制器创建出来的pod</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 这里发现控制器创建出来的pod的名称是在控制器名称后面拼接了-xxxxx随机码</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl get pod -n dev</span><br><span class="line">NAME                          READY   STATUS    RESTARTS   AGE</span><br><span class="line">pc-replicaset-6vmvt   1/1     Running   0          54s</span><br><span class="line">pc-replicaset-fmb8f   1/1     Running   0          54s</span><br><span class="line">pc-replicaset-snrk2   1/1     Running   0          54s</span><br></pre></td></tr></table></figure></div>

<p><strong>扩缩容</strong></p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 编辑rs的副本数量，修改spec:replicas: 6即可</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl edit rs pc-replicaset -n dev</span><br><span class="line">replicaset.apps/pc-replicaset edited</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看pod</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl get pods -n dev</span><br><span class="line">NAME                          READY   STATUS    RESTARTS   AGE</span><br><span class="line">pc-replicaset-6vmvt   1/1     Running   0          114m</span><br><span class="line">pc-replicaset-cftnp   1/1     Running   0          10s</span><br><span class="line">pc-replicaset-fjlm6   1/1     Running   0          10s</span><br><span class="line">pc-replicaset-fmb8f   1/1     Running   0          114m</span><br><span class="line">pc-replicaset-s2whj   1/1     Running   0          10s</span><br><span class="line">pc-replicaset-snrk2   1/1     Running   0          114m</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 当然也可以直接使用命令实现</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 使用scale命令实现扩缩容， 后面--replicas=n直接指定目标数量即可</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl scale rs pc-replicaset --replicas=2 -n dev</span><br><span class="line">replicaset.apps/pc-replicaset scaled</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 命令运行完毕，立即查看，发现已经有4个开始准备退出了</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl get pods -n dev</span><br><span class="line">NAME                       READY   STATUS        RESTARTS   AGE</span><br><span class="line">pc-replicaset-6vmvt   0/1     Terminating   0          118m</span><br><span class="line">pc-replicaset-cftnp   0/1     Terminating   0          4m17s</span><br><span class="line">pc-replicaset-fjlm6   0/1     Terminating   0          4m17s</span><br><span class="line">pc-replicaset-fmb8f   1/1     Running       0          118m</span><br><span class="line">pc-replicaset-s2whj   0/1     Terminating   0          4m17s</span><br><span class="line">pc-replicaset-snrk2   1/1     Running       0          118m</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">稍等片刻，就只剩下2个了</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl get pods -n dev</span><br><span class="line">NAME                       READY   STATUS    RESTARTS   AGE</span><br><span class="line">pc-replicaset-fmb8f   1/1     Running   0          119m</span><br><span class="line">pc-replicaset-snrk2   1/1     Running   0          119m</span><br></pre></td></tr></table></figure></div>

<p><strong>镜像升级</strong></p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 编辑rs的容器镜像 - image: nginx:1.17.2</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl edit rs pc-replicaset -n dev</span><br><span class="line">replicaset.apps/pc-replicaset edited</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 再次查看，发现镜像版本已经变更了</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl get rs -n dev -o wide</span><br><span class="line">NAME                DESIRED  CURRENT   READY   AGE    CONTAINERS   IMAGES        ...</span><br><span class="line">pc-replicaset       2        2         2       140m   nginx         nginx:1.17.2  ...</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 同样的道理，也可以使用命令完成这个工作</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> kubectl <span class="built_in">set</span> image rs rs名称 容器=镜像版本 -n namespace</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl set image rs pc-replicaset nginx=nginx:1.17.1  -n dev</span><br><span class="line">replicaset.apps/pc-replicaset image updated</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 再次查看，发现镜像版本已经变更了</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl get rs -n dev -o wide</span><br><span class="line">NAME                 DESIRED  CURRENT   READY   AGE    CONTAINERS   IMAGES            ...</span><br><span class="line">pc-replicaset        2        2         2       145m   nginx        nginx:1.17.1 ... </span><br></pre></td></tr></table></figure></div>

<p><strong>删除ReplicaSet</strong></p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 使用kubectl delete命令会删除此RS以及它管理的Pod</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 在kubernetes删除RS前，会将RS的replicasclear调整为0，等待所有的Pod被删除后，在执行RS对象的删除</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl delete rs pc-replicaset -n dev</span><br><span class="line">replicaset.apps &quot;pc-replicaset&quot; deleted</span><br><span class="line">[root@k8s-master01 ~]# kubectl get pod -n dev -o wide</span><br><span class="line">No resources found in dev namespace.</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 如果希望仅仅删除RS对象（保留Pod），可以使用kubectl delete命令时添加--cascade=<span class="literal">false</span>选项（不推荐）。</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl delete rs pc-replicaset -n dev --cascade=false</span><br><span class="line">replicaset.apps &quot;pc-replicaset&quot; deleted</span><br><span class="line">[root@k8s-master01 ~]# kubectl get pods -n dev</span><br><span class="line">NAME                  READY   STATUS    RESTARTS   AGE</span><br><span class="line">pc-replicaset-cl82j   1/1     Running   0          75s</span><br><span class="line">pc-replicaset-dslhb   1/1     Running   0          75s</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 也可以使用yaml直接删除(推荐)</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl delete -f pc-replicaset.yaml</span><br><span class="line">replicaset.apps &quot;pc-replicaset&quot; deleted</span><br></pre></td></tr></table></figure></div>

<h4 id="6-3-Deployment-Deploy"><a href="#6-3-Deployment-Deploy" class="headerlink" title="6.3 Deployment(Deploy)"></a>6.3 Deployment(Deploy)</h4><p>为了更好的解决服务编排的问题，kubernetes在V1.2版本开始，引入了Deployment控制器。值得一提的是，这种控制器并不直接管理pod，而是通过管理ReplicaSet来简介管理Pod，即：Deployment管理ReplicaSet，ReplicaSet管理Pod。所以Deployment比ReplicaSet功能更加强大。</p>
<p>为了更好的解决服务编排的问题，kubernetes在V1.2版本开始，引入了Deployment控制器。值得一提的是，这种控制器并不直接管理pod，而是通过管理ReplicaSet来简介管理Pod，即：Deployment管理ReplicaSet，ReplicaSet管理Pod。所以Deployment比ReplicaSet功能更加强大。</p>
<p><img src="/2022/06/09/uncatalog/cl46zbaye000q7or7bx6mhrl3/image-20200612005524778.png" alt="img"></p>
<p>Deployment主要功能有下面几个：</p>
<ul>
<li>支持ReplicaSet的所有功能</li>
<li>支持发布的停止、继续</li>
<li>支持滚动升级和回滚版本</li>
</ul>
<p>Deployment的资源清单文件：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span> <span class="comment"># 版本号</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span> <span class="comment"># 类型       </span></span><br><span class="line"><span class="attr">metadata:</span> <span class="comment"># 元数据</span></span><br><span class="line">  <span class="attr">name:</span> <span class="comment"># rs名称 </span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="comment"># 所属命名空间 </span></span><br><span class="line">  <span class="attr">labels:</span> <span class="comment">#标签</span></span><br><span class="line">    <span class="attr">controller:</span> <span class="string">deploy</span></span><br><span class="line"><span class="attr">spec:</span> <span class="comment"># 详情描述</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">3</span> <span class="comment"># 副本数量</span></span><br><span class="line">  <span class="attr">revisionHistoryLimit:</span> <span class="number">3</span> <span class="comment"># 保留历史版本</span></span><br><span class="line">  <span class="attr">paused:</span> <span class="literal">false</span> <span class="comment"># 暂停部署，默认是false</span></span><br><span class="line">  <span class="attr">progressDeadlineSeconds:</span> <span class="number">600</span> <span class="comment"># 部署超时时间（s），默认是600</span></span><br><span class="line">  <span class="attr">strategy:</span> <span class="comment"># 策略</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">RollingUpdate</span> <span class="comment"># 滚动更新策略</span></span><br><span class="line">    <span class="attr">rollingUpdate:</span> <span class="comment"># 滚动更新</span></span><br><span class="line">      <span class="string">违规词汇:</span> <span class="number">30</span><span class="string">%</span> <span class="comment"># 最大额外可以存在的副本数，可以为百分比，也可以为整数</span></span><br><span class="line">      <span class="attr">maxUnavailable:</span> <span class="number">30</span><span class="string">%</span> <span class="comment"># 最大不可用状态的 Pod 的最大值，可以为百分比，也可以为整数</span></span><br><span class="line">  <span class="attr">selector:</span> <span class="comment"># 选择器，通过它指定该控制器管理哪些pod</span></span><br><span class="line">    <span class="attr">matchLabels:</span>      <span class="comment"># Labels匹配规则</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">nginx-pod</span></span><br><span class="line">    <span class="attr">matchExpressions:</span> <span class="comment"># Expressions匹配规则</span></span><br><span class="line">      <span class="bullet">-</span> &#123;<span class="attr">key:</span> <span class="string">app</span>, <span class="attr">operator:</span> <span class="string">In</span>, <span class="attr">values:</span> [<span class="string">nginx-pod</span>]&#125;</span><br><span class="line">  <span class="attr">template:</span> <span class="comment"># 模板，当副本数量不足时，会根据下面的模板创建pod副本</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">nginx-pod</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure></div>

<h5 id="6-3-1-创建deployment"><a href="#6-3-1-创建deployment" class="headerlink" title="6.3.1 创建deployment"></a>6.3.1 创建deployment</h5><p>创建pc-deployment.yaml，内容如下：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span>      </span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pc-deployment</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span> </span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">3</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">nginx-pod</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">nginx-pod</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br></pre></td></tr></table></figure></div>

<h5 id="6-3-2-扩缩容"><a href="#6-3-2-扩缩容" class="headerlink" title="6.3.2 扩缩容"></a>6.3.2 扩缩容</h5><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 变更副本数量为5个</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl scale deploy pc-deployment --replicas=5  -n dev</span><br><span class="line">deployment.apps/pc-deployment scaled</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看deployment</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl get deploy pc-deployment -n dev</span><br><span class="line">NAME            READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">pc-deployment   5/5     5            5           2m</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看pod</span></span><br><span class="line">[root@k8s-master01 ~]#  kubectl get pods -n dev</span><br><span class="line">NAME                             READY   STATUS    RESTARTS   AGE</span><br><span class="line">pc-deployment-6696798b78-d2c8n   1/1     Running   0          4m19s</span><br><span class="line">pc-deployment-6696798b78-jxmdq   1/1     Running   0          94s</span><br><span class="line">pc-deployment-6696798b78-mktqv   1/1     Running   0          93s</span><br><span class="line">pc-deployment-6696798b78-smpvp   1/1     Running   0          4m19s</span><br><span class="line">pc-deployment-6696798b78-wvjd8   1/1     Running   0          4m19s</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 编辑deployment的副本数量，修改spec:replicas: 4即可</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl edit deploy pc-deployment -n dev</span><br><span class="line">deployment.apps/pc-deployment edited</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看pod</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl get pods -n dev</span><br><span class="line">NAME                             READY   STATUS    RESTARTS   AGE</span><br><span class="line">pc-deployment-6696798b78-d2c8n   1/1     Running   0          5m23s</span><br><span class="line">pc-deployment-6696798b78-jxmdq   1/1     Running   0          2m38s</span><br><span class="line">pc-deployment-6696798b78-smpvp   1/1     Running   0          5m23s</span><br><span class="line">pc-deployment-6696798b78-wvjd8   1/1     Running   0          5m23s</span><br></pre></td></tr></table></figure></div>

<p><strong>镜像更新</strong></p>
<p>deployment支持两种更新策略:<code>重建更新</code>和<code>滚动更新</code>,可以通过<code>strategy</code>指定策略类型,支持两个属性:</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="MARKDOWN"><figure class="iseeu highlight /markdown"><table><tr><td class="code"><pre><span class="line">strategy：指定新的Pod替换旧的Pod的策略， 支持两个属性：</span><br><span class="line">  type：指定策略类型，支持两种策略</span><br><span class="line"><span class="code">    Recreate：在创建出新的Pod之前会先杀掉所有已存在的Pod</span></span><br><span class="line"><span class="code">    RollingUpdate：滚动更新，就是杀死一部分，就启动一部分，在更新过程中，存在两个版本Pod</span></span><br><span class="line"><span class="code">  rollingUpdate：当type为RollingUpdate时生效，用于为RollingUpdate设置参数，支持两个属性：</span></span><br><span class="line"><span class="code">    maxUnavailable：用来指定在升级过程中不可用Pod的最大数量，默认为25%。</span></span><br><span class="line"><span class="code">    违规词汇： 用来指定在升级过程中可以超过期望的Pod的最大数量，默认为25%。</span></span><br></pre></td></tr></table></figure></div>

<p>重建更新</p>
<ol>
<li>编辑pc-deployment.yaml,在spec节点下添加更新策略</li>
</ol>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">strategy:</span> <span class="comment"># 策略</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">Recreate</span> <span class="comment"># 重建更新</span></span><br></pre></td></tr></table></figure></div>

<ol start="2">
<li>创建deploy进行验证</li>
</ol>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 变更镜像</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl set image deployment pc-deployment nginx=nginx:1.17.2 -n dev</span><br><span class="line">deployment.apps/pc-deployment image updated</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 观察升级过程</span></span><br><span class="line">[root@k8s-master01 ~]#  kubectl get pods -n dev -w</span><br><span class="line">NAME                             READY   STATUS    RESTARTS   AGE</span><br><span class="line">pc-deployment-5d89bdfbf9-65qcw   1/1     Running   0          31s</span><br><span class="line">pc-deployment-5d89bdfbf9-w5nzv   1/1     Running   0          31s</span><br><span class="line">pc-deployment-5d89bdfbf9-xpt7w   1/1     Running   0          31s</span><br><span class="line"></span><br><span class="line">pc-deployment-5d89bdfbf9-xpt7w   1/1     Terminating   0          41s</span><br><span class="line">pc-deployment-5d89bdfbf9-65qcw   1/1     Terminating   0          41s</span><br><span class="line">pc-deployment-5d89bdfbf9-w5nzv   1/1     Terminating   0          41s</span><br><span class="line"></span><br><span class="line">pc-deployment-675d469f8b-grn8z   0/1     Pending       0          0s</span><br><span class="line">pc-deployment-675d469f8b-hbl4v   0/1     Pending       0          0s</span><br><span class="line">pc-deployment-675d469f8b-67nz2   0/1     Pending       0          0s</span><br><span class="line"></span><br><span class="line">pc-deployment-675d469f8b-grn8z   0/1     ContainerCreating   0          0s</span><br><span class="line">pc-deployment-675d469f8b-hbl4v   0/1     ContainerCreating   0          0s</span><br><span class="line">pc-deployment-675d469f8b-67nz2   0/1     ContainerCreating   0          0s</span><br><span class="line"></span><br><span class="line">pc-deployment-675d469f8b-grn8z   1/1     Running             0          1s</span><br><span class="line">pc-deployment-675d469f8b-67nz2   1/1     Running             0          1s</span><br><span class="line">pc-deployment-675d469f8b-hbl4v   1/1     Running             0          2s</span><br></pre></td></tr></table></figure></div>

<p>滚动更新</p>
<ol>
<li>编辑pc-deployment.yaml,在spec节点下添加更新策略</li>
</ol>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">strategy:</span> <span class="comment"># 策略</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">RollingUpdate</span> <span class="comment"># 滚动更新策略</span></span><br><span class="line">    <span class="attr">rollingUpdate:</span></span><br><span class="line">      <span class="string">违规词汇:</span> <span class="number">25</span><span class="string">%</span> </span><br><span class="line">      <span class="attr">maxUnavailable:</span> <span class="number">25</span><span class="string">%</span></span><br></pre></td></tr></table></figure></div>

<ol start="2">
<li>创建deploy进行验证</li>
</ol>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 变更镜像</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl set image deployment pc-deployment nginx=nginx:1.17.3 -n dev </span><br><span class="line">deployment.apps/pc-deployment image updated</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 观察升级过程</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl get pods -n dev -w</span><br><span class="line">NAME                           READY   STATUS    RESTARTS   AGE</span><br><span class="line">pc-deployment-c848d767-8rbzt   1/1     Running   0          31m</span><br><span class="line">pc-deployment-c848d767-h4p68   1/1     Running   0          31m</span><br><span class="line">pc-deployment-c848d767-hlmz4   1/1     Running   0          31m</span><br><span class="line">pc-deployment-c848d767-rrqcn   1/1     Running   0          31m</span><br><span class="line"></span><br><span class="line">pc-deployment-966bf7f44-226rx   0/1     Pending             0          0s</span><br><span class="line">pc-deployment-966bf7f44-226rx   0/1     ContainerCreating   0          0s</span><br><span class="line">pc-deployment-966bf7f44-226rx   1/1     Running             0          1s</span><br><span class="line">pc-deployment-c848d767-h4p68    0/1     Terminating         0          34m</span><br><span class="line"></span><br><span class="line">pc-deployment-966bf7f44-cnd44   0/1     Pending             0          0s</span><br><span class="line">pc-deployment-966bf7f44-cnd44   0/1     ContainerCreating   0          0s</span><br><span class="line">pc-deployment-966bf7f44-cnd44   1/1     Running             0          2s</span><br><span class="line">pc-deployment-c848d767-hlmz4    0/1     Terminating         0          34m</span><br><span class="line"></span><br><span class="line">pc-deployment-966bf7f44-px48p   0/1     Pending             0          0s</span><br><span class="line">pc-deployment-966bf7f44-px48p   0/1     ContainerCreating   0          0s</span><br><span class="line">pc-deployment-966bf7f44-px48p   1/1     Running             0          0s</span><br><span class="line">pc-deployment-c848d767-8rbzt    0/1     Terminating         0          34m</span><br><span class="line"></span><br><span class="line">pc-deployment-966bf7f44-dkmqp   0/1     Pending             0          0s</span><br><span class="line">pc-deployment-966bf7f44-dkmqp   0/1     ContainerCreating   0          0s</span><br><span class="line">pc-deployment-966bf7f44-dkmqp   1/1     Running             0          2s</span><br><span class="line">pc-deployment-c848d767-rrqcn    0/1     Terminating         0          34m</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 至此，新版本的pod创建完毕，就版本的pod销毁完毕</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 中间过程是滚动进行的，也就是边销毁边创建</span></span><br></pre></td></tr></table></figure></div>

<p>滚动更新的过程：</p>
<p><img src="/2022/06/09/uncatalog/cl46zbaye000q7or7bx6mhrl3/image-20200416140251491.png" alt="img"></p>
<p>镜像更新中rs的变化</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 查看rs,发现原来的rs的依旧存在，只是pod数量变为了0，而后又新产生了一个rs，pod数量为4</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 其实这就是deployment能够进行版本回退的奥妙所在，后面会详细解释</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl get rs -n dev</span><br><span class="line">NAME                       DESIRED   CURRENT   READY   AGE</span><br><span class="line">pc-deployment-6696798b78   0         0         0       7m37s</span><br><span class="line">pc-deployment-6696798b11   0         0         0       5m37s</span><br><span class="line">pc-deployment-c848d76789   4         4         4       72s</span><br></pre></td></tr></table></figure></div>

<h5 id="6-3-3-版本回退"><a href="#6-3-3-版本回退" class="headerlink" title="6.3.3 版本回退"></a>6.3.3 版本回退</h5><p>deployment支持版本升级过程中的暂停、继续功能以及版本回退等诸多功能，下面具体来看.</p>
<p>kubectl rollout： 版本升级相关功能，支持下面的选项：</p>
<ul>
<li>status    显示当前升级状态</li>
<li>history   显示 升级历史记录</li>
<li>pause    暂停版本升级过程</li>
<li>resume   继续已经暂停的版本升级过程</li>
<li>restart    重启版本升级过程</li>
<li>undo 回滚到上一级版本（可以使用–to-revision回滚到指定版本）</li>
</ul>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 查看当前升级版本的状态</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl rollout status deploy pc-deployment -n dev</span><br><span class="line">deployment &quot;pc-deployment&quot; successfully rolled out</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看升级历史记录</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl rollout history deploy pc-deployment -n dev</span><br><span class="line">deployment.apps/pc-deployment</span><br><span class="line">REVISION  CHANGE-CAUSE</span><br><span class="line">1         kubectl create --filename=pc-deployment.yaml --record=true</span><br><span class="line">2         kubectl create --filename=pc-deployment.yaml --record=true</span><br><span class="line">3         kubectl create --filename=pc-deployment.yaml --record=true</span><br><span class="line"><span class="meta">#</span><span class="bash"> 可以发现有三次版本记录，说明完成过两次升级</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 版本回滚</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 这里直接使用--to-revision=1回滚到了1版本， 如果省略这个选项，就是回退到上个版本，就是2版本</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl rollout undo deployment pc-deployment --to-revision=1 -n dev</span><br><span class="line">deployment.apps/pc-deployment rolled back</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看发现，通过nginx镜像版本可以发现到了第一版</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl get deploy -n dev -o wide</span><br><span class="line">NAME            READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS   IMAGES         </span><br><span class="line">pc-deployment   4/4     4            4           74m   nginx        nginx:1.17.1   </span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看rs，发现第一个rs中有4个pod运行，后面两个版本的rs中pod为运行</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 其实deployment之所以可是实现版本的回滚，就是通过记录下历史rs来实现的，</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 一旦想回滚到哪个版本，只需要将当前版本pod数量降为0，然后将回滚版本的pod提升为目标数量就可以了</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl get rs -n dev</span><br><span class="line">NAME                       DESIRED   CURRENT   READY   AGE</span><br><span class="line">pc-deployment-6696798b78   4         4         4       78m</span><br><span class="line">pc-deployment-966bf7f44    0         0         0       37m</span><br><span class="line">pc-deployment-c848d767     0         0         0       71m</span><br></pre></td></tr></table></figure></div>

<h5 id="6-3-4-金丝雀发布"><a href="#6-3-4-金丝雀发布" class="headerlink" title="6.3.4 金丝雀发布"></a>6.3.4 金丝雀发布</h5><p>Deployment控制器支持控制更新过程中的控制，如“暂停(pause)”或“继续(resume)”更新操作。</p>
<p>比如有一批新的Pod资源创建完成后立即暂停更新过程，此时，仅存在一部分新版本的应用，主体部分还是旧的版本。然后，再筛选一小部分的用户请求路由到新版本的Pod应用，继续观察能否稳定地按期望的方式运行。确定没问题之后再继续完成余下的Pod资源滚动更新，否则立即回滚更新操作。这就是所谓的金丝雀发布。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 更新deployment的版本，并配置暂停deployment</span></span><br><span class="line">[root@k8s-master01 ~]#  kubectl set image deploy pc-deployment nginx=nginx:1.17.4 -n dev &amp;&amp; kubectl rollout pause deployment pc-deployment  -n dev</span><br><span class="line">deployment.apps/pc-deployment image updated</span><br><span class="line">deployment.apps/pc-deployment paused</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">观察更新状态</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl rollout status deploy pc-deployment -n dev　</span><br><span class="line">Waiting for deployment &quot;pc-deployment&quot; rollout to finish: 2 out of 4 new replicas have been updated...</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 监控更新的过程，可以看到已经新增了一个资源，但是并未按照预期的状态去删除一个旧的资源，就是因为使用了pause暂停命令</span></span><br><span class="line"></span><br><span class="line">[root@k8s-master01 ~]# kubectl get rs -n dev -o wide</span><br><span class="line">NAME                       DESIRED   CURRENT   READY   AGE     CONTAINERS   IMAGES         </span><br><span class="line">pc-deployment-5d89bdfbf9   3         3         3       19m     nginx        nginx:1.17.1   </span><br><span class="line">pc-deployment-675d469f8b   0         0         0       14m     nginx        nginx:1.17.2   </span><br><span class="line">pc-deployment-6c9f56fcfb   2         2         2       3m16s   nginx        nginx:1.17.4   </span><br><span class="line">[root@k8s-master01 ~]# kubectl get pods -n dev</span><br><span class="line">NAME                             READY   STATUS    RESTARTS   AGE</span><br><span class="line">pc-deployment-5d89bdfbf9-rj8sq   1/1     Running   0          7m33s</span><br><span class="line">pc-deployment-5d89bdfbf9-ttwgg   1/1     Running   0          7m35s</span><br><span class="line">pc-deployment-5d89bdfbf9-v4wvc   1/1     Running   0          7m34s</span><br><span class="line">pc-deployment-6c9f56fcfb-996rt   1/1     Running   0          3m31s</span><br><span class="line">pc-deployment-6c9f56fcfb-j2gtj   1/1     Running   0          3m31s</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 确保更新的pod没问题了，继续更新</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl rollout resume deploy pc-deployment -n dev</span><br><span class="line">deployment.apps/pc-deployment resumed</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看最后的更新情况</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl get rs -n dev -o wide</span><br><span class="line">NAME                       DESIRED   CURRENT   READY   AGE     CONTAINERS   IMAGES         </span><br><span class="line">pc-deployment-5d89bdfbf9   0         0         0       21m     nginx        nginx:1.17.1   </span><br><span class="line">pc-deployment-675d469f8b   0         0         0       16m     nginx        nginx:1.17.2   </span><br><span class="line">pc-deployment-6c9f56fcfb   4         4         4       5m11s   nginx        nginx:1.17.4   </span><br><span class="line"></span><br><span class="line">[root@k8s-master01 ~]# kubectl get pods -n dev</span><br><span class="line">NAME                             READY   STATUS    RESTARTS   AGE</span><br><span class="line">pc-deployment-6c9f56fcfb-7bfwh   1/1     Running   0          37s</span><br><span class="line">pc-deployment-6c9f56fcfb-996rt   1/1     Running   0          5m27s</span><br><span class="line">pc-deployment-6c9f56fcfb-j2gtj   1/1     Running   0          5m27s</span><br><span class="line">pc-deployment-6c9f56fcfb-rf84v   1/1     Running   0          37s</span><br></pre></td></tr></table></figure></div>

<p><strong>删除Deployment</strong></p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 删除deployment，其下的rs和pod也将被删除</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl delete -f pc-deployment.yaml</span><br><span class="line">deployment.apps &quot;pc-deployment&quot; deleted</span><br></pre></td></tr></table></figure></div>

<h4 id="6-4-Horizontal-Pod-Autoscaler-HPA"><a href="#6-4-Horizontal-Pod-Autoscaler-HPA" class="headerlink" title="6.4 Horizontal Pod Autoscaler(HPA)"></a>6.4 Horizontal Pod Autoscaler(HPA)</h4><p>在前面的课程中，我们已经可以实现通过手工执行<code>kubectl scale</code>命令实现Pod扩容或缩容，但是这显然不符合Kubernetes的定位目标–自动化、智能化。 Kubernetes期望可以实现通过监测Pod的使用情况，实现pod数量的自动调整，于是就产生了Horizontal Pod Autoscaler（HPA）这种控制器。</p>
<p>HPA可以获取每个Pod利用率，然后和HPA中定义的指标进行对比，同时计算出需要伸缩的具体值，最后实现Pod的数量的调整。其实HPA与之前的Deployment一样，也属于一种Kubernetes资源对象，它通过追踪分析RC控制的所有目标Pod的负载变化情况，来确定是否需要针对性地调整目标Pod的副本数，这是HPA的实现原理。</p>
<p><img src="/2022/06/09/uncatalog/cl46zbaye000q7or7bx6mhrl3/image-20200608155858271.png" alt="img"></p>
<p>接下来，我们来做一个实验</p>
<h5 id="6-4-1-安装metrics-server"><a href="#6-4-1-安装metrics-server" class="headerlink" title="6.4.1 安装metrics-server"></a>6.4.1 安装metrics-server</h5><p>metrics-server可以用来收集集群中的资源使用情况</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 安装git</span></span><br><span class="line">[root@k8s-master01 ~]# yum install git -y</span><br><span class="line"><span class="meta">#</span><span class="bash"> 获取metrics-server, 注意使用的版本</span></span><br><span class="line">[root@k8s-master01 ~]# git clone -b v0.3.6 https://github.com/kubernetes-incubator/metrics-server</span><br><span class="line"><span class="meta">#</span><span class="bash"> 修改deployment, 注意修改的是镜像和初始化参数</span></span><br><span class="line">[root@k8s-master01 ~]# cd /root/metrics-server/deploy/1.8+/</span><br><span class="line">[root@k8s-master01 1.8+]# vim metrics-server-deployment.yaml</span><br><span class="line">按图中添加下面选项</span><br><span class="line">hostNetwork: true</span><br><span class="line">image: registry.cn-hangzhou.aliyuncs.com/google_containers/metrics-server-amd64:v0.3.6</span><br><span class="line">args:</span><br><span class="line">- --kubelet-insecure-tls</span><br><span class="line">- --kubelet-preferred-address-types=InternalIP,Hostname,InternalDNS,ExternalDNS,ExternalIP</span><br></pre></td></tr></table></figure></div>

<p><img src="/2022/06/09/uncatalog/cl46zbaye000q7or7bx6mhrl3/image-20200608163326496.png" alt="image-20200608163326496"></p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 安装metrics-server</span></span><br><span class="line">[root@k8s-master01 1.8+]# kubectl apply -f ./</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看pod运行情况</span></span><br><span class="line">[root@k8s-master01 1.8+]# kubectl get pod -n kube-system</span><br><span class="line">metrics-server-6b976979db-2xwbj   1/1     Running   0          90s</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 使用kubectl top node 查看资源使用情况</span></span><br><span class="line">[root@k8s-master01 1.8+]# kubectl top node</span><br><span class="line">NAME           CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%</span><br><span class="line">k8s-master01   289m         14%    1582Mi          54%       </span><br><span class="line">k8s-node01     81m          4%     1195Mi          40%       </span><br><span class="line">k8s-node02     72m          3%     1211Mi          41%  </span><br><span class="line">[root@k8s-master01 1.8+]# kubectl top pod -n kube-system</span><br><span class="line">NAME                              CPU(cores)   MEMORY(bytes)</span><br><span class="line">coredns-6955765f44-7ptsb          3m           9Mi</span><br><span class="line">coredns-6955765f44-vcwr5          3m           8Mi</span><br><span class="line">etcd-master                       14m          145Mi</span><br><span class="line">...</span><br><span class="line"><span class="meta">#</span><span class="bash"> 至此,metrics-server安装完成</span></span><br></pre></td></tr></table></figure></div>

<h5 id="6-4-2-准备deployment和servie"><a href="#6-4-2-准备deployment和servie" class="headerlink" title="6.4.2 准备deployment和servie"></a>6.4.2 准备deployment和servie</h5><p>创建pc-hpa-pod.yaml文件，内容如下：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">strategy:</span> <span class="comment"># 策略</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">RollingUpdate</span> <span class="comment"># 滚动更新策略</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">nginx-pod</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">nginx-pod</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br><span class="line">        <span class="attr">resources:</span> <span class="comment"># 资源配额</span></span><br><span class="line">          <span class="attr">limits:</span>  <span class="comment"># 限制资源（上限）</span></span><br><span class="line">            <span class="attr">cpu:</span> <span class="string">&quot;1&quot;</span> <span class="comment"># CPU限制，单位是core数</span></span><br><span class="line">          <span class="attr">requests:</span> <span class="comment"># 请求资源（下限）</span></span><br><span class="line">            <span class="attr">cpu:</span> <span class="string">&quot;100m&quot;</span>  <span class="comment"># CPU限制，单位是core数</span></span><br></pre></td></tr></table></figure></div>

<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建deployment</span></span><br><span class="line">[root@k8s-master01 1.8+]# kubectl run nginx --image=nginx:1.17.1 --requests=cpu=100m -n dev</span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建service</span></span><br><span class="line">[root@k8s-master01 1.8+]# kubectl expose deployment nginx --type=NodePort --port=80 -n dev</span><br></pre></td></tr></table></figure></div>

<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 查看</span></span><br><span class="line">[root@k8s-master01 1.8+]# kubectl get deployment,pod,svc -n dev</span><br><span class="line">NAME                    READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">deployment.apps/nginx   1/1     1            1           47s</span><br><span class="line"></span><br><span class="line">NAME                         READY   STATUS    RESTARTS   AGE</span><br><span class="line">pod/nginx-7df9756ccc-bh8dr   1/1     Running   0          47s</span><br><span class="line"></span><br><span class="line">NAME            TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE</span><br><span class="line">service/nginx   NodePort   10.101.18.29   &lt;none&gt;        80:31830/TCP   35s</span><br></pre></td></tr></table></figure></div>

<h5 id="6-4-3-部署HPA"><a href="#6-4-3-部署HPA" class="headerlink" title="6.4.3 部署HPA"></a>6.4.3 部署HPA</h5><p>创建pc-hpa.yaml文件，内容如下：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">autoscaling/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">HorizontalPodAutoscaler</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pc-hpa</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">minReplicas:</span> <span class="number">1</span>  <span class="comment">#最小pod数量</span></span><br><span class="line">  <span class="attr">maxReplicas:</span> <span class="number">10</span> <span class="comment">#最大pod数量</span></span><br><span class="line">  <span class="attr">targetCPUUtilizationPercentage:</span> <span class="number">3</span> <span class="comment"># CPU使用率指标</span></span><br><span class="line">  <span class="attr">scaleTargetRef:</span>   <span class="comment"># 指定要控制的nginx信息</span></span><br><span class="line">    <span class="attr">apiVersion:</span>  <span class="string">/v1</span></span><br><span class="line">    <span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">nginx</span></span><br></pre></td></tr></table></figure></div>

<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建hpa</span></span><br><span class="line">[root@k8s-master01 1.8+]# kubectl create -f pc-hpa.yaml</span><br><span class="line">horizontalpodautoscaler.autoscaling/pc-hpa created</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看hpa</span></span><br><span class="line">    [root@k8s-master01 1.8+]# kubectl get hpa -n dev</span><br><span class="line">NAME     REFERENCE          TARGETS   MINPODS   MAXPODS   REPLICAS   AGE</span><br><span class="line">pc-hpa   Deployment/nginx   0%/3%     1         10        1          62s</span><br></pre></td></tr></table></figure></div>

<h5 id="6-4-4-测试"><a href="#6-4-4-测试" class="headerlink" title="6.4.4 测试"></a>6.4.4 测试</h5><p>使用压测工具对service地址<code>192.168.5.4:31830</code>进行压测，然后通过控制台查看hpa和pod的变化</p>
<p>hpa变化</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master01 ~]# kubectl get hpa -n dev -w</span><br><span class="line">NAME   REFERENCE      TARGETS  MINPODS  MAXPODS  REPLICAS  AGE</span><br><span class="line">pc-hpa  Deployment/nginx  0%/3%   1     10     1      4m11s</span><br><span class="line">pc-hpa  Deployment/nginx  0%/3%   1     10     1      5m19s</span><br><span class="line">pc-hpa  Deployment/nginx  22%/3%   1     10     1      6m50s</span><br><span class="line">pc-hpa  Deployment/nginx  22%/3%   1     10     4      7m5s</span><br><span class="line">pc-hpa  Deployment/nginx  22%/3%   1     10     8      7m21s</span><br><span class="line">pc-hpa  Deployment/nginx  6%/3%   1     10     8      7m51s</span><br><span class="line">pc-hpa  Deployment/nginx  0%/3%   1     10     8      9m6s</span><br><span class="line">pc-hpa  Deployment/nginx  0%/3%   1     10     8      13m</span><br><span class="line">pc-hpa  Deployment/nginx  0%/3%   1     10     1      14m</span><br></pre></td></tr></table></figure></div>

<p>deployment变化</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master01 ~]# kubectl get deployment -n dev -w</span><br><span class="line">NAME    READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">nginx   1/1     1            1           11m</span><br><span class="line">nginx   1/4     1            1           13m</span><br><span class="line">nginx   1/4     1            1           13m</span><br><span class="line">nginx   1/4     1            1           13m</span><br><span class="line">nginx   1/4     4            1           13m</span><br><span class="line">nginx   1/8     4            1           14m</span><br><span class="line">nginx   1/8     4            1           14m</span><br><span class="line">nginx   1/8     4            1           14m</span><br><span class="line">nginx   1/8     8            1           14m</span><br><span class="line">nginx   2/8     8            2           14m</span><br><span class="line">nginx   3/8     8            3           14m</span><br><span class="line">nginx   4/8     8            4           14m</span><br><span class="line">nginx   5/8     8            5           14m</span><br><span class="line">nginx   6/8     8            6           14m</span><br><span class="line">nginx   7/8     8            7           14m</span><br><span class="line">nginx   8/8     8            8           15m</span><br><span class="line">nginx   8/1     8            8           20m</span><br><span class="line">nginx   8/1     8            8           20m</span><br><span class="line">nginx   1/1     1            1           20m</span><br></pre></td></tr></table></figure></div>

<p>pod变化</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tr><td class="code"><pre><span class="line">[root@k8s-master01 ~]# kubectl get pods -n dev -w</span><br><span class="line">NAME                     READY   STATUS    RESTARTS   AGE</span><br><span class="line">nginx-7df9756ccc-bh8dr   1&#x2F;1     Running   0          11m</span><br><span class="line">nginx-7df9756ccc-cpgrv   0&#x2F;1     Pending   0          0s</span><br><span class="line">nginx-7df9756ccc-8zhwk   0&#x2F;1     Pending   0          0s</span><br><span class="line">nginx-7df9756ccc-rr9bn   0&#x2F;1     Pending   0          0s</span><br><span class="line">nginx-7df9756ccc-cpgrv   0&#x2F;1     ContainerCreating   0          0s</span><br><span class="line">nginx-7df9756ccc-8zhwk   0&#x2F;1     ContainerCreating   0          0s</span><br><span class="line">nginx-7df9756ccc-rr9bn   0&#x2F;1     ContainerCreating   0          0s</span><br><span class="line">nginx-7df9756ccc-m9gsj   0&#x2F;1     Pending             0          0s</span><br><span class="line">nginx-7df9756ccc-g56qb   0&#x2F;1     Pending             0          0s</span><br><span class="line">nginx-7df9756ccc-sl9c6   0&#x2F;1     Pending             0          0s</span><br><span class="line">nginx-7df9756ccc-fgst7   0&#x2F;1     Pending             0          0s</span><br><span class="line">nginx-7df9756ccc-g56qb   0&#x2F;1     ContainerCreating   0          0s</span><br><span class="line">nginx-7df9756ccc-m9gsj   0&#x2F;1     ContainerCreating   0          0s</span><br><span class="line">nginx-7df9756ccc-sl9c6   0&#x2F;1     ContainerCreating   0          0s</span><br><span class="line">nginx-7df9756ccc-fgst7   0&#x2F;1     ContainerCreating   0          0s</span><br><span class="line">nginx-7df9756ccc-8zhwk   1&#x2F;1     Running             0          19s</span><br><span class="line">nginx-7df9756ccc-rr9bn   1&#x2F;1     Running             0          30s</span><br><span class="line">nginx-7df9756ccc-m9gsj   1&#x2F;1     Running             0          21s</span><br><span class="line">nginx-7df9756ccc-cpgrv   1&#x2F;1     Running             0          47s</span><br><span class="line">nginx-7df9756ccc-sl9c6   1&#x2F;1     Running             0          33s</span><br><span class="line">nginx-7df9756ccc-g56qb   1&#x2F;1     Running             0          48s</span><br><span class="line">nginx-7df9756ccc-fgst7   1&#x2F;1     Running             0          66s</span><br><span class="line">nginx-7df9756ccc-fgst7   1&#x2F;1     Terminating         0          6m50s</span><br><span class="line">nginx-7df9756ccc-8zhwk   1&#x2F;1     Terminating         0          7m5s</span><br><span class="line">nginx-7df9756ccc-cpgrv   1&#x2F;1     Terminating         0          7m5s</span><br><span class="line">nginx-7df9756ccc-g56qb   1&#x2F;1     Terminating         0          6m50s</span><br><span class="line">nginx-7df9756ccc-rr9bn   1&#x2F;1     Terminating         0          7m5s</span><br><span class="line">nginx-7df9756ccc-m9gsj   1&#x2F;1     Terminating         0          6m50s</span><br><span class="line">nginx-7df9756ccc-sl9c6   1&#x2F;1     Terminating         0          6m50s</span><br></pre></td></tr></table></figure></div>

<h4 id="6-5-DaemonSet-DS"><a href="#6-5-DaemonSet-DS" class="headerlink" title="6.5 DaemonSet(DS)"></a>6.5 DaemonSet(DS)</h4><p>DaemonSet类型的控制器可以保证在集群中的每一台（或指定）节点上都运行一个副本。一般适用于日志收集、节点监控等场景。也就是说，如果一个Pod提供的功能是节点级别的（每个节点都需要且只需要一个），那么这类Pod就适合使用DaemonSet类型的控制器创建。</p>
<p><img src="/2022/06/09/uncatalog/cl46zbaye000q7or7bx6mhrl3/image-20200612010223537.png" alt="img"></p>
<p>DaemonSet控制器的特点：</p>
<ul>
<li>每当向集群中添加一个节点时，指定的 Pod 副本也将添加到该节点上</li>
<li>当节点从集群中移除时，Pod 也就被垃圾回收了</li>
</ul>
<p>下面先来看下DaemonSet的资源清单文件</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span> <span class="comment"># 版本号</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">DaemonSet</span> <span class="comment"># 类型       </span></span><br><span class="line"><span class="attr">metadata:</span> <span class="comment"># 元数据</span></span><br><span class="line">  <span class="attr">name:</span> <span class="comment"># rs名称 </span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="comment"># 所属命名空间 </span></span><br><span class="line">  <span class="attr">labels:</span> <span class="comment">#标签</span></span><br><span class="line">    <span class="attr">controller:</span> <span class="string">daemonset</span></span><br><span class="line"><span class="attr">spec:</span> <span class="comment"># 详情描述</span></span><br><span class="line">  <span class="attr">revisionHistoryLimit:</span> <span class="number">3</span> <span class="comment"># 保留历史版本</span></span><br><span class="line">  <span class="attr">updateStrategy:</span> <span class="comment"># 更新策略</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">RollingUpdate</span> <span class="comment"># 滚动更新策略</span></span><br><span class="line">    <span class="attr">rollingUpdate:</span> <span class="comment"># 滚动更新</span></span><br><span class="line">      <span class="attr">maxUnavailable:</span> <span class="number">1</span> <span class="comment"># 最大不可用状态的 Pod 的最大值，可以为百分比，也可以为整数</span></span><br><span class="line">  <span class="attr">selector:</span> <span class="comment"># 选择器，通过它指定该控制器管理哪些pod</span></span><br><span class="line">    <span class="attr">matchLabels:</span>      <span class="comment"># Labels匹配规则</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">nginx-pod</span></span><br><span class="line">    <span class="attr">matchExpressions:</span> <span class="comment"># Expressions匹配规则</span></span><br><span class="line">      <span class="bullet">-</span> &#123;<span class="attr">key:</span> <span class="string">app</span>, <span class="attr">operator:</span> <span class="string">In</span>, <span class="attr">values:</span> [<span class="string">nginx-pod</span>]&#125;</span><br><span class="line">  <span class="attr">template:</span> <span class="comment"># 模板，当副本数量不足时，会根据下面的模板创建pod副本</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">nginx-pod</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure></div>

<p>创建pc-daemonset.yaml，内容如下：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">DaemonSet</span>      </span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pc-daemonset</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span> </span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">nginx-pod</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">nginx-pod</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br></pre></td></tr></table></figure></div>

<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建daemonset</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl create -f  pc-daemonset.yaml</span><br><span class="line">daemonset.apps/pc-daemonset created</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看daemonset</span></span><br><span class="line">[root@k8s-master01 ~]#  kubectl get ds -n dev -o wide</span><br><span class="line">NAME        DESIRED  CURRENT  READY  UP-TO-DATE  AVAILABLE   AGE   CONTAINERS   IMAGES         </span><br><span class="line">pc-daemonset   2        2        2      2           2        24s   nginx        nginx:1.17.1   </span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看pod,发现在每个Node上都运行一个pod</span></span><br><span class="line">[root@k8s-master01 ~]#  kubectl get pods -n dev -o wide</span><br><span class="line">NAME                 READY   STATUS    RESTARTS   AGE   IP            NODE    </span><br><span class="line">pc-daemonset-9bck8   1/1     Running   0          37s   10.244.1.43   node1     </span><br><span class="line">pc-daemonset-k224w   1/1     Running   0          37s   10.244.2.74   node2      </span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 删除daemonset</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl delete -f pc-daemonset.yaml</span><br><span class="line">daemonset.apps &quot;pc-daemonset&quot; deleted</span><br></pre></td></tr></table></figure></div>

<h4 id="6-6-Job"><a href="#6-6-Job" class="headerlink" title="6.6 Job"></a>6.6 Job</h4><p>Job，主要用于负责**批量处理(一次要处理指定数量任务)<strong>短暂的</strong>一次性(每个任务仅运行一次就结束)**任务。Job特点如下：</p>
<ul>
<li>当Job创建的pod执行成功结束时，Job将记录成功结束的pod数量</li>
<li>当成功结束的pod达到指定的数量时，Job将完成执行</li>
</ul>
<p><img src="/2022/06/09/uncatalog/cl46zbaye000q7or7bx6mhrl3/image-20200618213054113.png" alt="img"></p>
<p>Job的资源清单文件：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">batch/v1</span> <span class="comment"># 版本号</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Job</span> <span class="comment"># 类型       </span></span><br><span class="line"><span class="attr">metadata:</span> <span class="comment"># 元数据</span></span><br><span class="line">  <span class="attr">name:</span> <span class="comment"># rs名称 </span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="comment"># 所属命名空间 </span></span><br><span class="line">  <span class="attr">labels:</span> <span class="comment">#标签</span></span><br><span class="line">    <span class="attr">controller:</span> <span class="string">job</span></span><br><span class="line"><span class="attr">spec:</span> <span class="comment"># 详情描述</span></span><br><span class="line">  <span class="attr">completions:</span> <span class="number">1</span> <span class="comment"># 指定job需要成功运行Pods的次数。默认值: 1</span></span><br><span class="line">  <span class="attr">parallelism:</span> <span class="number">1</span> <span class="comment"># 指定job在任一时刻应该并发运行Pods的数量。默认值: 1</span></span><br><span class="line">  <span class="attr">activeDeadlineSeconds:</span> <span class="number">30</span> <span class="comment"># 指定job可运行的时间期限，超过时间还未结束，系统将会尝试进行终止。</span></span><br><span class="line">  <span class="attr">backoffLimit:</span> <span class="number">6</span> <span class="comment"># 指定job失败后进行重试的次数。默认是6</span></span><br><span class="line">  <span class="attr">manualSelector:</span> <span class="literal">true</span> <span class="comment"># 是否可以使用selector选择器选择pod，默认是false</span></span><br><span class="line">  <span class="attr">selector:</span> <span class="comment"># 选择器，通过它指定该控制器管理哪些pod</span></span><br><span class="line">    <span class="attr">matchLabels:</span>      <span class="comment"># Labels匹配规则</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">counter-pod</span></span><br><span class="line">    <span class="attr">matchExpressions:</span> <span class="comment"># Expressions匹配规则</span></span><br><span class="line">      <span class="bullet">-</span> &#123;<span class="attr">key:</span> <span class="string">app</span>, <span class="attr">operator:</span> <span class="string">In</span>, <span class="attr">values:</span> [<span class="string">counter-pod</span>]&#125;</span><br><span class="line">  <span class="attr">template:</span> <span class="comment"># 模板，当副本数量不足时，会根据下面的模板创建pod副本</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">counter-pod</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">restartPolicy:</span> <span class="string">Never</span> <span class="comment"># 重启策略只能设置为Never或者OnFailure</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">counter</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">busybox:1.30</span></span><br><span class="line">        <span class="attr">command:</span> [<span class="string">&quot;bin/sh&quot;</span>,<span class="string">&quot;-c&quot;</span>,<span class="string">&quot;for i in 9 8 7 6 5 4 3 2 1; do echo $i;sleep 2;done&quot;</span>]</span><br></pre></td></tr></table></figure></div>

<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="MARKDOWN"><figure class="iseeu highlight /markdown"><table><tr><td class="code"><pre><span class="line">关于重启策略设置的说明：</span><br><span class="line"><span class="code">    如果指定为OnFailure，则job会在pod出现故障时重启容器，而不是创建pod，failed次数不变</span></span><br><span class="line"><span class="code">    如果指定为Never，则job会在pod出现故障时创建新的pod，并且故障pod不会消失，也不会重启，failed次数加1</span></span><br><span class="line"><span class="code">    如果指定为Always的话，就意味着一直重启，意味着job任务会重复去执行了，当然不对，所以不能设置为Always</span></span><br></pre></td></tr></table></figure></div>

<p>创建pc-job.yaml，内容如下：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">batch/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Job</span>      </span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pc-job</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">manualSelector:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">counter-pod</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">counter-pod</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">restartPolicy:</span> <span class="string">Never</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">counter</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">busybox:1.30</span></span><br><span class="line">        <span class="attr">command:</span> [<span class="string">&quot;bin/sh&quot;</span>,<span class="string">&quot;-c&quot;</span>,<span class="string">&quot;for i in 9 8 7 6 5 4 3 2 1; do echo $i;sleep 3;done&quot;</span>]</span><br></pre></td></tr></table></figure></div>

<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建job</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl create -f pc-job.yaml</span><br><span class="line">job.batch/pc-job created</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看job</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl get job -n dev -o wide  -w</span><br><span class="line">NAME     COMPLETIONS   DURATION   AGE   CONTAINERS   IMAGES         SELECTOR</span><br><span class="line">pc-job   0/1           21s        21s   counter      busybox:1.30   app=counter-pod</span><br><span class="line">pc-job   1/1           31s        79s   counter      busybox:1.30   app=counter-pod</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 通过观察pod状态可以看到，pod在运行完毕任务后，就会变成Completed状态</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl get pods -n dev -w</span><br><span class="line">NAME           READY   STATUS     RESTARTS      AGE</span><br><span class="line">pc-job-rxg96   1/1     Running     0            29s</span><br><span class="line">pc-job-rxg96   0/1     Completed   0            33s</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 接下来，调整下pod运行的总数量和并行数量 即：在spec下设置下面两个选项</span></span><br><span class="line"><span class="meta">#</span><span class="bash">  completions: 6 <span class="comment"># 指定job需要成功运行Pods的次数为6</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash">  parallelism: 3 <span class="comment"># 指定job并发运行Pods的数量为3</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash">  然后重新运行job，观察效果，此时会发现，job会每次运行3个pod，总共执行了6个pod</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl get pods -n dev -w</span><br><span class="line">NAME           READY   STATUS    RESTARTS   AGE</span><br><span class="line">pc-job-684ft   1/1     Running   0          5s</span><br><span class="line">pc-job-jhj49   1/1     Running   0          5s</span><br><span class="line">pc-job-pfcvh   1/1     Running   0          5s</span><br><span class="line">pc-job-684ft   0/1     Completed   0          11s</span><br><span class="line">pc-job-v7rhr   0/1     Pending     0          0s</span><br><span class="line">pc-job-v7rhr   0/1     Pending     0          0s</span><br><span class="line">pc-job-v7rhr   0/1     ContainerCreating   0          0s</span><br><span class="line">pc-job-jhj49   0/1     Completed           0          11s</span><br><span class="line">pc-job-fhwf7   0/1     Pending             0          0s</span><br><span class="line">pc-job-fhwf7   0/1     Pending             0          0s</span><br><span class="line">pc-job-pfcvh   0/1     Completed           0          11s</span><br><span class="line">pc-job-5vg2j   0/1     Pending             0          0s</span><br><span class="line">pc-job-fhwf7   0/1     ContainerCreating   0          0s</span><br><span class="line">pc-job-5vg2j   0/1     Pending             0          0s</span><br><span class="line">pc-job-5vg2j   0/1     ContainerCreating   0          0s</span><br><span class="line">pc-job-fhwf7   1/1     Running             0          2s</span><br><span class="line">pc-job-v7rhr   1/1     Running             0          2s</span><br><span class="line">pc-job-5vg2j   1/1     Running             0          3s</span><br><span class="line">pc-job-fhwf7   0/1     Completed           0          12s</span><br><span class="line">pc-job-v7rhr   0/1     Completed           0          12s</span><br><span class="line">pc-job-5vg2j   0/1     Completed           0          12s</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 删除job</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl delete -f pc-job.yaml</span><br><span class="line">job.batch &quot;pc-job&quot; deleted</span><br></pre></td></tr></table></figure></div>

<h4 id="6-7-CronJob-CJ"><a href="#6-7-CronJob-CJ" class="headerlink" title="6.7 CronJob(CJ)"></a>6.7 CronJob(CJ)</h4><p>CronJob控制器以 Job控制器资源为其管控对象，并借助它管理pod资源对象，Job控制器定义的作业任务在其控制器资源创建之后便会立即执行，但CronJob可以以类似于Linux操作系统的周期性任务作业计划的方式控制其运行<strong>时间点</strong>及<strong>重复运行</strong>的方式。也就是说，<strong>CronJob可以在特定的时间点(反复的)去运行job任务</strong>。</p>
<p><img src="/2022/06/09/uncatalog/cl46zbaye000q7or7bx6mhrl3/image-20200618213149531.png" alt="img"></p>
<p>CronJob的资源清单文件：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">batch/v1beta1</span> <span class="comment"># 版本号</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">CronJob</span> <span class="comment"># 类型       </span></span><br><span class="line"><span class="attr">metadata:</span> <span class="comment"># 元数据</span></span><br><span class="line">  <span class="attr">name:</span> <span class="comment"># rs名称 </span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="comment"># 所属命名空间 </span></span><br><span class="line">  <span class="attr">labels:</span> <span class="comment">#标签</span></span><br><span class="line">    <span class="attr">controller:</span> <span class="string">cronjob</span></span><br><span class="line"><span class="attr">spec:</span> <span class="comment"># 详情描述</span></span><br><span class="line">  <span class="attr">schedule:</span> <span class="comment"># cron格式的作业调度运行时间点,用于控制任务在什么时间执行</span></span><br><span class="line">  <span class="attr">concurrencyPolicy:</span> <span class="comment"># 并发执行策略，用于定义前一次作业运行尚未完成时是否以及如何运行后一次的作业</span></span><br><span class="line">  <span class="attr">failedJobHistoryLimit:</span> <span class="comment"># 为失败的任务执行保留的历史记录数，默认为1</span></span><br><span class="line">  <span class="attr">successfulJobHistoryLimit:</span> <span class="comment"># 为成功的任务执行保留的历史记录数，默认为3</span></span><br><span class="line">  <span class="attr">startingDeadlineSeconds:</span> <span class="comment"># 启动作业错误的超时时长</span></span><br><span class="line">  <span class="attr">jobTemplate:</span> <span class="comment"># job控制器模板，用于为cronjob控制器生成job对象;下面其实就是job的定义</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">completions:</span> <span class="number">1</span></span><br><span class="line">      <span class="attr">parallelism:</span> <span class="number">1</span></span><br><span class="line">      <span class="attr">activeDeadlineSeconds:</span> <span class="number">30</span></span><br><span class="line">      <span class="attr">backoffLimit:</span> <span class="number">6</span></span><br><span class="line">      <span class="attr">manualSelector:</span> <span class="literal">true</span></span><br><span class="line">      <span class="attr">selector:</span></span><br><span class="line">        <span class="attr">matchLabels:</span></span><br><span class="line">          <span class="attr">app:</span> <span class="string">counter-pod</span></span><br><span class="line">        <span class="attr">matchExpressions:</span> <span class="string">规则</span></span><br><span class="line">          <span class="bullet">-</span> &#123;<span class="attr">key:</span> <span class="string">app</span>, <span class="attr">operator:</span> <span class="string">In</span>, <span class="attr">values:</span> [<span class="string">counter-pod</span>]&#125;</span><br><span class="line">      <span class="attr">template:</span></span><br><span class="line">        <span class="attr">metadata:</span></span><br><span class="line">          <span class="attr">labels:</span></span><br><span class="line">            <span class="attr">app:</span> <span class="string">counter-pod</span></span><br><span class="line">        <span class="attr">spec:</span></span><br><span class="line">          <span class="attr">restartPolicy:</span> <span class="string">Never</span> </span><br><span class="line">          <span class="attr">containers:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">counter</span></span><br><span class="line">            <span class="attr">image:</span> <span class="string">busybox:1.30</span></span><br><span class="line">            <span class="attr">command:</span> [<span class="string">&quot;bin/sh&quot;</span>,<span class="string">&quot;-c&quot;</span>,<span class="string">&quot;for i in 9 8 7 6 5 4 3 2 1; do echo $i;sleep 20;done&quot;</span>]</span><br></pre></td></tr></table></figure></div>

<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="MARKDOWN"><figure class="iseeu highlight /markdown"><table><tr><td class="code"><pre><span class="line">需要重点解释的几个选项：</span><br><span class="line">schedule: cron表达式，用于指定任务的执行时间</span><br><span class="line"><span class="code">    */1    *      *    *     *</span></span><br><span class="line"><span class="code">    &lt;分钟&gt; &lt;小时&gt; &lt;日&gt; &lt;月份&gt; &lt;星期&gt;</span></span><br><span class="line"><span class="code"></span></span><br><span class="line"><span class="code">    分钟 值从 0 到 59.</span></span><br><span class="line"><span class="code">    小时 值从 0 到 23.</span></span><br><span class="line"><span class="code">    日 值从 1 到 31.</span></span><br><span class="line"><span class="code">    月 值从 1 到 12.</span></span><br><span class="line"><span class="code">    星期 值从 0 到 6, 0 代表星期日</span></span><br><span class="line"><span class="code">    多个时间可以用逗号隔开； 范围可以用连字符给出；*可以作为通配符； /表示每...</span></span><br><span class="line"><span class="code">concurrencyPolicy:</span></span><br><span class="line"><span class="code">    Allow:   允许Jobs并发运行(默认)</span></span><br><span class="line"><span class="code">    Forbid:  禁止并发运行，如果上一次运行尚未完成，则跳过下一次运行</span></span><br><span class="line"><span class="code">    Replace: 替换，取消当前正在运行的作业并用新作业替换它</span></span><br></pre></td></tr></table></figure></div>

<p>创建pc-cronjob.yaml，内容如下：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">batch/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">CronJob</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pc-cronjob</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">controller:</span> <span class="string">cronjob</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">schedule:</span> <span class="string">&quot;*/1 * * * *&quot;</span></span><br><span class="line">  <span class="attr">jobTemplate:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">template:</span></span><br><span class="line">        <span class="attr">spec:</span></span><br><span class="line">          <span class="attr">restartPolicy:</span> <span class="string">Never</span></span><br><span class="line">          <span class="attr">containers:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">counter</span></span><br><span class="line">            <span class="attr">image:</span> <span class="string">busybox:1.30</span></span><br><span class="line">            <span class="attr">command:</span> [<span class="string">&quot;bin/sh&quot;</span>,<span class="string">&quot;-c&quot;</span>,<span class="string">&quot;for i in 9 8 7 6 5 4 3 2 1; do echo $i;sleep 3;done&quot;</span>]</span><br></pre></td></tr></table></figure></div>

<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建cronjob</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl create -f pc-cronjob.yaml</span><br><span class="line">cronjob.batch/pc-cronjob created</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看cronjob</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl get cronjobs -n dev</span><br><span class="line">NAME         SCHEDULE      SUSPEND   ACTIVE   LAST SCHEDULE   AGE</span><br><span class="line">pc-cronjob   */1 * * * *   False     0        &lt;none&gt;          6s</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看job</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl get jobs -n dev</span><br><span class="line">NAME                    COMPLETIONS   DURATION   AGE</span><br><span class="line">pc-cronjob-1592587800   1/1           28s        3m26s</span><br><span class="line">pc-cronjob-1592587860   1/1           28s        2m26s</span><br><span class="line">pc-cronjob-1592587920   1/1           28s        86s</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看pod</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl get pods -n dev</span><br><span class="line">pc-cronjob-1592587800-x4tsm   0/1     Completed   0          2m24s</span><br><span class="line">pc-cronjob-1592587860-r5gv4   0/1     Completed   0          84s</span><br><span class="line">pc-cronjob-1592587920-9dxxq   1/1     Running     0          24s</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 删除cronjob</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl  delete -f pc-cronjob.yaml</span><br><span class="line">cronjob.batch &quot;pc-cronjob&quot; deleted</span><br></pre></td></tr></table></figure></div>
]]></content>
      <tags>
        <tag>云原生基础系列</tag>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>云原生基础系列之Kubernetes(五)Pod详解</title>
    <url>/2022/06/09/uncatalog/cl46zbayg000v7or7a4o0f4yd/</url>
    <content><![CDATA[<hr>
<span id="more"></span>



<hr>
<h4 id="5-1-Pod介绍"><a href="#5-1-Pod介绍" class="headerlink" title="5.1 Pod介绍"></a>5.1 Pod介绍</h4><h5 id="5-1-1-Pod结构"><a href="#5-1-1-Pod结构" class="headerlink" title="5.1.1 Pod结构"></a>5.1.1 Pod结构</h5><p><img src="/2022/06/09/uncatalog/cl46zbayg000v7or7a4o0f4yd/image-20200407121501907-1626781151898.png" alt="image-20200407121501907"></p>
<p>每个Pod中都可以包含一个或者多个容器，这些容器可以分为两类：</p>
<ul>
<li><p>用户程序所在的容器，数量可多可少</p>
</li>
<li><p>Pause容器，这是每个Pod都会有的一个<strong>根容器</strong>，它的作用有两个：</p>
<ul>
<li><p>可以以它为依据，评估整个Pod的健康状态</p>
</li>
<li><p>可以在根容器上设置Ip地址，其它容器都此Ip（Pod IP），以实现Pod内部的网路通信</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tr><td class="code"><pre><span class="line">这里是Pod内部的通讯，Pod的之间的通讯采用虚拟二层网络技术来实现，我们当前环境用的是Flannel</span><br></pre></td></tr></table></figure></div></li>
</ul>
</li>
</ul>
<h5 id="5-1-2-Pod定义"><a href="#5-1-2-Pod定义" class="headerlink" title="5.1.2 Pod定义"></a>5.1.2 Pod定义</h5><p>下面是Pod的资源清单：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span>     <span class="comment">#必选，版本号，例如v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span>       　 <span class="comment">#必选，资源类型，例如 Pod</span></span><br><span class="line"><span class="attr">metadata:</span>       　 <span class="comment">#必选，元数据</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">string</span>     <span class="comment">#必选，Pod名称</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">string</span>  <span class="comment">#Pod所属的命名空间,默认为&quot;default&quot;</span></span><br><span class="line">  <span class="attr">labels:</span>       　　  <span class="comment">#自定义标签列表</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">string</span>      　          </span><br><span class="line"><span class="attr">spec:</span>  <span class="comment">#必选，Pod中容器的详细定义</span></span><br><span class="line">  <span class="attr">containers:</span>  <span class="comment">#必选，Pod中容器列表</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">string</span>   <span class="comment">#必选，容器名称</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">string</span>  <span class="comment">#必选，容器的镜像名称</span></span><br><span class="line">    <span class="attr">imagePullPolicy:</span> [ <span class="string">Always|Never|IfNotPresent</span> ]  <span class="comment">#获取镜像的策略 </span></span><br><span class="line">    <span class="attr">command:</span> [<span class="string">string</span>]   <span class="comment">#容器的启动命令列表，如不指定，使用打包时使用的启动命令</span></span><br><span class="line">    <span class="attr">args:</span> [<span class="string">string</span>]      <span class="comment">#容器的启动命令参数列表</span></span><br><span class="line">    <span class="attr">workingDir:</span> <span class="string">string</span>  <span class="comment">#容器的工作目录</span></span><br><span class="line">    <span class="attr">volumeMounts:</span>       <span class="comment">#挂载到容器内部的存储卷配置</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">string</span>      <span class="comment">#引用pod定义的共享存储卷的名称，需用volumes[]部分定义的的卷名</span></span><br><span class="line">      <span class="attr">mountPath:</span> <span class="string">string</span> <span class="comment">#存储卷在容器内mount的绝对路径，应少于512字符</span></span><br><span class="line">      <span class="attr">readOnly:</span> <span class="string">boolean</span> <span class="comment">#是否为只读模式</span></span><br><span class="line">    <span class="attr">ports:</span> <span class="comment">#需要暴露的端口库号列表</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">string</span>        <span class="comment">#端口的名称</span></span><br><span class="line">      <span class="attr">containerPort:</span> <span class="string">int</span>  <span class="comment">#容器需要监听的端口号</span></span><br><span class="line">      <span class="attr">hostPort:</span> <span class="string">int</span>       <span class="comment">#容器所在主机需要监听的端口号，默认与Container相同</span></span><br><span class="line">      <span class="attr">protocol:</span> <span class="string">string</span>    <span class="comment">#端口协议，支持TCP和UDP，默认TCP</span></span><br><span class="line">    <span class="attr">env:</span>   <span class="comment">#容器运行前需设置的环境变量列表</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">string</span>  <span class="comment">#环境变量名称</span></span><br><span class="line">      <span class="attr">value:</span> <span class="string">string</span> <span class="comment">#环境变量的值</span></span><br><span class="line">    <span class="attr">resources:</span> <span class="comment">#资源限制和请求的设置</span></span><br><span class="line">      <span class="attr">limits:</span>  <span class="comment">#资源限制的设置</span></span><br><span class="line">        <span class="attr">cpu:</span> <span class="string">string</span>     <span class="comment">#Cpu的限制，单位为core数，将用于docker run --cpu-shares参数</span></span><br><span class="line">        <span class="attr">memory:</span> <span class="string">string</span>  <span class="comment">#内存限制，单位可以为Mib/Gib，将用于docker run --memory参数</span></span><br><span class="line">      <span class="attr">requests:</span> <span class="comment">#资源请求的设置</span></span><br><span class="line">        <span class="attr">cpu:</span> <span class="string">string</span>    <span class="comment">#Cpu请求，容器启动的初始可用数量</span></span><br><span class="line">        <span class="attr">memory:</span> <span class="string">string</span> <span class="comment">#内存请求,容器启动的初始可用数量</span></span><br><span class="line">    <span class="attr">lifecycle:</span> <span class="comment">#生命周期钩子</span></span><br><span class="line">        <span class="attr">postStart:</span> <span class="comment">#容器启动后立即执行此钩子,如果执行失败,会根据重启策略进行重启</span></span><br><span class="line">        <span class="attr">preStop:</span> <span class="comment">#容器终止前执行此钩子,无论结果如何,容器都会终止</span></span><br><span class="line">    <span class="attr">livenessProbe:</span>  <span class="comment">#对Pod内各容器健康检查的设置，当探测无响应几次后将自动重启该容器</span></span><br><span class="line">      <span class="attr">exec:</span>       　 <span class="comment">#对Pod容器内检查方式设置为exec方式</span></span><br><span class="line">        <span class="attr">command:</span> [<span class="string">string</span>]  <span class="comment">#exec方式需要制定的命令或脚本</span></span><br><span class="line">      <span class="attr">httpGet:</span>       <span class="comment">#对Pod内个容器健康检查方法设置为HttpGet，需要制定Path、port</span></span><br><span class="line">        <span class="attr">path:</span> <span class="string">string</span></span><br><span class="line">        <span class="attr">port:</span> <span class="string">number</span></span><br><span class="line">        <span class="attr">host:</span> <span class="string">string</span></span><br><span class="line">        <span class="attr">scheme:</span> <span class="string">string</span></span><br><span class="line">        <span class="attr">HttpHeaders:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">string</span></span><br><span class="line">          <span class="attr">value:</span> <span class="string">string</span></span><br><span class="line">      <span class="attr">tcpSocket:</span>     <span class="comment">#对Pod内个容器健康检查方式设置为tcpSocket方式</span></span><br><span class="line">         <span class="attr">port:</span> <span class="string">number</span></span><br><span class="line">       <span class="attr">initialDelaySeconds:</span> <span class="number">0</span>       <span class="comment">#容器启动完成后首次探测的时间，单位为秒</span></span><br><span class="line">       <span class="attr">timeoutSeconds:</span> <span class="number">0</span>    　　    <span class="comment">#对容器健康检查探测等待响应的超时时间，单位秒，默认1秒</span></span><br><span class="line">       <span class="attr">periodSeconds:</span> <span class="number">0</span>     　　    <span class="comment">#对容器监控检查的定期探测时间设置，单位秒，默认10秒一次</span></span><br><span class="line">       <span class="attr">successThreshold:</span> <span class="number">0</span></span><br><span class="line">       <span class="attr">failureThreshold:</span> <span class="number">0</span></span><br><span class="line">       <span class="attr">securityContext:</span></span><br><span class="line">         <span class="attr">privileged:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">restartPolicy:</span> [<span class="string">Always</span> <span class="string">|</span> <span class="string">Never</span> <span class="string">|</span> <span class="string">OnFailure</span>]  <span class="comment">#Pod的重启策略</span></span><br><span class="line">  <span class="attr">nodeName:</span> <span class="string">&lt;string&gt;</span> <span class="comment">#设置NodeName表示将该Pod调度到指定到名称的node节点上</span></span><br><span class="line">  <span class="attr">nodeSelector:</span> <span class="string">obeject</span> <span class="comment">#设置NodeSelector表示将该Pod调度到包含这个label的node上</span></span><br><span class="line">  <span class="attr">imagePullSecrets:</span> <span class="comment">#Pull镜像时使用的secret名称，以key：secretkey格式指定</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">string</span></span><br><span class="line">  <span class="attr">hostNetwork:</span> <span class="literal">false</span>   <span class="comment">#是否使用主机网络模式，默认为false，如果设置为true，表示使用宿主机网络</span></span><br><span class="line">  <span class="attr">volumes:</span>   <span class="comment">#在该pod上定义共享存储卷列表</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">string</span>    <span class="comment">#共享存储卷名称 （volumes类型有很多种）</span></span><br><span class="line">    <span class="attr">emptyDir:</span> &#123;&#125;       <span class="comment">#类型为emtyDir的存储卷，与Pod同生命周期的一个临时目录。为空值</span></span><br><span class="line">    <span class="attr">hostPath:</span> <span class="string">string</span>   <span class="comment">#类型为hostPath的存储卷，表示挂载Pod所在宿主机的目录</span></span><br><span class="line">      <span class="attr">path:</span> <span class="string">string</span>      　　        <span class="comment">#Pod所在宿主机的目录，将被用于同期中mount的目录</span></span><br><span class="line">    <span class="attr">secret:</span>       　　　<span class="comment">#类型为secret的存储卷，挂载集群与定义的secret对象到容器内部</span></span><br><span class="line">      <span class="attr">scretname:</span> <span class="string">string</span>  </span><br><span class="line">      <span class="attr">items:</span>     </span><br><span class="line">      <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">string</span></span><br><span class="line">        <span class="attr">path:</span> <span class="string">string</span></span><br><span class="line">    <span class="attr">configMap:</span>         <span class="comment">#类型为configMap的存储卷，挂载预定义的configMap对象到容器内部</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">string</span></span><br><span class="line">      <span class="attr">items:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">string</span></span><br><span class="line">        <span class="attr">path:</span> <span class="string">string</span></span><br></pre></td></tr></table></figure></div>

<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment">#小提示：</span></span><br><span class="line"><span class="comment">#   在这里，可通过一个命令来查看每种资源的可配置项</span></span><br><span class="line"><span class="comment">#   kubectl explain 资源类型         查看某种资源可以配置的一级属性</span></span><br><span class="line"><span class="comment">#   kubectl explain 资源类型.属性     查看属性的子属性</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># kubectl explain pod</span></span><br><span class="line"><span class="attr">KIND:</span>     <span class="string">Pod</span></span><br><span class="line"><span class="attr">VERSION:</span>  <span class="string">v1</span></span><br><span class="line"><span class="attr">FIELDS:</span></span><br><span class="line">   <span class="string">apiVersion</span>   <span class="string">&lt;string&gt;</span></span><br><span class="line">   <span class="string">kind</span> <span class="string">&lt;string&gt;</span></span><br><span class="line">   <span class="string">metadata</span>     <span class="string">&lt;Object&gt;</span></span><br><span class="line">   <span class="string">spec</span> <span class="string">&lt;Object&gt;</span></span><br><span class="line">   <span class="string">status</span>       <span class="string">&lt;Object&gt;</span></span><br><span class="line"></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># kubectl explain pod.metadata</span></span><br><span class="line"><span class="attr">KIND:</span>     <span class="string">Pod</span></span><br><span class="line"><span class="attr">VERSION:</span>  <span class="string">v1</span></span><br><span class="line"><span class="attr">RESOURCE:</span> <span class="string">metadata</span> <span class="string">&lt;Object&gt;</span></span><br><span class="line"><span class="attr">FIELDS:</span></span><br><span class="line">   <span class="string">annotations</span>  <span class="string">&lt;map[string]string&gt;</span></span><br><span class="line">   <span class="string">clusterName</span>  <span class="string">&lt;string&gt;</span></span><br><span class="line">   <span class="string">creationTimestamp</span>    <span class="string">&lt;string&gt;</span></span><br><span class="line">   <span class="string">deletionGracePeriodSeconds</span>   <span class="string">&lt;integer&gt;</span></span><br><span class="line">   <span class="string">deletionTimestamp</span>    <span class="string">&lt;string&gt;</span></span><br><span class="line">   <span class="string">finalizers</span>   <span class="string">&lt;[]string&gt;</span></span><br><span class="line">   <span class="string">generateName</span> <span class="string">&lt;string&gt;</span></span><br><span class="line">   <span class="string">generation</span>   <span class="string">&lt;integer&gt;</span></span><br><span class="line">   <span class="string">labels</span>       <span class="string">&lt;map[string]string&gt;</span></span><br><span class="line">   <span class="string">managedFields</span>        <span class="string">&lt;[]Object&gt;</span></span><br><span class="line">   <span class="string">name</span> <span class="string">&lt;string&gt;</span></span><br><span class="line">   <span class="string">namespace</span>    <span class="string">&lt;string&gt;</span></span><br><span class="line">   <span class="string">ownerReferences</span>      <span class="string">&lt;[]Object&gt;</span></span><br><span class="line">   <span class="string">resourceVersion</span>      <span class="string">&lt;string&gt;</span></span><br><span class="line">   <span class="string">selfLink</span>     <span class="string">&lt;string&gt;</span></span><br><span class="line">   <span class="string">uid</span>  <span class="string">&lt;string&gt;</span></span><br></pre></td></tr></table></figure></div>

<p>在kubernetes中基本所有资源的一级属性都是一样的，主要包含5部分：</p>
<ul>
<li>apiVersion <string> 版本，由kubernetes内部定义，版本号必须可以用 kubectl api-versions 查询到</string></li>
<li>kind <string> 类型，由kubernetes内部定义，版本号必须可以用 kubectl api-resources 查询到</string></li>
<li>metadata <Object> 元数据，主要是资源标识和说明，常用的有name、namespace、labels等</Object></li>
<li>spec <Object> 描述，这是配置中最重要的一部分，里面是对各种资源配置的详细描述</Object></li>
<li>status <Object> 状态信息，里面的内容不需要定义，由kubernetes自动生成</Object></li>
</ul>
<p>在上面的属性中，spec是接下来研究的重点，继续看下它的常见子属性:</p>
<ul>
<li>containers &lt;[]Object&gt; 容器列表，用于定义容器的详细信息</li>
<li>nodeName <String> 根据nodeName的值将pod调度到指定的Node节点上</String></li>
<li>nodeSelector &lt;map[]&gt; 根据NodeSelector中定义的信息选择将该Pod调度到包含这些label的Node 上</li>
<li>hostNetwork <boolean> 是否使用主机网络模式，默认为false，如果设置为true，表示使用宿主机网络</boolean></li>
<li>volumes &lt;[]Object&gt; 存储卷，用于定义Pod上面挂在的存储信息</li>
<li>restartPolicy <string> 重启策略，表示Pod在遇到故障的时候的处理策略</string></li>
</ul>
<h4 id="5-2-Pod配置"><a href="#5-2-Pod配置" class="headerlink" title="5.2 Pod配置"></a>5.2 Pod配置</h4><p>本小节主要来研究<code>pod.spec.containers</code>属性，这也是pod配置中最为关键的一项配置。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># kubectl explain pod.spec.containers</span></span><br><span class="line"><span class="attr">KIND:</span>     <span class="string">Pod</span></span><br><span class="line"><span class="attr">VERSION:</span>  <span class="string">v1</span></span><br><span class="line"><span class="attr">RESOURCE:</span> <span class="string">containers</span> <span class="string">&lt;[]Object&gt;</span>   <span class="comment"># 数组，代表可以有多个容器</span></span><br><span class="line"><span class="attr">FIELDS:</span></span><br><span class="line">   <span class="string">name</span>  <span class="string">&lt;string&gt;</span>     <span class="comment"># 容器名称</span></span><br><span class="line">   <span class="string">image</span> <span class="string">&lt;string&gt;</span>     <span class="comment"># 容器需要的镜像地址</span></span><br><span class="line">   <span class="string">imagePullPolicy</span>  <span class="string">&lt;string&gt;</span> <span class="comment"># 镜像拉取策略 </span></span><br><span class="line">   <span class="string">command</span>  <span class="string">&lt;[]string&gt;</span> <span class="comment"># 容器的启动命令列表，如不指定，使用打包时使用的启动命令</span></span><br><span class="line">   <span class="string">args</span>     <span class="string">&lt;[]string&gt;</span> <span class="comment"># 容器的启动命令需要的参数列表</span></span><br><span class="line">   <span class="string">env</span>      <span class="string">&lt;[]Object&gt;</span> <span class="comment"># 容器环境变量的配置</span></span><br><span class="line">   <span class="string">ports</span>    <span class="string">&lt;[]Object&gt;</span>     <span class="comment"># 容器需要暴露的端口号列表</span></span><br><span class="line">   <span class="string">resources</span> <span class="string">&lt;Object&gt;</span>      <span class="comment"># 资源限制和资源请求的设置</span></span><br></pre></td></tr></table></figure></div>

<h5 id="5-2-1-基本配置"><a href="#5-2-1-基本配置" class="headerlink" title="5.2.1 基本配置"></a>5.2.1 基本配置</h5><p>创建pod-base.yaml文件，内容如下：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-base</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">user:</span> <span class="string">heima</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">busybox</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">busybox:1.30</span></span><br></pre></td></tr></table></figure></div>

<p><img src="/2022/06/09/uncatalog/cl46zbayg000v7or7a4o0f4yd/image-20210617223823675-1626781695411.png" alt="image-20210617223823675"></p>
<p>上面定义了一个比较简单Pod的配置，里面有两个容器：</p>
<ul>
<li>nginx：用1.17.1版本的nginx镜像创建，（nginx是一个轻量级web容器）</li>
<li>busybox：用1.30版本的busybox镜像创建，（busybox是一个小巧的linux命令集合）</li>
</ul>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建Pod</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">pod</span>]<span class="comment"># kubectl apply -f pod-base.yaml</span></span><br><span class="line"><span class="string">pod/pod-base</span> <span class="string">created</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看Pod状况</span></span><br><span class="line"><span class="comment"># READY 1/2 : 表示当前Pod中有2个容器，其中1个准备就绪，1个未就绪</span></span><br><span class="line"><span class="comment"># RESTARTS  : 重启次数，因为有1个容器故障了，Pod一直在重启试图恢复它</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">pod</span>]<span class="comment"># kubectl get pod -n dev</span></span><br><span class="line"><span class="string">NAME</span>       <span class="string">READY</span>   <span class="string">STATUS</span>    <span class="string">RESTARTS</span>   <span class="string">AGE</span></span><br><span class="line"><span class="string">pod-base</span>   <span class="number">1</span><span class="string">/2</span>     <span class="string">Running</span>   <span class="number">4</span>          <span class="string">95s</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 可以通过describe查看内部的详情</span></span><br><span class="line"><span class="comment"># 此时已经运行起来了一个基本的Pod，虽然它暂时有问题</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">pod</span>]<span class="comment"># kubectl describe pod pod-base -n dev</span></span><br></pre></td></tr></table></figure></div>

<h5 id="5-2-2-镜像拉取"><a href="#5-2-2-镜像拉取" class="headerlink" title="5.2.2 镜像拉取"></a>5.2.2 镜像拉取</h5><p>创建pod-imagepullpolicy.yaml文件，内容如下：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-imagepullpolicy</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br><span class="line">    <span class="attr">imagePullPolicy:</span> <span class="string">Never</span> <span class="comment"># 用于设置镜像拉取策略</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">busybox</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">busybox:1.30</span></span><br></pre></td></tr></table></figure></div>

<p><img src="/2022/06/09/uncatalog/cl46zbayg000v7or7a4o0f4yd/image-20210617223923659.png" alt="image-20210617223923659"></p>
<p>imagePullPolicy，用于设置镜像拉取策略，kubernetes支持配置三种拉取策略：</p>
<ul>
<li>Always：总是从远程仓库拉取镜像（一直远程下载）</li>
<li>IfNotPresent：本地有则使用本地镜像，本地没有则从远程仓库拉取镜像（本地有就本地 本地没远程下载）</li>
<li>Never：只使用本地镜像，从不去远程仓库拉取，本地没有就报错 （一直使用本地）</li>
</ul>
<blockquote>
<p>默认值说明：</p>
<p>如果镜像tag为具体版本号， 默认策略是：IfNotPresent</p>
<p>如果镜像tag为：latest（最终版本） ，默认策略是always</p>
</blockquote>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建Pod</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">pod</span>]<span class="comment"># kubectl create -f pod-imagepullpolicy.yaml</span></span><br><span class="line"><span class="string">pod/pod-imagepullpolicy</span> <span class="string">created</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看Pod详情</span></span><br><span class="line"><span class="comment"># 此时明显可以看到nginx镜像有一步Pulling image &quot;nginx:1.17.1&quot;的过程</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">pod</span>]<span class="comment"># kubectl describe pod pod-imagepullpolicy -n dev</span></span><br><span class="line"><span class="string">......</span></span><br><span class="line"><span class="attr">Events:</span></span><br><span class="line">  <span class="string">Type</span>     <span class="string">Reason</span>     <span class="string">Age</span>               <span class="string">From</span>               <span class="string">Message</span></span><br><span class="line">  <span class="string">----</span>     <span class="string">------</span>     <span class="string">----</span>              <span class="string">----</span>               <span class="string">-------</span></span><br><span class="line">  <span class="string">Normal</span>   <span class="string">Scheduled</span>  <span class="string">&lt;unknown&gt;</span>         <span class="string">default-scheduler</span>  <span class="string">Successfully</span> <span class="string">assigned</span> <span class="string">dev/pod-imagePullPolicy</span> <span class="string">to</span> <span class="string">node1</span></span><br><span class="line">  <span class="string">Normal</span>   <span class="string">Pulling</span>    <span class="string">32s</span>               <span class="string">kubelet,</span> <span class="string">node1</span>     <span class="string">Pulling</span> <span class="string">image</span> <span class="string">&quot;nginx:1.17.1&quot;</span></span><br><span class="line">  <span class="string">Normal</span>   <span class="string">Pulled</span>     <span class="string">26s</span>               <span class="string">kubelet,</span> <span class="string">node1</span>     <span class="string">Successfully</span> <span class="string">pulled</span> <span class="string">image</span> <span class="string">&quot;nginx:1.17.1&quot;</span></span><br><span class="line">  <span class="string">Normal</span>   <span class="string">Created</span>    <span class="string">26s</span>               <span class="string">kubelet,</span> <span class="string">node1</span>     <span class="string">Created</span> <span class="string">container</span> <span class="string">nginx</span></span><br><span class="line">  <span class="string">Normal</span>   <span class="string">Started</span>    <span class="string">25s</span>               <span class="string">kubelet,</span> <span class="string">node1</span>     <span class="string">Started</span> <span class="string">container</span> <span class="string">nginx</span></span><br><span class="line">  <span class="string">Normal</span>   <span class="string">Pulled</span>     <span class="string">7s</span> <span class="string">(x3</span> <span class="string">over</span> <span class="string">25s)</span>  <span class="string">kubelet,</span> <span class="string">node1</span>     <span class="string">Container</span> <span class="string">image</span> <span class="string">&quot;busybox:1.30&quot;</span> <span class="string">already</span> <span class="string">present</span> <span class="string">on</span> <span class="string">machine</span></span><br><span class="line">  <span class="string">Normal</span>   <span class="string">Created</span>    <span class="string">7s</span> <span class="string">(x3</span> <span class="string">over</span> <span class="string">25s)</span>  <span class="string">kubelet,</span> <span class="string">node1</span>     <span class="string">Created</span> <span class="string">container</span> <span class="string">busybox</span></span><br><span class="line">  <span class="string">Normal</span>   <span class="string">Started</span>    <span class="string">7s</span> <span class="string">(x3</span> <span class="string">over</span> <span class="string">25s)</span>  <span class="string">kubelet,</span> <span class="string">node1</span>     <span class="string">Started</span> <span class="string">container</span> <span class="string">busybox</span></span><br></pre></td></tr></table></figure></div>

<h5 id="5-2-3-启动命令"><a href="#5-2-3-启动命令" class="headerlink" title="5.2.3 启动命令"></a>5.2.3 启动命令</h5><p>在前面的案例中，一直有一个问题没有解决，就是的busybox容器一直没有成功运行，那么到底是什么原因导致这个容器的故障呢？</p>
<p>原来busybox并不是一个程序，而是类似于一个工具类的集合，kubernetes集群启动管理后，它会自动关闭。解决方法就是让其一直在运行，这就用到了command配置。</p>
<p>创建pod-command.yaml文件，内容如下：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-command</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">busybox</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">busybox:1.30</span></span><br><span class="line">    <span class="attr">command:</span> [<span class="string">&quot;/bin/sh&quot;</span>,<span class="string">&quot;-c&quot;</span>,<span class="string">&quot;touch /tmp/hello.txt;while true;do /bin/echo $(date +%T) &gt;&gt; /tmp/hello.txt; sleep 3; done;&quot;</span>]</span><br></pre></td></tr></table></figure></div>

<p><img src="/2022/06/09/uncatalog/cl46zbayg000v7or7a4o0f4yd/image-20210617224457945.png" alt="image-20210617224457945"></p>
<p>command，用于在pod中的容器初始化完毕之后运行一个命令。</p>
<blockquote>
<p>稍微解释下上面命令的意思：</p>
<p>“/bin/sh”,”-c”, 使用sh执行命令</p>
<p>touch /tmp/hello.txt; 创建一个/tmp/hello.txt 文件</p>
<p>while true;do /bin/echo $(date +%T) &gt;&gt; /tmp/hello.txt; sleep 3; done; 每隔3秒向文件中写入当前时间</p>
</blockquote>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建Pod</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">pod</span>]<span class="comment"># kubectl create  -f pod-command.yaml</span></span><br><span class="line"><span class="string">pod/pod-command</span> <span class="string">created</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看Pod状态</span></span><br><span class="line"><span class="comment"># 此时发现两个pod都正常运行了</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">pod</span>]<span class="comment"># kubectl get pods pod-command -n dev</span></span><br><span class="line"><span class="string">NAME</span>          <span class="string">READY</span>   <span class="string">STATUS</span>   <span class="string">RESTARTS</span>   <span class="string">AGE</span></span><br><span class="line"><span class="string">pod-command</span>   <span class="number">2</span><span class="string">/2</span>     <span class="string">Runing</span>   <span class="number">0</span>          <span class="string">2s</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 进入pod中的busybox容器，查看文件内容</span></span><br><span class="line"><span class="comment"># 补充一个命令: kubectl exec  pod名称 -n 命名空间 -it -c 容器名称 /bin/sh  在容器内部执行命令</span></span><br><span class="line"><span class="comment"># 使用这个命令就可以进入某个容器的内部，然后进行相关操作了</span></span><br><span class="line"><span class="comment"># 比如，可以查看txt文件的内容</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">pod</span>]<span class="comment"># kubectl exec pod-command -n dev -it -c busybox /bin/sh</span></span><br><span class="line"><span class="string">/</span> <span class="comment"># tail -f /tmp/hello.txt</span></span><br><span class="line"><span class="number">14</span><span class="string">:44:19</span></span><br><span class="line"><span class="number">14</span><span class="string">:44:22</span></span><br><span class="line"><span class="number">14</span><span class="string">:44:25</span></span><br></pre></td></tr></table></figure></div>

<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">特别说明：</span></span><br><span class="line">    <span class="string">通过上面发现command已经可以完成启动命令和传递参数的功能，为什么这里还要提供一个args选项，用于传递参数呢?这其实跟docker有点关系，kubernetes中的command、args两项其实是实现覆盖Dockerfile中ENTRYPOINT的功能。</span></span><br><span class="line"> <span class="number">1</span> <span class="string">如果command和args均没有写，那么用Dockerfile的配置。</span></span><br><span class="line"> <span class="number">2</span> <span class="string">如果command写了，但args没有写，那么Dockerfile默认的配置会被忽略，执行输入的command</span></span><br><span class="line"> <span class="number">3</span> <span class="string">如果command没写，但args写了，那么Dockerfile中配置的ENTRYPOINT的命令会被执行，使用当前args的参数</span></span><br><span class="line"> <span class="number">4</span> <span class="string">如果command和args都写了，那么Dockerfile的配置被忽略，执行command并追加上args参数</span></span><br></pre></td></tr></table></figure></div>

<h5 id="5-2-4-环境变量"><a href="#5-2-4-环境变量" class="headerlink" title="5.2.4 环境变量"></a>5.2.4 环境变量</h5><p>创建pod-env.yaml文件，内容如下：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-env</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">busybox</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">busybox:1.30</span></span><br><span class="line">    <span class="attr">command:</span> [<span class="string">&quot;/bin/sh&quot;</span>,<span class="string">&quot;-c&quot;</span>,<span class="string">&quot;while true;do /bin/echo $(date +%T);sleep 60; done;&quot;</span>]</span><br><span class="line">    <span class="attr">env:</span> <span class="comment"># 设置环境变量列表</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">&quot;username&quot;</span></span><br><span class="line">      <span class="attr">value:</span> <span class="string">&quot;admin&quot;</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">&quot;password&quot;</span></span><br><span class="line">      <span class="attr">value:</span> <span class="string">&quot;123456&quot;</span></span><br></pre></td></tr></table></figure></div>

<p>env，环境变量，用于在pod中的容器设置环境变量。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建Pod</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl create -f pod-env.yaml</span><br><span class="line">pod/pod-env created</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 进入容器，输出环境变量</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl exec pod-env -n dev -c busybox -it /bin/sh</span><br><span class="line">/ # echo $username</span><br><span class="line">admin</span><br><span class="line">/ # echo $password</span><br><span class="line">123456</span><br></pre></td></tr></table></figure></div>

<p>这种方式不是很推荐，推荐将这些配置单独存储在配置文件中，这种方式将在后面介绍。</p>
<h5 id="5-2-5-端口设置"><a href="#5-2-5-端口设置" class="headerlink" title="5.2.5 端口设置"></a>5.2.5 端口设置</h5><p>本小节来介绍容器的端口设置，也就是containers的ports选项。</p>
<p>首先看下ports支持的子选项：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># kubectl explain pod.spec.containers.ports</span></span><br><span class="line"><span class="attr">KIND:</span>     <span class="string">Pod</span></span><br><span class="line"><span class="attr">VERSION:</span>  <span class="string">v1</span></span><br><span class="line"><span class="attr">RESOURCE:</span> <span class="string">ports</span> <span class="string">&lt;[]Object&gt;</span></span><br><span class="line"><span class="attr">FIELDS:</span></span><br><span class="line">   <span class="string">name</span>         <span class="string">&lt;string&gt;</span>  <span class="comment"># 端口名称，如果指定，必须保证name在pod中是唯一的		</span></span><br><span class="line">   <span class="string">containerPort&lt;integer&gt;</span> <span class="comment"># 容器要监听的端口(0&lt;x&lt;65536)</span></span><br><span class="line">   <span class="string">hostPort</span>     <span class="string">&lt;integer&gt;</span> <span class="comment"># 容器要在主机上公开的端口，如果设置，主机上只能运行容器的一个副本(一般省略) </span></span><br><span class="line">   <span class="string">hostIP</span>       <span class="string">&lt;string&gt;</span>  <span class="comment"># 要将外部端口绑定到的主机IP(一般省略)</span></span><br><span class="line">   <span class="string">protocol</span>     <span class="string">&lt;string&gt;</span>  <span class="comment"># 端口协议。必须是UDP、TCP或SCTP。默认为“TCP”。</span></span><br></pre></td></tr></table></figure></div>

<p>接下来，编写一个测试案例，创建pod-ports.yaml</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-ports</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br><span class="line">    <span class="attr">ports:</span> <span class="comment"># 设置容器暴露的端口列表</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx-port</span></span><br><span class="line">      <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">      <span class="attr">protocol:</span> <span class="string">TCP</span></span><br></pre></td></tr></table></figure></div>

<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建Pod</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl create -f pod-ports.yaml</span><br><span class="line">pod/pod-ports created</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看pod</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 在下面可以明显看到配置信息</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl get pod pod-ports -n dev -o yaml</span><br><span class="line">......</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - image: nginx:1.17.1</span><br><span class="line">    imagePullPolicy: IfNotPresent</span><br><span class="line">    name: nginx</span><br><span class="line">    ports:</span><br><span class="line">    - containerPort: 80</span><br><span class="line">      name: nginx-port</span><br><span class="line">      protocol: TCP</span><br><span class="line">......</span><br></pre></td></tr></table></figure></div>

<p>访问容器中的程序需要使用的是<code>Podip:containerPort</code></p>
<h5 id="5-2-6-资源配额"><a href="#5-2-6-资源配额" class="headerlink" title="5.2.6 资源配额"></a>5.2.6 资源配额</h5><p>容器中的程序要运行，肯定是要占用一定资源的，比如cpu和内存等，如果不对某个容器的资源做限制，那么它就可能吃掉大量资源，导致其它容器无法运行。针对这种情况，kubernetes提供了对内存和cpu的资源进行配额的机制，这种机制主要通过resources选项实现，他有两个子选项：</p>
<ul>
<li>limits：用于限制运行时容器的最大占用资源，当容器占用资源超过limits时会被终止，并进行重启</li>
<li>requests ：用于设置容器需要的最小资源，如果环境资源不够，容器将无法启动</li>
</ul>
<p>可以通过上面两个选项设置资源的上下限。</p>
<p>接下来，编写一个测试案例，创建pod-resources.yaml</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-resources</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br><span class="line">    <span class="attr">resources:</span> <span class="comment"># 资源配额</span></span><br><span class="line">      <span class="attr">limits:</span>  <span class="comment"># 限制资源（上限）</span></span><br><span class="line">        <span class="attr">cpu:</span> <span class="string">&quot;2&quot;</span> <span class="comment"># CPU限制，单位是core数</span></span><br><span class="line">        <span class="attr">memory:</span> <span class="string">&quot;10Gi&quot;</span> <span class="comment"># 内存限制</span></span><br><span class="line">      <span class="attr">requests:</span> <span class="comment"># 请求资源（下限）</span></span><br><span class="line">        <span class="attr">cpu:</span> <span class="string">&quot;1&quot;</span>  <span class="comment"># CPU限制，单位是core数</span></span><br><span class="line">        <span class="attr">memory:</span> <span class="string">&quot;10Mi&quot;</span>  <span class="comment"># 内存限制</span></span><br></pre></td></tr></table></figure></div>

<p>在这对cpu和memory的单位做一个说明：</p>
<ul>
<li>cpu：core数，可以为整数或小数</li>
<li>memory： 内存大小，可以使用Gi、Mi、G、M等形式</li>
</ul>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 运行Pod</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># kubectl create  -f pod-resources.yaml</span></span><br><span class="line"><span class="string">pod/pod-resources</span> <span class="string">created</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看发现pod运行正常</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># kubectl get pod pod-resources -n dev</span></span><br><span class="line"><span class="string">NAME</span>            <span class="string">READY</span>   <span class="string">STATUS</span>    <span class="string">RESTARTS</span>   <span class="string">AGE</span>  </span><br><span class="line"><span class="string">pod-resources</span>   <span class="number">1</span><span class="string">/1</span>     <span class="string">Running</span>   <span class="number">0</span>          <span class="string">39s</span>   </span><br><span class="line"></span><br><span class="line"><span class="comment"># 接下来，停止Pod</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># kubectl delete  -f pod-resources.yaml</span></span><br><span class="line"><span class="string">pod</span> <span class="string">&quot;pod-resources&quot;</span> <span class="string">deleted</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 编辑pod，修改resources.requests.memory的值为10Gi</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># vim pod-resources.yaml</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 再次启动pod</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># kubectl create  -f pod-resources.yaml</span></span><br><span class="line"><span class="string">pod/pod-resources</span> <span class="string">created</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看Pod状态，发现Pod启动失败</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># kubectl get pod pod-resources -n dev -o wide</span></span><br><span class="line"><span class="string">NAME</span>            <span class="string">READY</span>   <span class="string">STATUS</span>    <span class="string">RESTARTS</span>   <span class="string">AGE</span>          </span><br><span class="line"><span class="string">pod-resources</span>   <span class="number">0</span><span class="string">/1</span>     <span class="string">Pending</span>   <span class="number">0</span>          <span class="string">20s</span>    </span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看pod详情会发现，如下提示</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># kubectl describe pod pod-resources -n dev</span></span><br><span class="line"><span class="string">......</span></span><br><span class="line"><span class="attr">Warning  FailedScheduling  35s   default-scheduler  0/3 nodes are available:</span> <span class="number">1</span> <span class="string">node(s)</span> <span class="string">had</span> <span class="string">taint</span> &#123;<span class="attr">node-role.kubernetes.io/master:</span> &#125;<span class="string">,</span> <span class="string">that</span> <span class="string">the</span> <span class="string">pod</span> <span class="string">didn&#x27;t</span> <span class="string">tolerate,</span> <span class="number">2</span> <span class="string">Insufficient</span> <span class="string">memory.(内存不足)</span></span><br></pre></td></tr></table></figure></div>

<h4 id="5-3-Pod生命周期"><a href="#5-3-Pod生命周期" class="headerlink" title="5.3 Pod生命周期"></a>5.3 Pod生命周期</h4><p>我们一般将pod对象从创建至终的这段时间范围称为pod的生命周期，它主要包含下面的过程：</p>
<ul>
<li>pod创建过程</li>
<li>运行初始化容器（init container）过程</li>
<li>运行主容器（main container）<ul>
<li>容器启动后钩子（post start）、容器终止前钩子（pre stop）</li>
<li>容器的存活性探测（liveness probe）、就绪性探测（readiness probe）</li>
</ul>
</li>
<li>pod终止过程</li>
</ul>
<p><img src="/2022/06/09/uncatalog/cl46zbayg000v7or7a4o0f4yd/image-20200412111402706-1626782188724.png" alt="image-20200412111402706"></p>
<p>在整个生命周期中，Pod会出现5种<strong>状态</strong>（<strong>相位</strong>），分别如下：</p>
<ul>
<li>挂起（Pending）：apiserver已经创建了pod资源对象，但它尚未被调度完成或者仍处于下载镜像的过程中</li>
<li>运行中（Running）：pod已经被调度至某节点，并且所有容器都已经被kubelet创建完成</li>
<li>成功（Succeeded）：pod中的所有容器都已经成功终止并且不会被重启</li>
<li>失败（Failed）：所有容器都已经终止，但至少有一个容器终止失败，即容器返回了非0值的退出状态</li>
<li>未知（Unknown）：apiserver无法正常获取到pod对象的状态信息，通常由网络通信失败所导致</li>
</ul>
<h5 id="5-3-1-创建和终止"><a href="#5-3-1-创建和终止" class="headerlink" title="5.3.1 创建和终止"></a>5.3.1 创建和终止</h5><p><strong>pod的创建过程</strong></p>
<ol>
<li><p>用户通过kubectl或其他api客户端提交需要创建的pod信息给apiServer</p>
</li>
<li><p>apiServer开始生成pod对象的信息，并将信息存入etcd，然后返回确认信息至客户端</p>
</li>
<li><p>apiServer开始反映etcd中的pod对象的变化，其它组件使用watch机制来跟踪检查apiServer上的变动</p>
</li>
<li><p>scheduler发现有新的pod对象要创建，开始为Pod分配主机并将结果信息更新至apiServer</p>
</li>
<li><p>node节点上的kubelet发现有pod调度过来，尝试调用docker启动容器，并将结果回送至apiServer</p>
</li>
<li><p>apiServer将接收到的pod状态信息存入etcd中</p>
<p><img src="/2022/06/09/uncatalog/cl46zbayg000v7or7a4o0f4yd/image-20200406184656917-1626782168787.png" alt="image-20200406184656917"></p>
</li>
</ol>
<p><strong>pod的终止过程</strong></p>
<ol>
<li>用户向apiServer发送删除pod对象的命令</li>
<li>apiServcer中的pod对象信息会随着时间的推移而更新，在宽限期内（默认30s），pod被视为dead</li>
<li>将pod标记为terminating状态</li>
<li>kubelet在监控到pod对象转为terminating状态的同时启动pod关闭过程</li>
<li>端点控制器监控到pod对象的关闭行为时将其从所有匹配到此端点的service资源的端点列表中移除</li>
<li>如果当前pod对象定义了preStop钩子处理器，则在其标记为terminating后即会以同步的方式启动执行</li>
<li>pod对象中的容器进程收到停止信号</li>
<li>宽限期结束后，若pod中还存在仍在运行的进程，那么pod对象会收到立即终止的信号</li>
<li>kubelet请求apiServer将此pod资源的宽限期设置为0从而完成删除操作，此时pod对于用户已不可见</li>
</ol>
<h5 id="5-3-2-初始化容器"><a href="#5-3-2-初始化容器" class="headerlink" title="5.3.2 初始化容器"></a>5.3.2 初始化容器</h5><p>初始化容器是在pod的主容器启动之前要运行的容器，主要是做一些主容器的前置工作，它具有两大特征：</p>
<ol>
<li>初始化容器必须运行完成直至结束，若某初始化容器运行失败，那么kubernetes需要重启它直到成功完成</li>
<li>初始化容器必须按照定义的顺序执行，当且仅当前一个成功之后，后面的一个才能运行</li>
</ol>
<p>初始化容器有很多的应用场景，下面列出的是最常见的几个：</p>
<ul>
<li>提供主容器镜像中不具备的工具程序或自定义代码</li>
<li>初始化容器要先于应用容器串行启动并运行完成，因此可用于延后应用容器的启动直至其依赖的条件得到满足</li>
</ul>
<p>接下来做一个案例，模拟下面这个需求：</p>
<p>假设要以主容器来运行nginx，但是要求在运行nginx之前先要能够连接上mysql和redis所在服务器</p>
<p>为了简化测试，事先规定好mysql<code>(192.168.90.14)</code>和redis<code>(192.168.90.15)</code>服务器的地址</p>
<p>创建pod-initcontainer.yaml，内容如下：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-initcontainer</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">main-container</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br><span class="line">    <span class="attr">ports:</span> </span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx-port</span></span><br><span class="line">      <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">  <span class="attr">initContainers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">test-mysql</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">busybox:1.30</span></span><br><span class="line">    <span class="attr">command:</span> [<span class="string">&#x27;sh&#x27;</span>, <span class="string">&#x27;-c&#x27;</span>, <span class="string">&#x27;until ping 192.168.90.14 -c 1 ; do echo waiting for mysql...; sleep 2; done;&#x27;</span>]</span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">test-redis</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">busybox:1.30</span></span><br><span class="line">    <span class="attr">command:</span> [<span class="string">&#x27;sh&#x27;</span>, <span class="string">&#x27;-c&#x27;</span>, <span class="string">&#x27;until ping 192.168.90.15 -c 1 ; do echo waiting for reids...; sleep 2; done;&#x27;</span>]</span><br></pre></td></tr></table></figure></div>

<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建pod</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># kubectl create -f pod-initcontainer.yaml</span></span><br><span class="line"><span class="string">pod/pod-initcontainer</span> <span class="string">created</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看pod状态</span></span><br><span class="line"><span class="comment"># 发现pod卡在启动第一个初始化容器过程中，后面的容器不会运行</span></span><br><span class="line"><span class="string">root@k8s-master01</span> <span class="string">~]#</span> <span class="string">kubectl</span> <span class="string">describe</span> <span class="string">pod</span>  <span class="string">pod-initcontainer</span> <span class="string">-n</span> <span class="string">dev</span></span><br><span class="line"><span class="string">........</span></span><br><span class="line"><span class="attr">Events:</span></span><br><span class="line">  <span class="string">Type</span>    <span class="string">Reason</span>     <span class="string">Age</span>   <span class="string">From</span>               <span class="string">Message</span></span><br><span class="line">  <span class="string">----</span>    <span class="string">------</span>     <span class="string">----</span>  <span class="string">----</span>               <span class="string">-------</span></span><br><span class="line">  <span class="string">Normal</span>  <span class="string">Scheduled</span>  <span class="string">49s</span>   <span class="string">default-scheduler</span>  <span class="string">Successfully</span> <span class="string">assigned</span> <span class="string">dev/pod-initcontainer</span> <span class="string">to</span> <span class="string">node1</span></span><br><span class="line">  <span class="string">Normal</span>  <span class="string">Pulled</span>     <span class="string">48s</span>   <span class="string">kubelet,</span> <span class="string">node1</span>     <span class="string">Container</span> <span class="string">image</span> <span class="string">&quot;busybox:1.30&quot;</span> <span class="string">already</span> <span class="string">present</span> <span class="string">on</span> <span class="string">machine</span></span><br><span class="line">  <span class="string">Normal</span>  <span class="string">Created</span>    <span class="string">48s</span>   <span class="string">kubelet,</span> <span class="string">node1</span>     <span class="string">Created</span> <span class="string">container</span> <span class="string">test-mysql</span></span><br><span class="line">  <span class="string">Normal</span>  <span class="string">Started</span>    <span class="string">48s</span>   <span class="string">kubelet,</span> <span class="string">node1</span>     <span class="string">Started</span> <span class="string">container</span> <span class="string">test-mysql</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 动态查看pod</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># kubectl get pods pod-initcontainer -n dev -w</span></span><br><span class="line"><span class="string">NAME</span>                             <span class="string">READY</span>   <span class="string">STATUS</span>     <span class="string">RESTARTS</span>   <span class="string">AGE</span></span><br><span class="line"><span class="string">pod-initcontainer</span>                <span class="number">0</span><span class="string">/1</span>     <span class="string">Init:0/2</span>   <span class="number">0</span>          <span class="string">15s</span></span><br><span class="line"><span class="string">pod-initcontainer</span>                <span class="number">0</span><span class="string">/1</span>     <span class="string">Init:1/2</span>   <span class="number">0</span>          <span class="string">52s</span></span><br><span class="line"><span class="string">pod-initcontainer</span>                <span class="number">0</span><span class="string">/1</span>     <span class="string">Init:1/2</span>   <span class="number">0</span>          <span class="string">53s</span></span><br><span class="line"><span class="string">pod-initcontainer</span>                <span class="number">0</span><span class="string">/1</span>     <span class="string">PodInitializing</span>   <span class="number">0</span>          <span class="string">89s</span></span><br><span class="line"><span class="string">pod-initcontainer</span>                <span class="number">1</span><span class="string">/1</span>     <span class="string">Running</span>           <span class="number">0</span>          <span class="string">90s</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 接下来新开一个shell，为当前服务器新增两个ip，观察pod的变化</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># ifconfig ens33:1 192.168.90.14 netmask 255.255.255.0 up</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># ifconfig ens33:2 192.168.90.15 netmask 255.255.255.0 up</span></span><br></pre></td></tr></table></figure></div>

<h5 id="5-3-3-钩子函数"><a href="#5-3-3-钩子函数" class="headerlink" title="5.3.3 钩子函数"></a>5.3.3 钩子函数</h5><p>钩子函数能够感知自身生命周期中的事件，并在相应的时刻到来时运行用户指定的程序代码。</p>
<p>kubernetes在主容器的启动之后和停止之前提供了两个钩子函数：</p>
<ul>
<li>post start：容器创建之后执行，如果失败了会重启容器</li>
<li>pre stop ：容器终止之前执行，执行完成之后容器将成功终止，在其完成之前会阻塞删除容器的操作</li>
</ul>
<p>钩子处理器支持使用下面三种方式定义动作：</p>
<ul>
<li><p>Exec命令：在容器内执行一次命令</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">……</span></span><br><span class="line">  <span class="attr">lifecycle:</span></span><br><span class="line">    <span class="attr">postStart:</span> </span><br><span class="line">      <span class="attr">exec:</span></span><br><span class="line">        <span class="attr">command:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">cat</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">/tmp/healthy</span></span><br><span class="line"><span class="string">……</span></span><br></pre></td></tr></table></figure></div></li>
<li><p>TCPSocket：在当前容器尝试访问指定的socket</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">……</span>      </span><br><span class="line">  <span class="attr">lifecycle:</span></span><br><span class="line">    <span class="attr">postStart:</span></span><br><span class="line">      <span class="attr">tcpSocket:</span></span><br><span class="line">        <span class="attr">port:</span> <span class="number">8080</span></span><br><span class="line"><span class="string">……</span></span><br></pre></td></tr></table></figure></div></li>
<li><p>HTTPGet：在当前容器中向某url发起http请求</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">……</span></span><br><span class="line">  <span class="attr">lifecycle:</span></span><br><span class="line">    <span class="attr">postStart:</span></span><br><span class="line">      <span class="attr">httpGet:</span></span><br><span class="line">        <span class="attr">path:</span> <span class="string">/</span> <span class="comment">#URI地址</span></span><br><span class="line">        <span class="attr">port:</span> <span class="number">80</span> <span class="comment">#端口号</span></span><br><span class="line">        <span class="attr">host:</span> <span class="number">192.168</span><span class="number">.5</span><span class="number">.3</span> <span class="comment">#主机地址</span></span><br><span class="line">        <span class="attr">scheme:</span> <span class="string">HTTP</span> <span class="comment">#支持的协议，http或者https</span></span><br><span class="line"><span class="string">……</span></span><br></pre></td></tr></table></figure></div></li>
</ul>
<p>接下来，以exec方式为例，演示下钩子函数的使用，创建pod-hook-exec.yaml文件，内容如下：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-hook-exec</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">main-container</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx-port</span></span><br><span class="line">      <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">lifecycle:</span></span><br><span class="line">      <span class="attr">postStart:</span> </span><br><span class="line">        <span class="attr">exec:</span> <span class="comment"># 在容器启动的时候执行一个命令，修改掉nginx的默认首页内容</span></span><br><span class="line">          <span class="attr">command:</span> [<span class="string">&quot;/bin/sh&quot;</span>, <span class="string">&quot;-c&quot;</span>, <span class="string">&quot;echo postStart... &gt; /usr/share/nginx/html/index.html&quot;</span>]</span><br><span class="line">      <span class="attr">preStop:</span></span><br><span class="line">        <span class="attr">exec:</span> <span class="comment"># 在容器停止之前停止nginx服务</span></span><br><span class="line">          <span class="attr">command:</span> [<span class="string">&quot;/usr/sbin/nginx&quot;</span>,<span class="string">&quot;-s&quot;</span>,<span class="string">&quot;quit&quot;</span>]</span><br></pre></td></tr></table></figure></div>

<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建pod</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># kubectl create -f pod-hook-exec.yaml</span></span><br><span class="line"><span class="string">pod/pod-hook-exec</span> <span class="string">created</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看pod</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># kubectl get pods  pod-hook-exec -n dev -o wide</span></span><br><span class="line"><span class="string">NAME</span>           <span class="string">READY</span>   <span class="string">STATUS</span>     <span class="string">RESTARTS</span>   <span class="string">AGE</span>    <span class="string">IP</span>            <span class="string">NODE</span>    </span><br><span class="line"><span class="string">pod-hook-exec</span>  <span class="number">1</span><span class="string">/1</span>     <span class="string">Running</span>    <span class="number">0</span>          <span class="string">29s</span>    <span class="number">10.244</span><span class="number">.2</span><span class="number">.48</span>   <span class="string">node2</span>   </span><br><span class="line"></span><br><span class="line"><span class="comment"># 访问pod</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># curl 10.244.2.48</span></span><br><span class="line"><span class="string">postStart...</span></span><br></pre></td></tr></table></figure></div>

<h5 id="5-3-4-容器探测"><a href="#5-3-4-容器探测" class="headerlink" title="5.3.4 容器探测"></a>5.3.4 容器探测</h5><p>容器探测用于检测容器中的应用实例是否正常工作，是保障业务可用性的一种传统机制。如果经过探测，实例的状态不符合预期，那么kubernetes就会把该问题实例” 摘除 “，不承担业务流量。kubernetes提供了两种探针来实现容器探测，分别是：</p>
<ul>
<li>liveness probes：存活性探针，用于检测应用实例当前是否处于正常运行状态，如果不是，k8s会重启容器</li>
<li>readiness probes：就绪性探针，用于检测应用实例当前是否可以接收请求，如果不能，k8s不会转发流量</li>
</ul>
<blockquote>
<p>livenessProbe 决定是否重启容器，readinessProbe 决定是否将请求转发给容器。</p>
</blockquote>
<p>上面两种探针目前均支持三种探测方式：</p>
<ul>
<li><p>Exec命令：在容器内执行一次命令，如果命令执行的退出码为0，则认为程序正常，否则不正常</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">……</span></span><br><span class="line">  <span class="attr">livenessProbe:</span></span><br><span class="line">    <span class="attr">exec:</span></span><br><span class="line">      <span class="attr">command:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">cat</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">/tmp/healthy</span></span><br><span class="line"><span class="string">……</span></span><br></pre></td></tr></table></figure></div></li>
<li><p>TCPSocket：将会尝试访问一个用户容器的端口，如果能够建立这条连接，则认为程序正常，否则不正常</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">……</span>      </span><br><span class="line">  <span class="attr">livenessProbe:</span></span><br><span class="line">    <span class="attr">tcpSocket:</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">8080</span></span><br><span class="line"><span class="string">……</span></span><br></pre></td></tr></table></figure></div></li>
<li><p>HTTPGet：调用容器内Web应用的URL，如果返回的状态码在200和399之间，则认为程序正常，否则不正常</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">……</span></span><br><span class="line">  <span class="attr">livenessProbe:</span></span><br><span class="line">    <span class="attr">httpGet:</span></span><br><span class="line">      <span class="attr">path:</span> <span class="string">/</span> <span class="comment">#URI地址</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">80</span> <span class="comment">#端口号</span></span><br><span class="line">      <span class="attr">host:</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span> <span class="comment">#主机地址</span></span><br><span class="line">      <span class="attr">scheme:</span> <span class="string">HTTP</span> <span class="comment">#支持的协议，http或者https</span></span><br><span class="line"><span class="string">……</span></span><br></pre></td></tr></table></figure></div></li>
</ul>
<p>下面以liveness probes为例，做几个演示：</p>
<p><strong>方式一：Exec</strong></p>
<p>创建pod-liveness-exec.yaml</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-liveness-exec</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br><span class="line">    <span class="attr">ports:</span> </span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx-port</span></span><br><span class="line">      <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">livenessProbe:</span></span><br><span class="line">      <span class="attr">exec:</span></span><br><span class="line">        <span class="attr">command:</span> [<span class="string">&quot;/bin/cat&quot;</span>,<span class="string">&quot;/tmp/hello.txt&quot;</span>] <span class="comment"># 执行一个查看文件的命令</span></span><br></pre></td></tr></table></figure></div>

<p>创建pod，观察效果</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建Pod</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># kubectl create -f pod-liveness-exec.yaml</span></span><br><span class="line"><span class="string">pod/pod-liveness-exec</span> <span class="string">created</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看Pod详情</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># kubectl describe pods pod-liveness-exec -n dev</span></span><br><span class="line"><span class="string">......</span></span><br><span class="line">  <span class="string">Normal</span>   <span class="string">Created</span>    <span class="string">20s</span> <span class="string">(x2</span> <span class="string">over</span> <span class="string">50s)</span>  <span class="string">kubelet,</span> <span class="string">node1</span>     <span class="string">Created</span> <span class="string">container</span> <span class="string">nginx</span></span><br><span class="line">  <span class="string">Normal</span>   <span class="string">Started</span>    <span class="string">20s</span> <span class="string">(x2</span> <span class="string">over</span> <span class="string">50s)</span>  <span class="string">kubelet,</span> <span class="string">node1</span>     <span class="string">Started</span> <span class="string">container</span> <span class="string">nginx</span></span><br><span class="line">  <span class="string">Normal</span>   <span class="string">Killing</span>    <span class="string">20s</span>                <span class="string">kubelet,</span> <span class="string">node1</span>     <span class="string">Container</span> <span class="string">nginx</span> <span class="string">failed</span> <span class="string">liveness</span> <span class="string">probe,</span> <span class="string">will</span> <span class="string">be</span> <span class="string">restarted</span></span><br><span class="line">  <span class="string">Warning</span>  <span class="string">Unhealthy</span>  <span class="string">0s</span> <span class="string">(x5</span> <span class="string">over</span> <span class="string">40s)</span>   <span class="string">kubelet,</span> <span class="attr">node1     Liveness probe failed: cat:</span> <span class="string">can&#x27;t</span> <span class="string">open</span> <span class="string">&#x27;/tmp/hello11.txt&#x27;</span><span class="string">:</span> <span class="literal">No</span> <span class="string">such</span> <span class="string">file</span> <span class="string">or</span> <span class="string">directory</span></span><br><span class="line">  </span><br><span class="line"><span class="comment"># 观察上面的信息就会发现nginx容器启动之后就进行了健康检查</span></span><br><span class="line"><span class="comment"># 检查失败之后，容器被kill掉，然后尝试进行重启（这是重启策略的作用，后面讲解）</span></span><br><span class="line"><span class="comment"># 稍等一会之后，再观察pod信息，就可以看到RESTARTS不再是0，而是一直增长</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># kubectl get pods pod-liveness-exec -n dev</span></span><br><span class="line"><span class="string">NAME</span>                <span class="string">READY</span>   <span class="string">STATUS</span>             <span class="string">RESTARTS</span>   <span class="string">AGE</span></span><br><span class="line"><span class="string">pod-liveness-exec</span>   <span class="number">0</span><span class="string">/1</span>     <span class="string">CrashLoopBackOff</span>   <span class="number">2</span>          <span class="string">3m19s</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 当然接下来，可以修改成一个存在的文件，比如/tmp/hello.txt，再试，结果就正常了......</span></span><br></pre></td></tr></table></figure></div>

<p><strong>方式二：TCPSocket</strong></p>
<p>创建pod-liveness-tcpsocket.yaml</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-liveness-tcpsocket</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br><span class="line">    <span class="attr">ports:</span> </span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx-port</span></span><br><span class="line">      <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">livenessProbe:</span></span><br><span class="line">      <span class="attr">tcpSocket:</span></span><br><span class="line">        <span class="attr">port:</span> <span class="number">8080</span> <span class="comment"># 尝试访问8080端口</span></span><br></pre></td></tr></table></figure></div>

<p>创建pod，观察效果</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建Pod</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># kubectl create -f pod-liveness-tcpsocket.yaml</span></span><br><span class="line"><span class="string">pod/pod-liveness-tcpsocket</span> <span class="string">created</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看Pod详情</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># kubectl describe pods pod-liveness-tcpsocket -n dev</span></span><br><span class="line"><span class="string">......</span></span><br><span class="line">  <span class="string">Normal</span>   <span class="string">Scheduled</span>  <span class="string">31s</span>                            <span class="string">default-scheduler</span>  <span class="string">Successfully</span> <span class="string">assigned</span> <span class="string">dev/pod-liveness-tcpsocket</span> <span class="string">to</span> <span class="string">node2</span></span><br><span class="line">  <span class="string">Normal</span>   <span class="string">Pulled</span>     <span class="string">&lt;invalid&gt;</span>                      <span class="string">kubelet,</span> <span class="string">node2</span>     <span class="string">Container</span> <span class="string">image</span> <span class="string">&quot;nginx:1.17.1&quot;</span> <span class="string">already</span> <span class="string">present</span> <span class="string">on</span> <span class="string">machine</span></span><br><span class="line">  <span class="string">Normal</span>   <span class="string">Created</span>    <span class="string">&lt;invalid&gt;</span>                      <span class="string">kubelet,</span> <span class="string">node2</span>     <span class="string">Created</span> <span class="string">container</span> <span class="string">nginx</span></span><br><span class="line">  <span class="string">Normal</span>   <span class="string">Started</span>    <span class="string">&lt;invalid&gt;</span>                      <span class="string">kubelet,</span> <span class="string">node2</span>     <span class="string">Started</span> <span class="string">container</span> <span class="string">nginx</span></span><br><span class="line">  <span class="string">Warning</span>  <span class="string">Unhealthy</span>  <span class="string">&lt;invalid&gt;</span> <span class="string">(x2</span> <span class="string">over</span> <span class="string">&lt;invalid&gt;)</span>  <span class="string">kubelet,</span> <span class="attr">node2     Liveness probe failed: dial tcp 10.244.2.44:8080: connect:</span> <span class="string">connection</span> <span class="string">refused</span></span><br><span class="line">  </span><br><span class="line"><span class="comment"># 观察上面的信息，发现尝试访问8080端口,但是失败了</span></span><br><span class="line"><span class="comment"># 稍等一会之后，再观察pod信息，就可以看到RESTARTS不再是0，而是一直增长</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># kubectl get pods pod-liveness-tcpsocket  -n dev</span></span><br><span class="line"><span class="string">NAME</span>                     <span class="string">READY</span>   <span class="string">STATUS</span>             <span class="string">RESTARTS</span>   <span class="string">AGE</span></span><br><span class="line"><span class="string">pod-liveness-tcpsocket</span>   <span class="number">0</span><span class="string">/1</span>     <span class="string">CrashLoopBackOff</span>   <span class="number">2</span>          <span class="string">3m19s</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 当然接下来，可以修改成一个可以访问的端口，比如80，再试，结果就正常了......</span></span><br></pre></td></tr></table></figure></div>

<p><strong>方式三：HTTPGet</strong></p>
<p>创建pod-liveness-httpget.yaml</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-liveness-httpget</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx-port</span></span><br><span class="line">      <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">livenessProbe:</span></span><br><span class="line">      <span class="attr">httpGet:</span>  <span class="comment"># 其实就是访问http://127.0.0.1:80/hello  </span></span><br><span class="line">        <span class="attr">scheme:</span> <span class="string">HTTP</span> <span class="comment">#支持的协议，http或者https</span></span><br><span class="line">        <span class="attr">port:</span> <span class="number">80</span> <span class="comment">#端口号</span></span><br><span class="line">        <span class="attr">path:</span> <span class="string">/hello</span> <span class="comment">#URI地址</span></span><br></pre></td></tr></table></figure></div>

<p>创建pod，观察效果</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建Pod</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># kubectl create -f pod-liveness-httpget.yaml</span></span><br><span class="line"><span class="string">pod/pod-liveness-httpget</span> <span class="string">created</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看Pod详情</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># kubectl describe pod pod-liveness-httpget -n dev</span></span><br><span class="line"><span class="string">.......</span></span><br><span class="line">  <span class="string">Normal</span>   <span class="string">Pulled</span>     <span class="string">6s</span> <span class="string">(x3</span> <span class="string">over</span> <span class="string">64s)</span>  <span class="string">kubelet,</span> <span class="string">node1</span>     <span class="string">Container</span> <span class="string">image</span> <span class="string">&quot;nginx:1.17.1&quot;</span> <span class="string">already</span> <span class="string">present</span> <span class="string">on</span> <span class="string">machine</span></span><br><span class="line">  <span class="string">Normal</span>   <span class="string">Created</span>    <span class="string">6s</span> <span class="string">(x3</span> <span class="string">over</span> <span class="string">64s)</span>  <span class="string">kubelet,</span> <span class="string">node1</span>     <span class="string">Created</span> <span class="string">container</span> <span class="string">nginx</span></span><br><span class="line">  <span class="string">Normal</span>   <span class="string">Started</span>    <span class="string">6s</span> <span class="string">(x3</span> <span class="string">over</span> <span class="string">63s)</span>  <span class="string">kubelet,</span> <span class="string">node1</span>     <span class="string">Started</span> <span class="string">container</span> <span class="string">nginx</span></span><br><span class="line">  <span class="string">Warning</span>  <span class="string">Unhealthy</span>  <span class="string">6s</span> <span class="string">(x6</span> <span class="string">over</span> <span class="string">56s)</span>  <span class="string">kubelet,</span> <span class="attr">node1     Liveness probe failed: HTTP probe failed with statuscode:</span> <span class="number">404</span></span><br><span class="line">  <span class="string">Normal</span>   <span class="string">Killing</span>    <span class="string">6s</span> <span class="string">(x2</span> <span class="string">over</span> <span class="string">36s)</span>  <span class="string">kubelet,</span> <span class="string">node1</span>     <span class="string">Container</span> <span class="string">nginx</span> <span class="string">failed</span> <span class="string">liveness</span> <span class="string">probe,</span> <span class="string">will</span> <span class="string">be</span> <span class="string">restarted</span></span><br><span class="line">  </span><br><span class="line"><span class="comment"># 观察上面信息，尝试访问路径，但是未找到,出现404错误</span></span><br><span class="line"><span class="comment"># 稍等一会之后，再观察pod信息，就可以看到RESTARTS不再是0，而是一直增长</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># kubectl get pod pod-liveness-httpget -n dev</span></span><br><span class="line"><span class="string">NAME</span>                   <span class="string">READY</span>   <span class="string">STATUS</span>    <span class="string">RESTARTS</span>   <span class="string">AGE</span></span><br><span class="line"><span class="string">pod-liveness-httpget</span>   <span class="number">1</span><span class="string">/1</span>     <span class="string">Running</span>   <span class="number">5</span>          <span class="string">3m17s</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 当然接下来，可以修改成一个可以访问的路径path，比如/，再试，结果就正常了......</span></span><br></pre></td></tr></table></figure></div>

<p>至此，已经使用liveness Probe演示了三种探测方式，但是查看livenessProbe的子属性，会发现除了这三种方式，还有一些其他的配置，在这里一并解释下：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># kubectl explain pod.spec.containers.livenessProbe</span></span><br><span class="line"><span class="attr">FIELDS:</span></span><br><span class="line">   <span class="string">exec</span> <span class="string">&lt;Object&gt;</span>  </span><br><span class="line">   <span class="string">tcpSocket</span>    <span class="string">&lt;Object&gt;</span></span><br><span class="line">   <span class="string">httpGet</span>      <span class="string">&lt;Object&gt;</span></span><br><span class="line">   <span class="string">initialDelaySeconds</span>  <span class="string">&lt;integer&gt;</span>  <span class="comment"># 容器启动后等待多少秒执行第一次探测</span></span><br><span class="line">   <span class="string">timeoutSeconds</span>       <span class="string">&lt;integer&gt;</span>  <span class="comment"># 探测超时时间。默认1秒，最小1秒</span></span><br><span class="line">   <span class="string">periodSeconds</span>        <span class="string">&lt;integer&gt;</span>  <span class="comment"># 执行探测的频率。默认是10秒，最小1秒</span></span><br><span class="line">   <span class="string">failureThreshold</span>     <span class="string">&lt;integer&gt;</span>  <span class="comment"># 连续探测失败多少次才被认定为失败。默认是3。最小值是1</span></span><br><span class="line">   <span class="string">successThreshold</span>     <span class="string">&lt;integer&gt;</span>  <span class="comment"># 连续探测成功多少次才被认定为成功。默认是1</span></span><br></pre></td></tr></table></figure></div>

<p>下面稍微配置两个，演示下效果即可：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># more pod-liveness-httpget.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-liveness-httpget</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx-port</span></span><br><span class="line">      <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">livenessProbe:</span></span><br><span class="line">      <span class="attr">httpGet:</span></span><br><span class="line">        <span class="attr">scheme:</span> <span class="string">HTTP</span></span><br><span class="line">        <span class="attr">port:</span> <span class="number">80</span> </span><br><span class="line">        <span class="attr">path:</span> <span class="string">/</span></span><br><span class="line">      <span class="attr">initialDelaySeconds:</span> <span class="number">30</span> <span class="comment"># 容器启动后30s开始探测</span></span><br><span class="line">      <span class="attr">timeoutSeconds:</span> <span class="number">5</span> <span class="comment"># 探测超时时间为5s</span></span><br></pre></td></tr></table></figure></div>

<h5 id="5-3-5-重启策略"><a href="#5-3-5-重启策略" class="headerlink" title="5.3.5 重启策略"></a>5.3.5 重启策略</h5><p>在上一节中，一旦容器探测出现了问题，kubernetes就会对容器所在的Pod进行重启，其实这是由pod的重启策略决定的，pod的重启策略有 3 种，分别如下：</p>
<ul>
<li>Always ：容器失效时，自动重启该容器，这也是默认值。</li>
<li>OnFailure ： 容器终止运行且退出码不为0时重启</li>
<li>Never ： 不论状态为何，都不重启该容器</li>
</ul>
<p>重启策略适用于pod对象中的所有容器，首次需要重启的容器，将在其需要时立即进行重启，随后再次需要重启的操作将由kubelet延迟一段时间后进行，且反复的重启操作的延迟时长以此为10s、20s、40s、80s、160s和300s，300s是最大延迟时长。</p>
<p>创建pod-restartpolicy.yaml：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-restartpolicy</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx-port</span></span><br><span class="line">      <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">livenessProbe:</span></span><br><span class="line">      <span class="attr">httpGet:</span></span><br><span class="line">        <span class="attr">scheme:</span> <span class="string">HTTP</span></span><br><span class="line">        <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">        <span class="attr">path:</span> <span class="string">/hello</span></span><br><span class="line">  <span class="attr">restartPolicy:</span> <span class="string">Never</span> <span class="comment"># 设置重启策略为Never</span></span><br></pre></td></tr></table></figure></div>

<p>运行Pod测试</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建Pod</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># kubectl create -f pod-restartpolicy.yaml</span></span><br><span class="line"><span class="string">pod/pod-restartpolicy</span> <span class="string">created</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看Pod详情，发现nginx容器失败</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># kubectl  describe pods pod-restartpolicy  -n dev</span></span><br><span class="line"><span class="string">......</span></span><br><span class="line">  <span class="string">Warning</span>  <span class="string">Unhealthy</span>  <span class="string">15s</span> <span class="string">(x3</span> <span class="string">over</span> <span class="string">35s)</span>  <span class="string">kubelet,</span> <span class="attr">node1     Liveness probe failed: HTTP probe failed with statuscode:</span> <span class="number">404</span></span><br><span class="line">  <span class="string">Normal</span>   <span class="string">Killing</span>    <span class="string">15s</span>                <span class="string">kubelet,</span> <span class="string">node1</span>     <span class="string">Container</span> <span class="string">nginx</span> <span class="string">failed</span> <span class="string">liveness</span> <span class="string">probe</span></span><br><span class="line">  </span><br><span class="line"><span class="comment"># 多等一会，再观察pod的重启次数，发现一直是0，并未重启   </span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># kubectl  get pods pod-restartpolicy -n dev</span></span><br><span class="line"><span class="string">NAME</span>                   <span class="string">READY</span>   <span class="string">STATUS</span>    <span class="string">RESTARTS</span>   <span class="string">AGE</span></span><br><span class="line"><span class="string">pod-restartpolicy</span>      <span class="number">0</span><span class="string">/1</span>     <span class="string">Running</span>   <span class="number">0</span>          <span class="string">5min42s</span></span><br></pre></td></tr></table></figure></div>

<h4 id="5-4-Pod调度"><a href="#5-4-Pod调度" class="headerlink" title="5.4 Pod调度"></a>5.4 Pod调度</h4><p>在默认情况下，一个Pod在哪个Node节点上运行，是由Scheduler组件采用相应的算法计算出来的，这个过程是不受人工控制的。但是在实际使用中，这并不满足的需求，因为很多情况下，我们想控制某些Pod到达某些节点上，那么应该怎么做呢？这就要求了解kubernetes对Pod的调度规则，kubernetes提供了四大类调度方式：</p>
<ul>
<li>自动调度：运行在哪个节点上完全由Scheduler经过一系列的算法计算得出</li>
<li>定向调度：NodeName、NodeSelector</li>
<li>亲和性调度：NodeAffinity、PodAffinity、PodAntiAffinity</li>
<li>污点（容忍）调度：Taints、Toleration</li>
</ul>
<h5 id="5-4-1-定向调度"><a href="#5-4-1-定向调度" class="headerlink" title="5.4.1 定向调度"></a>5.4.1 定向调度</h5><p>定向调度，指的是利用在pod上声明nodeName或者nodeSelector，以此将Pod调度到期望的node节点上。注意，这里的调度是强制的，这就意味着即使要调度的目标Node不存在，也会向上面进行调度，只不过pod运行失败而已。</p>
<p><strong>NodeName</strong></p>
<p>NodeName用于强制约束将Pod调度到指定的Name的Node节点上。这种方式，其实是直接跳过Scheduler的调度逻辑，直接将Pod调度到指定名称的节点。</p>
<p>接下来，实验一下：创建一个pod-nodename.yaml文件</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-nodename</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br><span class="line">  <span class="attr">nodeName:</span> <span class="string">node1</span> <span class="comment"># 指定调度到node1节点上</span></span><br></pre></td></tr></table></figure></div>

<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment">#创建Pod</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># kubectl create -f pod-nodename.yaml</span></span><br><span class="line"><span class="string">pod/pod-nodename</span> <span class="string">created</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#查看Pod调度到NODE属性，确实是调度到了node1节点上</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># kubectl get pods pod-nodename -n dev -o wide</span></span><br><span class="line"><span class="string">NAME</span>           <span class="string">READY</span>   <span class="string">STATUS</span>    <span class="string">RESTARTS</span>   <span class="string">AGE</span>   <span class="string">IP</span>            <span class="string">NODE</span>      <span class="string">......</span></span><br><span class="line"><span class="string">pod-nodename</span>   <span class="number">1</span><span class="string">/1</span>     <span class="string">Running</span>   <span class="number">0</span>          <span class="string">56s</span>   <span class="number">10.244</span><span class="number">.1</span><span class="number">.87</span>   <span class="string">node1</span>     <span class="string">......</span>   </span><br><span class="line"></span><br><span class="line"><span class="comment"># 接下来，删除pod，修改nodeName的值为node3（并没有node3节点）</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># kubectl delete -f pod-nodename.yaml</span></span><br><span class="line"><span class="string">pod</span> <span class="string">&quot;pod-nodename&quot;</span> <span class="string">deleted</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># vim pod-nodename.yaml</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># kubectl create -f pod-nodename.yaml</span></span><br><span class="line"><span class="string">pod/pod-nodename</span> <span class="string">created</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#再次查看，发现已经向Node3节点调度，但是由于不存在node3节点，所以pod无法正常运行</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># kubectl get pods pod-nodename -n dev -o wide</span></span><br><span class="line"><span class="string">NAME</span>           <span class="string">READY</span>   <span class="string">STATUS</span>    <span class="string">RESTARTS</span>   <span class="string">AGE</span>   <span class="string">IP</span>       <span class="string">NODE</span>    <span class="string">......</span></span><br><span class="line"><span class="string">pod-nodename</span>   <span class="number">0</span><span class="string">/1</span>     <span class="string">Pending</span>   <span class="number">0</span>          <span class="string">6s</span>    <span class="string">&lt;none&gt;</span>   <span class="string">node3</span>   <span class="string">......</span>           </span><br></pre></td></tr></table></figure></div>

<p><strong>NodeSelector</strong></p>
<p>NodeSelector用于将pod调度到添加了指定标签的node节点上。它是通过kubernetes的label-selector机制实现的，也就是说，在pod创建之前，会由scheduler使用MatchNodeSelector调度策略进行label匹配，找出目标node，然后将pod调度到目标节点，该匹配规则是强制约束。</p>
<p>接下来，实验一下：</p>
<p>1 首先分别为node节点添加标签</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master01 ~]# kubectl label nodes node1 nodeenv=pro</span><br><span class="line">node/node2 labeled</span><br><span class="line">[root@k8s-master01 ~]# kubectl label nodes node2 nodeenv=test</span><br><span class="line">node/node2 labeled</span><br></pre></td></tr></table></figure></div>

<p>2 创建一个pod-nodeselector.yaml文件，并使用它创建Pod</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-nodeselector</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br><span class="line">  <span class="attr">nodeSelector:</span> </span><br><span class="line">    <span class="attr">nodeenv:</span> <span class="string">pro</span> <span class="comment"># 指定调度到具有nodeenv=pro标签的节点上</span></span><br></pre></td></tr></table></figure></div>

<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment">#创建Pod</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># kubectl create -f pod-nodeselector.yaml</span></span><br><span class="line"><span class="string">pod/pod-nodeselector</span> <span class="string">created</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#查看Pod调度到NODE属性，确实是调度到了node1节点上</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># kubectl get pods pod-nodeselector -n dev -o wide</span></span><br><span class="line"><span class="string">NAME</span>               <span class="string">READY</span>   <span class="string">STATUS</span>    <span class="string">RESTARTS</span>   <span class="string">AGE</span>     <span class="string">IP</span>          <span class="string">NODE</span>    <span class="string">......</span></span><br><span class="line"><span class="string">pod-nodeselector</span>   <span class="number">1</span><span class="string">/1</span>     <span class="string">Running</span>   <span class="number">0</span>          <span class="string">47s</span>   <span class="number">10.244</span><span class="number">.1</span><span class="number">.87</span>   <span class="string">node1</span>   <span class="string">......</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 接下来，删除pod，修改nodeSelector的值为nodeenv: xxxx（不存在打有此标签的节点）</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># kubectl delete -f pod-nodeselector.yaml</span></span><br><span class="line"><span class="string">pod</span> <span class="string">&quot;pod-nodeselector&quot;</span> <span class="string">deleted</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># vim pod-nodeselector.yaml</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># kubectl create -f pod-nodeselector.yaml</span></span><br><span class="line"><span class="string">pod/pod-nodeselector</span> <span class="string">created</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#再次查看，发现pod无法正常运行,Node的值为none</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># kubectl get pods -n dev -o wide</span></span><br><span class="line"><span class="string">NAME</span>               <span class="string">READY</span>   <span class="string">STATUS</span>    <span class="string">RESTARTS</span>   <span class="string">AGE</span>     <span class="string">IP</span>       <span class="string">NODE</span>    </span><br><span class="line"><span class="string">pod-nodeselector</span>   <span class="number">0</span><span class="string">/1</span>     <span class="string">Pending</span>   <span class="number">0</span>          <span class="string">2m20s</span>   <span class="string">&lt;none&gt;</span>   <span class="string">&lt;none&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看详情,发现node selector匹配失败的提示</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># kubectl describe pods pod-nodeselector -n dev</span></span><br><span class="line"><span class="string">.......</span></span><br><span class="line"><span class="attr">Events:</span></span><br><span class="line">  <span class="string">Type</span>     <span class="string">Reason</span>            <span class="string">Age</span>        <span class="string">From</span>               <span class="string">Message</span></span><br><span class="line">  <span class="string">----</span>     <span class="string">------</span>            <span class="string">----</span>       <span class="string">----</span>               <span class="string">-------</span></span><br><span class="line">  <span class="string">Warning</span>  <span class="string">FailedScheduling</span>  <span class="string">&lt;unknown&gt;</span>  <span class="attr">default-scheduler  0/3 nodes are available:</span> <span class="number">3</span> <span class="string">node(s)</span> <span class="string">didn&#x27;t</span> <span class="string">match</span> <span class="string">node</span> <span class="string">selector.</span></span><br></pre></td></tr></table></figure></div>

<h5 id="5-4-2-亲和性调度"><a href="#5-4-2-亲和性调度" class="headerlink" title="5.4.2 亲和性调度"></a>5.4.2 亲和性调度</h5><p>上一节，介绍了两种定向调度的方式，使用起来非常方便，但是也有一定的问题，那就是如果没有满足条件的Node，那么Pod将不会被运行，即使在集群中还有可用Node列表也不行，这就限制了它的使用场景。</p>
<p>基于上面的问题，kubernetes还提供了一种亲和性调度（Affinity）。它在NodeSelector的基础之上的进行了扩展，可以通过配置的形式，实现优先选择满足条件的Node进行调度，如果没有，也可以调度到不满足条件的节点上，使调度更加灵活。</p>
<p>Affinity主要分为三类：</p>
<ul>
<li>nodeAffinity(node亲和性）: 以node为目标，解决pod可以调度到哪些node的问题</li>
<li>podAffinity(pod亲和性) : 以pod为目标，解决pod可以和哪些已存在的pod部署在同一个拓扑域中的问题</li>
<li>podAntiAffinity(pod反亲和性) : 以pod为目标，解决pod不能和哪些已存在pod部署在同一个拓扑域中的问题</li>
</ul>
<blockquote>
<p>关于亲和性(反亲和性)使用场景的说明：</p>
<p><strong>亲和性</strong>：如果两个应用频繁交互，那就有必要利用亲和性让两个应用的尽可能的靠近，这样可以减少因网络通信而带来的性能损耗。</p>
<p><strong>反亲和性</strong>：当应用的采用多副本部署时，有必要采用反亲和性让各个应用实例打散分布在各个node上，这样可以提高服务的高可用性。</p>
</blockquote>
<p><strong>NodeAffinity</strong></p>
<p>首先来看一下<code>NodeAffinity</code>的可配置项：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="MARKDOWN"><figure class="iseeu highlight /markdown"><table><tr><td class="code"><pre><span class="line">pod.spec.affinity.nodeAffinity</span><br><span class="line">  requiredDuringSchedulingIgnoredDuringExecution  Node节点必须满足指定的所有规则才可以，相当于硬限制</span><br><span class="line"><span class="code">    nodeSelectorTerms  节点选择列表</span></span><br><span class="line"><span class="code">      matchFields   按节点字段列出的节点选择器要求列表</span></span><br><span class="line"><span class="code">      matchExpressions   按节点标签列出的节点选择器要求列表(推荐)</span></span><br><span class="line"><span class="code">        key    键</span></span><br><span class="line"><span class="code">        values 值</span></span><br><span class="line"><span class="code">        operat or 关系符 支持Exists, DoesNotExist, In, NotIn, Gt, Lt</span></span><br><span class="line"><span class="code">  preferredDuringSchedulingIgnoredDuringExecution 优先调度到满足指定的规则的Node，相当于软限制 (倾向)</span></span><br><span class="line"><span class="code">    preference   一个节点选择器项，与相应的权重相关联</span></span><br><span class="line"><span class="code">      matchFields   按节点字段列出的节点选择器要求列表</span></span><br><span class="line"><span class="code">      matchExpressions   按节点标签列出的节点选择器要求列表(推荐)</span></span><br><span class="line"><span class="code">        key    键</span></span><br><span class="line"><span class="code">        values 值</span></span><br><span class="line"><span class="code">        operator 关系符 支持In, NotIn, Exists, DoesNotExist, Gt, Lt</span></span><br><span class="line"><span class="code">	weight 倾向权重，在范围1-100。</span></span><br></pre></td></tr></table></figure></div>

<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">关系符的使用说明:</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> <span class="attr">matchExpressions:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">nodeenv</span>              <span class="comment"># 匹配存在标签的key为nodeenv的节点</span></span><br><span class="line">    <span class="attr">operator:</span> <span class="string">Exists</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">nodeenv</span>              <span class="comment"># 匹配标签的key为nodeenv,且value是&quot;xxx&quot;或&quot;yyy&quot;的节点</span></span><br><span class="line">    <span class="attr">operator:</span> <span class="string">In</span></span><br><span class="line">    <span class="attr">values:</span> [<span class="string">&quot;xxx&quot;</span>,<span class="string">&quot;yyy&quot;</span>]</span><br><span class="line">  <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">nodeenv</span>              <span class="comment"># 匹配标签的key为nodeenv,且value大于&quot;xxx&quot;的节点</span></span><br><span class="line">    <span class="attr">operator:</span> <span class="string">Gt</span></span><br><span class="line">    <span class="attr">values:</span> <span class="string">&quot;xxx&quot;</span></span><br></pre></td></tr></table></figure></div>

<p>接下来首先演示一下<code>requiredDuringSchedulingIgnoredDuringExecution</code> ,</p>
<p>创建pod-nodeaffinity-required.yaml</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-nodeaffinity-required</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br><span class="line">  <span class="attr">affinity:</span>  <span class="comment">#亲和性设置</span></span><br><span class="line">    <span class="attr">nodeAffinity:</span> <span class="comment">#设置node亲和性</span></span><br><span class="line">      <span class="attr">requiredDuringSchedulingIgnoredDuringExecution:</span> <span class="comment"># 硬限制</span></span><br><span class="line">        <span class="attr">nodeSelectorTerms:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">matchExpressions:</span> <span class="comment"># 匹配env的值在[&quot;xxx&quot;,&quot;yyy&quot;]中的标签</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">nodeenv</span></span><br><span class="line">            <span class="attr">operator:</span> <span class="string">In</span></span><br><span class="line">            <span class="attr">values:</span> [<span class="string">&quot;xxx&quot;</span>,<span class="string">&quot;yyy&quot;</span>]</span><br></pre></td></tr></table></figure></div>

<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建pod</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># kubectl create -f pod-nodeaffinity-required.yaml</span></span><br><span class="line"><span class="string">pod/pod-nodeaffinity-required</span> <span class="string">created</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看pod状态 （运行失败）</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># kubectl get pods pod-nodeaffinity-required -n dev -o wide</span></span><br><span class="line"><span class="string">NAME</span>                        <span class="string">READY</span>   <span class="string">STATUS</span>    <span class="string">RESTARTS</span>   <span class="string">AGE</span>   <span class="string">IP</span>       <span class="string">NODE</span>    <span class="string">......</span> </span><br><span class="line"><span class="string">pod-nodeaffinity-required</span>   <span class="number">0</span><span class="string">/1</span>     <span class="string">Pending</span>   <span class="number">0</span>          <span class="string">16s</span>   <span class="string">&lt;none&gt;</span>   <span class="string">&lt;none&gt;</span>  <span class="string">......</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看Pod的详情</span></span><br><span class="line"><span class="comment"># 发现调度失败，提示node选择失败</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># kubectl describe pod pod-nodeaffinity-required -n dev</span></span><br><span class="line"><span class="string">......</span></span><br><span class="line">  <span class="string">Warning</span>  <span class="string">FailedScheduling</span>  <span class="string">&lt;unknown&gt;</span>  <span class="attr">default-scheduler  0/3 nodes are available:</span> <span class="number">3</span> <span class="string">node(s)</span> <span class="string">didn&#x27;t</span> <span class="string">match</span> <span class="string">node</span> <span class="string">selector.</span></span><br><span class="line">  <span class="string">Warning</span>  <span class="string">FailedScheduling</span>  <span class="string">&lt;unknown&gt;</span>  <span class="attr">default-scheduler  0/3 nodes are available:</span> <span class="number">3</span> <span class="string">node(s)</span> <span class="string">didn&#x27;t</span> <span class="string">match</span> <span class="string">node</span> <span class="string">selector.</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#接下来，停止pod</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># kubectl delete -f pod-nodeaffinity-required.yaml</span></span><br><span class="line"><span class="string">pod</span> <span class="string">&quot;pod-nodeaffinity-required&quot;</span> <span class="string">deleted</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改文件，将values: [&quot;xxx&quot;,&quot;yyy&quot;]------&gt; [&quot;pro&quot;,&quot;yyy&quot;]</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># vim pod-nodeaffinity-required.yaml</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 再次启动</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># kubectl create -f pod-nodeaffinity-required.yaml</span></span><br><span class="line"><span class="string">pod/pod-nodeaffinity-required</span> <span class="string">created</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 此时查看，发现调度成功，已经将pod调度到了node1上</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># kubectl get pods pod-nodeaffinity-required -n dev -o wide</span></span><br><span class="line"><span class="string">NAME</span>                        <span class="string">READY</span>   <span class="string">STATUS</span>    <span class="string">RESTARTS</span>   <span class="string">AGE</span>   <span class="string">IP</span>            <span class="string">NODE</span>  <span class="string">......</span> </span><br><span class="line"><span class="string">pod-nodeaffinity-required</span>   <span class="number">1</span><span class="string">/1</span>     <span class="string">Running</span>   <span class="number">0</span>          <span class="string">11s</span>   <span class="number">10.244</span><span class="number">.1</span><span class="number">.89</span>   <span class="string">node1</span> <span class="string">......</span></span><br></pre></td></tr></table></figure></div>

<p>接下来再演示一下<code>requiredDuringSchedulingIgnoredDuringExecution</code> ,</p>
<p>创建pod-nodeaffinity-preferred.yaml</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-nodeaffinity-preferred</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br><span class="line">  <span class="attr">affinity:</span>  <span class="comment">#亲和性设置</span></span><br><span class="line">    <span class="attr">nodeAffinity:</span> <span class="comment">#设置node亲和性</span></span><br><span class="line">      <span class="attr">preferredDuringSchedulingIgnoredDuringExecution:</span> <span class="comment"># 软限制</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">weight:</span> <span class="number">1</span></span><br><span class="line">        <span class="attr">preference:</span></span><br><span class="line">          <span class="attr">matchExpressions:</span> <span class="comment"># 匹配env的值在[&quot;xxx&quot;,&quot;yyy&quot;]中的标签(当前环境没有)</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">nodeenv</span></span><br><span class="line">            <span class="attr">operator:</span> <span class="string">In</span></span><br><span class="line">            <span class="attr">values:</span> [<span class="string">&quot;xxx&quot;</span>,<span class="string">&quot;yyy&quot;</span>]</span><br></pre></td></tr></table></figure></div>

<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建pod</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># kubectl create -f pod-nodeaffinity-preferred.yaml</span></span><br><span class="line"><span class="string">pod/pod-nodeaffinity-preferred</span> <span class="string">created</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看pod状态 （运行成功）</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># kubectl get pod pod-nodeaffinity-preferred -n dev</span></span><br><span class="line"><span class="string">NAME</span>                         <span class="string">READY</span>   <span class="string">STATUS</span>    <span class="string">RESTARTS</span>   <span class="string">AGE</span></span><br><span class="line"><span class="string">pod-nodeaffinity-preferred</span>   <span class="number">1</span><span class="string">/1</span>     <span class="string">Running</span>   <span class="number">0</span>          <span class="string">40s</span></span><br></pre></td></tr></table></figure></div>

<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tr><td class="code"><pre><span class="line">NodeAffinity规则设置的注意事项：</span><br><span class="line">    1 如果同时定义了nodeSelector和nodeAffinity，那么必须两个条件都得到满足，Pod才能运行在指定的Node上</span><br><span class="line">    2 如果nodeAffinity指定了多个nodeSelectorTerms，那么只需要其中一个能够匹配成功即可</span><br><span class="line">    3 如果一个nodeSelectorTerms中有多个matchExpressions ，则一个节点必须满足所有的才能匹配成功</span><br><span class="line">    4 如果一个pod所在的Node在Pod运行期间其标签发生了改变，不再符合该Pod的节点亲和性需求，则系统将忽略此变化</span><br></pre></td></tr></table></figure></div>

<p><strong>PodAffinity</strong></p>
<p>PodAffinity主要实现以运行的Pod为参照，实现让新创建的Pod跟参照pod在一个区域的功能。</p>
<p>首先来看一下<code>PodAffinity</code>的可配置项：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="MARKDOWN"><figure class="iseeu highlight /markdown"><table><tr><td class="code"><pre><span class="line">pod.spec.affinity.podAffinity</span><br><span class="line">  requiredDuringSchedulingIgnoredDuringExecution  硬限制</span><br><span class="line"><span class="code">    namespaces       指定参照pod的namespace</span></span><br><span class="line"><span class="code">    topologyKey      指定调度作用域</span></span><br><span class="line"><span class="code">    labelSelector    标签选择器</span></span><br><span class="line"><span class="code">      matchExpressions  按节点标签列出的节点选择器要求列表(推荐)</span></span><br><span class="line"><span class="code">        key    键</span></span><br><span class="line"><span class="code">        values 值</span></span><br><span class="line"><span class="code">        operator 关系符 支持In, NotIn, Exists, DoesNotExist.</span></span><br><span class="line"><span class="code">      matchLabels    指多个matchExpressions映射的内容</span></span><br><span class="line"><span class="code">  preferredDuringSchedulingIgnoredDuringExecution 软限制</span></span><br><span class="line"><span class="code">    podAffinityTerm  选项</span></span><br><span class="line"><span class="code">      namespaces      </span></span><br><span class="line"><span class="code">      topologyKey</span></span><br><span class="line"><span class="code">      labelSelector</span></span><br><span class="line"><span class="code">        matchExpressions  </span></span><br><span class="line"><span class="code">          key    键</span></span><br><span class="line"><span class="code">          values 值</span></span><br><span class="line"><span class="code">          operator</span></span><br><span class="line"><span class="code">        matchLabels </span></span><br><span class="line"><span class="code">    weight 倾向权重，在范围1-100</span></span><br></pre></td></tr></table></figure></div>

<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="MARKDOWN"><figure class="iseeu highlight /markdown"><table><tr><td class="code"><pre><span class="line">topologyKey用于指定调度时作用域,例如:</span><br><span class="line"><span class="code">    如果指定为kubernetes.io/hostname，那就是以Node节点为区分范围</span></span><br><span class="line"><span class="code">	如果指定为beta.kubernetes.io/os,则以Node节点的操作系统类型来区分</span></span><br></pre></td></tr></table></figure></div>

<p>接下来，演示下<code>requiredDuringSchedulingIgnoredDuringExecution</code>,</p>
<p>1）首先创建一个参照Pod，pod-podaffinity-target.yaml：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-podaffinity-target</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">podenv:</span> <span class="string">pro</span> <span class="comment">#设置标签</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br><span class="line">  <span class="attr">nodeName:</span> <span class="string">node1</span> <span class="comment"># 将目标pod名确指定到node1上</span></span><br></pre></td></tr></table></figure></div>

<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 启动目标pod</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl create -f pod-podaffinity-target.yaml</span><br><span class="line">pod/pod-podaffinity-target created</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看pod状况</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl get pods  pod-podaffinity-target -n dev</span><br><span class="line">NAME                     READY   STATUS    RESTARTS   AGE</span><br><span class="line">pod-podaffinity-target   1/1     Running   0          4s</span><br></pre></td></tr></table></figure></div>

<p>2）创建pod-podaffinity-required.yaml，内容如下：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-podaffinity-required</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br><span class="line">  <span class="attr">affinity:</span>  <span class="comment">#亲和性设置</span></span><br><span class="line">    <span class="attr">podAffinity:</span> <span class="comment">#设置pod亲和性</span></span><br><span class="line">      <span class="attr">requiredDuringSchedulingIgnoredDuringExecution:</span> <span class="comment"># 硬限制</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">labelSelector:</span></span><br><span class="line">          <span class="attr">matchExpressions:</span> <span class="comment"># 匹配env的值在[&quot;xxx&quot;,&quot;yyy&quot;]中的标签</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">podenv</span></span><br><span class="line">            <span class="attr">operator:</span> <span class="string">In</span></span><br><span class="line">            <span class="attr">values:</span> [<span class="string">&quot;xxx&quot;</span>,<span class="string">&quot;yyy&quot;</span>]</span><br><span class="line">        <span class="attr">topologyKey:</span> <span class="string">kubernetes.io/hostname</span></span><br></pre></td></tr></table></figure></div>

<p>上面配置表达的意思是：新Pod必须要与拥有标签nodeenv=xxx或者nodeenv=yyy的pod在同一Node上，显然现在没有这样pod，接下来，运行测试一下。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 启动pod</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># kubectl create -f pod-podaffinity-required.yaml</span></span><br><span class="line"><span class="string">pod/pod-podaffinity-required</span> <span class="string">created</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看pod状态，发现未运行</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># kubectl get pods pod-podaffinity-required -n dev</span></span><br><span class="line"><span class="string">NAME</span>                       <span class="string">READY</span>   <span class="string">STATUS</span>    <span class="string">RESTARTS</span>   <span class="string">AGE</span></span><br><span class="line"><span class="string">pod-podaffinity-required</span>   <span class="number">0</span><span class="string">/1</span>     <span class="string">Pending</span>   <span class="number">0</span>          <span class="string">9s</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看详细信息</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># kubectl describe pods pod-podaffinity-required  -n dev</span></span><br><span class="line"><span class="string">......</span></span><br><span class="line"><span class="attr">Events:</span></span><br><span class="line">  <span class="string">Type</span>     <span class="string">Reason</span>            <span class="string">Age</span>        <span class="string">From</span>               <span class="string">Message</span></span><br><span class="line">  <span class="string">----</span>     <span class="string">------</span>            <span class="string">----</span>       <span class="string">----</span>               <span class="string">-------</span></span><br><span class="line">  <span class="string">Warning</span>  <span class="string">FailedScheduling</span>  <span class="string">&lt;unknown&gt;</span>  <span class="attr">default-scheduler  0/3 nodes are available:</span> <span class="number">2</span> <span class="string">node(s)</span> <span class="string">didn&#x27;t</span> <span class="string">match</span> <span class="string">pod</span> <span class="string">affinity</span> <span class="string">rules,</span> <span class="number">1</span> <span class="string">node(s)</span> <span class="string">had</span> <span class="string">taints</span> <span class="string">that</span> <span class="string">the</span> <span class="string">pod</span> <span class="string">didn&#x27;t</span> <span class="string">tolerate.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 接下来修改  values: [&quot;xxx&quot;,&quot;yyy&quot;]-----&gt;values:[&quot;pro&quot;,&quot;yyy&quot;]</span></span><br><span class="line"><span class="comment"># 意思是：新Pod必须要与拥有标签nodeenv=xxx或者nodeenv=yyy的pod在同一Node上</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># vim pod-podaffinity-required.yaml</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 然后重新创建pod，查看效果</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># kubectl delete -f  pod-podaffinity-required.yaml</span></span><br><span class="line"><span class="string">pod</span> <span class="string">&quot;pod-podaffinity-required&quot;</span> <span class="string">de</span> <span class="string">leted</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># kubectl create -f pod-podaffinity-required.yaml</span></span><br><span class="line"><span class="string">pod/pod-podaffinity-required</span> <span class="string">created</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 发现此时Pod运行正常</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># kubectl get pods pod-podaffinity-required -n dev</span></span><br><span class="line"><span class="string">NAME</span>                       <span class="string">READY</span>   <span class="string">STATUS</span>    <span class="string">RESTARTS</span>   <span class="string">AGE</span>   <span class="string">LABELS</span></span><br><span class="line"><span class="string">pod-podaffinity-required</span>   <span class="number">1</span><span class="string">/1</span>     <span class="string">Running</span>   <span class="number">0</span>          <span class="string">6s</span>    <span class="string">&lt;none&gt;</span></span><br></pre></td></tr></table></figure></div>

<p>关于<code>PodAffinity</code>的 <code>preferredDuringSchedulingIgnoredDuringExecution</code>，这里不再演示。</p>
<p><strong>PodAntiAffinity</strong></p>
<p>PodAntiAffinity主要实现以运行的Pod为参照，让新创建的Pod跟参照pod不在一个区域中的功能。</p>
<p>它的配置方式和选项跟PodAffinty是一样的，这里不再做详细解释，直接做一个测试案例。</p>
<p>1）继续使用上个案例中目标pod</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master01 ~]# kubectl get pods -n dev -o wide --show-labels</span><br><span class="line">NAME                     READY   STATUS    RESTARTS   AGE     IP            NODE    LABELS</span><br><span class="line">pod-podaffinity-required 1/1     Running   0          3m29s   10.244.1.38   node1   &lt;none&gt;     </span><br><span class="line">pod-podaffinity-target   1/1     Running   0          9m25s   10.244.1.37   node1   podenv=pro</span><br></pre></td></tr></table></figure></div>

<p>2）创建pod-podantiaffinity-required.yaml，内容如下：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-podantiaffinity-required</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br><span class="line">  <span class="attr">affinity:</span>  <span class="comment">#亲和性设置</span></span><br><span class="line">    <span class="attr">podAntiAffinity:</span> <span class="comment">#设置pod亲和性</span></span><br><span class="line">      <span class="attr">requiredDuringSchedulingIgnoredDuringExecution:</span> <span class="comment"># 硬限制</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">labelSelector:</span></span><br><span class="line">          <span class="attr">matchExpressions:</span> <span class="comment"># 匹配podenv的值在[&quot;pro&quot;]中的标签</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">podenv</span></span><br><span class="line">            <span class="attr">operator:</span> <span class="string">In</span></span><br><span class="line">            <span class="attr">values:</span> [<span class="string">&quot;pro&quot;</span>]</span><br><span class="line">        <span class="attr">topologyKey:</span> <span class="string">kubernetes.io/hostname</span></span><br></pre></td></tr></table></figure></div>

<p>上面配置表达的意思是：新Pod必须要与拥有标签nodeenv=pro的pod不在同一Node上，运行测试一下。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建pod</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># kubectl create -f pod-podantiaffinity-required.yaml</span></span><br><span class="line"><span class="string">pod/pod-podantiaffinity-required</span> <span class="string">created</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看pod</span></span><br><span class="line"><span class="comment"># 发现调度到了node2上</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># kubectl get pods pod-podantiaffinity-required -n dev -o wide</span></span><br><span class="line"><span class="string">NAME</span>                           <span class="string">READY</span>   <span class="string">STATUS</span>    <span class="string">RESTARTS</span>   <span class="string">AGE</span>   <span class="string">IP</span>            <span class="string">NODE</span>   <span class="string">..</span> </span><br><span class="line"><span class="string">pod-podantiaffinity-required</span>   <span class="number">1</span><span class="string">/1</span>     <span class="string">Running</span>   <span class="number">0</span>          <span class="string">30s</span>   <span class="number">10.244</span><span class="number">.1</span><span class="number">.96</span>   <span class="string">node2</span>  <span class="string">..</span></span><br></pre></td></tr></table></figure></div>

<h5 id="5-4-3-污点和容忍"><a href="#5-4-3-污点和容忍" class="headerlink" title="5.4.3 污点和容忍"></a>5.4.3 污点和容忍</h5><p><strong>污点（Taints）</strong></p>
<p>前面的调度方式都是站在Pod的角度上，通过在Pod上添加属性，来确定Pod是否要调度到指定的Node上，其实我们也可以站在Node的角度上，通过在Node上添加<strong>污点</strong>属性，来决定是否允许Pod调度过来。</p>
<p>Node被设置上污点之后就和Pod之间存在了一种相斥的关系，进而拒绝Pod调度进来，甚至可以将已经存在的Pod驱逐出去。</p>
<p>污点的格式为：<code>key=value:effect</code>, key和value是污点的标签，effect描述污点的作用，支持如下三个选项：</p>
<ul>
<li>PreferNoSchedule：kubernetes将尽量避免把Pod调度到具有该污点的Node上，除非没有其他节点可调度</li>
<li>NoSchedule：kubernetes将不会把Pod调度到具有该污点的Node上，但不会影响当前Node上已存在的Pod</li>
<li>NoExecute：kubernetes将不会把Pod调度到具有该污点的Node上，同时也会将Node上已存在的Pod驱离</li>
</ul>
<p><img src="/2022/06/09/uncatalog/cl46zbayg000v7or7a4o0f4yd/image-20200605021831545.png" alt="image-20200605021606508"></p>
<p>使用kubectl设置和去除污点的命令示例如下：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 设置污点</span></span><br><span class="line">kubectl taint nodes node1 key=value:effect</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 去除污点</span></span><br><span class="line">kubectl taint nodes node1 key:effect-</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 去除所有污点</span></span><br><span class="line">kubectl taint nodes node1 key-</span><br></pre></td></tr></table></figure></div>

<p>接下来，演示下污点的效果：</p>
<ol>
<li>准备节点node1（为了演示效果更加明显，暂时停止node2节点）</li>
<li>为node1节点设置一个污点: <code>tag=heima:PreferNoSchedule</code>；然后创建pod1( pod1 可以 )</li>
<li>修改为node1节点设置一个污点: <code>tag=heima:NoSchedule</code>；然后创建pod2( pod1 正常 pod2 失败 )</li>
<li>修改为node1节点设置一个污点: <code>tag=heima:NoExecute</code>；然后创建pod3 ( 3个pod都失败 )</li>
</ol>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 为node1设置污点(PreferNoSchedule)</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># kubectl taint nodes node1 tag=heima:PreferNoSchedule</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建pod1</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># kubectl run taint1 --image=nginx:1.17.1 -n dev</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># kubectl get pods -n dev -o wide</span></span><br><span class="line"><span class="string">NAME</span>                      <span class="string">READY</span>   <span class="string">STATUS</span>    <span class="string">RESTARTS</span>   <span class="string">AGE</span>     <span class="string">IP</span>           <span class="string">NODE</span>   </span><br><span class="line"><span class="string">taint1-7665f7fd85-574h4</span>   <span class="number">1</span><span class="string">/1</span>     <span class="string">Running</span>   <span class="number">0</span>          <span class="string">2m24s</span>   <span class="number">10.244</span><span class="number">.1</span><span class="number">.59</span>   <span class="string">node1</span>    </span><br><span class="line"></span><br><span class="line"><span class="comment"># 为node1设置污点(取消PreferNoSchedule，设置NoSchedule)</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># kubectl taint nodes node1 tag:PreferNoSchedule-</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># kubectl taint nodes node1 tag=heima:NoSchedule</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建pod2</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># kubectl run taint2 --image=nginx:1.17.1 -n dev</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># kubectl get pods taint2 -n dev -o wide</span></span><br><span class="line"><span class="string">NAME</span>                      <span class="string">READY</span>   <span class="string">STATUS</span>    <span class="string">RESTARTS</span>   <span class="string">AGE</span>     <span class="string">IP</span>            <span class="string">NODE</span></span><br><span class="line"><span class="string">taint1-7665f7fd85-574h4</span>   <span class="number">1</span><span class="string">/1</span>     <span class="string">Running</span>   <span class="number">0</span>          <span class="string">2m24s</span>   <span class="number">10.244</span><span class="number">.1</span><span class="number">.59</span>   <span class="string">node1</span> </span><br><span class="line"><span class="string">taint2-544694789-6zmlf</span>    <span class="number">0</span><span class="string">/1</span>     <span class="string">Pending</span>   <span class="number">0</span>          <span class="string">21s</span>     <span class="string">&lt;none&gt;</span>        <span class="string">&lt;none&gt;</span>   </span><br><span class="line"></span><br><span class="line"><span class="comment"># 为node1设置污点(取消NoSchedule，设置NoExecute)</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># kubectl taint nodes node1 tag:NoSchedule-</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># kubectl taint nodes node1 tag=heima:NoExecute</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建pod3</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># kubectl run taint3 --image=nginx:1.17.1 -n dev</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># kubectl get pods -n dev -o wide</span></span><br><span class="line"><span class="string">NAME</span>                      <span class="string">READY</span>   <span class="string">STATUS</span>    <span class="string">RESTARTS</span>   <span class="string">AGE</span>   <span class="string">IP</span>       <span class="string">NODE</span>     <span class="string">NOMINATED</span> </span><br><span class="line"><span class="string">taint1-7665f7fd85-htkmp</span>   <span class="number">0</span><span class="string">/1</span>     <span class="string">Pending</span>   <span class="number">0</span>          <span class="string">35s</span>   <span class="string">&lt;none&gt;</span>   <span class="string">&lt;none&gt;</span>   <span class="string">&lt;none&gt;</span>    </span><br><span class="line"><span class="string">taint2-544694789-bn7wb</span>    <span class="number">0</span><span class="string">/1</span>     <span class="string">Pending</span>   <span class="number">0</span>          <span class="string">35s</span>   <span class="string">&lt;none&gt;</span>   <span class="string">&lt;none&gt;</span>   <span class="string">&lt;none&gt;</span>     </span><br><span class="line"><span class="string">taint3-6d78dbd749-tktkq</span>   <span class="number">0</span><span class="string">/1</span>     <span class="string">Pending</span>   <span class="number">0</span>          <span class="string">6s</span>    <span class="string">&lt;none&gt;</span>   <span class="string">&lt;none&gt;</span>   <span class="string">&lt;none&gt;</span>     </span><br></pre></td></tr></table></figure></div>

<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tr><td class="code"><pre><span class="line">小提示：</span><br><span class="line">    使用kubeadm搭建的集群，默认就会给master节点添加一个污点标记,所以pod就不会调度到master节点上.</span><br></pre></td></tr></table></figure></div>

<p><strong>容忍（Toleration）</strong></p>
<p>上面介绍了污点的作用，我们可以在node上添加污点用于拒绝pod调度上来，但是如果就是想将一个pod调度到一个有污点的node上去，这时候应该怎么做呢？这就要使用到<strong>容忍</strong>。</p>
<p><img src="/2022/06/09/uncatalog/cl46zbayg000v7or7a4o0f4yd/image-20200514095913741.png" alt="image-20200514095913741"></p>
<blockquote>
<p>污点就是拒绝，容忍就是忽略，Node通过污点拒绝pod调度上去，Pod通过容忍忽略拒绝</p>
</blockquote>
<p>下面先通过一个案例看下效果：</p>
<ol>
<li>上一小节，已经在node1节点上打上了<code>NoExecute</code>的污点，此时pod是调度不上去的</li>
<li>本小节，可以通过给pod添加容忍，然后将其调度上去</li>
</ol>
<p>创建pod-toleration.yaml,内容如下</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-toleration</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br><span class="line">  <span class="attr">tolerations:</span>      <span class="comment"># 添加容忍</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">&quot;tag&quot;</span>        <span class="comment"># 要容忍的污点的key</span></span><br><span class="line">    <span class="attr">operator:</span> <span class="string">&quot;Equal&quot;</span> <span class="comment"># 操作符</span></span><br><span class="line">    <span class="attr">value:</span> <span class="string">&quot;heima&quot;</span>    <span class="comment"># 容忍的污点的value</span></span><br><span class="line">    <span class="attr">effect:</span> <span class="string">&quot;NoExecute&quot;</span>   <span class="comment"># 添加容忍的规则，这里必须和标记的污点规则相同</span></span><br></pre></td></tr></table></figure></div>

<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 添加容忍之前的pod</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># kubectl get pods -n dev -o wide</span></span><br><span class="line"><span class="string">NAME</span>             <span class="string">READY</span>   <span class="string">STATUS</span>    <span class="string">RESTARTS</span>   <span class="string">AGE</span>   <span class="string">IP</span>       <span class="string">NODE</span>     <span class="string">NOMINATED</span> </span><br><span class="line"><span class="string">pod-toleration</span>   <span class="number">0</span><span class="string">/1</span>     <span class="string">Pending</span>   <span class="number">0</span>          <span class="string">3s</span>    <span class="string">&lt;none&gt;</span>   <span class="string">&lt;none&gt;</span>   <span class="string">&lt;none&gt;</span>           </span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加容忍之后的pod</span></span><br><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># kubectl get pods -n dev -o wide</span></span><br><span class="line"><span class="string">NAME</span>             <span class="string">READY</span>   <span class="string">STATUS</span>    <span class="string">RESTARTS</span>   <span class="string">AGE</span>   <span class="string">IP</span>            <span class="string">NODE</span>    <span class="string">NOMINATED</span></span><br><span class="line"><span class="string">pod-toleration</span>   <span class="number">1</span><span class="string">/1</span>     <span class="string">Running</span>   <span class="number">0</span>          <span class="string">3s</span>    <span class="number">10.244</span><span class="number">.1</span><span class="number">.62</span>   <span class="string">node1</span>   <span class="string">&lt;none&gt;</span>        </span><br></pre></td></tr></table></figure></div>

<p>下面看一下容忍的详细配置:</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line">[<span class="string">root@k8s-master01</span> <span class="string">~</span>]<span class="comment"># kubectl explain pod.spec.tolerations</span></span><br><span class="line"><span class="string">......</span></span><br><span class="line"><span class="attr">FIELDS:</span></span><br><span class="line">   <span class="string">key</span>       <span class="comment"># 对应着要容忍的污点的键，空意味着匹配所有的键</span></span><br><span class="line">   <span class="string">value</span>     <span class="comment"># 对应着要容忍的污点的值</span></span><br><span class="line">   <span class="string">operator</span>  <span class="comment"># key-value的运算符，支持Equal和Exists（默认）</span></span><br><span class="line">   <span class="string">effect</span>    <span class="comment"># 对应污点的effect，空意味着匹配所有影响</span></span><br><span class="line">   <span class="string">tolerationSeconds</span>   <span class="comment"># 容忍时间, 当effect为NoExecute时生效，表示pod在Node上的停留时间</span></span><br></pre></td></tr></table></figure></div>

]]></content>
      <tags>
        <tag>云原生基础系列</tag>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>云原生基础系列之Docker(一)基础</title>
    <url>/2022/06/09/uncatalog/cl46zbgi6000y7or7g7cnd6w6/</url>
    <content><![CDATA[<hr>
<span id="more"></span>



<hr>
<h1 id="Docker概述"><a href="#Docker概述" class="headerlink" title="Docker概述"></a>Docker概述</h1><h2 id="Docker为什么会出现？"><a href="#Docker为什么会出现？" class="headerlink" title="Docker为什么会出现？"></a>Docker为什么会出现？</h2><p>一款产品： 开发–上线 两套环境！应用环境，应用配置！</p>
<p>开发 — 运维。 问题：我在我的电脑上可以允许！版本更新，导致服务不可用！对于运维来说考验十分大？</p>
<p>环境配置是十分的麻烦，每一个及其都要部署环境(集群Redis、ES、Hadoop…) !费事费力。</p>
<p>发布一个项目( jar + (Redis MySQL JDK ES) ),项目能不能带上环境安装打包！</p>
<p>之前在服务器配置一个应用的环境 Redis MySQL JDK ES Hadoop 配置超麻烦了，不能够跨平台。</p>
<p>开发环境Windows，最后发布到Linux！</p>
<p><strong>传统：</strong>开发jar，运维来做！</p>
<p><strong>现在：</strong>开发打包部署上线，一套流程做完！</p>
<p><strong>安卓流程：</strong>java — apk —发布（应用商店）一 张三使用apk一安装即可用！</p>
<p><strong>docker流程：</strong> java-jar（环境）— 打包项目帯上环境（镜像）— ( Docker仓库：商店）—下载我们发布的镜像 —直接运行即可！</p>
<p>Docker给以上的问题，提出了解决方案！</p>
<p><img src="/2022/06/09/uncatalog/cl46zbgi6000y7or7g7cnd6w6/image-20200610142308099.png" alt="image-20200610142308099"></p>
<p>Docker的思想来源于集装箱！</p>
<p>JRE —多个应用（端口冲突）—原来都是交叉的！</p>
<p>隔离：Docker核心思想！打包装箱！每个箱子都是相互隔离的。</p>
<p>Docker通过隔离机制可以将服务器利用到极致！</p>
<p>本质：所有的技术都是因为出现了一些问题，我们需要去解决，才去学习！</p>
<h2 id="Docker的历史"><a href="#Docker的历史" class="headerlink" title="Docker的历史"></a>Docker的历史</h2><p>2010年，几个的年轻人，就在美国成立了一家公司 <strong>dotcloud</strong></p>
<p>做一些pass的云计算服务！LXC（Linux Container容器）有关的容器技术！</p>
<p>Linux Container容器是一种内核虚拟化技术，可以提供轻量级的虚拟化，以便隔离进程和资源。</p>
<p>他们将自己的技术（容器化技术）命名就是 Docker</p>
<p>Docker刚刚延生的时候，没有引起行业的注意！dotCloud，就活不下去！</p>
<p><strong>开源</strong></p>
<p>2013年，Docker开源！</p>
<p>越来越多的人发现docker的优点！火了。Docker每个月都会更新一个版本！</p>
<p>2014年4月9日，Docker1.0发布！</p>
<p>docker为什么这么火？十分的轻巧！</p>
<p>在容器技术出来之前，我们都是使用虚拟机技术！</p>
<p>虚拟机：在window中装一个VMware，通过这个软件我们可以虚拟出来一台或者多台电脑！笨重！</p>
<p>虚拟机也属于虚拟化技术，Docker容器技术，也是一种虚拟化技术！</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">VMware : linux centos 原生镜像（一个电脑！） 隔离、需要开启多个虚拟机！ 几个G 几分钟</span><br><span class="line">docker: 隔离，镜像（最核心的环境 4m + jdk + mysql）十分的小巧，运行镜像就可以了！小巧！ 几个M 秒级启动！</span><br></pre></td></tr></table></figure></div>

<blockquote>
<p>聊聊Docker</p>
</blockquote>
<p>Docker基于Go语言开发的！开源项目！</p>
<p>docker官网：<a href="https://www.docker.com/">https://www.docker.com/</a></p>
<p><img src="/2022/06/09/uncatalog/cl46zbgi6000y7or7g7cnd6w6/image-20200610143923433.png" alt="image-20200610143923433"></p>
<p>文档：<a href="https://docs.docker.com/">https://docs.docker.com/</a> Docker的文档是超级详细的！</p>
<p>仓库：<a href="https://hub.docker.com/">https://hub.docker.com/</a></p>
<h2 id="Docker能干嘛"><a href="#Docker能干嘛" class="headerlink" title="Docker能干嘛"></a>Docker能干嘛</h2><blockquote>
<p>之前的虚拟机技术</p>
</blockquote>
<p><img src="/2022/06/09/uncatalog/cl46zbgi6000y7or7g7cnd6w6/image-20200610144126122.png" alt="image-20200610144126122"></p>
<blockquote>
<p>虚拟机技术缺点</p>
</blockquote>
<p>1、 资源占用十分多</p>
<p>2、 冗余步骤多</p>
<p>3、 启动很慢！</p>
<blockquote>
<p>容器技术</p>
</blockquote>
<p>容器化技术不是模拟一个完整的操作系统</p>
<p><img src="/2022/06/09/uncatalog/cl46zbgi6000y7or7g7cnd6w6/image-20200610144338073.png" alt="image-20200610144338073"></p>
<p>比较Docker和虚拟机技术的不同：</p>
<ul>
<li>传统虚拟机，虚拟出一套容器内的应用直接运行在宿主机硬件，运行一个完整的操作系统，然后在这个系统上安装和运行软件</li>
<li>容器内的应用直接运行在宿主机内，容器是没有自己的内核的，也没有虚拟我们的硬件，所以就轻便了</li>
<li>每个容器间是相互隔离的，每个容器内都有一个属于自己的文件系统，互不影响</li>
</ul>
<blockquote>
<p>DevOps (开发、运维)</p>
</blockquote>
<p><strong>应用更快速的交付和部署</strong></p>
<p>传统：一堆帮助文档，安装程序</p>
<p>Docker：打包镜像发布测试，一键运行</p>
<p><strong>更便捷的升级和扩缩容</strong></p>
<p>使用了Docker之后，我们部署应用就和搭积木一样！</p>
<p>项目打包为一个镜像，扩展服务器A! 服务器B</p>
<p><strong>更简单的系统运维</strong></p>
<p>在容器化之后，我们的开发，测试环境都是高度一致的。</p>
<p><strong>更高效的计算资源利用</strong></p>
<p>Docker是内核级别的虚拟化，可以在一个物理机上运行很多个容器实例！服务器的性能可以被压榨到极致。</p>
<hr>
<h1 id="Docker安装"><a href="#Docker安装" class="headerlink" title="Docker安装"></a>Docker安装</h1><h2 id="Docker的基本组成"><a href="#Docker的基本组成" class="headerlink" title="Docker的基本组成"></a>Docker的基本组成</h2><p><img src="/2022/06/09/uncatalog/cl46zbgi6000y7or7g7cnd6w6/image-20200610145818895.png" alt="image-20200610145818895"></p>
<p><strong>镜像（image）：</strong></p>
<p>docker镜像就好比是一个目标，可以通过这个目标来创建容器服务，tomcat镜像==&gt;run==&gt;容器（提供服务器），通过这个镜像可以创建多个容器（最终服务运行或者项目运行就是在容器中的）。</p>
<p><strong>容器（container）:</strong></p>
<p>Docker利用容器技术，独立运行一个或者一组应用，通过镜像来创建的.</p>
<p>启动，停止，删除，基本命令</p>
<p>目前就可以把这个容器理解为就是一个简易的 Linux系统。</p>
<p><strong>仓库（repository）:</strong></p>
<p>仓库就是存放镜像的地方！</p>
<p>仓库分为公有仓库和私有仓库。(很类似git)</p>
<p>Docker Hub是国外的。</p>
<p>阿里云…都有容器服务器 (配置镜像加速!)</p>
<h2 id="安装Docker"><a href="#安装Docker" class="headerlink" title="安装Docker"></a>安装Docker</h2><blockquote>
<p>环境准备</p>
</blockquote>
<p>1.Linux要求内核3.0以上</p>
<p>2.CentOS 7</p>
<blockquote>
<p>环境查看</p>
</blockquote>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">系统内核要求3.0以上</span></span><br><span class="line">[root@localhost ~]# uname -r</span><br><span class="line">3.10.0-1062.el7.x86_64</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">系统版本</span></span><br><span class="line">[root@localhost ~]# cat /etc/os-release </span><br><span class="line">NAME=&quot;CentOS Linux&quot;</span><br><span class="line">VERSION=&quot;7 (Core)&quot;</span><br><span class="line">ID=&quot;centos&quot;</span><br><span class="line">ID_LIKE=&quot;rhel fedora&quot;</span><br><span class="line">VERSION_ID=&quot;7&quot;</span><br><span class="line">PRETTY_NAME=&quot;CentOS Linux 7 (Core)&quot;</span><br><span class="line">ANSI_COLOR=&quot;0;31&quot;</span><br><span class="line">CPE_NAME=&quot;cpe:/o:centos:centos:7&quot;</span><br><span class="line">HOME_URL=&quot;https://www.centos.org/&quot;</span><br><span class="line">BUG_REPORT_URL=&quot;https://bugs.centos.org/&quot;</span><br><span class="line"></span><br><span class="line">CENTOS_MANTISBT_PROJECT=&quot;CentOS-7&quot;</span><br><span class="line">CENTOS_MANTISBT_PROJECT_VERSION=&quot;7&quot;</span><br><span class="line">REDHAT_SUPPORT_PRODUCT=&quot;centos&quot;</span><br><span class="line">REDHAT_SUPPORT_PRODUCT_VERSION=&quot;7&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>



<blockquote>
<p>安装</p>
</blockquote>
<p>帮助文档：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">1.卸载旧版本</span></span><br><span class="line"> yum remove docker \</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">                   docker-client \</span></span><br><span class="line"><span class="bash">&gt;                   docker-client-latest \</span></span><br><span class="line"><span class="bash">&gt;                   docker-common \</span></span><br><span class="line"><span class="bash">&gt;                   docker-latest \</span></span><br><span class="line"><span class="bash">&gt;                   docker-latest-logrotate \</span></span><br><span class="line"><span class="bash">&gt;                   docker-logrotate \</span></span><br><span class="line"><span class="bash">&gt;                   docker-engine</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">2.需要的安装包</span></span><br><span class="line">yum install -y yum-utils</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">3.设置镜像的仓库</span></span><br><span class="line">yum-config-manager \</span><br><span class="line">    --add-repo \</span><br><span class="line">    https://download.docker.com/linux/centos/docker-ce.repo</span><br><span class="line"><span class="meta">#</span><span class="bash">上述方法默认是从国外的，不推荐</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">推荐使用国内的</span></span><br><span class="line">yum-config-manager \</span><br><span class="line">    --add-repo \</span><br><span class="line">    https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</span><br><span class="line">  </span><br><span class="line"><span class="meta">#</span><span class="bash">更新软件包索引</span></span><br><span class="line">yum makecache fast</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">4.安装docker docker-ce 社区版 而ee是企业版</span></span><br><span class="line">yum install docker-ce docker-ce-cli containerd.io # 这里我们使用社区版即可</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">5.启动docker</span></span><br><span class="line">systemctl start docker</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">6.使用docker version 查看是否安装成功</span></span><br><span class="line">docker version</span><br></pre></td></tr></table></figure></div>

<p><img src="/2022/06/09/uncatalog/cl46zbgi6000y7or7g7cnd6w6/image-20200610153718450.png" alt="image-20200610153718450"></p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">7.测试</span></span><br><span class="line">docker run hello-world</span><br></pre></td></tr></table></figure></div>

<p><img src="/2022/06/09/uncatalog/cl46zbgi6000y7or7g7cnd6w6/image-20200610154108118.png" alt="image-20200610154108118"></p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">8.查看一下下载的hello-world镜像</span></span><br><span class="line">[root@localhost /]# docker images</span><br><span class="line">REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">hello-world         latest              bf756fb1ae65        5 months ago        13.3kB</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>

<p>了解：卸载docker</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">1.卸载依赖</span></span><br><span class="line">yum remove docker-ce docker-ce-cli containerd.io</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">2. 删除资源</span></span><br><span class="line">rm -rf /var/lib/docker</span><br><span class="line"><span class="meta">#</span><span class="bash"> /var/lib/docker 是docker的默认工作路径！</span></span><br></pre></td></tr></table></figure></div>

<p>阿里云镜像加速</p>
<p><strong>1、登录阿里云找到容器服务——&gt;镜像加速器</strong></p>
<p><img src="/2022/06/09/uncatalog/cl46zbgi6000y7or7g7cnd6w6/image-20200610155156310.png" alt="image-20200610155156310"></p>
<p><strong>2、配置使用</strong></p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">sudo mkdir -p /etc/docker</span><br><span class="line"></span><br><span class="line">sudo tee /etc/docker/daemon.json &lt;&lt;-&#x27;EOF&#x27;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;registry-mirrors&quot;: [&quot;https://cdoid6va.mirror.aliyuncs.com&quot;]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">sudo systemctl daemon-reload</span><br><span class="line"></span><br><span class="line">sudo systemctl restart docker</span><br></pre></td></tr></table></figure></div>



<h2 id="回顾hello-world流程"><a href="#回顾hello-world流程" class="headerlink" title="回顾hello-world流程"></a>回顾hello-world流程</h2><p><img src="/2022/06/09/uncatalog/cl46zbgi6000y7or7g7cnd6w6/image-20200610160359287.png" alt="image-20200610160359287"></p>
<p><strong>docker run 流程图</strong></p>
<p><img src="/2022/06/09/uncatalog/cl46zbgi6000y7or7g7cnd6w6/image-20200610160609037.png" alt="image-20200610160609037"></p>
<h2 id="底层原理"><a href="#底层原理" class="headerlink" title="底层原理"></a>底层原理</h2><p><strong>Docker是怎么工作的？</strong></p>
<p>Docker是一个Client-Server结构的系统，Docker的守护进程运行在宿主机上，通过Socket从客户端访问！</p>
<p>DockerServer接受到Docker-Client的指令，就会执行这个命令！</p>
<p><img src="/2022/06/09/uncatalog/cl46zbgi6000y7or7g7cnd6w6/image-20200610161147612.png" alt="image-20200610161147612"></p>
<p><strong>Docker为什么比VM快？</strong></p>
<p>1、Docker有着比虚拟机更少的抽象层</p>
<p>2、Docker利用的是宿主机的内核，vm需要Guest Os。</p>
<p><img src="/2022/06/09/uncatalog/cl46zbgi6000y7or7g7cnd6w6/image-20200610161342662.png" alt="image-20200610161342662"></p>
<p>所以说，新建一个容器的时候，docker不需要像虚拟机一样重新加载一个操作系统内核，避免引导。虚拟机是加载Guest Os，分钟级别的，而docker是利用当前宿主机的操作系统，省略了复杂的过程，秒级的！</p>
<p><img src="/2022/06/09/uncatalog/cl46zbgi6000y7or7g7cnd6w6/image-20200610161845790.png" alt="image-20200610161845790"></p>
<hr>
<h1 id="Docker的常用命令"><a href="#Docker的常用命令" class="headerlink" title="Docker的常用命令"></a>Docker的常用命令</h1><h2 id="帮助命令"><a href="#帮助命令" class="headerlink" title="帮助命令"></a>帮助命令</h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">docker version     # 显示docker的版本信息</span><br><span class="line">docker info        # 显示docker的系统信息，包括镜像和容器的数量</span><br><span class="line">docker 命令 --help  # 帮助命令</span><br></pre></td></tr></table></figure></div>

<p>帮助文档的地址：<a href="https://docs.docker.com/engine/reference/commandline/build/">https://docs.docker.com/engine/reference/commandline/build/</a></p>
<h2 id="镜像命令"><a href="#镜像命令" class="headerlink" title="镜像命令"></a>镜像命令</h2><p><strong>docker images</strong></p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">[root@localhost /]# docker images</span><br><span class="line">REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">hello-world         latest              bf756fb1ae65        5 months ago        13.3kB</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">解释</span></span><br><span class="line">REPOSITORY  镜像的仓库源</span><br><span class="line">TAG         镜像标签</span><br><span class="line">IMAGE ID    镜像id</span><br><span class="line">CREATED     镜像的创建时间</span><br><span class="line">SIZE        镜像的大小</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">可选项</span></span><br><span class="line">Options:</span><br><span class="line">  -a, --all             # 列出所有镜像</span><br><span class="line">  -q, --quiet           # 只显示镜像id</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>

<p><strong>docker search 搜索镜像</strong></p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">[root@localhost /]# docker search mysql</span><br><span class="line">NAME                              DESCRIPTION                                     STARS               OFFICIAL            AUTOMATED</span><br><span class="line">mysql                             MySQL is a widely used, open-source relation…   9604                [OK]                </span><br><span class="line">mariadb                           MariaDB is a community-developed fork of MyS…   3490                [OK]                </span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">可选项，通过收藏来过滤</span></span><br><span class="line">--filter=STARS=3000  #搜索出来的镜像就是STARS大于3000的</span><br><span class="line">[root@localhost /]# docker search mysql --filter=STARS=3000</span><br><span class="line">NAME                DESCRIPTION                                     STARS               OFFICIAL            AUTOMATED</span><br><span class="line">mysql               MySQL is a widely used, open-source relation…   9604                [OK]                </span><br><span class="line">mariadb             MariaDB is a community-developed fork of MyS…   3490                [OK]                </span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure></div>

<p><strong>docker pull 下载镜像</strong></p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 下载镜像 docker pull 镜像名[:tag]</span></span><br><span class="line">[root@localhost /]# docker pull mysql</span><br><span class="line">Using default tag: latest    # 如果不写 tag,默认就是latest</span><br><span class="line">latest: Pulling from library/mysql</span><br><span class="line">8559a31e96f4: Pull complete  # 分层下载，docker image的核心 联合文件系统</span><br><span class="line">d51ce1c2e575: Pull complete </span><br><span class="line">c2344adc4858: Pull complete </span><br><span class="line">fcf3ceff18fc: Pull complete </span><br><span class="line">16da0c38dc5b: Pull complete </span><br><span class="line">b905d1797e97: Pull complete </span><br><span class="line">4b50d1c6b05c: Pull complete </span><br><span class="line">c75914a65ca2: Pull complete </span><br><span class="line">1ae8042bdd09: Pull complete </span><br><span class="line">453ac13c00a3: Pull complete </span><br><span class="line">9e680cd72f08: Pull complete </span><br><span class="line">a6b5dc864b6c: Pull complete </span><br><span class="line">Digest: sha256:8b7b328a7ff6de46ef96bcf83af048cb00a1c86282bfca0cb119c84568b4caf6 # 签名</span><br><span class="line">Status: Downloaded newer image for mysql:latest</span><br><span class="line">docker.io/library/mysql:latest  # 真实地址</span><br><span class="line"></span><br><span class="line">docker pull mysql 等价于: docker pull docker.io/library/mysql:latest</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 指定版本下载</span></span><br><span class="line">[root@localhost /]# docker pull mysql:5.7</span><br><span class="line">5.7: Pulling from library/mysql</span><br><span class="line">8559a31e96f4: Already exists   # 联合文件系统的好处：上面下载过的MySQL与5.7版本的MySQL有相同的文件时不需要重复下载</span><br><span class="line">d51ce1c2e575: Already exists </span><br><span class="line">c2344adc4858: Already exists </span><br><span class="line">fcf3ceff18fc: Already exists </span><br><span class="line">16da0c38dc5b: Already exists </span><br><span class="line">b905d1797e97: Already exists </span><br><span class="line">4b50d1c6b05c: Already exists </span><br><span class="line">d85174a87144: Pull complete </span><br><span class="line">a4ad33703fa8: Pull complete </span><br><span class="line">f7a5433ce20d: Pull complete </span><br><span class="line">3dcd2a278b4a: Pull complete </span><br><span class="line">Digest: sha256:32f9d9a069f7a735e28fd44ea944d53c61f990ba71460c5c183e610854ca4854</span><br><span class="line">Status: Downloaded newer image for mysql:5.7</span><br><span class="line">docker.io/library/mysql:5.7</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>

<p><img src="/2022/06/09/uncatalog/cl46zbgi6000y7or7g7cnd6w6/image-20200610165130055.png" alt="image-20200610165130055"></p>
<p><strong>docker rmi 删除镜像</strong></p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">[root@localhost /]# docker rmi -f 镜像id  				 #删除指定镜像</span><br><span class="line">[root@localhost /]# docker rmi -f 镜像id 镜像id 镜像id  	   #删除多个镜像</span><br><span class="line">[root@localhost /]# docker rmi -f $(docker images -aq)     #删除全部镜像</span><br></pre></td></tr></table></figure></div>

<h2 id="容器命令"><a href="#容器命令" class="headerlink" title="容器命令"></a>容器命令</h2><p><strong>说明：有了镜像才可以创建容器，linux,下载一个centos镜像来学习</strong></p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">docker pull centos</span><br></pre></td></tr></table></figure></div>

<p><strong>新建容器并启动</strong></p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">docker run [可选参数] image</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 参数说明</span></span><br><span class="line">--name=&quot;Name&quot;	容器名字 tomcat01 tomcat02 ，用来区分容器</span><br><span class="line">-d              后台方式运行</span><br><span class="line">-it             使用交互方式运行，进入容器查看内容</span><br><span class="line">-p              指定容器的端口 -p 8080:80</span><br><span class="line">	-p  ip:主机(即宿主机)端口：容器端口</span><br><span class="line">	-p  主机端口：容器端口  #这种方式常用</span><br><span class="line">	-p  容器端口</span><br><span class="line">	容器端口P</span><br><span class="line">-P              随机指定端口(大写P)</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 测试，启动并进入容器</span></span><br><span class="line">[root@localhost /]# docker run -it centos /bin/bash</span><br><span class="line">[root@8b4c74381205 /]# ls     #查看容器内的centos,基础版本，很多命令都是不完善的！</span><br><span class="line">bin  etc   lib	  lost+found  mnt  proc  run   srv  tmp  var</span><br><span class="line">dev  home  lib64  media       opt  root  sbin  sys  usr</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 从容器中退回主机</span></span><br><span class="line">[root@8b4c74381205 /]# exit</span><br><span class="line">exit</span><br><span class="line">[root@localhost /]# ls</span><br><span class="line">123  bin   dev  home  lib64  mnt  proc  run   srv  tmp  var</span><br><span class="line">222  boot  etc  lib   media  opt  root  sbin  sys  usr</span><br></pre></td></tr></table></figure></div>

<p><strong>列出所有运行的容器</strong></p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> docker ps 命令</span></span><br><span class="line">(不加） # 列出当前正在运行的容器</span><br><span class="line">-a     # 列出当前正在运行的容器 + 带出历史运行过的容器</span><br><span class="line">-n=?   # 显示最近创建的容器</span><br><span class="line">-q    # 只显示当前容器的编号</span><br><span class="line">[root@localhost /]# docker ps</span><br><span class="line">CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES</span><br><span class="line">[root@localhost /]# docker ps -a</span><br><span class="line">CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS                          PORTS               NAMES</span><br><span class="line">8b4c74381205        centos              &quot;/bin/bash&quot;         4 minutes ago       Exited (0) About a minute ago                       epic_wilson</span><br><span class="line">fb87667bbc19        bf756fb1ae65        &quot;/hello&quot;            2 hours ago         Exited (0) 2 hours ago                              awesome_banach</span><br><span class="line">[root@localhost /]# docker ps -a -n=1</span><br><span class="line">CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS                     PORTS               NAMES</span><br><span class="line">8b4c74381205        centos              &quot;/bin/bash&quot;         9 minutes ago       Exited (0) 6 minutes ago                       epic_wilson</span><br><span class="line">[root@localhost /]# docker ps -aq</span><br><span class="line">8b4c74381205</span><br><span class="line">fb87667bbc19</span><br></pre></td></tr></table></figure></div>

<p><strong>退出容器</strong></p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">exit   # 直接退出容器</span><br><span class="line">Ctrl + p + q  # 容器不停止退出</span><br></pre></td></tr></table></figure></div>

<p><strong>删除容器</strong></p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">docker rm 容器id				   # 删除指定容器，不能删除正在运行的容器，如果要强制删除 rm -f</span><br><span class="line">docker rm -f $(docker ps -aq)    # 删除所有容器 </span><br><span class="line">docker ps -a -q|xargs docker rm  # 删除所有容器</span><br></pre></td></tr></table></figure></div>

<p><strong>启动和停止容器的操作</strong></p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">docker start 容器id     # 启动容器</span><br><span class="line">docker restart 容器id   # 重启容器</span><br><span class="line">docker stop 容器id      # 停止当前正在运行的容器</span><br><span class="line">docker kill 容器id      # 强制停止当前正在运行的容器</span><br></pre></td></tr></table></figure></div>

<h2 id="常用其他命令"><a href="#常用其他命令" class="headerlink" title="常用其他命令"></a>常用其他命令</h2><p><strong>后台启动容器</strong></p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 命令 docker run -d 镜像名</span></span><br><span class="line"></span><br><span class="line">[root@localhost /]# docker run -d centos</span><br><span class="line">e9d60f206fa19963203db6c42c2f83c5120eb90eeee2b7ba9fdc4589370fd6b6</span><br><span class="line">[root@localhost /]# docker ps</span><br><span class="line">CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 问题docker ps,发现 centos 停止了</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 常见的坑，docker 容器使用后台运行，就必须要有一个前台进程，docker发现没有应用，就会自动停止</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> nginx,容器启动后，发现自己没有提供服务，就会立刻停止，就是没有程序了</span></span><br></pre></td></tr></table></figure></div>

<p><strong>查看日志</strong></p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">docker logs -f -t --tail 数字 容器id</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 显示日志</span></span><br><span class="line">-tf 	# 显示日志</span><br><span class="line">--tail  # 要显示的日志条数</span><br><span class="line">[root@localhost /]# docker logs -tf --tail 10 ce989f90023d </span><br></pre></td></tr></table></figure></div>

<p><strong>查看容器中进程信息</strong></p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 命令 docker top 容器id</span></span><br><span class="line">[root@localhost /]# docker top ce989f90023d</span><br><span class="line">UID                 PID                 PPID                C                   STIME               TTY                 TIME     </span><br><span class="line">root                12249               12232               0                   22:44               pts/0               00:00:00 </span><br></pre></td></tr></table></figure></div>

<p><strong>查看镜像的元数据</strong></p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 命令</span></span><br><span class="line">docker inspect 容器id</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 测试</span></span><br><span class="line">[root@localhost /]# docker inspect ce989f90023d</span><br><span class="line">[</span><br><span class="line">    &#123;</span><br><span class="line">        &quot;Id&quot;: &quot;ce989f90023dedc0b3f39c057b91f5c0b17180b3aef7aea0df8c93731e724244&quot;,</span><br><span class="line">        &quot;Created&quot;: &quot;2020-06-10T14:44:45.025360147Z&quot;,</span><br><span class="line">        &quot;Path&quot;: &quot;/bin/bash&quot;,</span><br><span class="line">        &quot;Args&quot;: [],</span><br><span class="line">        &quot;State&quot;: &#123;</span><br><span class="line">            &quot;Status&quot;: &quot;running&quot;,</span><br><span class="line">            &quot;Running&quot;: true,</span><br><span class="line">            &quot;Paused&quot;: false,</span><br><span class="line">            &quot;Restarting&quot;: false,</span><br><span class="line">            &quot;OOMKilled&quot;: false,</span><br><span class="line">            &quot;Dead&quot;: false,</span><br><span class="line">            &quot;Pid&quot;: 12249,</span><br><span class="line">            &quot;ExitCode&quot;: 0,</span><br><span class="line">            &quot;Error&quot;: &quot;&quot;,</span><br><span class="line">            &quot;StartedAt&quot;: &quot;2020-06-10T14:44:45.770227584Z&quot;,</span><br><span class="line">            &quot;FinishedAt&quot;: &quot;0001-01-01T00:00:00Z&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;Image&quot;: &quot;sha256:470671670cac686c7cf0081e0b37da2e9f4f768ddc5f6a26102ccd1c6954c1ee&quot;,</span><br><span class="line">        &quot;ResolvConfPath&quot;: &quot;/var/lib/docker/containers/ce989f90023dedc0b3f39c057b91f5c0b17180b3aef7aea0df8c93731e724244/resolv.conf&quot;,</span><br><span class="line">        &quot;HostnamePath&quot;: &quot;/var/lib/docker/containers/ce989f90023dedc0b3f39c057b91f5c0b17180b3aef7aea0df8c93731e724244/hostname&quot;,</span><br><span class="line">        &quot;HostsPath&quot;: &quot;/var/lib/docker/containers/ce989f90023dedc0b3f39c057b91f5c0b17180b3aef7aea0df8c93731e724244/hosts&quot;,</span><br><span class="line">        &quot;LogPath&quot;: &quot;/var/lib/docker/containers/ce989f90023dedc0b3f39c057b91f5c0b17180b3aef7aea0df8c93731e724244/ce989f90023dedc0b3f39c057b91f5c0b17180b3aef7aea0df8c93731e724244-json.log&quot;,</span><br><span class="line">        &quot;Name&quot;: &quot;/nifty_johnson&quot;,</span><br><span class="line">        &quot;RestartCount&quot;: 0,</span><br><span class="line">        &quot;Driver&quot;: &quot;overlay2&quot;,</span><br><span class="line">        &quot;Platform&quot;: &quot;linux&quot;,</span><br><span class="line">        &quot;MountLabel&quot;: &quot;&quot;,</span><br><span class="line">        &quot;ProcessLabel&quot;: &quot;&quot;,</span><br><span class="line">        &quot;AppArmorProfile&quot;: &quot;&quot;,</span><br><span class="line">        &quot;ExecIDs&quot;: null,</span><br><span class="line">        &quot;HostConfig&quot;: &#123;</span><br><span class="line">            &quot;Binds&quot;: null,</span><br><span class="line">            &quot;ContainerIDFile&quot;: &quot;&quot;,</span><br><span class="line">            &quot;LogConfig&quot;: &#123;</span><br><span class="line">                &quot;Type&quot;: &quot;json-file&quot;,</span><br><span class="line">                &quot;Config&quot;: &#123;&#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;NetworkMode&quot;: &quot;default&quot;,</span><br><span class="line">            &quot;PortBindings&quot;: &#123;&#125;,</span><br><span class="line">            &quot;RestartPolicy&quot;: &#123;</span><br><span class="line">                &quot;Name&quot;: &quot;no&quot;,</span><br><span class="line">                &quot;MaximumRetryCount&quot;: 0</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;AutoRemove&quot;: false,</span><br><span class="line">            &quot;VolumeDriver&quot;: &quot;&quot;,</span><br><span class="line">            &quot;VolumesFrom&quot;: null,</span><br><span class="line">            &quot;CapAdd&quot;: null,</span><br><span class="line">            &quot;CapDrop&quot;: null,</span><br><span class="line">            &quot;Capabilities&quot;: null,</span><br><span class="line">            &quot;Dns&quot;: [],</span><br><span class="line">            &quot;DnsOptions&quot;: [],</span><br><span class="line">            &quot;DnsSearch&quot;: [],</span><br><span class="line">            &quot;ExtraHosts&quot;: null,</span><br><span class="line">            &quot;GroupAdd&quot;: null,</span><br><span class="line">            &quot;IpcMode&quot;: &quot;private&quot;,</span><br><span class="line">            &quot;Cgroup&quot;: &quot;&quot;,</span><br><span class="line">            &quot;Links&quot;: null,</span><br><span class="line">            &quot;OomScoreAdj&quot;: 0,</span><br><span class="line">            &quot;PidMode&quot;: &quot;&quot;,</span><br><span class="line">            &quot;Privileged&quot;: false,</span><br><span class="line">            &quot;PublishAllPorts&quot;: false,</span><br><span class="line">            &quot;ReadonlyRootfs&quot;: false,</span><br><span class="line">            &quot;SecurityOpt&quot;: null,</span><br><span class="line">            &quot;UTSMode&quot;: &quot;&quot;,</span><br><span class="line">            &quot;UsernsMode&quot;: &quot;&quot;,</span><br><span class="line">            &quot;ShmSize&quot;: 67108864,</span><br><span class="line">            &quot;Runtime&quot;: &quot;runc&quot;,</span><br><span class="line">            &quot;ConsoleSize&quot;: [</span><br><span class="line">                0,</span><br><span class="line">                0</span><br><span class="line">            ],</span><br><span class="line">            &quot;Isolation&quot;: &quot;&quot;,</span><br><span class="line">            &quot;CpuShares&quot;: 0,</span><br><span class="line">            &quot;Memory&quot;: 0,</span><br><span class="line">            &quot;NanoCpus&quot;: 0,</span><br><span class="line">            &quot;CgroupParent&quot;: &quot;&quot;,</span><br><span class="line">            &quot;BlkioWeight&quot;: 0,</span><br><span class="line">            &quot;BlkioWeightDevice&quot;: [],</span><br><span class="line">            &quot;BlkioDeviceReadBps&quot;: null,</span><br><span class="line">            &quot;BlkioDeviceWriteBps&quot;: null,</span><br><span class="line">            &quot;BlkioDeviceReadIOps&quot;: null,</span><br><span class="line">            &quot;BlkioDeviceWriteIOps&quot;: null,</span><br><span class="line">            &quot;CpuPeriod&quot;: 0,</span><br><span class="line">            &quot;CpuQuota&quot;: 0,</span><br><span class="line">            &quot;CpuRealtimePeriod&quot;: 0,</span><br><span class="line">            &quot;CpuRealtimeRuntime&quot;: 0,</span><br><span class="line">            &quot;CpusetCpus&quot;: &quot;&quot;,</span><br><span class="line">            &quot;CpusetMems&quot;: &quot;&quot;,</span><br><span class="line">            &quot;Devices&quot;: [],</span><br><span class="line">            &quot;DeviceCgroupRules&quot;: null,</span><br><span class="line">            &quot;DeviceRequests&quot;: null,</span><br><span class="line">            &quot;KernelMemory&quot;: 0,</span><br><span class="line">            &quot;KernelMemoryTCP&quot;: 0,</span><br><span class="line">            &quot;MemoryReservation&quot;: 0,</span><br><span class="line">            &quot;MemorySwap&quot;: 0,</span><br><span class="line">            &quot;MemorySwappiness&quot;: null,</span><br><span class="line">            &quot;OomKillDisable&quot;: false,</span><br><span class="line">            &quot;PidsLimit&quot;: null,</span><br><span class="line">            &quot;Ulimits&quot;: null,</span><br><span class="line">            &quot;CpuCount&quot;: 0,</span><br><span class="line">            &quot;CpuPercent&quot;: 0,</span><br><span class="line">            &quot;IOMaximumIOps&quot;: 0,</span><br><span class="line">            &quot;IOMaximumBandwidth&quot;: 0,</span><br><span class="line">            &quot;MaskedPaths&quot;: [</span><br><span class="line">                &quot;/proc/asound&quot;,</span><br><span class="line">                &quot;/proc/acpi&quot;,</span><br><span class="line">                &quot;/proc/kcore&quot;,</span><br><span class="line">                &quot;/proc/keys&quot;,</span><br><span class="line">                &quot;/proc/latency_stats&quot;,</span><br><span class="line">                &quot;/proc/timer_list&quot;,</span><br><span class="line">                &quot;/proc/timer_stats&quot;,</span><br><span class="line">                &quot;/proc/sched_debug&quot;,</span><br><span class="line">                &quot;/proc/scsi&quot;,</span><br><span class="line">                &quot;/sys/firmware&quot;</span><br><span class="line">            ],</span><br><span class="line">            &quot;ReadonlyPaths&quot;: [</span><br><span class="line">                &quot;/proc/bus&quot;,</span><br><span class="line">                &quot;/proc/fs&quot;,</span><br><span class="line">                &quot;/proc/irq&quot;,</span><br><span class="line">                &quot;/proc/sys&quot;,</span><br><span class="line">                &quot;/proc/sysrq-trigger&quot;</span><br><span class="line">            ]</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;GraphDriver&quot;: &#123;</span><br><span class="line">            &quot;Data&quot;: &#123;</span><br><span class="line">                &quot;LowerDir&quot;: &quot;/var/lib/docker/overlay2/bce8b2400427de29dd406d54ec08b3c07dc95530e80d37977a156ca971b37641-init/diff:/var/lib/docker/overlay2/d4cd3bedb1e7340e62bb292c1e0d5ae37b1d1689ffc1640da67b2a8325facc21/diff&quot;,</span><br><span class="line">                &quot;MergedDir&quot;: &quot;/var/lib/docker/overlay2/bce8b2400427de29dd406d54ec08b3c07dc95530e80d37977a156ca971b37641/merged&quot;,</span><br><span class="line">                &quot;UpperDir&quot;: &quot;/var/lib/docker/overlay2/bce8b2400427de29dd406d54ec08b3c07dc95530e80d37977a156ca971b37641/diff&quot;,</span><br><span class="line">                &quot;WorkDir&quot;: &quot;/var/lib/docker/overlay2/bce8b2400427de29dd406d54ec08b3c07dc95530e80d37977a156ca971b37641/work&quot;</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;Name&quot;: &quot;overlay2&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;Mounts&quot;: [],</span><br><span class="line">        &quot;Config&quot;: &#123;</span><br><span class="line">            &quot;Hostname&quot;: &quot;ce989f90023d&quot;,</span><br><span class="line">            &quot;Domainname&quot;: &quot;&quot;,</span><br><span class="line">            &quot;User&quot;: &quot;&quot;,</span><br><span class="line">            &quot;AttachStdin&quot;: true,</span><br><span class="line">            &quot;AttachStdout&quot;: true,</span><br><span class="line">            &quot;AttachStderr&quot;: true,</span><br><span class="line">            &quot;Tty&quot;: true,</span><br><span class="line">            &quot;OpenStdin&quot;: true,</span><br><span class="line">            &quot;StdinOnce&quot;: true,</span><br><span class="line">            &quot;Env&quot;: [</span><br><span class="line">                &quot;PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin&quot;</span><br><span class="line">            ],</span><br><span class="line">            &quot;Cmd&quot;: [</span><br><span class="line">                &quot;/bin/bash&quot;</span><br><span class="line">            ],</span><br><span class="line">            &quot;Image&quot;: &quot;centos&quot;,</span><br><span class="line">            &quot;Volumes&quot;: null,</span><br><span class="line">            &quot;WorkingDir&quot;: &quot;&quot;,</span><br><span class="line">            &quot;Entrypoint&quot;: null,</span><br><span class="line">            &quot;OnBuild&quot;: null,</span><br><span class="line">            &quot;Labels&quot;: &#123;</span><br><span class="line">                &quot;org.label-schema.build-date&quot;: &quot;20200114&quot;,</span><br><span class="line">                &quot;org.label-schema.license&quot;: &quot;GPLv2&quot;,</span><br><span class="line">                &quot;org.label-schema.name&quot;: &quot;CentOS Base Image&quot;,</span><br><span class="line">                &quot;org.label-schema.schema-version&quot;: &quot;1.0&quot;,</span><br><span class="line">                &quot;org.label-schema.vendor&quot;: &quot;CentOS&quot;,</span><br><span class="line">                &quot;org.opencontainers.image.created&quot;: &quot;2020-01-14 00:00:00-08:00&quot;,</span><br><span class="line">                &quot;org.opencontainers.image.licenses&quot;: &quot;GPL-2.0-only&quot;,</span><br><span class="line">                &quot;org.opencontainers.image.title&quot;: &quot;CentOS Base Image&quot;,</span><br><span class="line">                &quot;org.opencontainers.image.vendor&quot;: &quot;CentOS&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;NetworkSettings&quot;: &#123;</span><br><span class="line">            &quot;Bridge&quot;: &quot;&quot;,</span><br><span class="line">            &quot;SandboxID&quot;: &quot;74d140bbc60432c5fdce865fa48f78c1138923dd292e708a25c4de17de812d56&quot;,</span><br><span class="line">            &quot;HairpinMode&quot;: false,</span><br><span class="line">            &quot;LinkLocalIPv6Address&quot;: &quot;&quot;,</span><br><span class="line">            &quot;LinkLocalIPv6PrefixLen&quot;: 0,</span><br><span class="line">            &quot;Ports&quot;: &#123;&#125;,</span><br><span class="line">            &quot;SandboxKey&quot;: &quot;/var/run/docker/netns/74d140bbc604&quot;,</span><br><span class="line">            &quot;SecondaryIPAddresses&quot;: null,</span><br><span class="line">            &quot;SecondaryIPv6Addresses&quot;: null,</span><br><span class="line">            &quot;EndpointID&quot;: &quot;3580dd1064b07f434c61e316f14cb7d7b53a3d6d7c9c0f77eb6570f1781623bc&quot;,</span><br><span class="line">            &quot;Gateway&quot;: &quot;172.17.0.1&quot;,</span><br><span class="line">            &quot;GlobalIPv6Address&quot;: &quot;&quot;,</span><br><span class="line">            &quot;GlobalIPv6PrefixLen&quot;: 0,</span><br><span class="line">            &quot;IPAddress&quot;: &quot;172.17.0.3&quot;,</span><br><span class="line">            &quot;IPPrefixLen&quot;: 16,</span><br><span class="line">            &quot;IPv6Gateway&quot;: &quot;&quot;,</span><br><span class="line">            &quot;MacAddress&quot;: &quot;02:42:ac:11:00:03&quot;,</span><br><span class="line">            &quot;Networks&quot;: &#123;</span><br><span class="line">                &quot;bridge&quot;: &#123;</span><br><span class="line">                    &quot;IPAMConfig&quot;: null,</span><br><span class="line">                    &quot;Links&quot;: null,</span><br><span class="line">                    &quot;Aliases&quot;: null,</span><br><span class="line">                    &quot;NetworkID&quot;: &quot;58fd9703e96d12128c30f244be3205e3fe31fc7d1fb7fffdddba72d981e782f4&quot;,</span><br><span class="line">                    &quot;EndpointID&quot;: &quot;3580dd1064b07f434c61e316f14cb7d7b53a3d6d7c9c0f77eb6570f1781623bc&quot;,</span><br><span class="line">                    &quot;Gateway&quot;: &quot;172.17.0.1&quot;,</span><br><span class="line">                    &quot;IPAddress&quot;: &quot;172.17.0.3&quot;,</span><br><span class="line">                    &quot;IPPrefixLen&quot;: 16,</span><br><span class="line">                    &quot;IPv6Gateway&quot;: &quot;&quot;,</span><br><span class="line">                    &quot;GlobalIPv6Address&quot;: &quot;&quot;,</span><br><span class="line">                    &quot;GlobalIPv6PrefixLen&quot;: 0,</span><br><span class="line">                    &quot;MacAddress&quot;: &quot;02:42:ac:11:00:03&quot;,</span><br><span class="line">                    &quot;DriverOpts&quot;: null</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure></div>

<p><strong>进入当前正在运行的容器</strong></p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 我们通常容器都是使用后台方式运行的，需要进入容器，修改一些配置</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 命令</span></span><br><span class="line">docker exec -it 容器id bashShell</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 测试</span></span><br><span class="line">[root@localhost /]# docker exec -it ce989f90023d /bin/bash</span><br><span class="line">[root@ce989f90023d /]# ls</span><br><span class="line">bin  dev  etc  home  lib  lib64  lost+found  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var</span><br><span class="line">[root@ce989f90023d /]# ps -ef</span><br><span class="line">UID         PID   PPID  C STIME TTY          TIME CMD</span><br><span class="line">root          1      0  0 14:44 pts/0    00:00:00 /bin/bash</span><br><span class="line">root         15      0  0 15:19 pts/1    00:00:00 /bin/bash</span><br><span class="line">root         29     15  0 15:20 pts/1    00:00:00 ps -ef</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 方式二</span></span><br><span class="line">docker attach 容器id</span><br><span class="line"><span class="meta">#</span><span class="bash"> 测试</span></span><br><span class="line">[root@localhost /]# docker attach ce989f90023d</span><br><span class="line">正在执行当前的代码...</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> docker <span class="built_in">exec</span>		<span class="comment"># 进入容器后开启一个新的终端，可以在里面操作（常用）</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> docker attach 	<span class="comment"># 进入容器正在执行的终端，不会启动新的进程</span></span></span><br></pre></td></tr></table></figure></div>

<p><strong>从容器内拷贝文件到主机上</strong></p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">docker cp 容器id:容器内目标文件路径  目的主机路径</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看当前主机目录</span></span><br><span class="line">[root@localhost home]# ls</span><br><span class="line">ztx</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 进入docker容器内部</span></span><br><span class="line">[root@localhost home]# docker attach ce989f90023d</span><br><span class="line">[root@ce989f90023d /]# cd /home/</span><br><span class="line">[root@ce989f90023d home]# ls</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 在容器内新建一个文件</span></span><br><span class="line">[root@ce989f90023d home]# touch test.java</span><br><span class="line">[root@ce989f90023d home]# exit</span><br><span class="line">exit</span><br><span class="line">[root@localhost home]# docker ps -a</span><br><span class="line">CONTAINER ID     IMAGE      COMMAND       CREATED           STATUS                PORTS           NAMES</span><br><span class="line">ce989f90023d     centos  &quot;/bin/bash&quot;  44 minutes ago  Exited (0) 46 seconds ago               nifty_johnson</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 将docker内文件拷贝到主机上</span></span><br><span class="line">[root@localhost home]# docker cp ce989f90023d:/home/test.java /home</span><br><span class="line">[root@localhost home]# ls</span><br><span class="line">test.java  ztx</span><br><span class="line">[root@localhost home]# </span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 拷贝是一个手动过程，未来我们使用 -v 卷的技术，可以实现自动同步</span> </span><br></pre></td></tr></table></figure></div>

<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p><img src="/2022/06/09/uncatalog/cl46zbgi6000y7or7g7cnd6w6/image-20200611085918923.png" alt="image-20200611085918923"></p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">attach      Attach to a running container 	      # 当前shell下attach连接指定运行的镜像</span><br><span class="line">build       Build an image from a Dockerfile        # 通过Dockerfile定制镜像</span><br><span class="line">commit      Create a new image from a container changes  #提交当前容器为新的镜像</span><br><span class="line">cp          Copy files/folders between a container and the local filesystem #从容器中拷贝指定文件或目录到宿主机中</span><br><span class="line">create      Create a new container 				  # 创建一个新的容器，同run,但不启动容器</span><br><span class="line">diff        Inspect changes to files or directories on a container&#x27;s filesystem #查看docker容器的变化</span><br><span class="line">events      Get real time events from the server 	  # 从docker服务获取容器实时事件</span><br><span class="line">exec        Run a command in a running container    # 在已存在的容器上运行命令</span><br><span class="line">export      Export a container filesystem as a tar archive # 导出容器的内容流作为一个tar归档文件[对应import]</span><br><span class="line">history     Show the history of an image            # 展示一个镜像形成历史</span><br><span class="line">images      List images                             # 列出系统当前的镜像</span><br><span class="line">import      Import the contents from a tarball to create a filesystem image # 从tar包中的内容创建一个新的文件系统镜像[对应export]</span><br><span class="line">info        Display system-wide information         # 显示系统相关信息</span><br><span class="line">inspect     Return low-level information on Docker objects # 查看容器详细信息</span><br><span class="line">kill        Kill one or more running containers     # 杀死指定的docker容器</span><br><span class="line">load        Load an image from a tar archive or STDIN # 从一个tar包加载一个镜像[对应save]</span><br><span class="line">login       Log in to a Docker registry			  # 注册或者登录一个docker源服务器</span><br><span class="line">logout      Log out from a Docker registry		  # 从当前Docker registry退出</span><br><span class="line">logs        Fetch the logs of a container			  # 输出当前容器日志信息</span><br><span class="line">pause       Pause all processes within one or more containers 	     # 暂停容器</span><br><span class="line">port        List port mappings or a specific mapping for the container # 查看映射端口对应容器内部源端口</span><br><span class="line">ps          List containers						  # 列出容器列表</span><br><span class="line">pull        Pull an image or a repository from a registry # 从docker镜像源服务器拉取指定镜像或库镜像</span><br><span class="line">push        Push an image or a repository to a registry   # 推送指定镜像或者库镜像至docker源服务器</span><br><span class="line">rename      Rename a container					  # 给docker容器重新命名</span><br><span class="line">restart     Restart one or more containers		  # 重启运行的容器</span><br><span class="line">rm          Remove one or more containers			  # 移除一个或者多个容器</span><br><span class="line">rmi         Remove one or more images				  # 移除一个或者多个镜像[无容器使用该镜像时才可删除，否则需删除相关容器才可继续或 -f 强制删除]</span><br><span class="line">run         Run a command in a new container		  # 创建一个新的容器并运行一个命令</span><br><span class="line">save        Save one or more images to a tar archive (streamed to STDOUT by default) # 保存一个镜像为一个tar包[对应load]</span><br><span class="line">search      Search the Docker Hub for images		  # 在docker hub中搜索镜像</span><br><span class="line">start       Start one or more stopped containers	  # 启动容器</span><br><span class="line">stats       Display a live stream of container(s) resource usage statistics # 实时显示容器资源使用统计</span><br><span class="line">stop        Stop one or more running containers	  # 停止容器</span><br><span class="line">tag         Create a tag TARGET_IMAGE that refers to SOURCE_IMAGE # 给源中镜像打标签</span><br><span class="line">top         Display the running processes of a container   	  # 查看容器中运行的进程信息</span><br><span class="line">unpause     Unpause all processes within one or more containers # 取消暂停容器</span><br><span class="line">update      Update configuration of one or more containers	  # 更新一个或多个容器配置</span><br><span class="line">version     Show the Docker version information	  # 查看docker版本号 </span><br><span class="line">wait        Block until one or more containers stop, then print their exit codes # 截取容器停止时的退出状态值</span><br></pre></td></tr></table></figure></div>

<h2 id="作业练习"><a href="#作业练习" class="headerlink" title="作业练习"></a>作业练习</h2><blockquote>
<p>作业1：Docker 安装Nginx</p>
</blockquote>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 1.搜索镜像 search 建议去docker搜索，可以看到帮助文档</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 2.下载镜像 pull</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 3.运行测试</span></span><br><span class="line">[root@localhost /]# docker images</span><br><span class="line">REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">nginx               latest              2622e6cca7eb        23 hours ago        132MB</span><br><span class="line">centos              latest              470671670cac        4 months ago        237MB</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> -d 后台运行</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> --name 给容器命名</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> -p 宿主机端口：容器内部端口   【端口映射操作】</span></span><br><span class="line">[root@localhost /]# docker run -d --name nginx01 -p 3344:80 nginx</span><br><span class="line">d60570d1e45024e3687e3bf3105a6959af8ee68d34f0c62a7deee1c16ec6579f</span><br><span class="line">CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                  NAMES</span><br><span class="line">d60570d1e450        nginx               &quot;/docker-entrypoint.…&quot;   2 minutes ago       Up 2 minutes        0.0.0.0:3344-&gt;80/tcp   nginx01</span><br><span class="line"><span class="meta">#</span><span class="bash"> 本地测试访问nginx</span></span><br><span class="line">[root@localhost /]# curl localhost:3344</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 进入容器</span></span><br><span class="line">[root@localhost /]# docker exec -it nginx01 /bin/bash</span><br><span class="line">root@d60570d1e450:/# whereis nginx</span><br><span class="line">nginx: /usr/sbin/nginx /usr/lib/nginx /etc/nginx /usr/share/nginx</span><br><span class="line">root@d60570d1e450:/# cd /etc/nginx/</span><br><span class="line">root@d60570d1e450:/etc/nginx# ls</span><br><span class="line">conf.d	fastcgi_params	koi-utf  koi-win  mime.types  modules  nginx.conf  scgi_params	uwsgi_params  win-utf</span><br></pre></td></tr></table></figure></div>

<p><strong>端口暴露的概念</strong></p>
<p><img src="/2022/06/09/uncatalog/cl46zbgi6000y7or7g7cnd6w6/image-20200611085948617.png" alt="image-20200611085948617"></p>
<p><strong>思考问题：</strong>我们每次改动nginx配置文件，都需要进入容器内部？十分麻烦，我要是可以在容器外部提供一个映射路径，达到在容器外部修改文件名，容器内部就可以自动修改？-v 数据卷 技术！</p>
<blockquote>
<p>作业2：Docker来装一个tomcat</p>
</blockquote>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 官方文档</span></span><br><span class="line">docker run -it --rm tomcat:9.0</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 我们之前的启动都是后台，停止了容器之后，容器还是可以查到 docker run -it --rm,一般用来测试，用完就删除</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 下载再启动</span></span><br><span class="line">docker pull tomcat</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 启动运行</span></span><br><span class="line">docker run -d -p 3355:8080 --name tomcat01 tomcat</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">测试访问没有问题</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 进入容器</span></span><br><span class="line">[root@localhost /]# docker exec -it tomcat01 /bin/bash</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 发现问题：1、linux命令少了 2、webapps内没有内容（这是阿里云镜像的原因：默认是最小镜像，所有不必要的都删除）</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 保证最小可运行环境</span></span><br><span class="line"><span class="meta">#</span><span class="bash">解决方法：将webapps.dist目录下内容拷至webapps下</span></span><br><span class="line">root@c435d5b974a7:/usr/local/tomcat# cd webapps</span><br><span class="line">root@c435d5b974a7:/usr/local/tomcat/webapps# ls</span><br><span class="line">root@c435d5b974a7:/usr/local/tomcat/webapps# cd ..</span><br><span class="line">root@c435d5b974a7:/usr/local/tomcat# ls</span><br><span class="line">BUILDING.txt  CONTRIBUTING.md  LICENSE	NOTICE	README.md  RELEASE-NOTES  RUNNING.txt  bin  conf  lib  logs  native-jni-lib  temp  webapps  webapps.dist  work</span><br><span class="line">root@c435d5b974a7:/usr/local/tomcat# cd webapps.dist/</span><br><span class="line">root@c435d5b974a7:/usr/local/tomcat/webapps.dist# ls</span><br><span class="line">ROOT  docs  examples  host-manager  manager</span><br><span class="line">root@c435d5b974a7:/usr/local/tomcat/webapps.dist# cd ..</span><br><span class="line">root@c435d5b974a7:/usr/local/tomcat# cp -r webapps.dist/* webapps </span><br><span class="line">root@c435d5b974a7:/usr/local/tomcat# cd webapps</span><br><span class="line">root@c435d5b974a7:/usr/local/tomcat/webapps# ls</span><br><span class="line">ROOT  docs  examples  host-manager  manager</span><br></pre></td></tr></table></figure></div>

<p>拷贝完成就可以访问了：</p>
<p><img src="/2022/06/09/uncatalog/cl46zbgi6000y7or7g7cnd6w6/image-20200611090019494.png" alt="image-20200611090019494"></p>
<p><strong>思考问题：</strong>我们以后要部署项目，如果每次都要进入容器是不是十分麻烦？我要是可以在容器外部提供映射路径，webapps,我们在外部放置项目，就自动同步到内部就好了！</p>
<blockquote>
<p>作业3：部署es+kibana</p>
</blockquote>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> es 暴露的端口很多！</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> es 十分耗内存</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> es 的数据一般需要放置到安全目录！挂载</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> --net somenetwork？网络配置</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 启动 elasticsearch</span></span><br><span class="line">docker run -d --name elasticsearch -p 9200:9200 -p 9300:9300 -e &quot;discovery.type=single-node&quot; elasticsearch:7.6.2</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 启动了 Linux就可卡住了   docker stats 查看cpu的状态</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> es 是十分耗内存的</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 测试一下es是否成功了</span></span><br><span class="line">[root@localhost /]# curl localhost:9200</span><br><span class="line">&#123;</span><br><span class="line">  &quot;name&quot; : &quot;83b0d5dca26e&quot;,</span><br><span class="line">  &quot;cluster_name&quot; : &quot;docker-cluster&quot;,</span><br><span class="line">  &quot;cluster_uuid&quot; : &quot;MjhNfYTvRVui1UCrAwMdqw&quot;,</span><br><span class="line">  &quot;version&quot; : &#123;</span><br><span class="line">    &quot;number&quot; : &quot;7.6.2&quot;,</span><br><span class="line">    &quot;build_flavor&quot; : &quot;default&quot;,</span><br><span class="line">    &quot;build_type&quot; : &quot;docker&quot;,</span><br><span class="line">    &quot;build_hash&quot; : &quot;ef48eb35cf30adf4db14086e8aabd07ef6fb113f&quot;,</span><br><span class="line">    &quot;build_date&quot; : &quot;2020-03-26T06:34:37.794943Z&quot;,</span><br><span class="line">    &quot;build_snapshot&quot; : false,</span><br><span class="line">    &quot;lucene_version&quot; : &quot;8.4.0&quot;,</span><br><span class="line">    &quot;minimum_wire_compatibility_version&quot; : &quot;6.8.0&quot;,</span><br><span class="line">    &quot;minimum_index_compatibility_version&quot; : &quot;6.0.0-beta1&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;tagline&quot; : &quot;You Know, for Search&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看docker容器占用资源情况</span></span><br></pre></td></tr></table></figure></div>

<p><img src="/2022/06/09/uncatalog/cl46zbgi6000y7or7g7cnd6w6/image-20200611124706727.png" alt="image-20200611124706727"></p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 赶紧关闭容器，增加内存限制，修改配置文件 -e 环境配置修改</span></span><br><span class="line">docker run -d --name elasticsearch02 -p 9200:9200 -p 9300:9300 -e &quot;discovery.type=single-node&quot; -e ES_JAVA_OPTS=&quot;-Xms64m -Xmx512m&quot; elasticsearch:7.6.2</span><br><span class="line"> </span><br><span class="line"><span class="meta"> #</span><span class="bash"> 查看docker容器占用资源情况</span></span><br></pre></td></tr></table></figure></div>

<p><img src="/2022/06/09/uncatalog/cl46zbgi6000y7or7g7cnd6w6/image-20200611124755826.png" alt="image-20200611124755826"></p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">[root@localhost /]# curl localhost:9200</span><br><span class="line">&#123;</span><br><span class="line">  &quot;name&quot; : &quot;5a262b522bbf&quot;,</span><br><span class="line">  &quot;cluster_name&quot; : &quot;docker-cluster&quot;,</span><br><span class="line">  &quot;cluster_uuid&quot; : &quot;rGMaCpVXScGaZcv_UtK3gQ&quot;,</span><br><span class="line">  &quot;version&quot; : &#123;</span><br><span class="line">    &quot;number&quot; : &quot;7.6.2&quot;,</span><br><span class="line">    &quot;build_flavor&quot; : &quot;default&quot;,</span><br><span class="line">    &quot;build_type&quot; : &quot;docker&quot;,</span><br><span class="line">    &quot;build_hash&quot; : &quot;ef48eb35cf30adf4db14086e8aabd07ef6fb113f&quot;,</span><br><span class="line">    &quot;build_date&quot; : &quot;2020-03-26T06:34:37.794943Z&quot;,</span><br><span class="line">    &quot;build_snapshot&quot; : false,</span><br><span class="line">    &quot;lucene_version&quot; : &quot;8.4.0&quot;,</span><br><span class="line">    &quot;minimum_wire_compatibility_version&quot; : &quot;6.8.0&quot;,</span><br><span class="line">    &quot;minimum_index_compatibility_version&quot; : &quot;6.0.0-beta1&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;tagline&quot; : &quot;You Know, for Search&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>



<blockquote>
<p>作业4：使用 kibana 连接 es ? 思考网络如何才能连接过去！</p>
</blockquote>
<p><img src="/2022/06/09/uncatalog/cl46zbgi6000y7or7g7cnd6w6/image-20200611125352717.png" alt="image-20200611125352717"></p>
<h2 id="可视化"><a href="#可视化" class="headerlink" title="可视化"></a>可视化</h2><ul>
<li>portainer（线用这个）</li>
</ul>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">docker run -d -p 8088:9000 \</span><br><span class="line">--restart=always -v /var/run/docker.sock:/var/run/docker.sock --privileged=true portainer/portainer</span><br></pre></td></tr></table></figure></div>

<ul>
<li>Rancher （CI/CD再用）</li>
</ul>
<h2 id="什么是portainer"><a href="#什么是portainer" class="headerlink" title="什么是portainer ?"></a>什么是portainer ?</h2><p>Docker图形化界面管理工具！提供一个后台面板供我们操作！</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">docker run -d -p 8088:9000 \</span><br><span class="line">--restart=always -v /var/run/docker.sock:/var/run/docker.sock --privileged=true portainer/portainer</span><br></pre></td></tr></table></figure></div>

<p>外部访问测试：<a href="http://ip:8088/">http://ip:8088/</a></p>
<p>通过它来访问了;</p>
<p><img src="/2022/06/09/uncatalog/cl46zbgi6000y7or7g7cnd6w6/image-20200611141621853.png" alt="image-20200611141621853"></p>
<p>选择本地的：</p>
<p><img src="/2022/06/09/uncatalog/cl46zbgi6000y7or7g7cnd6w6/image-20200611142004773.png" alt="image-20200611142004773"></p>
<p>进入之后的面板：</p>
<p><img src="/2022/06/09/uncatalog/cl46zbgi6000y7or7g7cnd6w6/image-20200611144838665.png" alt="image-20200611144838665"></p>
<p><img src="/2022/06/09/uncatalog/cl46zbgi6000y7or7g7cnd6w6/image-20200611144900114.png" alt="image-20200611144900114"></p>
<p>可视化面板我们平时不会使用，大家自己测试玩玩即可！</p>
<h1 id="Docker镜像讲解"><a href="#Docker镜像讲解" class="headerlink" title="Docker镜像讲解"></a>Docker镜像讲解</h1><h2 id="镜像是什么"><a href="#镜像是什么" class="headerlink" title="镜像是什么"></a>镜像是什么</h2><p>镜像是一种轻量级、可执行的独立软件保，用来打包软件运行环境和基于运行环境开发的软件，他包含运行某个软件所需的所有内容，包括代码、运行时库、环境变量和配置文件。</p>
<p>所有应用，直接打包docker镜像，就可以直接跑起来！</p>
<p><strong>如何得到镜像</strong></p>
<ul>
<li>从远程仓库下载</li>
<li>别人拷贝给你</li>
<li>自己制作一个镜像 DockerFile</li>
</ul>
<h2 id="Docker镜像加载原理"><a href="#Docker镜像加载原理" class="headerlink" title="Docker镜像加载原理"></a>Docker镜像加载原理</h2><blockquote>
<p>UnionFs （联合文件系统）</p>
</blockquote>
<p>UnionFs（联合文件系统）：Union文件系统（UnionFs）是一种分层、轻量级并且高性能的文件系统，他支持对文件系统的修改作为一次提交来一层层的叠加，同时可以将不同目录挂载到同一个虚拟文件系统下（ unite several directories into a single virtual filesystem)。Union文件系统是 Docker镜像的基础。镜像可以通过分层来进行继承，基于基础镜像（没有父镜像），可以制作各种具体的应用镜像</p>
<p>特性：一次同时加载多个文件系统，但从外面看起来，只能看到一个文件系统，联合加载会把各层文件系统叠加起来，这样最终的文件系统会包含所有底层的文件和目录。</p>
<blockquote>
<p>Docker镜像加载原理</p>
</blockquote>
<p>docker的镜像实际上由一层一层的文件系统组成，这种层级的文件系统UnionFS。</p>
<p>boots(boot file system）主要包含 bootloader和 Kernel, bootloader主要是引导加载 kernel, Linux刚启动时会加载bootfs文件系统，在 Docker镜像的最底层是 boots。这一层与我们典型的Linux/Unix系统是一样的，包括bootloader和 Kernel。当boot加载完成之后整个内核就都在内存中了，此时内存的使用权已由 bootfs转交给内核，此时系统也会卸载bootfs。</p>
<p>rootfs（root file system),在 bootfs之上。包含的就是典型 Linux系统中的/dev,/proc,/bin,/etc等标准目录和文件。 rootfs就是各种不同的操作系统发行版，比如 Ubuntu, Centos等等。<br><img src="/2022/06/09/uncatalog/cl46zbgi6000y7or7g7cnd6w6/image-20200611162007055.png" alt="image-20200611162007055"></p>
<p>平时我们安装进虚拟机的CentOS都是好几个G，为什么Docker这里才200M？</p>
<p><img src="/2022/06/09/uncatalog/cl46zbgi6000y7or7g7cnd6w6/image-20200611162057734.png" alt="image-20200611162057734"></p>
<p>对于个精简的OS, rootfs可以很小，只需要包合最基本的命令、工具和程序库就可以了，因为底层直接用Host的kernel，自己只需要提供rootfs就可以了。由此可见对于不同的Linux发行版， boots基本是一致的， rootfs会有差別，因此不同的发行版可以公用bootfs.</p>
<p>虚拟机是分钟级别，容器是秒级！</p>
<h2 id="分层理解"><a href="#分层理解" class="headerlink" title="分层理解"></a>分层理解</h2><blockquote>
<p>分层的镜像</p>
</blockquote>
<p>我们可以去下载一个镜像，注意观察下载的日志输出，可以看到是一层层的在下载！<img src="/2022/06/09/uncatalog/cl46zbgi6000y7or7g7cnd6w6/image-20200611163839741.png" alt="image-20200611163839741"></p>
<p><strong>思考：为什么Docker镜像要采用这种分层的结构呢？</strong></p>
<p>最大的好处，我觉得莫过于资源共享了！比如有多个镜像都从相同的Base镜像构建而来，那么宿主机只需在磁盘上保留一份base镜像，同时内存中也只需要加载一份base镜像，这样就可以为所有的容器服务了，而且镜像的每一层都可以被共享。</p>
<p>查看镜像分层的方式可以通过docker image inspect 命令</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">➜  / docker image inspect redis          </span><br><span class="line">[</span><br><span class="line">    &#123;</span><br><span class="line">        &quot;Id&quot;: &quot;sha256:f9b9909726890b00d2098081642edf32e5211b7ab53563929a47f250bcdc1d7c&quot;,</span><br><span class="line">        &quot;RepoTags&quot;: [</span><br><span class="line">            &quot;redis:latest&quot;</span><br><span class="line">        ],</span><br><span class="line">        &quot;RepoDigests&quot;: [</span><br><span class="line">            &quot;redis@sha256:399a9b17b8522e24fbe2fd3b42474d4bb668d3994153c4b5d38c3dafd5903e32&quot;</span><br><span class="line">        ],</span><br><span class="line">        &quot;Parent&quot;: &quot;&quot;,</span><br><span class="line">        &quot;Comment&quot;: &quot;&quot;,</span><br><span class="line">        &quot;Created&quot;: &quot;2020-05-02T01:40:19.112130797Z&quot;,</span><br><span class="line">        &quot;Container&quot;: &quot;d30c0bcea88561bc5139821227d2199bb027eeba9083f90c701891b4affce3bc&quot;,</span><br><span class="line">        &quot;ContainerConfig&quot;: &#123;</span><br><span class="line">            &quot;Hostname&quot;: &quot;d30c0bcea885&quot;,</span><br><span class="line">            &quot;Domainname&quot;: &quot;&quot;,</span><br><span class="line">            &quot;User&quot;: &quot;&quot;,</span><br><span class="line">            &quot;AttachStdin&quot;: false,</span><br><span class="line">            &quot;AttachStdout&quot;: false,</span><br><span class="line">            &quot;AttachStderr&quot;: false,</span><br><span class="line">            &quot;ExposedPorts&quot;: &#123;</span><br><span class="line">                &quot;6379/tcp&quot;: &#123;&#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;Tty&quot;: false,</span><br><span class="line">            &quot;OpenStdin&quot;: false,</span><br><span class="line">            &quot;StdinOnce&quot;: false,</span><br><span class="line">            &quot;Env&quot;: [</span><br><span class="line">                &quot;PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin&quot;,</span><br><span class="line">                &quot;GOSU_VERSION=1.12&quot;,</span><br><span class="line">                &quot;REDIS_VERSION=6.0.1&quot;,</span><br><span class="line">                &quot;REDIS_DOWNLOAD_URL=http://download.redis.io/releases/redis-6.0.1.tar.gz&quot;,</span><br><span class="line">                &quot;REDIS_DOWNLOAD_SHA=b8756e430479edc162ba9c44dc89ac394316cd482f2dc6b91bcd5fe12593f273&quot;</span><br><span class="line">            ],</span><br><span class="line">            &quot;Cmd&quot;: [</span><br><span class="line">                &quot;/bin/sh&quot;,</span><br><span class="line">                &quot;-c&quot;,</span><br><span class="line">                &quot;#(nop) &quot;,</span><br><span class="line">                &quot;CMD [\&quot;redis-server\&quot;]&quot;</span><br><span class="line">            ],</span><br><span class="line">            &quot;ArgsEscaped&quot;: true,</span><br><span class="line">            &quot;Image&quot;: &quot;sha256:704c602fa36f41a6d2d08e49bd2319ccd6915418f545c838416318b3c29811e0&quot;,</span><br><span class="line">            &quot;Volumes&quot;: &#123;</span><br><span class="line">                &quot;/data&quot;: &#123;&#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;WorkingDir&quot;: &quot;/data&quot;,</span><br><span class="line">            &quot;Entrypoint&quot;: [</span><br><span class="line">                &quot;docker-entrypoint.sh&quot;</span><br><span class="line">            ],</span><br><span class="line">            &quot;OnBuild&quot;: null,</span><br><span class="line">            &quot;Labels&quot;: &#123;&#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;DockerVersion&quot;: &quot;18.09.7&quot;,</span><br><span class="line">        &quot;Author&quot;: &quot;&quot;,</span><br><span class="line">        &quot;Config&quot;: &#123;</span><br><span class="line">            &quot;Hostname&quot;: &quot;&quot;,</span><br><span class="line">            &quot;Domainname&quot;: &quot;&quot;,</span><br><span class="line">            &quot;User&quot;: &quot;&quot;,</span><br><span class="line">            &quot;AttachStdin&quot;: false,</span><br><span class="line">            &quot;AttachStdout&quot;: false,</span><br><span class="line">            &quot;AttachStderr&quot;: false,</span><br><span class="line">            &quot;ExposedPorts&quot;: &#123;</span><br><span class="line">                &quot;6379/tcp&quot;: &#123;&#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;Tty&quot;: false,</span><br><span class="line">            &quot;OpenStdin&quot;: false,</span><br><span class="line">            &quot;StdinOnce&quot;: false,</span><br><span class="line">            &quot;Env&quot;: [</span><br><span class="line">                &quot;PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin&quot;,</span><br><span class="line">                &quot;GOSU_VERSION=1.12&quot;,</span><br><span class="line">                &quot;REDIS_VERSION=6.0.1&quot;,</span><br><span class="line">                &quot;REDIS_DOWNLOAD_URL=http://download.redis.io/releases/redis-6.0.1.tar.gz&quot;,</span><br><span class="line">                &quot;REDIS_DOWNLOAD_SHA=b8756e430479edc162ba9c44dc89ac394316cd482f2dc6b91bcd5fe12593f273&quot;</span><br><span class="line">            ],</span><br><span class="line">            &quot;Cmd&quot;: [</span><br><span class="line">                &quot;redis-server&quot;</span><br><span class="line">            ],</span><br><span class="line">            &quot;ArgsEscaped&quot;: true,</span><br><span class="line">            &quot;Image&quot;: &quot;sha256:704c602fa36f41a6d2d08e49bd2319ccd6915418f545c838416318b3c29811e0&quot;,</span><br><span class="line">            &quot;Volumes&quot;: &#123;</span><br><span class="line">                &quot;/data&quot;: &#123;&#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;WorkingDir&quot;: &quot;/data&quot;,</span><br><span class="line">            &quot;Entrypoint&quot;: [</span><br><span class="line">                &quot;docker-entrypoint.sh&quot;</span><br><span class="line">            ],</span><br><span class="line">            &quot;OnBuild&quot;: null,</span><br><span class="line">            &quot;Labels&quot;: null</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;Architecture&quot;: &quot;amd64&quot;,</span><br><span class="line">        &quot;Os&quot;: &quot;linux&quot;,</span><br><span class="line">        &quot;Size&quot;: 104101893,</span><br><span class="line">        &quot;VirtualSize&quot;: 104101893,</span><br><span class="line">        &quot;GraphDriver&quot;: &#123;</span><br><span class="line">            &quot;Data&quot;: &#123;</span><br><span class="line">                &quot;LowerDir&quot;: &quot;/var/lib/docker/overlay2/adea96bbe6518657dc2d4c6331a807eea70567144abda686588ef6c3bb0d778a/diff:/var/lib/docker/overlay2/66abd822d34dc6446e6bebe73721dfd1dc497c2c8063c43ffb8cf8140e2caeb6/diff:/var/lib/docker/overlay2/d19d24fb6a24801c5fa639c1d979d19f3f17196b3c6dde96d3b69cd2ad07ba8a/diff:/var/lib/docker/overlay2/a1e95aae5e09ca6df4f71b542c86c677b884f5280c1d3e3a1111b13644b221f9/diff:/var/lib/docker/overlay2/cd90f7a9cd0227c1db29ea992e889e4e6af057d9ab2835dd18a67a019c18bab4/diff&quot;,</span><br><span class="line">                &quot;MergedDir&quot;: &quot;/var/lib/docker/overlay2/afa1de233453b60686a3847854624ef191d7bc317fb01e015b4f06671139fb11/merged&quot;,</span><br><span class="line">                &quot;UpperDir&quot;: &quot;/var/lib/docker/overlay2/afa1de233453b60686a3847854624ef191d7bc317fb01e015b4f06671139fb11/diff&quot;,</span><br><span class="line">                &quot;WorkDir&quot;: &quot;/var/lib/docker/overlay2/afa1de233453b60686a3847854624ef191d7bc317fb01e015b4f06671139fb11/work&quot;</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;Name&quot;: &quot;overlay2&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;RootFS&quot;: &#123;</span><br><span class="line">            &quot;Type&quot;: &quot;layers&quot;,</span><br><span class="line">            &quot;Layers&quot;: [</span><br><span class="line">                &quot;sha256:c2adabaecedbda0af72b153c6499a0555f3a769d52370469d8f6bd6328af9b13&quot;,</span><br><span class="line">                &quot;sha256:744315296a49be711c312dfa1b3a80516116f78c437367ff0bc678da1123e990&quot;,</span><br><span class="line">                &quot;sha256:379ef5d5cb402a5538413d7285b21aa58a560882d15f1f553f7868dc4b66afa8&quot;,</span><br><span class="line">                &quot;sha256:d00fd460effb7b066760f97447c071492d471c5176d05b8af1751806a1f905f8&quot;,</span><br><span class="line">                &quot;sha256:4d0c196331523cfed7bf5bafd616ecb3855256838d850b6f3d5fba911f6c4123&quot;,</span><br><span class="line">                &quot;sha256:98b4a6242af2536383425ba2d6de033a510e049d9ca07ff501b95052da76e894&quot;</span><br><span class="line">            ]</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;Metadata&quot;: &#123;</span><br><span class="line">            &quot;LastTagTime&quot;: &quot;0001-01-01T00:00:00Z&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure></div>

<p><strong>理解：</strong></p>
<p>所有的 Docker镜像都起始于一个基础镜像层，当进行修改或培加新的内容时，就会在当前镜像层之上，创建新的镜像层。</p>
<p>举一个简单的例子，假如基于 Ubuntu Linux16.04创建一个新的镜像，这就是新镜像的第一层；如果在该镜像中添加 Python包，就会在基础镜像层之上创建第二个镜像层；如果继续添加一个安全补丁，就会创建第三个镜像层。</p>
<p>该镜像当前已经包含3个镜像层，如下图所示（这只是一个用于演示的很简单的例子）。</p>
<p><img src="/2022/06/09/uncatalog/cl46zbgi6000y7or7g7cnd6w6/image-20200611163818495.png" alt="image-20200611163818495"></p>
<p>在添加额外的镜像层的同时，镜像始终保持是当前所有镜像的组合，理解这一点非常重要。下图中举了一个简单的例子，每个镜像层包含3个文件，而整体的大镜像包含了来自两个镜像层的6个文件。</p>
<p><img src="/2022/06/09/uncatalog/cl46zbgi6000y7or7g7cnd6w6/image-20200611164322267.png" alt="image-20200611164322267"></p>
<p>上图中的镜像层跟之前图中的略有区別，主要目的是便于展示文件。</p>
<p>下图中展示了一个稍微复杂的三层镜像，在外部看来整个镜像只有6个文件，这是因为最上层中的文件7是文件5的一个更新版。</p>
<p><img src="/2022/06/09/uncatalog/cl46zbgi6000y7or7g7cnd6w6/image-20200611164447964.png" alt="image-20200611164447964"></p>
<p>这种情況下，上层镜像层中的文件覆盖了底层镜像层中的文件。这样就使得文件的更新版本作为一个新镜像层添加到镜像当中。</p>
<p>Docker通过存储引擎（新版本采用快照机制）的方式来实现镜像层堆栈，并保证多镜像层对外展示为统一的文件系统。</p>
<p>Linux上可用的存储引撃有AUFS、 Overlay2、 Device Mapper、Btrfs以及ZFS。顾名思义，每种存储引擎都基于 Linux中对应的文件系统或者块设备技术，井且每种存储引擎都有其独有的性能特点。</p>
<p>Docker在 Windows上仅支持 windowsfilter 一种存储引擎，该引擎基于NTFS文件系统之上实现了分层和CoW [1]。</p>
<blockquote>
<p>特点</p>
</blockquote>
<p>Docker 镜像都是只读的，当容器启动时，一个新的可写层加载到镜像的顶部！</p>
<p>这一层就是我们通常说的容器层，容器之下的都叫镜像层！<img src="/2022/06/09/uncatalog/cl46zbgi6000y7or7g7cnd6w6/image-20200611165355825.png" alt="image-20200611165355825"></p>
<p>如何提交一个自己的镜像？</p>
<h2 id="commit镜像"><a href="#commit镜像" class="headerlink" title="commit镜像"></a>commit镜像</h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">docker commit 提交容器成为一个新的副本</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 命令和git原理类似</span></span><br><span class="line">docker commit -m=&quot;描述信息&quot; -a=&quot;作者&quot; 容器id 目标镜像名:[版本TAG]</span><br></pre></td></tr></table></figure></div>

<p>实战测试</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">1、启动一个默认的tomcat</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">2、发现这个默认的tomcat是没有webapps应用的，镜像的原因。官方的镜像默认webapps下面是没有文件的！</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">3、我自己将webapp.dist下文件拷贝至webapps下</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">4、将我们操作过的容器通过commit提交为一个镜像！我们以后就可以使用我们修改过的镜像了，这就是我们自己的一个修改的镜像</span></span><br></pre></td></tr></table></figure></div>

<p><img src="/2022/06/09/uncatalog/cl46zbgi6000y7or7g7cnd6w6/image-20200611172701729.png" alt="image-20200611172701729"></p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">如果你想要保存当前容器的状态，就可以通过commit来提交，获得一个镜像，就好比我们我们使用虚拟机的快照。</span><br></pre></td></tr></table></figure></div>

<p>到了这里就算是入门Docker了！</p>
]]></content>
      <tags>
        <tag>云原生基础系列</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>云原生基础系列之Docker(一)进阶</title>
    <url>/2022/06/09/uncatalog/cl46zffyz00127or72j1r80ti/</url>
    <content><![CDATA[<hr>
<span id="more"></span>



<hr>
<h1 id="容器数据卷"><a href="#容器数据卷" class="headerlink" title="容器数据卷"></a>容器数据卷</h1><h2 id="什么是容器数据卷"><a href="#什么是容器数据卷" class="headerlink" title="什么是容器数据卷"></a>什么是容器数据卷</h2><p><strong>docker的理念回顾</strong></p>
<p>将应用和环境打包成一个镜像！</p>
<p>数据？如果数据都在容器中，那么我们容器删除，数据就会丢失！需求：数据可以持久化</p>
<p>MySQL，容器删除了，删库跑路！需求：MySQL数据可以存储在本地！</p>
<p>容器之间可以有一个数据共享的技术！Docker容器中产生的数据，同步到本地！</p>
<p>这就是卷技术！目录的挂载，将我们容器内的目录，挂载到Linux上面！</p>
<p><img src="/2022/06/09/uncatalog/cl46zffyz00127or72j1r80ti/image-20200611220811766.png" alt="image-20200611220811766"></p>
<p><strong>总结一句话：容器的持久化和同步操作！容器间也是可以数据共享的！</strong></p>
<h2 id="使用数据卷"><a href="#使用数据卷" class="headerlink" title="使用数据卷"></a>使用数据卷</h2><blockquote>
<p>方式一：直接使用命令来挂载</p>
</blockquote>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">docker run -it -v 主机目录:容器目录</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 测试</span></span><br><span class="line">[root@localhost home]# docker run -it -v /home/ceshi:/home  centos  /bin/bash</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 启动起来的时候，我们可以通过docker inspect 容器id 来查看挂载情况：（见下图）</span></span><br></pre></td></tr></table></figure></div>

<p><img src="/2022/06/09/uncatalog/cl46zffyz00127or72j1r80ti/image-20200611224010091.png" alt="image-20200611224010091"></p>
<p>测试文件的同步</p>
<p><img src="/2022/06/09/uncatalog/cl46zffyz00127or72j1r80ti/image-20200611224046109.png" alt="image-20200611224046109"></p>
<p>在容器内指定目录下添加或修改一个文件，会同步到主机指定目录下！反之，在主机目录下做相关操作，也会同步到容器对应的目录下！</p>
<p>再来测试！</p>
<p>1、停止容器</p>
<p>2、宿主机修改文件</p>
<p>3、启动容器</p>
<p>4、容器内的数据依旧是同步的！</p>
<p><img src="/2022/06/09/uncatalog/cl46zffyz00127or72j1r80ti/image-20200611224137284.png" alt="image-20200611224137284"></p>
<p>好处：我们以后修改只需要在本地修改即可，容器内会自动同步！</p>
<h2 id="实战：安装MySQL"><a href="#实战：安装MySQL" class="headerlink" title="实战：安装MySQL"></a>实战：安装MySQL</h2><p>思考：MySQL的数据持久化的问题！</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 获取镜像</span></span><br><span class="line">[root@localhost home]# docker pull mysql:5.7</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 运行容器，需要做数据挂载！ <span class="comment"># 安装mysql,需要配置密码，这是要注意的点！</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 官方测试：docker run --name some-mysql -e MYSQL_ROOT_PASSWORD=my-secret-pw -d mysql:tag</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 启动我们的MySQL容器</span></span><br><span class="line">-d	后台运行</span><br><span class="line">-p	端口映射</span><br><span class="line">-v	卷挂载</span><br><span class="line">-e  环境配置</span><br><span class="line">--name  容器名字</span><br><span class="line">[root@localhost home]# docker run -d -p 3310:3306 -v /home/mysql/conf:/etc/mysql/conf.d -v /home/mysql/data:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 --name mysql01 mysql:5.7</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 启动成功之后，我们在本地使用sqlyog 连接测试一下</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> sqlyog —— 连接到服务器的3310 —— 3310和容器内的3306映射，这个时候我们就可以连接上了！</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 本地测试创建一个数据库，查看一下我们的映射的路径是否ok!</span></span><br></pre></td></tr></table></figure></div>

<p>假设我们将容器删除</p>
<p><img src="/2022/06/09/uncatalog/cl46zffyz00127or72j1r80ti/image-20200611230752177.png" alt="image-20200611230752177"></p>
<p>发现，我们挂载到本地的数据卷依旧没有丢失，这就实现了容器数据持久化功能！</p>
<h2 id="具名和匿名挂载"><a href="#具名和匿名挂载" class="headerlink" title="具名和匿名挂载"></a>具名和匿名挂载</h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 匿名挂载</span></span><br><span class="line">-v 容器内路径</span><br><span class="line">docker run -d -P --name nginx01 -v /etc/nginx nginx</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看所有卷的情况</span></span><br><span class="line">[root@localhost data]# docker volume ls</span><br><span class="line">DRIVER              VOLUME NAME</span><br><span class="line">local               2dd0379216c9ee4441ed56f8ce53461c19abe78b8cfd024ac5fbe07c3b8f09ba</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 这里发现，这种就是匿名挂载，我们在 -v 后只写了容器内的路径，没有写容器外的路径！</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 具名挂载</span></span><br><span class="line">[root@localhost home]# docker run -d -P --name nginx02 -v juming-nginx:/etc/nginx nginx</span><br><span class="line">5ba5708389bf71b2156fdbcedc50a62b16ac27adb2a3dfac42c52e9da5ace79f</span><br><span class="line">[root@localhost home]# docker volume ls</span><br><span class="line">DRIVER              VOLUME NAME</span><br><span class="line">local               juming-nginx</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 通过 -v 卷名：容器内路径</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看一下这个卷  <span class="comment"># 先找到卷所在路径 docker volume inspect 卷名，如下图：</span></span></span><br></pre></td></tr></table></figure></div>

<p><img src="/2022/06/09/uncatalog/cl46zffyz00127or72j1r80ti/image-20200611235522418.png" alt="image-20200611235522418"></p>
<p>所有的docker容器内的卷，没有指定目录的情况下都是在**/var/lib/docker/volumes/xxxx/_data**下！<br>我们通过具名挂载可以方便的找到我们的一个卷，大多数情况使用 <strong>具名挂载</strong></p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 如何确定是具名挂载还是匿名挂载，还是指定路径挂载！</span></span><br><span class="line">-v	容器内路径		       # 匿名挂载</span><br><span class="line">-v	卷名:容器内路径	 	 # 具名挂载</span><br><span class="line">-v	/宿主机路径:容器内路径   # 指定路径挂载！</span><br></pre></td></tr></table></figure></div>

<p>拓展：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 通过 -v 容器内路径：ro 或 rw   改变读写权限</span></span><br><span class="line">ro	 #readonly 只读</span><br><span class="line">rw	 #readwrite 可读可写</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 一旦创建容器时设置了容器权限，容器对我们挂载出来的内容就有限定了！</span></span><br><span class="line">docker run -d -P --name nginx05 -v juming:/etc/nginx:ro nginx</span><br><span class="line">docker run -d -P --name nginx05 -v juming:/etc/nginx:rw nginx</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 默认是 rw</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> ro 只要看到ro就说明这个路径只能通过宿主机来操作，容器内部是无法操作！</span></span><br></pre></td></tr></table></figure></div>

<h2 id="初始Dockerfile"><a href="#初始Dockerfile" class="headerlink" title="初始Dockerfile"></a>初始Dockerfile</h2><p>Dockerfile 就是用来构建 docker镜像的构建文件！命令脚本！ 先体验一下！</p>
<p>通过这个脚本可以生成镜像，镜像是一层一层的，脚本是一个个的命令，每个命令都是最终镜像的一层！</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建一个dockerfile文件，名字可以随机，建议 dockerfile</span></span><br><span class="line"></span><br><span class="line">[root@localhost docker-test-volume]# vim dockerfile</span><br><span class="line"><span class="meta">#</span><span class="bash"> 文件中的内容：指令(大写) 参数</span></span><br><span class="line">FROM centos</span><br><span class="line"></span><br><span class="line">VOLUME [&quot;volume01&quot;,&quot;volume02&quot;]</span><br><span class="line"></span><br><span class="line">CMD echo&quot;----end----&quot;</span><br><span class="line"></span><br><span class="line">CMD /bin/bash</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 这里的每个命令，就是镜像的一层！</span></span><br></pre></td></tr></table></figure></div>

<p><img src="/2022/06/09/uncatalog/cl46zffyz00127or72j1r80ti/image-20200612003052844.png" alt="image-20200612003052844"></p>
<p>注意：我们这里的 dockerfile  是我们编写的文件名哦！</p>
<p><img src="/2022/06/09/uncatalog/cl46zffyz00127or72j1r80ti/image-20200612003717223.png" alt="image-20200612003717223"></p>
<p>这两个卷和外部一定有两个同步的目录！</p>
<p><img src="/2022/06/09/uncatalog/cl46zffyz00127or72j1r80ti/image-20200612003946028.png" alt="image-20200612003946028"></p>
<p>查看一下卷挂载在主机上的路径</p>
<p><strong>docker inspect 容器id</strong></p>
<p><img src="/2022/06/09/uncatalog/cl46zffyz00127or72j1r80ti/image-20200612004608027.png" alt="image-20200612004608027"></p>
<p>测试一下刚才的文件是否同步出去了！</p>
<p>这种方式我们未来使用十分的多，因为我们通常会构建自己的镜像！</p>
<p>假设构建镜像的时候没有挂在卷，要手动镜像挂载即可： (参考上文<strong>具名和匿名挂载</strong>)</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">-v 卷名:容器内路径 </span><br></pre></td></tr></table></figure></div>

<h2 id="数据卷容器"><a href="#数据卷容器" class="headerlink" title="数据卷容器"></a>数据卷容器</h2><p><strong>多个mysql同步数据！</strong></p>
<p><img src="/2022/06/09/uncatalog/cl46zffyz00127or72j1r80ti/image-20200612223759573.png" alt="image-20200612223759573"></p>
<p><img src="/2022/06/09/uncatalog/cl46zffyz00127or72j1r80ti/image-20200612224621379.png" alt="image-20200612224621379"></p>
<p><img src="/2022/06/09/uncatalog/cl46zffyz00127or72j1r80ti/image-20200612225358172.png" alt="image-20200612225358172"></p>
<p>在docker03下创建docker03文件后，进入docker01发现也依旧会同步过来：</p>
<p><img src="/2022/06/09/uncatalog/cl46zffyz00127or72j1r80ti/image-20200612225641266.png" alt="image-20200612225641266"></p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 测试1：删除docker01后，docker02和docker03是否还可以访问原来docker01下创建的的文件？</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 测试1的结果为：依旧可以访问！！！</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 测试2：删除docker01后，docker02和docker03之间是否可以相互同步文件？</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 测试2的结果为：docket02和docker03之间一九可以完成同步！！！ 见下图：</span></span><br></pre></td></tr></table></figure></div>

<p><img src="/2022/06/09/uncatalog/cl46zffyz00127or72j1r80ti/image-20200612231431551.png" alt="image-20200612231431551"></p>
<p><img src="/2022/06/09/uncatalog/cl46zffyz00127or72j1r80ti/image-20200612231603498.png" alt="image-20200612231603498"></p>
<p><strong>多个mysql实现数据共享</strong></p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">➜  ~ docker run -d -p 3306:3306 -v /home/mysql/conf:/etc/mysql/conf.d -v /home/mysql/data:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 --name mysql01 mysql:5.7</span><br><span class="line">➜  ~ docker run -d -p 3307:3306 -e MYSQL_ROOT_PASSWORD=123456 --name mysql02 --volumes-from mysql01  mysql:5.7</span><br><span class="line"><span class="meta">#</span><span class="bash"> 这个时候，可以实现两个容器数据同步！</span></span><br></pre></td></tr></table></figure></div>

<p><strong>结论：</strong></p>
<p>容器之间的配置信息的传递，数据卷容器的生命周期一直持续到没有容器使用为止。</p>
<p>但是一旦你持久化到了本地，这个时候，本地的数据是不会删除的！</p>
<hr>
<h1 id="DockerFile"><a href="#DockerFile" class="headerlink" title="DockerFile"></a>DockerFile</h1><h2 id="DockerFile介绍"><a href="#DockerFile介绍" class="headerlink" title="DockerFile介绍"></a>DockerFile介绍</h2><p><code>dockerfile</code>是用来构建docker镜像的文件！命令参数脚本！</p>
<p><strong>构建步骤：</strong></p>
<p>1、 编写一个dockerfile文件</p>
<p>2、 docker build 构建称为一个镜像</p>
<p>3、 docker run运行镜像</p>
<p>4、 docker push发布镜像（DockerHub 、阿里云仓库)</p>
<p>查看官方是怎么做的！</p>
<p><img src="/2022/06/09/uncatalog/cl46zffyz00127or72j1r80ti/image-20200612233951676.png" alt="image-20200612233951676"></p>
<p><img src="/2022/06/09/uncatalog/cl46zffyz00127or72j1r80ti/image-20200612234022746.png" alt="image-20200612234022746"></p>
<p>很多官方镜像都是基础包，很多功能没有，我们通常会自己搭建自己的镜像！</p>
<p>官方既然可以制作镜像，那我们也可以！</p>
<h2 id="DockerFile构建过程"><a href="#DockerFile构建过程" class="headerlink" title="DockerFile构建过程"></a>DockerFile构建过程</h2><p><strong>基础知识：</strong></p>
<p>1、每个保留关键字(指令）都是必须是大写字母</p>
<p>2、执行从上到下顺序</p>
<p>3、# 表示注释</p>
<p>4、每一个指令都会创建提交一个新的镜像曾，并提交！</p>
<p><img src="/2022/06/09/uncatalog/cl46zffyz00127or72j1r80ti/image-20200612234419262.png" alt="image-20200612234419262"></p>
<p>Dockerfile是面向开发的，我们以后要发布项目，做镜像，就需要编写dockerfile文件，这个文件十分简单！</p>
<p>Docker镜像逐渐成企业交付的标准，必须要掌握！</p>
<p>DockerFile：构建文件，定义了一切的步骤，源代码</p>
<p>DockerImages：通过DockerFile构建生成的镜像，最终发布和运行产品。</p>
<p>Docker容器：容器就是镜像运行起来提供服务。</p>
<h2 id="DockerFile的指令"><a href="#DockerFile的指令" class="headerlink" title="DockerFile的指令"></a>DockerFile的指令</h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">FROM			# 基础镜像，一切从这里开始构建</span><br><span class="line">MAINTAINER		# 镜像是谁写的，姓名+邮箱</span><br><span class="line">RUN				# 镜像构建的时候需要运行的命令</span><br><span class="line">ADD				# 步骤：tomcat镜像，这个tomcat压缩包！ 添加内容</span><br><span class="line">WORKDIR			# 镜像的工作目录</span><br><span class="line">VOLUME			# 挂载的目录</span><br><span class="line">EXPOSE          # 暴露端口配置，跟 -p 是一个道理</span><br><span class="line">CMD				# 指定这个容器启动时要执行的命令,只有最后一个命令会生效，可悲替代</span><br><span class="line">ENTRYPOINT		# 指定这个容器启动的时候要执行的命令，可以追加命令</span><br><span class="line">ONBUILD			# 当构建一个被继承DockerFile 这个时候就会运行ONBUILD的指令。触发指令</span><br><span class="line">COPY			# 类似ADD,将我们文件拷贝到镜像中</span><br><span class="line">ENV				# 构建的时候设置环境变量，跟 -e 是一个意思</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> CMD 和 ENTRYPOINT 的区别说明：（后面也会介绍）</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 若CMD 和 ENTRYPOINT 后跟的都是 ls -a 这个命令，当docker run 一个容器时，添加了 -l 选项，则CMD里的ls -a 命令就会被替换成-l;而ENTRYPOINT中的 ls -a会追加-l变成 ls -a -l</span>  </span><br></pre></td></tr></table></figure></div>

<p><img src="/2022/06/09/uncatalog/cl46zffyz00127or72j1r80ti/image-20200613000838850.png" alt="image-20200613000838850"></p>
<h2 id="实战测试"><a href="#实战测试" class="headerlink" title="实战测试"></a>实战测试</h2><p>Docker Hub中99%镜像都是从这个基础镜像过来的( <strong>FROM scratch</strong> )，然后配置需要的软件和配置来构建。</p>
<p><img src="/2022/06/09/uncatalog/cl46zffyz00127or72j1r80ti/image-20200613001130237.png" alt="image-20200613001130237"></p>
<blockquote>
<p>创建一个自己的 centos</p>
</blockquote>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 1、编写DockerFile文件，内容如下：</span></span><br><span class="line">[root@localhost dockerfile]# cat mydockerfile-centos</span><br><span class="line">FROM centos						</span><br><span class="line">MAINTAINER ztx&lt;123456@qq.com&gt; </span><br><span class="line"></span><br><span class="line">ENV MYPATH /usr/local</span><br><span class="line">WORKDIR $MYPATH</span><br><span class="line"></span><br><span class="line">RUN yum -y install vim</span><br><span class="line">RUN yum -y install net-tools</span><br><span class="line"></span><br><span class="line">EXPOSE 80</span><br><span class="line"></span><br><span class="line">CMD echo $MYPATH</span><br><span class="line">CMD echo &quot;----end----&quot;</span><br><span class="line">CMD /bin/bash</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 2、通过这个文件构建镜像</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 命令docker build -f dockerfile文件路径 -t 镜像名:[tag] .</span></span><br><span class="line">[root@localhost dockerfile]# docker build -f mydockerfile-centos -t mycentos:0.1 .</span><br><span class="line">....</span><br><span class="line">Successfully built c987078b06cb</span><br><span class="line">Successfully tagged mycentos:0.1</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 3、测试运行</span></span><br></pre></td></tr></table></figure></div>

<p><strong>对比：</strong></p>
<p><strong>之前的原生的centos</strong></p>
<p><img src="/2022/06/09/uncatalog/cl46zffyz00127or72j1r80ti/image-20200613004551789.png" alt="image-20200613004551789"></p>
<p><strong>我们增加之后的镜像</strong></p>
<p><img src="/2022/06/09/uncatalog/cl46zffyz00127or72j1r80ti/image-20200613005056516.png" alt="image-20200613005056516"></p>
<p>注：net-tools 包含一系列程序，构成了 Linux 网络的基础。</p>
<p>我们可以列出本地镜像的变更历史：</p>
<p><img src="/2022/06/09/uncatalog/cl46zffyz00127or72j1r80ti/image-20200613005625844.png" alt="image-20200613005625844"></p>
<p>我们平时拿到一个镜像，可以研究一下它是怎么做的！</p>
<blockquote>
<p>CMD 和 ENTRYPOINT 的区别</p>
</blockquote>
<p><strong>测试CMD</strong></p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 编写dockerfile文件</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> vim dockerfile-test-cmd</span></span><br><span class="line">FROM centos</span><br><span class="line">CMD [&quot;ls&quot;,&quot;-a&quot;]</span><br><span class="line"><span class="meta">#</span><span class="bash"> 构建镜像</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> docker build  -f dockerfile-test-cmd -t cmd-test:0.1 .</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 运行镜像</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> docker run cmd-test:0.1</span></span><br><span class="line">.</span><br><span class="line">..</span><br><span class="line">.dockerenv</span><br><span class="line">bin</span><br><span class="line">dev</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 想追加一个命令  -l 成为ls -al</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> docker run cmd-test:0.1 -l</span></span><br><span class="line">docker: Error response from daemon: OCI runtime create failed: container_linux.go:349: starting container process caused &quot;exec: \&quot;-l\&quot;:</span><br><span class="line"> executable file not found in $PATH&quot;: unknown.</span><br><span class="line">ERRO[0000] error waiting for container: context canceled </span><br><span class="line"><span class="meta">#</span><span class="bash"> cmd的情况下 -l 替换了CMD[<span class="string">&quot;ls&quot;</span>,<span class="string">&quot;-l&quot;</span>]。 -l  不是命令,所以报错</span></span><br></pre></td></tr></table></figure></div>

<p><strong>测试ENTRYPOINT</strong></p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 编写dockerfile文件</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> vim dockerfile-test-entrypoint</span></span><br><span class="line">FROM centos</span><br><span class="line">ENTRYPOINT [&quot;ls&quot;,&quot;-a&quot;]</span><br><span class="line"><span class="meta">$</span><span class="bash"> docker run entrypoint-test:0.1</span></span><br><span class="line">.</span><br><span class="line">..</span><br><span class="line">.dockerenv</span><br><span class="line">bin</span><br><span class="line">dev</span><br><span class="line">etc</span><br><span class="line">home</span><br><span class="line">lib</span><br><span class="line">lib64</span><br><span class="line">lost+found ...</span><br><span class="line"><span class="meta">#</span><span class="bash"> 我们的命令，是直接拼接在我们的ENTRYPOINT命令后面的</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> docker run entrypoint-test:0.1 -l</span></span><br><span class="line">total 56</span><br><span class="line">drwxr-xr-x   1 root root 4096 May 16 06:32 .</span><br><span class="line">drwxr-xr-x   1 root root 4096 May 16 06:32 ..</span><br><span class="line">-rwxr-xr-x   1 root root    0 May 16 06:32 .dockerenv</span><br><span class="line">lrwxrwxrwx   1 root root    7 May 11  2019 bin -&gt; usr/bin</span><br><span class="line">drwxr-xr-x   5 root root  340 May 16 06:32 dev</span><br><span class="line">drwxr-xr-x   1 root root 4096 May 16 06:32 etc</span><br><span class="line">drwxr-xr-x   2 root root 4096 May 11  2019 home</span><br><span class="line">lrwxrwxrwx   1 root root    7 May 11  2019 lib -&gt; usr/lib</span><br><span class="line">lrwxrwxrwx   1 root root    9 May 11  2019 lib64 -&gt; usr/lib64 ....</span><br></pre></td></tr></table></figure></div>

<p>Dockerfile中很多命令都十分的相似，我们需要了解它们的区别，我们最好的学习就是对比他们然后测试效果！</p>
<h2 id="实战：Tomcat镜像"><a href="#实战：Tomcat镜像" class="headerlink" title="实战：Tomcat镜像"></a>实战：Tomcat镜像</h2><p>1、准备镜像文件tomcat压缩包，jdk压缩包！</p>
<p><img src="/2022/06/09/uncatalog/cl46zffyz00127or72j1r80ti/image-20200613151500712.png" alt="image-20200613151500712"></p>
<p>2、编写Dockerfile文件，官方命名: <strong>Dockerfile</strong> ，build会自动寻找这个文件，就不要 -f 指定了！</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">FROM centos</span><br><span class="line">MAINTAINER kuangshen&lt;123456@qq.com&gt;</span><br><span class="line"></span><br><span class="line">COPY readme.txt /usr/local/readme.txt</span><br><span class="line"></span><br><span class="line">ADD jdk-8u161-linux-x64.tar.gz    /usr/local/</span><br><span class="line">ADD apache-tomcat-8.0.53.tar.gz   /usr/local</span><br><span class="line"></span><br><span class="line">RUN yum -y install vim</span><br><span class="line">ENV MYPATH /usr/local</span><br><span class="line">WORKDIR $MYPATH</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ENV JAVA_HOME /usr/local/jdk1.8.0_161</span><br><span class="line">ENV CLASSPATH $JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar</span><br><span class="line">ENV CATALINA_HOME /usr/local/apache-tomcat-8.0.53</span><br><span class="line">ENV CATALINA_BASH /usr/local/apache-tomcat-8.0.53</span><br><span class="line">ENV PATH $PATH:$JAVA_HOME/bin:$CATALINA_HOME/lib:$CATALINA_HOME/bin</span><br><span class="line"></span><br><span class="line">EXPOSE 8080</span><br><span class="line"></span><br><span class="line">CMD /usr/local/apache-tomcat-8.0.53/bin/startup.sh &amp;&amp; tail -F /usr/local/apache-tomcat-8.0.53/bin/logs/catalina.out</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>

<p>3、构建镜像</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> docker build -t diytomcat .     diytomcat是定义的镜像名</span></span><br></pre></td></tr></table></figure></div>

<p>4、启动镜像，创建容器</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> docker run -d -p 9090:8080 --name kuangshentomcat02 -v /home/kuangshen/build/tomcat/<span class="built_in">test</span>:/usr/<span class="built_in">local</span>/apache-tomcat-8.0.53/webapps/<span class="built_in">test</span> -v /home/kuangshen/build/tomcat/tomcatlogs/:/usr/<span class="built_in">local</span>/apache-tomcat-8.0.53/logs diytomcat</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></div>

<p>5、访问测试</p>
<p><img src="/2022/06/09/uncatalog/cl46zffyz00127or72j1r80ti/image-20200613175551231.png" alt="image-20200613175551231"></p>
<p>6、发布项目（由于做了卷挂载，我们就可以直接在本地发布项目了）</p>
<p>在/home/kuangshen/build/tomcat/test目录下创建WEB-INF目录，在里面创建web.xml文件：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="XML"><figure class="iseeu highlight /xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">web-app</span> <span class="attr">xmlns</span>=<span class="string">&quot;http://java.sun.com/xml/ns/javaee&quot;</span></span></span><br><span class="line"><span class="tag">           <span class="attr">xmlns:xsi</span>=<span class="string">&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span></span></span><br><span class="line"><span class="tag">           <span class="attr">xsi:schemaLocation</span>=<span class="string">&quot;http://java.sun.com/xml/ns/javaee</span></span></span><br><span class="line"><span class="tag"><span class="string">                               http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd&quot;</span></span></span><br><span class="line"><span class="tag">           <span class="attr">version</span>=<span class="string">&quot;2.5&quot;</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">web-app</span>&gt;</span></span><br></pre></td></tr></table></figure></div>

<p>在回到test目录，添加一个index.jsp页面：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="HTML"><figure class="iseeu highlight /html"><table><tr><td class="code"><pre><span class="line">&lt;%@ page language=&quot;java&quot; contentType=&quot;text/html; charset=UTF-8&quot;</span><br><span class="line">    pageEncoding=&quot;UTF-8&quot;%&gt;</span><br><span class="line"><span class="meta">&lt;!DOCTYPE <span class="meta-keyword">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">meta</span> <span class="attr">charset</span>=<span class="string">&quot;utf-8&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">title</span>&gt;</span>hello kuangshen<span class="tag">&lt;/<span class="name">title</span>&gt;<span class="name">vim</span></span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">Hello World!<span class="tag">&lt;<span class="name">br</span>/&gt;</span></span><br><span class="line">&lt;%</span><br><span class="line">System.out.println(&quot;---my test web logs---&quot;);</span><br><span class="line">%&gt;</span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure></div>

<p>发现：test项目部署成功，可以直接访问！</p>
<p><img src="/2022/06/09/uncatalog/cl46zffyz00127or72j1r80ti/image-20200613180033633.png" alt="image-20200613180033633"></p>
<p>注意：这时进入/home/kuangshen/build/tomcat/tomcatlogs/目录下就可以看到日志信息了：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">[root@localhost tomcatlogs]# cat catalina.out </span><br></pre></td></tr></table></figure></div>

<p><img src="/2022/06/09/uncatalog/cl46zffyz00127or72j1r80ti/image-20200613180355186.png" alt="image-20200613180355186"></p>
<p>之前一直访问失败是web.xml配置有问题，最后也是查看该日志提示，才得以解决！！！</p>
<p>我们以后开发的步骤：需要掌握Dockerfile的编写！我们之后的一切都是使用docker镜像来发布运行！</p>
<h2 id="发布自己的镜像"><a href="#发布自己的镜像" class="headerlink" title="发布自己的镜像"></a>发布自己的镜像</h2><blockquote>
<p>Docker Hub</p>
</blockquote>
<p>1、地址 <a href="https://hub.docker.com/">https://hub.docker.com/</a></p>
<p>2、确定这个账号可以登录</p>
<p>3、在我们服务器上提交自己的镜像</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">[root@localhost tomcat]# docker login --help</span><br><span class="line"></span><br><span class="line">Usage:	docker login [OPTIONS] [SERVER]</span><br><span class="line"></span><br><span class="line">Log in to a Docker registry.</span><br><span class="line">If no server is specified, the default is defined by the daemon.</span><br><span class="line"></span><br><span class="line">Options:</span><br><span class="line">  -p, --password string   Password</span><br><span class="line">      --password-stdin    Take the password from stdin</span><br><span class="line">  -u, --username string   Username</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 登录dockerhub</span></span><br><span class="line">[root@localhost tomcat]# docker login -u ztx115</span><br><span class="line">Password: </span><br><span class="line">WARNING! Your password will be stored unencrypted in /root/.docker/config.json.</span><br><span class="line">Configure a credential helper to remove this warning. See</span><br><span class="line">https://docs.docker.com/engine/reference/commandline/login/#credentials-store</span><br><span class="line"></span><br><span class="line">Login Succeeded</span><br></pre></td></tr></table></figure></div>

<p>4、登录完毕后就可以提交镜像了，就是一步 docker push</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> push自己的镜像到服务器上！</span></span><br><span class="line">[root@localhost tomcat]# docker push diytomcat</span><br><span class="line">The push refers to repository [docker.io/library/diytomcat]</span><br><span class="line">c5593011cd68: Preparing </span><br><span class="line">d3ce40b8178e: Preparing </span><br><span class="line">02084c67dcc9: Preparing </span><br><span class="line">2b7c1c6c89c5: Preparing </span><br><span class="line">0683de282177: Preparing </span><br><span class="line">denied: requested access to the resource is denied  # 拒绝</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> push镜像的问题？</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 解决：增加一个tag         docker tag  指定镜像的id   dockerhub的用户名/镜像重命名:[tag]</span></span><br><span class="line">[root@localhost tomcat]# docker tag bb64ab96b432 ztx115/tomcat:1.0</span><br></pre></td></tr></table></figure></div>

<p><img src="/2022/06/09/uncatalog/cl46zffyz00127or72j1r80ti/image-20200613211709842.png" alt="image-20200613211709842"></p>
<p><strong>注意：镜像的重命名前一定要加当前的dockerhub的用户名，否则将会push失败！！！！</strong>（如：把ztx115改成ztx,  push一定失败！）</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> docekr push上去即可！  自己平时发布的镜像尽量带上版本号</span></span><br><span class="line">[root@localhost tomcat]# docker push ztx115/tomcat:1.0</span><br><span class="line">The push refers to repository [docker.io/ztx115/tomcat]</span><br><span class="line">c5593011cd68: Pushed </span><br><span class="line">d3ce40b8178e: Pushed </span><br><span class="line">02084c67dcc9: Pushed </span><br><span class="line">2b7c1c6c89c5: Pushed </span><br><span class="line">0683de282177: Pushed </span><br><span class="line">1.0: digest: sha256:b6733deccf85ad66c6f4302215dd9ea63e1579817f15a099b5858785708ed408 size: 1372</span><br></pre></td></tr></table></figure></div>

<p><img src="/2022/06/09/uncatalog/cl46zffyz00127or72j1r80ti/image-20200613210147709.png" alt="image-20200613210147709"></p>
<p>发现，提交时也是按照镜像的层级来进行提交的！</p>
<blockquote>
<p>发布到阿里云镜像服务上（狂神视频截图）</p>
</blockquote>
<p>1、登录阿里云</p>
<p>2、找到容器镜像服务</p>
<p>3、创建命名空间</p>
<p><img src="/2022/06/09/uncatalog/cl46zffyz00127or72j1r80ti/image-20200613212823736.png" alt="image-20200613212823736"></p>
<p>4、创建容器镜像仓库</p>
<p><img src="/2022/06/09/uncatalog/cl46zffyz00127or72j1r80ti/image-20200613213014849.png" alt="image-20200613213014849"></p>
<p><img src="/2022/06/09/uncatalog/cl46zffyz00127or72j1r80ti/image-20200613213135466.png" alt="image-20200613213135466"></p>
<p><img src="/2022/06/09/uncatalog/cl46zffyz00127or72j1r80ti/image-20200613213222587.png" alt="image-20200613213222587"></p>
<p>5、浏览阿里云</p>
<p><img src="/2022/06/09/uncatalog/cl46zffyz00127or72j1r80ti/image-20200613214159792.png" alt="image-20200613214159792"></p>
<p>使用阿里云容器镜像的参考官方指南即可！！！（即上图）</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p><img src="/2022/06/09/uncatalog/cl46zffyz00127or72j1r80ti/image-20200613214846464.png" alt="image-20200613214846464"></p>
<hr>
<h1 id="Docker网络"><a href="#Docker网络" class="headerlink" title="Docker网络"></a>Docker网络</h1><h2 id="理解Docker0"><a href="#理解Docker0" class="headerlink" title="理解Docker0"></a>理解Docker0</h2><p>清空所有环境</p>
<blockquote>
<p>测试</p>
</blockquote>
<p><img src="/2022/06/09/uncatalog/cl46zffyz00127or72j1r80ti/image-20200613224119526.png" alt="image-20200613224119526"></p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 问题： docker是如何处理容器网络访问的？</span></span><br></pre></td></tr></table></figure></div>

<p><img src="/2022/06/09/uncatalog/cl46zffyz00127or72j1r80ti/image-20200613220806390.png" alt="image-20200613220806390"></p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> [root@localhost /]<span class="comment"># docker run -d -P --name tomcat01 tomcat</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看容器的内部网络地址   ip addr,  发现容器启动的时候会得到一个 eth0@if43 ip地址，docker分配的！</span></span><br><span class="line">[root@localhost /]# docker exec -it tomcat01 ip addr</span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">42: eth0@if43: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default </span><br><span class="line">    link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff link-netnsid 0</span><br><span class="line">    inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 思考：linux能不能ping通docker容器内部！</span></span><br><span class="line">[root@localhost /]# ping 172.17.0.2</span><br><span class="line">PING 172.17.0.2 (172.17.0.2) 56(84) bytes of data.</span><br><span class="line">64 bytes from 172.17.0.2: icmp_seq=1 ttl=64 time=0.476 ms</span><br><span class="line">64 bytes from 172.17.0.2: icmp_seq=2 ttl=64 time=0.099 ms</span><br><span class="line">64 bytes from 172.17.0.2: icmp_seq=3 ttl=64 time=0.105 ms</span><br><span class="line">...</span><br><span class="line"><span class="meta">#</span><span class="bash"> linux 可以ping通docker容器内部</span></span><br></pre></td></tr></table></figure></div>

<blockquote>
<p>原理</p>
</blockquote>
<p>1、我们每启动一个docker容器，docker就会给docker容器分配一个ip，我们只要装了docker，就会有一个docker01网卡。</p>
<p>桥接模式，使用的技术是veth-pair技术！</p>
<p>再次测试 ip addr，发现多了一对网卡 :</p>
<p><img src="/2022/06/09/uncatalog/cl46zffyz00127or72j1r80ti/image-20200613224311838.png" alt="image-20200613224311838"></p>
<p>2、再启动一个容器测试，发现又多了一对网卡！！！</p>
<p><img src="/2022/06/09/uncatalog/cl46zffyz00127or72j1r80ti/image-20200613224610781.png" alt="image-20200613224610781"></p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 我们发现这个容器带来网卡，都是一对对的</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> veth-pair 就是一对的虚拟设备接口，他们都是成对出现的，一段连着协议，一段彼此相连</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 正因为有这个特性，veth-pair 充当一个桥梁，连接各种虚拟网络设备</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> OpenStack，Docker容器之间的连接，OVS的连接都是使用veth-pair技术</span></span><br></pre></td></tr></table></figure></div>

<p>3、我们来测试下tomcat01和tomcat02是否可以ping通！</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">[root@localhost /]# docker exec -it tomcat02 ping 172.17.0.2</span><br><span class="line">PING 172.17.0.2 (172.17.0.2) 56(84) bytes of data.</span><br><span class="line">64 bytes from 172.17.0.2: icmp_seq=1 ttl=64 time=0.556 ms</span><br><span class="line">64 bytes from 172.17.0.2: icmp_seq=2 ttl=64 time=0.096 ms</span><br><span class="line">64 bytes from 172.17.0.2: icmp_seq=3 ttl=64 time=0.111 ms</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 结论：容器与容器之间是可以相互ping通的！！！</span></span><br></pre></td></tr></table></figure></div>

<p><strong>绘制一个网络模型图：</strong></p>
<p><img src="/2022/06/09/uncatalog/cl46zffyz00127or72j1r80ti/image-20200613231046553.png" alt="image-20200613231046553"></p>
<p><strong>结论：tomcat01 和 tomcat02 是公用一个路由器，即 docker0 !</strong></p>
<p>所有的容器不指定网络的情况下，都是经 docker0 路由的，docker 会给我们的容器分配一个默认的可用ip</p>
<blockquote>
<p>小结</p>
</blockquote>
<p>Docker使用的是Linux的桥接技术，宿主机是一个Docker容器的网桥 docker0</p>
<p><img src="/2022/06/09/uncatalog/cl46zffyz00127or72j1r80ti/image-20200613232031835.png" alt="image-20200613232031835"></p>
<p><strong>注意：</strong>Docker中所有网络接口都是虚拟的，虚拟的转发效率高！（内网传递文件）</p>
<p>只要容器一删除，对应的一对网桥就没有！</p>
<h2 id="–link"><a href="#–link" class="headerlink" title="–link"></a>–link</h2><blockquote>
<p>思考一个场景：我们编写了一个微服务，database url = ip ，项目不重启，数据库ip换掉了，我们希望可以处理这个问题，可以通过名字来访问容器？</p>
</blockquote>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> tomcat02 想通过直接ping 容器名（即<span class="string">&quot;tomcat01&quot;</span>）来ping通，而不是ip，发现失败了！</span></span><br><span class="line">[root@localhost /]# docker exec -it tomcat02 ping tomcat01</span><br><span class="line">ping: tomcat01: Name or service not known</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 如何解决这个问题呢？</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 通过--link 就可以解决这个网络联通问题了！！！      发现新建的tomcat03可以ping通tomcat02</span></span><br><span class="line">[root@localhost /]# docker run -d -P --name tomcat03 --link tomcat02 tomcat</span><br><span class="line">87a0e5f5e6da34a7f043ff6210b57f92f40b24d0d4558462e7746b2e19902721</span><br><span class="line">[root@localhost /]# docker exec -it tomcat03 ping tomcat02</span><br><span class="line">PING tomcat02 (172.17.0.3) 56(84) bytes of data.</span><br><span class="line">64 bytes from tomcat02 (172.17.0.3): icmp_seq=1 ttl=64 time=0.132 ms</span><br><span class="line">64 bytes from tomcat02 (172.17.0.3): icmp_seq=2 ttl=64 time=0.116 ms</span><br><span class="line">64 bytes from tomcat02 (172.17.0.3): icmp_seq=3 ttl=64 time=0.116 ms</span><br><span class="line">64 bytes from tomcat02 (172.17.0.3): icmp_seq=4 ttl=64 time=0.116 ms</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 反向能ping通吗？       发现tomcat02不能oing通tomcat03</span></span><br><span class="line">[root@localhost /]# docker exec -it tomcat02 ping tomcat03</span><br><span class="line">ping: tomcat03: Name or service not known</span><br></pre></td></tr></table></figure></div>

<p>探究：inspect  ！！！</p>
<p><img src="/2022/06/09/uncatalog/cl46zffyz00127or72j1r80ti/image-20200614002609300.png" alt="image-20200614002609300"></p>
<p><img src="/2022/06/09/uncatalog/cl46zffyz00127or72j1r80ti/image-20200614002832045.png" alt="image-20200614002832045"></p>
<p>其实这个tomcat03就是在本地配置了到tomcat02的映射：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 查看hosts 配置，在这里发现原理！</span>  </span><br><span class="line">[root@localhost /]# docker exec -it tomcat03 cat /etc/hosts</span><br><span class="line">127.0.0.1	localhost</span><br><span class="line">::1	localhost ip6-localhost ip6-loopback</span><br><span class="line">fe00::0	ip6-localnet</span><br><span class="line">ff00::0	ip6-mcastprefix</span><br><span class="line">ff02::1	ip6-allnodes</span><br><span class="line">ff02::2	ip6-allrouters</span><br><span class="line">172.17.0.3	tomcat02 95303c12f6d9    # 就像windows中的 host 文件一样，做了地址绑定</span><br><span class="line">172.17.0.4	87a0e5f5e6da</span><br></pre></td></tr></table></figure></div>

<p>本质探究：–link  就是我们在hosts 配置中增加了一个 172.17.0.3    tomcat02   95303c12f6d9 （三条信息都是tomcat02 的）</p>
<p>我们现在玩Docker已经不建议使用 –link 了！！！</p>
<p><strong>自定义网络，不使用docker0！</strong></p>
<p>docker0问题：不支持容器名连接访问！</p>
<h2 id="自定义网络"><a href="#自定义网络" class="headerlink" title="自定义网络"></a>自定义网络</h2><blockquote>
<p>查看所有的docker网络</p>
</blockquote>
<p>‘<img src="/2022/06/09/uncatalog/cl46zffyz00127or72j1r80ti/image-20200614004445923.png" alt="image-20200614004445923"></p>
<p><strong>网络模式</strong></p>
<p>bridge  ：桥接 （docker默认，自己创建也使用bridge模式！）</p>
<p>none ：不配置网络</p>
<p>host  ：和宿主机共享网络</p>
<p>container  ：容器网络连通，容器直接互联！（用的少！局限很大！）</p>
<p><strong>测试</strong></p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 我们之前直接启动的命令 (默认是使用--net bridge，可省)，这个bridge就是我们的docker0</span> </span><br><span class="line">docker run -d -P --name tomcat01 tomcat   </span><br><span class="line">docker run -d -P --name tomcat01 --net bridge tomcat</span><br><span class="line"><span class="meta">#</span><span class="bash"> 上面两句等价</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> docker0（即bridge）默认不支持域名访问 ！ --link可以打通连接，即支持域名访问！</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 我们可以自定义一个网络！</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> --driver bridge    		网络模式定义为 ：桥接</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> --subnet 192.168.0.0/16	定义子网 ，范围为：192.168.0.2 ~ 192.168.255.255</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> --gateway 192.168.0.1		子网网关设为： 192.168.0.1</span> </span><br><span class="line">[root@localhost /]# docker network create --driver bridge --subnet 192.168.0.0/16 --gateway 192.168.0.1 mynet</span><br><span class="line">7ee3adf259c8c3d86fce6fd2c2c9f85df94e6e57c2dce5449e69a5b024efc28c</span><br><span class="line">[root@localhost /]# docker network ls</span><br><span class="line">NETWORK ID          NAME                DRIVER              SCOPE</span><br><span class="line">461bf576946c        bridge              bridge              local</span><br><span class="line">c501704cf28e        host                host                local</span><br><span class="line">7ee3adf259c8        mynet               bridge              local  	#自定义的网络</span><br><span class="line">9354fbcc160f        none                null                local</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>

<p><strong>自己的网络就创建好了：</strong></p>
<p><img src="/2022/06/09/uncatalog/cl46zffyz00127or72j1r80ti/image-20200614011229854.png" alt="image-20200614011229854"></p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">[root@localhost /]# docker run -d -P --name tomcat-net-01 --net mynet tomcat</span><br><span class="line">b168a37d31fcdc2ff172fd969e4de6de731adf53a2960eeae3dd9c24e14fac67</span><br><span class="line">[root@localhost /]# docker run -d -P --name tomcat-net-02 --net mynet tomcat</span><br><span class="line">c07d634e17152ca27e318c6fcf6c02e937e6d5e7a1631676a39166049a44c03c</span><br><span class="line">[root@localhost /]# docker network inspect mynet</span><br><span class="line">[</span><br><span class="line">    &#123;</span><br><span class="line">        &quot;Name&quot;: &quot;mynet&quot;,</span><br><span class="line">        &quot;Id&quot;: &quot;7ee3adf259c8c3d86fce6fd2c2c9f85df94e6e57c2dce5449e69a5b024efc28c&quot;,</span><br><span class="line">        &quot;Created&quot;: &quot;2020-06-14T01:03:53.767960765+08:00&quot;,</span><br><span class="line">        &quot;Scope&quot;: &quot;local&quot;,</span><br><span class="line">        &quot;Driver&quot;: &quot;bridge&quot;,</span><br><span class="line">        &quot;EnableIPv6&quot;: false,</span><br><span class="line">        &quot;IPAM&quot;: &#123;</span><br><span class="line">            &quot;Driver&quot;: &quot;default&quot;,</span><br><span class="line">            &quot;Options&quot;: &#123;&#125;,</span><br><span class="line">            &quot;Config&quot;: [</span><br><span class="line">                &#123;</span><br><span class="line">                    &quot;Subnet&quot;: &quot;192.168.0.0/16&quot;,</span><br><span class="line">                    &quot;Gateway&quot;: &quot;192.168.0.1&quot;</span><br><span class="line">                &#125;</span><br><span class="line">            ]</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;Internal&quot;: false,</span><br><span class="line">        &quot;Attachable&quot;: false,</span><br><span class="line">        &quot;Ingress&quot;: false,</span><br><span class="line">        &quot;ConfigFrom&quot;: &#123;</span><br><span class="line">            &quot;Network&quot;: &quot;&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;ConfigOnly&quot;: false,</span><br><span class="line">        &quot;Containers&quot;: &#123;</span><br><span class="line">            &quot;b168a37d31fcdc2ff172fd969e4de6de731adf53a2960eeae3dd9c24e14fac67&quot;: &#123;</span><br><span class="line">                &quot;Name&quot;: &quot;tomcat-net-01&quot;,</span><br><span class="line">                &quot;EndpointID&quot;: &quot;f0af1c33fc5d47031650d07d5bc769e0333da0989f73f4503140151d0e13f789&quot;,</span><br><span class="line">                &quot;MacAddress&quot;: &quot;02:42:c0:a8:00:02&quot;,</span><br><span class="line">                &quot;IPv4Address&quot;: &quot;192.168.0.2/16&quot;,</span><br><span class="line">                &quot;IPv6Address&quot;: &quot;&quot;</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;c07d634e17152ca27e318c6fcf6c02e937e6d5e7a1631676a39166049a44c03c&quot;: &#123;</span><br><span class="line">                &quot;Name&quot;: &quot;tomcat-net-02&quot;,</span><br><span class="line">                &quot;EndpointID&quot;: &quot;ba114b9bd5f3b75983097aa82f71678653619733efc1835db857b3862e744fbc&quot;,</span><br><span class="line">                &quot;MacAddress&quot;: &quot;02:42:c0:a8:00:03&quot;,</span><br><span class="line">                &quot;IPv4Address&quot;: &quot;192.168.0.3/16&quot;,</span><br><span class="line">                &quot;IPv6Address&quot;: &quot;&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;Options&quot;: &#123;&#125;,</span><br><span class="line">        &quot;Labels&quot;: &#123;&#125;</span><br><span class="line">    &#125;</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 再次测试 ping 连接</span></span><br><span class="line">[root@localhost /]# docker exec -it tomcat-net-01 ping 192.168.0.3</span><br><span class="line">PING 192.168.0.3 (192.168.0.3) 56(84) bytes of data.</span><br><span class="line">64 bytes from 192.168.0.3: icmp_seq=1 ttl=64 time=0.199 ms</span><br><span class="line">64 bytes from 192.168.0.3: icmp_seq=2 ttl=64 time=0.121 ms</span><br><span class="line">^C</span><br><span class="line">--- 192.168.0.3 ping statistics ---</span><br><span class="line">2 packets transmitted, 2 received, 0% packet loss, time 2ms</span><br><span class="line">rtt min/avg/max/mdev = 0.121/0.160/0.199/0.039 ms</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 现在不使用 --link,也可以ping 名字了！！！！！！</span></span><br><span class="line">[root@localhost /]# docker exec -it tomcat-net-01 ping tomcat-net-02</span><br><span class="line">PING tomcat-net-02 (192.168.0.3) 56(84) bytes of data.</span><br><span class="line">64 bytes from tomcat-net-02.mynet (192.168.0.3): icmp_seq=1 ttl=64 time=0.145 ms</span><br><span class="line">64 bytes from tomcat-net-02.mynet (192.168.0.3): icmp_seq=2 ttl=64 time=0.117 ms</span><br><span class="line">^C</span><br><span class="line">--- tomcat-net-02 ping statistics ---</span><br><span class="line">2 packets transmitted, 2 received, 0% packet loss, time 3ms</span><br><span class="line">rtt min/avg/max/mdev = 0.117/0.131/0.145/0.014 ms</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>

<p>我们在使用自定义的网络时，docker都已经帮我们维护好了对应关系，推荐我们平时这样使用网络！！！</p>
<p>好处：</p>
<p>redis——不同的集群使用不同的网络，保证了集群的安全和健康</p>
<p>mysql——不同的集群使用不同的网络，保证了集群的安全和健康</p>
<p><img src="/2022/06/09/uncatalog/cl46zffyz00127or72j1r80ti/image-20200614015209053.png" alt="image-20200614015209053"></p>
<h2 id="网络连通"><a href="#网络连通" class="headerlink" title="网络连通"></a>网络连通</h2><p><img src="/2022/06/09/uncatalog/cl46zffyz00127or72j1r80ti/image-20200614013625192.png" alt="image-20200614013625192"></p>
<p><img src="/2022/06/09/uncatalog/cl46zffyz00127or72j1r80ti/image-20200614013801842.png" alt="image-20200614013801842"></p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 测试打通 tomcat01 — mynet</span></span><br><span class="line">[root@localhost /]# docker network connect mynet tomcat01</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 连通之后就是将 tomcat01 放到了 mynet 网络下！ （见下图）</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 这就产生了 一个容器有两个ip地址 ! 参考阿里云的公有ip和私有ip</span></span><br><span class="line">[root@localhost /]# docker network inspect mynet</span><br></pre></td></tr></table></figure></div>

<p><img src="/2022/06/09/uncatalog/cl46zffyz00127or72j1r80ti/image-20200614014544797.png" alt="image-20200614014544797"></p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> tomcat01 连通ok</span></span><br><span class="line">[root@localhost /]# docker exec -it tomcat01 ping tomcat-net-01</span><br><span class="line">PING tomcat-net-01 (192.168.0.2) 56(84) bytes of data.</span><br><span class="line">64 bytes from tomcat-net-01.mynet (192.168.0.2): icmp_seq=1 ttl=64 time=0.124 ms</span><br><span class="line">64 bytes from tomcat-net-01.mynet (192.168.0.2): icmp_seq=2 ttl=64 time=0.162 ms</span><br><span class="line">64 bytes from tomcat-net-01.mynet (192.168.0.2): icmp_seq=3 ttl=64 time=0.107 ms</span><br><span class="line">^C</span><br><span class="line">--- tomcat-net-01 ping statistics ---</span><br><span class="line">3 packets transmitted, 3 received, 0% packet loss, time 3ms</span><br><span class="line">rtt min/avg/max/mdev = 0.107/0.131/0.162/0.023 ms</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> tomcat02 是依旧打不通的</span></span><br><span class="line">[root@localhost /]# docker exec -it tomcat02 ping tomcat-net-01</span><br><span class="line">ping: tomcat-net-01: Name or service not known</span><br></pre></td></tr></table></figure></div>

<p><strong>结论：</strong>假设要跨网络操作别人，就需要使用docker network connect  连通。。。</p>
<h2 id="实战：部署Redis集群"><a href="#实战：部署Redis集群" class="headerlink" title="实战：部署Redis集群"></a>实战：部署Redis集群</h2><p><img src="/2022/06/09/uncatalog/cl46zffyz00127or72j1r80ti/image-20200614124559172.png" alt="image-20200614124559172"></p>
<p>启动6个redis容器，上面三个是主，下面三个是备！</p>
<p>使用shell脚本启动！</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建redis集群网络</span></span><br><span class="line">docker network create redis --subnet 172.38.0.0/16</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 通过脚本创建六个redis配置</span></span><br><span class="line">[root@localhost /]# for port in $(seq 1 6);\</span><br><span class="line"><span class="meta">&gt;</span><span class="bash"> <span class="keyword">do</span> \</span></span><br><span class="line"><span class="bash">&gt; mkdir -p /mydata/redis/node-<span class="variable">$&#123;port&#125;</span>/conf</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash"> touch /mydata/redis/node-<span class="variable">$&#123;port&#125;</span>/conf/redis.conf</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash"> cat &lt;&lt;<span class="string">EOF&gt;&gt;/mydata/redis/node-$&#123;port&#125;/conf/redis.conf</span></span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash"> port 6379</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash"> <span class="built_in">bind</span> 0.0.0.0</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash"> cluster-enabled yes</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash"> cluster-config-file nodes.conf</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash"> cluster-node-timeout 5000</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash"> cluster-announce-ip 172.38.0.1<span class="variable">$&#123;port&#125;</span></span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash"> cluster-announce-port 6379</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash"> cluster-announce-bus-port 16379</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash"> appendonly yes</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash"> EOF</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash"> <span class="keyword">done</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看创建的六个redis</span></span><br><span class="line">[root@localhost /]# cd /mydata/</span><br><span class="line">[root@localhost mydata]# \ls</span><br><span class="line">redis</span><br><span class="line">[root@localhost mydata]# cd redis/</span><br><span class="line">[root@localhost redis]# ls</span><br><span class="line">node-1  node-2  node-3  node-4  node-5  node-6</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看redis-1的配置信息</span></span><br><span class="line">[root@localhost redis]# cd node-1</span><br><span class="line">[root@localhost node-1]# ls</span><br><span class="line">conf</span><br><span class="line">[root@localhost node-1]# cd conf/</span><br><span class="line">[root@localhost conf]# ls</span><br><span class="line">redis.conf</span><br><span class="line">[root@localhost conf]# cat redis.conf </span><br><span class="line">port 6379</span><br><span class="line">bind 0.0.0.0</span><br><span class="line">cluster-enabled yes</span><br><span class="line">cluster-config-file nodes.conf</span><br><span class="line">cluster-node-timeout 5000</span><br><span class="line">cluster-announce-ip 172.38.0.11</span><br><span class="line">cluster-announce-port 6379</span><br><span class="line">cluster-announce-bus-port 16379</span><br><span class="line">appendonly yes</span><br></pre></td></tr></table></figure></div>



<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">docker run -p 6371:6379 -p 16371:16379 --name redis-1 \</span><br><span class="line">-v /mydata/redis/node-1/data:/data \</span><br><span class="line">-v /mydata/redis/node-1/conf/redis.conf:/etc/redis/redis.conf \</span><br><span class="line">-d --net redis --ip 172.38.0.11 redis:5.0.9-alpine3.11 redis-server /etc/redis/redis.conf</span><br><span class="line"></span><br><span class="line">docker run -p 6372:6379 -p 16372:16379 --name redis-2 \</span><br><span class="line">-v /mydata/redis/node-2/data:/data \</span><br><span class="line">-v /mydata/redis/node-2/conf/redis.conf:/etc/redis/redis.conf \</span><br><span class="line">-d --net redis --ip 172.38.0.12 redis:5.0.9-alpine3.11 redis-server /etc/redis/redis.conf</span><br><span class="line"></span><br><span class="line">docker run -p 6373:6379 -p 16373:16379 --name redis-3 \</span><br><span class="line">-v /mydata/redis/node-3/data:/data \</span><br><span class="line">-v /mydata/redis/node-3/conf/redis.conf:/etc/redis/redis.conf \</span><br><span class="line">-d --net redis --ip 172.38.0.13 redis:5.0.9-alpine3.11 redis-server /etc/redis/redis.conf</span><br><span class="line"></span><br><span class="line">docker run -p 6374:6379 -p 16374:16379 --name redis-4 \</span><br><span class="line">-v /mydata/redis/node-4/data:/data \</span><br><span class="line">-v /mydata/redis/node-4/conf/redis.conf:/etc/redis/redis.conf \</span><br><span class="line">-d --net redis --ip 172.38.0.14 redis:5.0.9-alpine3.11 redis-server /etc/redis/redis.conf</span><br><span class="line"></span><br><span class="line">docker run -p 6375:6379 -p 16375:16379 --name redis-5 \</span><br><span class="line">-v /mydata/redis/node-5/data:/data \</span><br><span class="line">-v /mydata/redis/node-5/conf/redis.conf:/etc/redis/redis.conf \</span><br><span class="line">-d --net redis --ip 172.38.0.15 redis:5.0.9-alpine3.11 redis-server /etc/redis/redis.conf</span><br><span class="line"></span><br><span class="line">docker run -p 6376:6379 -p 16376:16379 --name redis-6 \</span><br><span class="line">-v /mydata/redis/node-6/data:/data \</span><br><span class="line">-v /mydata/redis/node-6/conf/redis.conf:/etc/redis/redis.conf \</span><br><span class="line">-d --net redis --ip 172.38.0.16 redis:5.0.9-alpine3.11 redis-server /etc/redis/redis.conf</span><br></pre></td></tr></table></figure></div>

<p><img src="/2022/06/09/uncatalog/cl46zffyz00127or72j1r80ti/image-20200614133829277.png" alt="image-20200614133829277"></p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">[root@localhost conf]# docker exec -it redis-1 /bin/sh</span><br><span class="line">/data # ls</span><br><span class="line">appendonly.aof  nodes.conf</span><br><span class="line">/data # redis-cli --cluster create 172.38.0.11:6379 172.38.0.12:6379 172.38.0.13:6379 172.38.0.14:6379 172.38.0.15:6379 172.38.0.16:6379 --cluster-replicas 1</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; Performing <span class="built_in">hash</span> slots allocation on 6 nodes...</span></span><br><span class="line">Master[0] -&gt; Slots 0 - 5460</span><br><span class="line">Master[1] -&gt; Slots 5461 - 10922</span><br><span class="line">Master[2] -&gt; Slots 10923 - 16383</span><br><span class="line">Adding replica 172.38.0.15:6379 to 172.38.0.11:6379</span><br><span class="line">Adding replica 172.38.0.16:6379 to 172.38.0.12:6379</span><br><span class="line">Adding replica 172.38.0.14:6379 to 172.38.0.13:6379</span><br><span class="line">M: c5551e2a30c220fc9de9df2e34692f20f3382b32 172.38.0.11:6379</span><br><span class="line">   slots:[0-5460] (5461 slots) master</span><br><span class="line">M: d12ebd8c9e12dbbe22e7b9b18f0f143bdc14e94b 172.38.0.12:6379</span><br><span class="line">   slots:[5461-10922] (5462 slots) master</span><br><span class="line">M: 825146ce6ab80fbb46ec43fcfec1c6e2dac55157 172.38.0.13:6379</span><br><span class="line">   slots:[10923-16383] (5461 slots) master</span><br><span class="line">S: 9f810c0e15ac99af68e114a0ee4e32c4c7067e2b 172.38.0.14:6379</span><br><span class="line">   replicates 825146ce6ab80fbb46ec43fcfec1c6e2dac55157</span><br><span class="line">S: e370225bf57d6ef6d54ad8e3d5d745a52b382d1a 172.38.0.15:6379</span><br><span class="line">   replicates c5551e2a30c220fc9de9df2e34692f20f3382b32</span><br><span class="line">S: 79428c1d018dd29cf191678658008cbe5100b714 172.38.0.16:6379</span><br><span class="line">   replicates d12ebd8c9e12dbbe22e7b9b18f0f143bdc14e94b</span><br><span class="line">Can I set the above configuration? (type &#x27;yes&#x27; to accept): yes</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; Nodes configuration updated</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; Assign a different config epoch to each node</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; Sending CLUSTER MEET messages to join the cluster</span></span><br><span class="line">Waiting for the cluster to join</span><br><span class="line">....</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; Performing Cluster Check (using node 172.38.0.11:6379)</span></span><br><span class="line">M: c5551e2a30c220fc9de9df2e34692f20f3382b32 172.38.0.11:6379</span><br><span class="line">   slots:[0-5460] (5461 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">S: 79428c1d018dd29cf191678658008cbe5100b714 172.38.0.16:6379</span><br><span class="line">   slots: (0 slots) slave</span><br><span class="line">   replicates d12ebd8c9e12dbbe22e7b9b18f0f143bdc14e94b</span><br><span class="line">M: d12ebd8c9e12dbbe22e7b9b18f0f143bdc14e94b 172.38.0.12:6379</span><br><span class="line">   slots:[5461-10922] (5462 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">S: e370225bf57d6ef6d54ad8e3d5d745a52b382d1a 172.38.0.15:6379</span><br><span class="line">   slots: (0 slots) slave</span><br><span class="line">   replicates c5551e2a30c220fc9de9df2e34692f20f3382b32</span><br><span class="line">S: 9f810c0e15ac99af68e114a0ee4e32c4c7067e2b 172.38.0.14:6379</span><br><span class="line">   slots: (0 slots) slave</span><br><span class="line">   replicates 825146ce6ab80fbb46ec43fcfec1c6e2dac55157</span><br><span class="line">M: 825146ce6ab80fbb46ec43fcfec1c6e2dac55157 172.38.0.13:6379</span><br><span class="line">   slots:[10923-16383] (5461 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">[OK] All nodes agree about slots configuration.</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; Check <span class="keyword">for</span> open slots...</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; Check slots coverage...</span></span><br><span class="line">[OK] All 16384 slots covered.</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>

<p>docker搭建redis集群完成！</p>
<p><img src="/2022/06/09/uncatalog/cl46zffyz00127or72j1r80ti/image-20200614141549867.png" alt="image-20200614141549867"></p>
<p>我们使用docker之后，所有的技术都会慢慢变得简单起来！</p>
<hr>
<h1 id="Springboot微服务打包Docker镜像"><a href="#Springboot微服务打包Docker镜像" class="headerlink" title="Springboot微服务打包Docker镜像"></a>Springboot微服务打包Docker镜像</h1><p>1、构建springboot项目，打包应用</p>
<p><img src="/2022/06/09/uncatalog/cl46zffyz00127or72j1r80ti/image-20200614155721369.png" alt="image-20200614155721369"></p>
<p>2、编写Dockerfile，连同项目的jar包一并上传指定目录下</p>
<p><img src="/2022/06/09/uncatalog/cl46zffyz00127or72j1r80ti/image-20200614153734161.png" alt="image-20200614153734161"></p>
<p><img src="/2022/06/09/uncatalog/cl46zffyz00127or72j1r80ti/image-20200614154114656.png" alt="image-20200614154114656"></p>
<p>3、构建镜像</p>
<p><img src="/2022/06/09/uncatalog/cl46zffyz00127or72j1r80ti/image-20200614154355597.png" alt="image-20200614154355597"></p>
<p>4、创建项目容器，发布运行！！！</p>
<p><img src="/2022/06/09/uncatalog/cl46zffyz00127or72j1r80ti/image-20200614155034087.png" alt="image-20200614155034087"></p>
<p><img src="/2022/06/09/uncatalog/cl46zffyz00127or72j1r80ti/image-20200614155340519.png" alt="image-20200614155340519"></p>
<p>以后我们使用了Docker之后，给别人交付就是一个镜像即可！</p>
]]></content>
      <tags>
        <tag>云原生基础系列</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>云原生基础系列之Kubernetes(二)集群环境搭建</title>
    <url>/2022/06/09/uncatalog/cl46zkqb400157or761km2b46/</url>
    <content><![CDATA[<hr>
<span id="more"></span>



<hr>
<h3 id="2-kubernetes集群环境搭建"><a href="#2-kubernetes集群环境搭建" class="headerlink" title="2. kubernetes集群环境搭建"></a>2. kubernetes集群环境搭建</h3><h4 id="2-1-前置知识点"><a href="#2-1-前置知识点" class="headerlink" title="2.1 前置知识点"></a>2.1 前置知识点</h4><p>目前生产部署Kubernetes 集群主要有两种方式：</p>
<p><strong>kubeadm</strong></p>
<p>Kubeadm 是一个K8s 部署工具，提供kubeadm init 和kubeadm join，用于快速部署Kubernetes 集群。</p>
<p>官方地址：<a href="https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm/">https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm/</a></p>
<p><strong>二进制包</strong></p>
<p>从github 下载发行版的二进制包，手动部署每个组件，组成Kubernetes 集群。</p>
<p>Kubeadm 降低部署门槛，但屏蔽了很多细节，遇到问题很难排查。如果想更容易可控，推荐使用二进制包部署Kubernetes 集群，虽然手动部署麻烦点，期间可以学习很多工作原理，也利于后期维护。</p>
<p><img src="/2022/06/09/uncatalog/cl46zkqb400157or761km2b46/image-20200404094800622.png" alt="image-20200404094800622"></p>
<h4 id="2-2-kubeadm-部署方式介绍"><a href="#2-2-kubeadm-部署方式介绍" class="headerlink" title="2.2 kubeadm 部署方式介绍"></a>2.2 kubeadm 部署方式介绍</h4><p>kubeadm 是官方社区推出的一个用于快速部署kubernetes 集群的工具，这个工具能通过两条指令完成一个kubernetes 集群的部署：</p>
<ul>
<li>创建一个Master 节点kubeadm init</li>
<li>将Node 节点加入到当前集群中$ kubeadm join &lt;Master 节点的IP 和端口&gt;</li>
</ul>
<h4 id="2-3-安装要求"><a href="#2-3-安装要求" class="headerlink" title="2.3 安装要求"></a>2.3 安装要求</h4><p>在开始之前，部署Kubernetes 集群机器需要满足以下几个条件：</p>
<ul>
<li>一台或多台机器，操作系统CentOS7.x-86_x64</li>
<li>硬件配置：2GB 或更多RAM，2 个CPU 或更多CPU，硬盘30GB 或更多</li>
<li>集群中所有机器之间网络互通</li>
<li>可以访问外网，需要拉取镜像</li>
<li>禁止swap 分区</li>
</ul>
<h4 id="2-4-最终目标"><a href="#2-4-最终目标" class="headerlink" title="2.4 最终目标"></a>2.4 最终目标</h4><ul>
<li>在所有节点上安装Docker 和kubeadm</li>
<li>部署Kubernetes Master</li>
<li>部署容器网络插件</li>
<li>部署Kubernetes Node，将节点加入Kubernetes 集群中</li>
<li>部署Dashboard Web 页面，可视化查看Kubernetes 资源</li>
</ul>
<h4 id="2-5-准备环境"><a href="#2-5-准备环境" class="headerlink" title="2.5 准备环境"></a>2.5 准备环境</h4><p><img src="/2022/06/09/uncatalog/cl46zkqb400157or761km2b46/image-20210609000002940.png" alt="image-20210609000002940"></p>
<table>
<thead>
<tr>
<th align="left">角色</th>
<th align="left">IP地址</th>
<th align="left">组件</th>
</tr>
</thead>
<tbody><tr>
<td align="left">master01</td>
<td align="left">192.168.5.3</td>
<td align="left">docker，kubectl，kubeadm，kubelet</td>
</tr>
<tr>
<td align="left">node01</td>
<td align="left">192.168.5.4</td>
<td align="left">docker，kubectl，kubeadm，kubelet</td>
</tr>
<tr>
<td align="left">node02</td>
<td align="left">192.168.5.5</td>
<td align="left">docker，kubectl，kubeadm，kubelet</td>
</tr>
</tbody></table>
<h4 id="2-6-环境初始化"><a href="#2-6-环境初始化" class="headerlink" title="2.6 环境初始化"></a>2.6 环境初始化</h4><h5 id="2-6-1-检查操作系统的版本"><a href="#2-6-1-检查操作系统的版本" class="headerlink" title="2.6.1 检查操作系统的版本"></a>2.6.1 检查操作系统的版本</h5><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="POWERSHELL"><figure class="iseeu highlight /powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 此方式下安装kubernetes集群要求Centos版本要在7.5或之上</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># cat /etc/redhat-release</span></span><br><span class="line">Centos Linux <span class="number">7.5</span>.<span class="number">1804</span> (Core)</span><br></pre></td></tr></table></figure></div>

<h5 id="2-6-2-主机名解析"><a href="#2-6-2-主机名解析" class="headerlink" title="2.6.2 主机名解析"></a>2.6.2 主机名解析</h5><p>为了方便集群节点间的直接调用，在这个配置一下主机名解析，企业中推荐使用内部DNS服务器</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="POWERSHELL"><figure class="iseeu highlight /powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 主机名成解析 编辑三台服务器的/etc/hosts文件，添加下面内容</span></span><br><span class="line"><span class="number">192.168</span>.<span class="number">90.100</span> master</span><br><span class="line"><span class="number">192.168</span>.<span class="number">90.106</span> node1</span><br><span class="line"><span class="number">192.168</span>.<span class="number">90.107</span> node2</span><br></pre></td></tr></table></figure></div>

<h5 id="2-6-3-时间同步"><a href="#2-6-3-时间同步" class="headerlink" title="2.6.3 时间同步"></a>2.6.3 时间同步</h5><p>kubernetes要求集群中的节点时间必须精确一直，这里使用chronyd服务从网络同步时间</p>
<p>企业中建议配置内部的会见同步服务器</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="POWERSHELL"><figure class="iseeu highlight /powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 启动chronyd服务</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># systemctl start chronyd</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># systemctl enable chronyd</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># date</span></span><br></pre></td></tr></table></figure></div>

<h5 id="2-6-4-禁用iptable和firewalld服务"><a href="#2-6-4-禁用iptable和firewalld服务" class="headerlink" title="2.6.4  禁用iptable和firewalld服务"></a>2.6.4  禁用iptable和firewalld服务</h5><p>kubernetes和docker 在运行的中会产生大量的iptables规则，为了不让系统规则跟它们混淆，直接关闭系统的规则</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="POWERSHELL"><figure class="iseeu highlight /powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 1 关闭firewalld服务</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># systemctl stop firewalld</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># systemctl disable firewalld</span></span><br><span class="line"><span class="comment"># 2 关闭iptables服务</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># systemctl stop iptables</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># systemctl disable iptables</span></span><br></pre></td></tr></table></figure></div>

<h5 id="2-6-5-禁用selinux"><a href="#2-6-5-禁用selinux" class="headerlink" title="2.6.5 禁用selinux"></a>2.6.5 禁用selinux</h5><p>selinux是linux系统下的一个安全服务，如果不关闭它，在安装集群中会产生各种各样的奇葩问题</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="POWERSHELL"><figure class="iseeu highlight /powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 编辑 /etc/selinux/config 文件，修改SELINUX的值为disable</span></span><br><span class="line"><span class="comment"># 注意修改完毕之后需要重启linux服务</span></span><br><span class="line">SELINUX=disabled</span><br></pre></td></tr></table></figure></div>

<h5 id="2-6-6-禁用swap分区"><a href="#2-6-6-禁用swap分区" class="headerlink" title="2.6.6 禁用swap分区"></a>2.6.6 禁用swap分区</h5><p>swap分区指的是虚拟内存分区，它的作用是物理内存使用完，之后将磁盘空间虚拟成内存来使用，启用swap设备会对系统的性能产生非常负面的影响，因此kubernetes要求每个节点都要禁用swap设备，但是如果因为某些原因确实不能关闭swap分区，就需要在集群安装过程中通过明确的参数进行配置说明</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="POWERSHELL"><figure class="iseeu highlight /powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 编辑分区配置文件/etc/fstab，注释掉swap分区一行</span></span><br><span class="line"><span class="comment"># 注意修改完毕之后需要重启linux服务</span></span><br><span class="line">vim /etc/fstab</span><br><span class="line">注释掉 /dev/mapper/centos<span class="literal">-swap</span> swap</span><br><span class="line"><span class="comment"># /dev/mapper/centos-swap swap</span></span><br></pre></td></tr></table></figure></div>

<h5 id="2-6-7-修改linux的内核参数"><a href="#2-6-7-修改linux的内核参数" class="headerlink" title="2.6.7 修改linux的内核参数"></a>2.6.7 修改linux的内核参数</h5><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="POWERSHELL"><figure class="iseeu highlight /powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 修改linux的内核采纳数，添加网桥过滤和地址转发功能</span></span><br><span class="line"><span class="comment"># 编辑/etc/sysctl.d/kubernetes.conf文件，添加如下配置：</span></span><br><span class="line">net.bridge.bridge<span class="literal">-nf</span><span class="literal">-call</span><span class="literal">-ip6tables</span> = <span class="number">1</span></span><br><span class="line">net.bridge.bridge<span class="literal">-nf</span><span class="literal">-call</span><span class="literal">-iptables</span> = <span class="number">1</span></span><br><span class="line">net.ipv4.ip_forward = <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 重新加载配置</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># sysctl -p</span></span><br><span class="line"><span class="comment"># 加载网桥过滤模块</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># modprobe br_netfilter</span></span><br><span class="line"><span class="comment"># 查看网桥过滤模块是否加载成功</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># lsmod | grep br_netfilter</span></span><br></pre></td></tr></table></figure></div>

<h5 id="2-6-8-配置ipvs功能"><a href="#2-6-8-配置ipvs功能" class="headerlink" title="2.6.8 配置ipvs功能"></a>2.6.8 配置ipvs功能</h5><p>在Kubernetes中Service有两种带来模型，一种是基于iptables的，一种是基于ipvs的两者比较的话，ipvs的性能明显要高一些，但是如果要使用它，需要手动载入ipvs模块</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="POWERSHELL"><figure class="iseeu highlight /powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 1.安装ipset和ipvsadm</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># yum install ipset ipvsadm -y</span></span><br><span class="line"><span class="comment"># 2.添加需要加载的模块写入脚本文件</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># cat &lt;&lt;EOF&gt; /etc/sysconfig/modules/ipvs.modules</span></span><br><span class="line"><span class="comment">#!/bin/bash</span></span><br><span class="line">modprobe -- ip_vs</span><br><span class="line">modprobe -- ip_vs_rr</span><br><span class="line">modprobe -- ip_vs_wrr</span><br><span class="line">modprobe -- ip_vs_sh</span><br><span class="line">modprobe -- nf_conntrack_ipv4</span><br><span class="line">EOF</span><br><span class="line"><span class="comment"># 3.为脚本添加执行权限</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># chmod +x /etc/sysconfig/modules/ipvs.modules</span></span><br><span class="line"><span class="comment"># 4.执行脚本文件</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># /bin/bash /etc/sysconfig/modules/ipvs.modules</span></span><br><span class="line"><span class="comment"># 5.查看对应的模块是否加载成功</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># lsmod | grep -e ip_vs -e nf_conntrack_ipv4</span></span><br></pre></td></tr></table></figure></div>

<h5 id="2-6-9-安装docker"><a href="#2-6-9-安装docker" class="headerlink" title="2.6.9 安装docker"></a>2.6.9 安装docker</h5><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="POWERSHELL"><figure class="iseeu highlight /powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 1、切换镜像源</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># wget https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo -O /etc/yum.repos.d/docker-ce.repo</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2、查看当前镜像源中支持的docker版本</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># yum list docker-ce --showduplicates</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3、安装特定版本的docker-ce</span></span><br><span class="line"><span class="comment"># 必须制定--setopt=obsoletes=0，否则yum会自动安装更高版本</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># yum install --setopt=obsoletes=0 docker-ce-18.06.3.ce-3.el7 -y</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 4、添加一个配置文件</span></span><br><span class="line"><span class="comment">#Docker 在默认情况下使用Vgroup Driver为cgroupfs，而Kubernetes推荐使用systemd来替代cgroupfs</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># mkdir /etc/docker</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># cat &lt;&lt;EOF&gt; /etc/docker/daemon.json</span></span><br><span class="line">&#123;</span><br><span class="line">	<span class="string">&quot;exec-opts&quot;</span>: [<span class="string">&quot;native.cgroupdriver=systemd&quot;</span>],</span><br><span class="line">	<span class="string">&quot;registry-mirrors&quot;</span>: [<span class="string">&quot;https://kn0t2bca.mirror.aliyuncs.com&quot;</span>]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5、启动dokcer</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># systemctl restart docker</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># systemctl enable docker</span></span><br></pre></td></tr></table></figure></div>

<h5 id="2-6-10-安装Kubernetes组件"><a href="#2-6-10-安装Kubernetes组件" class="headerlink" title="2.6.10 安装Kubernetes组件"></a>2.6.10 安装Kubernetes组件</h5><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="POWERSHELL"><figure class="iseeu highlight /powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 1、由于kubernetes的镜像在国外，速度比较慢，这里切换成国内的镜像源</span></span><br><span class="line"><span class="comment"># 2、编辑/etc/yum.repos.d/kubernetes.repo,添加下面的配置</span></span><br><span class="line">[<span class="type">kubernetes</span>]</span><br><span class="line">name=Kubernetes</span><br><span class="line">baseurl=http://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes<span class="literal">-el7</span><span class="literal">-x86_64</span></span><br><span class="line">enabled=<span class="number">1</span></span><br><span class="line">gpgchech=<span class="number">0</span></span><br><span class="line">repo_gpgcheck=<span class="number">0</span></span><br><span class="line">gpgkey=http://mirrors.aliyun.com/kubernetes/yum/doc/yum<span class="literal">-key</span>.gpg</span><br><span class="line">			http://mirrors.aliyun.com/kubernetes/yum/doc/rpm<span class="literal">-package</span><span class="literal">-key</span>.gpg</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3、安装kubeadm、kubelet和kubectl</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># yum install --setopt=obsoletes=0 kubeadm-1.17.4-0 kubelet-1.17.4-0 kubectl-1.17.4-0 -y</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 4、配置kubelet的cgroup</span></span><br><span class="line"><span class="comment">#编辑/etc/sysconfig/kubelet, 添加下面的配置</span></span><br><span class="line">KUBELET_CGROUP_ARGS=<span class="string">&quot;--cgroup-driver=systemd&quot;</span></span><br><span class="line">KUBE_PROXY_MODE=<span class="string">&quot;ipvs&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 5、设置kubelet开机自启</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># systemctl enable kubelet</span></span><br></pre></td></tr></table></figure></div>

<h5 id="2-6-11-准备集群镜像"><a href="#2-6-11-准备集群镜像" class="headerlink" title="2.6.11 准备集群镜像"></a>2.6.11 准备集群镜像</h5><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="POWERSHELL"><figure class="iseeu highlight /powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 在安装kubernetes集群之前，必须要提前准备好集群需要的镜像，所需镜像可以通过下面命令查看</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubeadm config images list</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载镜像</span></span><br><span class="line"><span class="comment"># 此镜像kubernetes的仓库中，由于网络原因，无法连接，下面提供了一种替换方案</span></span><br><span class="line">images=(</span><br><span class="line">	kube<span class="literal">-apiserver</span>:v1.<span class="number">17.4</span></span><br><span class="line">	kube<span class="literal">-controller</span><span class="literal">-manager</span>:v1.<span class="number">17.4</span></span><br><span class="line">	kube<span class="literal">-scheduler</span>:v1.<span class="number">17.4</span></span><br><span class="line">	kube<span class="literal">-proxy</span>:v1.<span class="number">17.4</span></span><br><span class="line">	pause:<span class="number">3.1</span></span><br><span class="line">	etcd:<span class="number">3.4</span>.<span class="number">3</span><span class="literal">-0</span></span><br><span class="line">	coredns:<span class="number">1.6</span>.<span class="number">5</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> imageName <span class="keyword">in</span> <span class="variable">$</span>&#123;images[<span class="selector-tag">@</span>]&#125;;<span class="keyword">do</span></span><br><span class="line">	docker pull registry.cn<span class="literal">-hangzhou</span>.aliyuncs.com/google_containers/<span class="variable">$imageName</span></span><br><span class="line">	docker tag registry.cn<span class="literal">-hangzhou</span>.aliyuncs.com/google_containers/<span class="variable">$imageName</span> k8s.gcr.io/<span class="variable">$imageName</span></span><br><span class="line">	docker rmi registry.cn<span class="literal">-hangzhou</span>.aliyuncs.com/google_containers/<span class="variable">$imageName</span> </span><br><span class="line">done</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>

<h5 id="2-6-11-集群初始化"><a href="#2-6-11-集群初始化" class="headerlink" title="2.6.11 集群初始化"></a>2.6.11 集群初始化</h5><blockquote>
<p>下面的操作只需要在master节点上执行即可</p>
</blockquote>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="POWERSHELL"><figure class="iseeu highlight /powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建集群</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubeadm init \</span></span><br><span class="line">	-<span class="literal">-apiserver</span><span class="literal">-advertise</span><span class="literal">-address</span>=<span class="number">192.168</span>.<span class="number">90.100</span> \</span><br><span class="line">	-<span class="literal">-image</span><span class="literal">-repository</span> registry.aliyuncs.com/google_containers \</span><br><span class="line">	-<span class="literal">-kubernetes</span><span class="literal">-version</span>=v1.<span class="number">17.4</span> \</span><br><span class="line">	-<span class="literal">-service</span><span class="literal">-cidr</span>=<span class="number">10.96</span>.<span class="number">0.0</span>/<span class="number">12</span> \</span><br><span class="line">	-<span class="literal">-pod</span><span class="literal">-network</span><span class="literal">-cidr</span>=<span class="number">10.244</span>.<span class="number">0.0</span>/<span class="number">16</span></span><br><span class="line"><span class="comment"># 创建必要文件</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># mkdir -p $HOME/.kube</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># sudo chown $(id -u):$(id -g) $HOME/.kube/config</span></span><br></pre></td></tr></table></figure></div>

<blockquote>
<p>下面的操作只需要在node节点上执行即可</p>
</blockquote>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="POWERSHELL"><figure class="iseeu highlight /powershell"><table><tr><td class="code"><pre><span class="line">kubeadm join <span class="number">192.168</span>.<span class="number">0.100</span>:<span class="number">6443</span> -<span class="literal">-token</span> awk15p.t6bamck54w69u4s8 \</span><br><span class="line">    -<span class="literal">-discovery</span><span class="literal">-token</span><span class="literal">-ca</span><span class="literal">-cert</span><span class="literal">-hash</span> sha256:a94fa09562466d32d29523ab6cff122186f1127599fa4dcd5fa0152694f17117 </span><br></pre></td></tr></table></figure></div>

<p>在master上查看节点信息</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="POWERSHELL"><figure class="iseeu highlight /powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubectl get nodes</span></span><br><span class="line">NAME    STATUS   ROLES     AGE   VERSION</span><br><span class="line">master  NotReady  master   <span class="number">6</span>m    v1.<span class="number">17.4</span></span><br><span class="line">node1   NotReady   &lt;none&gt;  <span class="number">22</span>s   v1.<span class="number">17.4</span></span><br><span class="line">node2   NotReady   &lt;none&gt;  <span class="number">19</span>s   v1.<span class="number">17.4</span></span><br></pre></td></tr></table></figure></div>

<h5 id="2-6-13-安装网络插件，只在master节点操作即可"><a href="#2-6-13-安装网络插件，只在master节点操作即可" class="headerlink" title="2.6.13 安装网络插件，只在master节点操作即可"></a>2.6.13 安装网络插件，只在master节点操作即可</h5><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="POWERSHELL"><figure class="iseeu highlight /powershell"><table><tr><td class="code"><pre><span class="line"><span class="built_in">wget</span> https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube<span class="literal">-flannel</span>.yml</span><br></pre></td></tr></table></figure></div>

<p>由于外网不好访问，如果出现无法访问的情况，可以直接用下面的 记得文件名是kube-flannel.yml，位置：/root/kube-flannel.yml内容：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="POWERSHELL"><figure class="iseeu highlight /powershell"><table><tr><td class="code"><pre><span class="line">https://github.com/flannel<span class="literal">-io</span>/flannel/tree/master/Documentation/kube<span class="literal">-flannel</span>.yml</span><br></pre></td></tr></table></figure></div>
<p>也可手动拉取指定版本<br>docker pull quay.io/coreos/flannel:v0.14.0              #拉取flannel网络，三台主机<br>docker images                  #查看仓库是否拉去下来</p>
<p><code>个人笔记</code><br>若是集群状态一直是 notready,用下面语句查看原因，<br>journalctl -f -u kubelet.service<br>若原因是： cni.go:237] Unable to update cni config: no networks found in /etc/cni/net.d<br>mkdir -p /etc/cni/net.d                    #创建目录给flannel做配置文件<br>vim /etc/cni/net.d/10-flannel.conf         #编写配置文件</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="POWERSHELL"><figure class="iseeu highlight /powershell"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">&#123;</span><br><span class="line"> <span class="string">&quot;name&quot;</span>:<span class="string">&quot;cbr0&quot;</span>,</span><br><span class="line"> <span class="string">&quot;cniVersion&quot;</span>:<span class="string">&quot;0.3.1&quot;</span>,</span><br><span class="line"> <span class="string">&quot;type&quot;</span>:<span class="string">&quot;flannel&quot;</span>,</span><br><span class="line"> <span class="string">&quot;deledate&quot;</span>:&#123;</span><br><span class="line">    <span class="string">&quot;hairpinMode&quot;</span>:true,</span><br><span class="line">    <span class="string">&quot;isDefaultGateway&quot;</span>:true</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>


<h5 id="2-6-14-使用kubeadm-reset重置集群"><a href="#2-6-14-使用kubeadm-reset重置集群" class="headerlink" title="2.6.14 使用kubeadm reset重置集群"></a>2.6.14 使用kubeadm reset重置集群</h5><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="PLAIN"><figure class="iseeu highlight /plain"><table><tr><td class="code"><pre><span class="line">#在master节点之外的节点进行操作</span><br><span class="line">kubeadm reset</span><br><span class="line">systemctl stop kubelet</span><br><span class="line">systemctl stop docker</span><br><span class="line">rm -rf &#x2F;var&#x2F;lib&#x2F;cni&#x2F;</span><br><span class="line">rm -rf &#x2F;var&#x2F;lib&#x2F;kubelet&#x2F;*</span><br><span class="line">rm -rf &#x2F;etc&#x2F;cni&#x2F;</span><br><span class="line">ifconfig cni0 down</span><br><span class="line">ifconfig flannel.1 down</span><br><span class="line">ifconfig docker0 down</span><br><span class="line">ip link delete cni0</span><br><span class="line">ip link delete flannel.1</span><br><span class="line">##重启kubelet</span><br><span class="line">systemctl restart kubelet</span><br><span class="line">##重启docker</span><br><span class="line">systemctl restart docker</span><br></pre></td></tr></table></figure></div>

<h5 id="2-6-15-重启kubelet和docker"><a href="#2-6-15-重启kubelet和docker" class="headerlink" title="2.6.15 重启kubelet和docker"></a>2.6.15 重启kubelet和docker</h5><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="POWERSHELL"><figure class="iseeu highlight /powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 重启kubelet</span></span><br><span class="line">systemctl restart kubelet</span><br><span class="line"><span class="comment"># 重启docker</span></span><br><span class="line">systemctl restart docker</span><br></pre></td></tr></table></figure></div>

<p>使用配置文件启动fannel</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="POWERSHELL"><figure class="iseeu highlight /powershell"><table><tr><td class="code"><pre><span class="line">kubectl apply <span class="operator">-f</span> kube<span class="literal">-flannel</span>.yml</span><br></pre></td></tr></table></figure></div>

<p>等待它安装完毕 发现已经是 集群的状态已经是Ready</p>
<p><img src="/2022/06/09/uncatalog/cl46zkqb400157or761km2b46/2232696-20210621233106024-1676033717.png" alt="img"></p>
<h5 id="2-6-16-kubeadm中的命令"><a href="#2-6-16-kubeadm中的命令" class="headerlink" title="2.6.16 kubeadm中的命令"></a>2.6.16 kubeadm中的命令</h5><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="POWERSHELL"><figure class="iseeu highlight /powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 生成 新的token</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># kubeadm token create --print-join-command</span></span><br></pre></td></tr></table></figure></div>

<h4 id="2-7-集群测试"><a href="#2-7-集群测试" class="headerlink" title="2.7 集群测试"></a>2.7 集群测试</h4><h5 id="2-7-1-创建一个nginx服务"><a href="#2-7-1-创建一个nginx服务" class="headerlink" title="2.7.1 创建一个nginx服务"></a>2.7.1 创建一个nginx服务</h5><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="POWERSHELL"><figure class="iseeu highlight /powershell"><table><tr><td class="code"><pre><span class="line">kubectl create deployment nginx  -<span class="literal">-image</span>=nginx:<span class="number">1.14</span><span class="literal">-alpine</span></span><br></pre></td></tr></table></figure></div>

<h5 id="2-7-2-暴露端口"><a href="#2-7-2-暴露端口" class="headerlink" title="2.7.2 暴露端口"></a>2.7.2 暴露端口</h5><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="POWERSHELL"><figure class="iseeu highlight /powershell"><table><tr><td class="code"><pre><span class="line">kubectl expose deploy nginx  -<span class="literal">-port</span>=<span class="number">80</span> -<span class="literal">-target</span><span class="literal">-port</span>=<span class="number">80</span>  -<span class="literal">-type</span>=NodePort</span><br></pre></td></tr></table></figure></div>

<h5 id="2-7-3-查看服务"><a href="#2-7-3-查看服务" class="headerlink" title="2.7.3 查看服务"></a>2.7.3 查看服务</h5><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="POWERSHELL"><figure class="iseeu highlight /powershell"><table><tr><td class="code"><pre><span class="line">kubectl get pod,svc</span><br></pre></td></tr></table></figure></div>

<h5 id="2-7-4-查看pod"><a href="#2-7-4-查看pod" class="headerlink" title="2.7.4 查看pod"></a>2.7.4 查看pod</h5><p><img src="/2022/06/09/uncatalog/cl46zkqb400157or761km2b46/2232696-20210621233130477-111035427.png" alt="img"></p>
<p>浏览器测试结果：</p>
<p><img src="/2022/06/09/uncatalog/cl46zkqb400157or761km2b46/2232696-20210621233157075-1117518703.png" alt="img"></p>
]]></content>
      <tags>
        <tag>云原生基础系列</tag>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>云原生基础系列之Kubernetes(一)Kubernetes介绍</title>
    <url>/2022/06/09/uncatalog/cl46zoo76000028r79whb5rff/</url>
    <content><![CDATA[<hr>
<span id="more"></span>
<hr>
<h3 id="1-Kubernetes介绍"><a href="#1-Kubernetes介绍" class="headerlink" title="1. Kubernetes介绍"></a>1. Kubernetes介绍</h3><h4 id="1-1-应用部署方式演变"><a href="#1-1-应用部署方式演变" class="headerlink" title="1.1 应用部署方式演变"></a>1.1 应用部署方式演变</h4><p>在部署应用程序的方式上，主要经历了三个时代：</p>
<ul>
<li><p><strong>传统部署</strong>：互联网早期，会直接将应用程序部署在物理机上</p>
<blockquote>
<p>优点：简单，不需要其它技术的参与</p>
<p>缺点：不能为应用程序定义资源使用边界，很难合理地分配计算资源，而且程序之间容易产生影响</p>
</blockquote>
</li>
<li><p><strong>虚拟化部署</strong>：可以在一台物理机上运行多个虚拟机，每个虚拟机都是独立的一个环境</p>
<blockquote>
<p>优点：程序环境不会相互产生影响，提供了一定程度的安全性</p>
<p>缺点：增加了操作系统，浪费了部分资源</p>
</blockquote>
</li>
<li><p><strong>容器化部署</strong>：与虚拟化类似，但是共享了操作系统</p>
<blockquote>
<p>优点：</p>
<p>可以保证每个容器拥有自己的文件系统、CPU、内存、进程空间等</p>
<p>运行应用程序所需要的资源都被容器包装，并和底层基础架构解耦</p>
<p>容器化的应用程序可以跨云服务商、跨Linux操作系统发行版进行部署</p>
</blockquote>
</li>
</ul>
<p><img src="/2022/06/09/uncatalog/cl46zoo76000028r79whb5rff/image-20200505183738289.png" alt="image-20200505183738289"></p>
<p>容器化部署方式给带来很多的便利，但是也会出现一些问题，比如说：</p>
<ul>
<li>一个容器故障停机了，怎么样让另外一个容器立刻启动去替补停机的容器</li>
<li>当并发访问量变大的时候，怎么样做到横向扩展容器数量</li>
</ul>
<p>这些容器管理的问题统称为<strong>容器编排</strong>问题，为了解决这些容器编排问题，就产生了一些容器编排的软件：</p>
<ul>
<li><strong>Swarm</strong>：Docker自己的容器编排工具</li>
<li><strong>Mesos</strong>：Apache的一个资源统一管控的工具，需要和Marathon结合使用</li>
<li><strong>Kubernetes</strong>：Google开源的的容器编排工具</li>
</ul>
<p><img src="/2022/06/09/uncatalog/cl46zoo76000028r79whb5rff/image-20200524150339551.png" alt="image-20200524150339551"></p>
<h4 id="1-2-kubernetes简介"><a href="#1-2-kubernetes简介" class="headerlink" title="1.2 kubernetes简介"></a>1.2 kubernetes简介</h4><p><img src="/2022/06/09/uncatalog/cl46zoo76000028r79whb5rff/image-20200406232838722.png" alt="image-20200406232838722"></p>
<p>kubernetes，是一个全新的基于容器技术的分布式架构领先方案，是谷歌严格保密十几年的秘密武器—-Borg系统的一个开源版本，于2014年9月发布第一个版本，2015年7月发布第一个正式版本。</p>
<p>kubernetes的本质是<strong>一组服务器集群</strong>，它可以在集群的每个节点上运行特定的程序，来对节点中的容器进行管理。目的是实现资源管理的自动化，主要提供了如下的主要功能：</p>
<ul>
<li><strong>自我修复</strong>：一旦某一个容器崩溃，能够在1秒中左右迅速启动新的容器</li>
<li><strong>弹性伸缩</strong>：可以根据需要，自动对集群中正在运行的容器数量进行调整</li>
<li><strong>服务发现</strong>：服务可以通过自动发现的形式找到它所依赖的服务</li>
<li><strong>负载均衡</strong>：如果一个服务起动了多个容器，能够自动实现请求的负载均衡</li>
<li><strong>版本回退</strong>：如果发现新发布的程序版本有问题，可以立即回退到原来的版本</li>
<li><strong>存储编排</strong>：可以根据容器自身的需求自动创建存储卷</li>
</ul>
<h4 id="1-3-kubernetes组件"><a href="#1-3-kubernetes组件" class="headerlink" title="1.3 kubernetes组件"></a>1.3 kubernetes组件</h4><p>一个kubernetes集群主要是由**控制节点(master)<strong>、</strong>工作节点(node)**构成，每个节点上都会安装不同的组件。</p>
<p><strong>master：集群的控制平面，负责集群的决策 ( 管理 )</strong></p>
<blockquote>
<p><strong>ApiServer</strong> : 资源操作的唯一入口，接收用户输入的命令，提供认证、授权、API注册和发现等机制</p>
<p><strong>Scheduler</strong> : 负责集群资源调度，按照预定的调度策略将Pod调度到相应的node节点上</p>
<p><strong>ControllerManager</strong> : 负责维护集群的状态，比如程序部署安排、故障检测、自动扩展、滚动更新等</p>
<p><strong>Etcd</strong> ：负责存储集群中各种资源对象的信息</p>
</blockquote>
<p><strong>node：集群的数据平面，负责为容器提供运行环境 ( 干活 )</strong></p>
<blockquote>
<p><strong>Kubelet</strong> : 负责维护容器的生命周期，即通过控制docker，来创建、更新、销毁容器</p>
<p><strong>KubeProxy</strong> : 负责提供集群内部的服务发现和负载均衡</p>
<p><strong>Docker</strong> : 负责节点上容器的各种操作</p>
</blockquote>
<p><img src="/2022/06/09/uncatalog/cl46zoo76000028r79whb5rff/image-20200406184656917.png" alt="image-20200406184656917"></p>
<p>下面，以部署一个nginx服务来说明kubernetes系统各个组件调用关系：</p>
<ol>
<li><p>首先要明确，一旦kubernetes环境启动之后，master和node都会将自身的信息存储到etcd数据库中</p>
</li>
<li><p>一个nginx服务的安装请求会首先被发送到master节点的apiServer组件</p>
</li>
<li><p>apiServer组件会调用scheduler组件来决定到底应该把这个服务安装到哪个node节点上</p>
<p>在此时，它会从etcd中读取各个node节点的信息，然后按照一定的算法进行选择，并将结果告知apiServer</p>
</li>
<li><p>apiServer调用controller-manager去调度Node节点安装nginx服务</p>
</li>
<li><p>kubelet接收到指令后，会通知docker，然后由docker来启动一个nginx的pod</p>
<p>pod是kubernetes的最小操作单元，容器必须跑在pod中至此，</p>
</li>
<li><p>一个nginx服务就运行了，如果需要访问nginx，就需要通过kube-proxy来对pod产生访问的代理</p>
</li>
</ol>
<p>这样，外界用户就可以访问集群中的nginx服务了</p>
<h4 id="1-4-kubernetes概念"><a href="#1-4-kubernetes概念" class="headerlink" title="1.4 kubernetes概念"></a>1.4 kubernetes概念</h4><p><strong>Master</strong>：集群控制节点，每个集群需要至少一个master节点负责集群的管控</p>
<p><strong>Node</strong>：工作负载节点，由master分配容器到这些node工作节点上，然后node节点上的docker负责容器的运行</p>
<p><strong>Pod</strong>：kubernetes的最小控制单元，容器都是运行在pod中的，一个pod中可以有1个或者多个容器</p>
<p><strong>Controller</strong>：控制器，通过它来实现对pod的管理，比如启动pod、停止pod、伸缩pod的数量等等</p>
<p><strong>Service</strong>：pod对外服务的统一入口，下面可以维护者同一类的多个pod</p>
<p><strong>Label</strong>：标签，用于对pod进行分类，同一类pod会拥有相同的标签</p>
<p><strong>NameSpace</strong>：命名空间，用来隔离pod的运行环境</p>
]]></content>
      <tags>
        <tag>云原生基础系列</tag>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>云原生基础系列之docker(三)docker基础技术:linux namespace</title>
    <url>/2022/06/10/uncatalog/cl483pse2000038r7fnpqhzig/</url>
    <content><![CDATA[<hr>
<span id="more"></span>


<hr>
<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><blockquote>
<p>时下最热的技术莫过于Docker了，很多人都觉得Docker是个新技术，其实不然，Docker除了其编程语言用go比较新外，其实它还真不是个新东西，也就是个新瓶装旧酒的东西，所谓的The New “Old Stuff”。Docker和Docker衍生的东西用到了很多很酷的技术，我会用几篇 文章来把这些技术给大家做个介绍，希望通过这些文章大家可以自己打造一个山寨版的docker。<br>当然，文章的风格一定会尊重时下的“流行”——我们再也没有整块整块的时间去看书去专研，而我们只有看微博微信那样的碎片时间（那怕我们有整块的时间，也被那些在手机上的APP碎片化了）。所以，这些文章的风格必然坚持“马桶风格”（希望简单到占用你拉一泡屎就时间，而且你还不用动脑子，并能学到些东西）<br>废话少说，我们开始。先从Linux Namespace开始。</p>
</blockquote>
<h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>Linux Namespace是Linux提供的一种内核级别环境隔离的方法。不知道你是否还记得很早以前的Unix有一个叫chroot的系统调用（通过修改根目录把用户jail到一个特定目录下），chroot提供了一种简单的隔离模式：chroot内部的文件系统无法访问外部的内容。Linux Namespace在此基础上，提供了对UTS、IPC、mount、PID、network、User等的隔离机制。<br>举个例子，我们都知道，Linux下的超级父亲进程的PID是1，所以，同chroot一样，如果我们可以把用户的进程空间jail到某个进程分支下，并像chroot那样让其下面的进程 看到的那个超级父进程的PID为1，于是就可以达到资源隔离的效果了（不同的PID namespace中的进程无法看到彼此）<br><strong>Linux Namespace 有如下种类</strong> ，官方文档在这里<a href="https://lwn.net/Articles/531114/" title="Front-end web development">Namespace in Operation</a></p>
<table>
<thead>
<tr>
<th align="left">分类</th>
<th align="left">系统调用参数</th>
<th align="left">相关内核版本</th>
</tr>
</thead>
<tbody><tr>
<td align="left">Mount namespaces</td>
<td align="left">CLONE_NEWNS</td>
<td align="left">Linux 2.4.19</td>
</tr>
<tr>
<td align="left">UTS namespaces</td>
<td align="left">CLONE_NEWUTS</td>
<td align="left">Linux 2.4.19</td>
</tr>
<tr>
<td align="left">IPC namespaces</td>
<td align="left">CLONE_NEWIPC</td>
<td align="left">Linux 2.4.19</td>
</tr>
<tr>
<td align="left">PID namespaces</td>
<td align="left">CLONE_NEWPID</td>
<td align="left">Linux 2.6.24</td>
</tr>
<tr>
<td align="left">Network namespaces</td>
<td align="left">CLONE_NEWNET</td>
<td align="left">始于Linux 2.6.24 完成于 Linux 2.6.29</td>
</tr>
<tr>
<td align="left">User namespaces</td>
<td align="left">CLONE_NEWUSER</td>
<td align="left">始于 Linux 2.6.23 完成于 Linux 3.8)</td>
</tr>
</tbody></table>
<p>主要是三个系统调用</p>
<ul>
<li><code>clone()</code> 实现线程的系统调用，用来创建一个新的进程，并可以通过设计上述参数达到隔离。</li>
<li><code>unshare()</code> 使某进程脱离某个namespace</li>
<li><code>setns()</code> 把某进程加入到某个namespace</li>
<li><code>unshare()</code> 和 <code>setns()</code> 都比较简单，大家可以自己man，我这里不说了。</li>
</ul>
<p>下面还是让我们来看一些示例（以下的测试程序最好在Linux 内核为3.8以上的版本中运行，我用的是ubuntu 14.04）。</p>
<h4 id="clone-系统调用"><a href="#clone-系统调用" class="headerlink" title="clone()系统调用"></a>clone()系统调用</h4><p>首先，我们来看一下一个最简单的clone()系统调用的示例，（后面，我们的程序都会基于这个程序做修改）：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="C"><figure class="iseeu highlight /c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> _GNU_SOURCE</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/types.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/wait.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sched.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;signal.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">/* 定义一个给 clone 用的栈，栈大小1M */</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> STACK_SIZE (1024 * 1024)</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">char</span> container_stack[STACK_SIZE];</span><br><span class="line"></span><br><span class="line"><span class="keyword">char</span>* <span class="keyword">const</span> container_args[] = &#123;</span><br><span class="line">    <span class="string">&quot;/bin/bash&quot;</span>,</span><br><span class="line">    <span class="literal">NULL</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">container_main</span><span class="params">(<span class="keyword">void</span>* arg)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Container - inside the container!\n&quot;</span>);</span><br><span class="line">    <span class="comment">/* 直接执行一个shell，以便我们观察这个进程空间里的资源是否被隔离了 */</span></span><br><span class="line">    execv(container_args[<span class="number">0</span>], container_args); </span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Something&#x27;s wrong!\n&quot;</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Parent - start a container!\n&quot;</span>);</span><br><span class="line">    <span class="comment">/* 调用clone函数，其中传出一个函数，还有一个栈空间的（为什么传尾指针，因为栈是反着的） */</span></span><br><span class="line">    <span class="keyword">int</span> container_pid = clone(container_main, container_stack+STACK_SIZE, SIGCHLD, <span class="literal">NULL</span>);</span><br><span class="line">    <span class="comment">/* 等待子进程结束 */</span></span><br><span class="line">    waitpid(container_pid, <span class="literal">NULL</span>, <span class="number">0</span>);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Parent - container stopped!\n&quot;</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<p>从上面的程序，我们可以看到，这和pthread基本上是一样的玩法。但是，对于上面的程序，父子进程的进程空间是没有什么差别的，父进程能访问到的子进程也能。</p>
<p>下面， 让我们来看几个例子看看，Linux的Namespace是什么样的。</p>
<h4 id="UTS-Namespace"><a href="#UTS-Namespace" class="headerlink" title="UTS Namespace"></a>UTS Namespace</h4><p>下面的代码，我略去了上面那些头文件和数据结构的定义，只有最重要的部分。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="C"><figure class="iseeu highlight /c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">container_main</span><span class="params">(<span class="keyword">void</span>* arg)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Container - inside the container!\n&quot;</span>);</span><br><span class="line">    sethostname(<span class="string">&quot;container&quot;</span>,<span class="number">10</span>); <span class="comment">/* 设置hostname */</span></span><br><span class="line">    execv(container_args[<span class="number">0</span>], container_args);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Something&#x27;s wrong!\n&quot;</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Parent - start a container!\n&quot;</span>);</span><br><span class="line">    <span class="keyword">int</span> container_pid = clone(container_main, container_stack+STACK_SIZE, </span><br><span class="line">            CLONE_NEWUTS | SIGCHLD, <span class="literal">NULL</span>); <span class="comment">/*启用CLONE_NEWUTS Namespace隔离 */</span></span><br><span class="line">    waitpid(container_pid, <span class="literal">NULL</span>, <span class="number">0</span>);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Parent - container stopped!\n&quot;</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<blockquote>
<p>运行上面的程序你会发现（需要root权限），子进程的hostname变成了 container。</p>
</blockquote>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">hchen@ubuntu:~$ sudo ./uts</span><br><span class="line">Parent - start a container!</span><br><span class="line">Container - inside the container!</span><br><span class="line">root@container:~# hostname</span><br><span class="line">container</span><br><span class="line">root@container:~# uname -n</span><br><span class="line">container</span><br></pre></td></tr></table></figure></div>
<h4 id="IPC-Namespace"><a href="#IPC-Namespace" class="headerlink" title="IPC Namespace"></a>IPC Namespace</h4><p>IPC全称 Inter-Process Communication，是Unix/Linux下进程间通信的一种方式，IPC有共享内存、信号量、消息队列等方法。所以，为了隔离，我们也需要把IPC给隔离开来，这样，只有在同一个Namespace下的进程才能相互通信。如果你熟悉IPC的原理的话，你会知道，IPC需要有一个全局的ID，即然是全局的，那么就意味着我们的Namespace需要对这个ID隔离，不能让别的Namespace的进程看到。</p>
<p>要启动IPC隔离，我们只需要在调用clone时加上CLONE_NEWIPC参数就可以了。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="C"><figure class="iseeu highlight /c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> container_pid = clone(container_main, container_stack+STACK_SIZE, </span><br><span class="line">            CLONE_NEWUTS | CLONE_NEWIPC | SIGCHLD, <span class="literal">NULL</span>);</span><br></pre></td></tr></table></figure></div>
<p>首先，我们先创建一个IPC的Queue（如下所示，全局的Queue ID是0）</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">hchen@ubuntu:~$ ipcmk -Q </span><br><span class="line">Message queue id: 0</span><br><span class="line"></span><br><span class="line">hchen@ubuntu:~$ ipcs -q</span><br><span class="line">------ Message Queues --------</span><br><span class="line">key        msqid      owner      perms      used-bytes   messages    </span><br><span class="line">0xd0d56eb2 0          hchen      644        0            0</span><br></pre></td></tr></table></figure></div>
<p>如果我们运行没有CLONE_NEWIPC的程序，我们会看到，在子进程中还是能看到这个全启的IPC Queue。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">hchen@ubuntu:~$ sudo ./uts </span><br><span class="line">Parent - start a container!</span><br><span class="line">Container - inside the container!</span><br><span class="line"></span><br><span class="line">root@container:~# ipcs -q</span><br><span class="line"></span><br><span class="line">------ Message Queues --------</span><br><span class="line">key        msqid      owner      perms      used-bytes   messages    </span><br><span class="line">0xd0d56eb2 0          hchen      644        0            0</span><br></pre></td></tr></table></figure></div>
<p>但是，如果我们运行加上了CLONE_NEWIPC的程序，我们就会下面的结果：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">root@ubuntu:~$ sudo./ipc</span><br><span class="line">Parent - start a container!</span><br><span class="line">Container - inside the container!</span><br><span class="line"></span><br><span class="line">root@container:~/linux_namespace# ipcs -q</span><br><span class="line"></span><br><span class="line">------ Message Queues --------</span><br><span class="line">key        msqid      owner      perms      used-bytes   messages</span><br></pre></td></tr></table></figure></div>
<p>我们可以看到IPC已经被隔离了。</p>
<h4 id="PID-Namespace"><a href="#PID-Namespace" class="headerlink" title="PID Namespace"></a>PID Namespace</h4><p>我们继续修改上面的程序：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="C"><figure class="iseeu highlight /c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">container_main</span><span class="params">(<span class="keyword">void</span>* arg)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">/* 查看子进程的PID，我们可以看到其输出子进程的 pid 为 1 */</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Container [%5d] - inside the container!\n&quot;</span>, getpid());</span><br><span class="line">    sethostname(<span class="string">&quot;container&quot;</span>,<span class="number">10</span>);</span><br><span class="line">    execv(container_args[<span class="number">0</span>], container_args);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Something&#x27;s wrong!\n&quot;</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Parent [%5d] - start a container!\n&quot;</span>, getpid());</span><br><span class="line">    <span class="comment">/*启用PID namespace - CLONE_NEWPID*/</span></span><br><span class="line">    <span class="keyword">int</span> container_pid = clone(container_main, container_stack+STACK_SIZE, </span><br><span class="line">            CLONE_NEWUTS | CLONE_NEWPID | SIGCHLD, <span class="literal">NULL</span>); </span><br><span class="line">    waitpid(container_pid, <span class="literal">NULL</span>, <span class="number">0</span>);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Parent - container stopped!\n&quot;</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<p>运行结果如下（我们可以看到，子进程的pid是1了）：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">hchen@ubuntu:~$ sudo ./pid</span><br><span class="line">Parent [ 3474] - start a container!</span><br><span class="line">Container [ 1] - inside the container!</span><br><span class="line">root@container:~# echo $$</span><br><span class="line">1</span><br></pre></td></tr></table></figure></div>
<p>你可能会问，PID为1有个毛用啊？我们知道，在传统的UNIX系统中，PID为1的进程是init，地位非常特殊。他作为所有进程的父进程，有很多特权（比如：屏蔽信号等），另外，其还会为检查所有进程的状态，我们知道，如果某个子进程脱离了父进程（父进程没有wait它），那么init就会负责回收资源并结束这个子进程。所以，要做到进程空间的隔离，首先要创建出PID为1的进程，最好就像chroot那样，把子进程的PID在容器内变成1。</p>
<p><strong>但是，我们会发现，在子进程的shell里输入ps,top等命令，我们还是可以看得到所有进程</strong>。说明并没有完全隔离。这是因为，像ps, top这些命令会去读/proc文件系统，所以，因为/proc文件系统在父进程和子进程都是一样的，所以这些命令显示的东西都是一样的。</p>
<p>所以，我们还需要对文件系统进行隔离。</p>
<h4 id="Mount-Namespace"><a href="#Mount-Namespace" class="headerlink" title="Mount Namespace"></a>Mount Namespace</h4><p>下面的例程中，我们在启用了mount namespace并在子进程中重新mount了/proc文件系统。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="C"><figure class="iseeu highlight /c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">container_main</span><span class="params">(<span class="keyword">void</span>* arg)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Container [%5d] - inside the container!\n&quot;</span>, getpid());</span><br><span class="line">    sethostname(<span class="string">&quot;container&quot;</span>,<span class="number">10</span>);</span><br><span class="line">    <span class="comment">/* 重新mount proc文件系统到 /proc下 */</span></span><br><span class="line">    system(<span class="string">&quot;mount -t proc proc /proc&quot;</span>);</span><br><span class="line">    execv(container_args[<span class="number">0</span>], container_args);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Something&#x27;s wrong!\n&quot;</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Parent [%5d] - start a container!\n&quot;</span>, getpid());</span><br><span class="line">    <span class="comment">/* 启用Mount Namespace - 增加CLONE_NEWNS参数 */</span></span><br><span class="line">    <span class="keyword">int</span> container_pid = clone(container_main, container_stack+STACK_SIZE, </span><br><span class="line">            CLONE_NEWUTS | CLONE_NEWPID | CLONE_NEWNS | SIGCHLD, <span class="literal">NULL</span>);</span><br><span class="line">    waitpid(container_pid, <span class="literal">NULL</span>, <span class="number">0</span>);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Parent - container stopped!\n&quot;</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<p>运行结果如下：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">hchen@ubuntu:~$ sudo ./pid.mnt</span><br><span class="line">Parent [ 3502] - start a container!</span><br><span class="line">Container [    1] - inside the container!</span><br><span class="line">root@container:~# ps -elf </span><br><span class="line">F S UID        PID  PPID  C PRI  NI ADDR SZ WCHAN  STIME TTY          TIME CMD</span><br><span class="line">4 S root         1     0  0  80   0 -  6917 wait   19:55 pts/2    00:00:00 /bin/bash</span><br><span class="line">0 R root        14     1  0  80   0 -  5671 -      19:56 pts/2    00:00:00 ps -elf</span><br></pre></td></tr></table></figure></div>
<p>上面，我们可以看到只有两个进程 ，而且pid=1的进程是我们的/bin/bash。我们还可以看到/proc目录下也干净了很多：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">root@container:~# ls /proc</span><br><span class="line">1          dma          key-users   net            sysvipc</span><br><span class="line">16         driver       kmsg        pagetypeinfo   timer_list</span><br><span class="line">acpi       execdomains  kpagecount  partitions     timer_stats</span><br><span class="line">asound     fb           kpageflags  sched_debug    tty</span><br><span class="line">buddyinfo  filesystems  loadavg     schedstat      uptime</span><br><span class="line">bus        fs           locks       scsi           version</span><br><span class="line">cgroups    interrupts   mdstat      self           version_signature</span><br><span class="line">cmdline    iomem        meminfo     slabinfo       vmallocinfo</span><br><span class="line">consoles   ioports      misc        softirqs       vmstat</span><br><span class="line">cpuinfo    irq          modules     stat           zoneinfo</span><br><span class="line">crypto     kallsyms     mounts      swaps</span><br><span class="line">devices    kcore        mpt         sys</span><br><span class="line">diskstats  keys         mtrr        sysrq-trigger</span><br></pre></td></tr></table></figure></div>
<p>下图，我们也可以看到在子进程中的top命令只看得到两个进程了。<br><img src="/2022/06/10/uncatalog/cl483pse2000038r7fnpqhzig/1.jpg" alt="1"><br>这里，多说一下。在通过CLONE_NEWNS创建mount namespace后，父进程会把自己的文件结构复制给子进程中。而子进程中新的namespace中的所有mount操作都只影响自身的文件系统，而不对外界产生任何影响。这样可以做到比较严格地隔离。</p>
<p>你可能会问，我们是不是还有别的一些文件系统也需要这样mount? 是的。</p>
<h5 id="Docker的-Mount-Namespace"><a href="#Docker的-Mount-Namespace" class="headerlink" title="Docker的 Mount Namespace"></a>Docker的 Mount Namespace</h5><p>下面我将向演示一个“山寨镜像”，其模仿了Docker的Mount Namespace。</p>
<p>首先，我们需要一个rootfs，也就是我们需要把我们要做的镜像中的那些命令什么的copy到一个rootfs的目录下，我们模仿Linux构建如下的目录：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">hchen@ubuntu:~/rootfs$ ls</span><br><span class="line">bin  dev  etc  home  lib  lib64  mnt  opt  proc  root  run  sbin  sys  tmp  usr  var</span><br></pre></td></tr></table></figure></div>
<p>然后，我们把一些我们需要的命令copy到 rootfs/bin目录中（sh命令必需要copy进去，不然我们无法 chroot ）</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">hchen@ubuntu:~/rootfs$ ls ./bin ./usr/bin</span><br><span class="line"> </span><br><span class="line">./bin:</span><br><span class="line">bash   chown  gzip      less  mount       netstat  rm     tabs  tee      top       tty</span><br><span class="line">cat    cp     hostname  ln    mountpoint  ping     sed    tac   test     touch     umount</span><br><span class="line">chgrp  echo   ip        ls    mv          ps       sh     tail  timeout  tr        uname</span><br><span class="line">chmod  grep   kill      more  nc          pwd      sleep  tar   toe      truncate  which</span><br><span class="line"></span><br><span class="line">./usr/bin:</span><br><span class="line">awk  env  groups  head  id  mesg  sort  strace  tail  top  uniq  vi  wc  xargs</span><br></pre></td></tr></table></figure></div>
<p>注：你可以使用ldd命令把这些命令相关的那些so文件copy到对应的目录：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">hchen@ubuntu:~/rootfs/bin$ ldd bash</span><br><span class="line">  linux-vdso.so.1 =&gt;  (0x00007fffd33fc000)</span><br><span class="line">  libtinfo.so.5 =&gt; /lib/x86_64-linux-gnu/libtinfo.so.5 (0x00007f4bd42c2000)</span><br><span class="line">  libdl.so.2 =&gt; /lib/x86_64-linux-gnu/libdl.so.2 (0x00007f4bd40be000)</span><br><span class="line">  libc.so.6 =&gt; /lib/x86_64-linux-gnu/libc.so.6 (0x00007f4bd3cf8000)</span><br><span class="line">  /lib64/ld-linux-x86-64.so.2 (0x00007f4bd4504000)</span><br></pre></td></tr></table></figure></div>

<p>下面是我的rootfs中的一些so文件：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">hchen@ubuntu:~/rootfs$ ls ./lib64 ./lib/x86_64-linux-gnu/</span><br><span class="line"></span><br><span class="line">./lib64:</span><br><span class="line">ld-linux-x86-64.so.2</span><br><span class="line"></span><br><span class="line">./lib/x86_64-linux-gnu/:</span><br><span class="line">libacl.so.1      libmemusage.so         libnss_files-2.19.so    libpython3.4m.so.1</span><br><span class="line">libacl.so.1.1.0  libmount.so.1          libnss_files.so.2       libpython3.4m.so.1.0</span><br><span class="line">libattr.so.1     libmount.so.1.1.0      libnss_hesiod-2.19.so   libresolv-2.19.so</span><br><span class="line">libblkid.so.1    libm.so.6              libnss_hesiod.so.2      libresolv.so.2</span><br><span class="line">libc-2.19.so     libncurses.so.5        libnss_nis-2.19.so      libselinux.so.1</span><br><span class="line">libcap.a         libncurses.so.5.9      libnss_nisplus-2.19.so  libtinfo.so.5</span><br><span class="line">libcap.so        libncursesw.so.5       libnss_nisplus.so.2     libtinfo.so.5.9</span><br><span class="line">libcap.so.2      libncursesw.so.5.9     libnss_nis.so.2         libutil-2.19.so</span><br><span class="line">libcap.so.2.24   libnsl-2.19.so         libpcre.so.3            libutil.so.1</span><br><span class="line">libc.so.6        libnsl.so.1            libprocps.so.3          libuuid.so.1</span><br><span class="line">libdl-2.19.so    libnss_compat-2.19.so  libpthread-2.19.so      libz.so.1</span><br><span class="line">libdl.so.2       libnss_compat.so.2     libpthread.so.0</span><br><span class="line">libgpm.so.2      libnss_dns-2.19.so     libpython2.7.so.1</span><br><span class="line">libm-2.19.so     libnss_dns.so.2        libpython2.7.so.1.0</span><br></pre></td></tr></table></figure></div>
<p>包括这些命令依赖的一些配置文件：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">hchen@ubuntu:~/rootfs$ ls ./etc</span><br><span class="line">bash.bashrc  group  hostname  hosts  ld.so.cache  nsswitch.conf  passwd  profile  </span><br><span class="line">resolv.conf  shadow</span><br></pre></td></tr></table></figure></div>
<p>你现在会说，我靠，有些配置我希望是在容器起动时给他设置的，而不是hard code在镜像中的。比如：/etc/hosts，/etc/hostname，还有DNS的/etc/resolv.conf文件。好的。那我们在rootfs外面，我们再创建一个conf目录，把这些文件放到这个目录中。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">hchen@ubuntu:~$ ls ./conf</span><br><span class="line">hostname     hosts     resolv.conf</span><br></pre></td></tr></table></figure></div>
<p>这样，我们的父进程就可以动态地设置容器需要的这些文件的配置， 然后再把他们mount进容器，这样，容器的镜像中的配置就比较灵活了。</p>
<p>好了，终于到了我们的程序。</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> _GNU_SOURCE</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys types.h=&quot;&quot;&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys wait.h=&quot;&quot;&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys mount.h=&quot;&quot;&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sched.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;signal.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> STACK_SIZE (1024 * 1024)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">char</span> container_stack[STACK_SIZE];</span><br><span class="line"><span class="keyword">char</span>* <span class="keyword">const</span> container_args[] = &#123;</span><br><span class="line">    <span class="string">&quot;/bin/bash&quot;</span>,</span><br><span class="line">    <span class="string">&quot;-l&quot;</span>,</span><br><span class="line">    <span class="literal">NULL</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">container_main</span><span class="params">(<span class="keyword">void</span>* arg)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Container [%5d] - inside the container!\n&quot;</span>, getpid());</span><br><span class="line"></span><br><span class="line">    <span class="comment">//set hostname</span></span><br><span class="line">    sethostname(<span class="string">&quot;container&quot;</span>,<span class="number">10</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//remount &quot;/proc&quot; to make sure the &quot;top&quot; and &quot;ps&quot; show container&#x27;s information</span></span><br><span class="line">    <span class="keyword">if</span> (mount(<span class="string">&quot;proc&quot;</span>, <span class="string">&quot;rootfs/proc&quot;</span>, <span class="string">&quot;proc&quot;</span>, <span class="number">0</span>, <span class="literal">NULL</span>) !=<span class="number">0</span> ) &#123;</span><br><span class="line">        perror(<span class="string">&quot;proc&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (mount(<span class="string">&quot;sysfs&quot;</span>, <span class="string">&quot;rootfs/sys&quot;</span>, <span class="string">&quot;sysfs&quot;</span>, <span class="number">0</span>, <span class="literal">NULL</span>)!=<span class="number">0</span>) &#123;</span><br><span class="line">        perror(<span class="string">&quot;sys&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (mount(<span class="string">&quot;none&quot;</span>, <span class="string">&quot;rootfs/tmp&quot;</span>, <span class="string">&quot;tmpfs&quot;</span>, <span class="number">0</span>, <span class="literal">NULL</span>)!=<span class="number">0</span>) &#123;</span><br><span class="line">        perror(<span class="string">&quot;tmp&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (mount(<span class="string">&quot;udev&quot;</span>, <span class="string">&quot;rootfs/dev&quot;</span>, <span class="string">&quot;devtmpfs&quot;</span>, <span class="number">0</span>, <span class="literal">NULL</span>)!=<span class="number">0</span>) &#123;</span><br><span class="line">        perror(<span class="string">&quot;dev&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (mount(<span class="string">&quot;devpts&quot;</span>, <span class="string">&quot;rootfs/dev/pts&quot;</span>, <span class="string">&quot;devpts&quot;</span>, <span class="number">0</span>, <span class="literal">NULL</span>)!=<span class="number">0</span>) &#123;</span><br><span class="line">        perror(<span class="string">&quot;dev/pts&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (mount(<span class="string">&quot;shm&quot;</span>, <span class="string">&quot;rootfs/dev/shm&quot;</span>, <span class="string">&quot;tmpfs&quot;</span>, <span class="number">0</span>, <span class="literal">NULL</span>)!=<span class="number">0</span>) &#123;</span><br><span class="line">        perror(<span class="string">&quot;dev/shm&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (mount(<span class="string">&quot;tmpfs&quot;</span>, <span class="string">&quot;rootfs/run&quot;</span>, <span class="string">&quot;tmpfs&quot;</span>, <span class="number">0</span>, <span class="literal">NULL</span>)!=<span class="number">0</span>) &#123;</span><br><span class="line">        perror(<span class="string">&quot;run&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/* </span></span><br><span class="line"><span class="comment">     * 模仿Docker的从外向容器里mount相关的配置文件 </span></span><br><span class="line"><span class="comment">     * 你可以查看：/var/lib/docker/containers/&lt;container_id&gt;/目录，</span></span><br><span class="line"><span class="comment">     * 你会看到docker的这些文件的。</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">if</span> (mount(<span class="string">&quot;conf/hosts&quot;</span>, <span class="string">&quot;rootfs/etc/hosts&quot;</span>, <span class="string">&quot;none&quot;</span>, MS_BIND, <span class="literal">NULL</span>)!=<span class="number">0</span> ||</span><br><span class="line">          mount(<span class="string">&quot;conf/hostname&quot;</span>, <span class="string">&quot;rootfs/etc/hostname&quot;</span>, <span class="string">&quot;none&quot;</span>, MS_BIND, <span class="literal">NULL</span>)!=<span class="number">0</span> ||</span><br><span class="line">          mount(<span class="string">&quot;conf/resolv.conf&quot;</span>, <span class="string">&quot;rootfs/etc/resolv.conf&quot;</span>, <span class="string">&quot;none&quot;</span>, MS_BIND, <span class="literal">NULL</span>)!=<span class="number">0</span> ) &#123;</span><br><span class="line">        perror(<span class="string">&quot;conf&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/* 模仿docker run命令中的 -v, --volume=[] 参数干的事 */</span></span><br><span class="line">    <span class="keyword">if</span> (mount(<span class="string">&quot;/tmp/t1&quot;</span>, <span class="string">&quot;rootfs/mnt&quot;</span>, <span class="string">&quot;none&quot;</span>, MS_BIND, <span class="literal">NULL</span>)!=<span class="number">0</span>) &#123;</span><br><span class="line">        perror(<span class="string">&quot;mnt&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* chroot 隔离目录 */</span></span><br><span class="line">    <span class="keyword">if</span> ( chdir(<span class="string">&quot;./rootfs&quot;</span>) != <span class="number">0</span> || chroot(<span class="string">&quot;./&quot;</span>) != <span class="number">0</span> )&#123;</span><br><span class="line">        perror(<span class="string">&quot;chdir/chroot&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    execv(container_args[<span class="number">0</span>], container_args);</span><br><span class="line">    perror(<span class="string">&quot;exec&quot;</span>);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Something&#x27;s wrong!\n&quot;</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Parent [%5d] - start a container!\n&quot;</span>, getpid());</span><br><span class="line">    <span class="keyword">int</span> container_pid = clone(container_main, container_stack+STACK_SIZE, </span><br><span class="line">            CLONE_NEWUTS | CLONE_NEWIPC | CLONE_NEWPID | CLONE_NEWNS | SIGCHLD, <span class="literal">NULL</span>);</span><br><span class="line">    waitpid(container_pid, <span class="literal">NULL</span>, <span class="number">0</span>);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Parent - container stopped!\n&quot;</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line">&lt;/container_id&gt;&lt;/unistd.h&gt;&lt;/signal.h&gt;&lt;/sched.h&gt;&lt;/stdio.h&gt;&lt;/sys&gt;&lt;/sys&gt;&lt;/sys&gt;</span><br></pre></td></tr></table></figure>

<p>sudo运行上面的程序，你会看到下面的挂载信息以及一个所谓的“镜像”：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">hchen@ubuntu:~$ sudo ./mount </span><br><span class="line">Parent [ 4517] - start a container!</span><br><span class="line">Container [    1] - inside the container!</span><br><span class="line">root@container:/# mount</span><br><span class="line">proc on /proc type proc (rw,relatime)</span><br><span class="line">sysfs on /sys type sysfs (rw,relatime)</span><br><span class="line">none on /tmp type tmpfs (rw,relatime)</span><br><span class="line">udev on /dev type devtmpfs (rw,relatime,size=493976k,nr_inodes=123494,mode=755)</span><br><span class="line">devpts on /dev/pts type devpts (rw,relatime,mode=600,ptmxmode=000)</span><br><span class="line">tmpfs on /run type tmpfs (rw,relatime)</span><br><span class="line">/dev/disk/by-uuid/18086e3b-d805-4515-9e91-7efb2fe5c0e2 on /etc/hosts type ext4 (rw,relatime,errors=remount-ro,data=ordered)</span><br><span class="line">/dev/disk/by-uuid/18086e3b-d805-4515-9e91-7efb2fe5c0e2 on /etc/hostname type ext4 (rw,relatime,errors=remount-ro,data=ordered)</span><br><span class="line">/dev/disk/by-uuid/18086e3b-d805-4515-9e91-7efb2fe5c0e2 on /etc/resolv.conf type ext4 (rw,relatime,errors=remount-ro,data=ordered)</span><br><span class="line"></span><br><span class="line">root@container:/# ls /bin /usr/bin</span><br><span class="line">/bin:</span><br><span class="line">bash   chmod  echo  hostname  less  more  mv   ping  rm   sleep  tail  test    top   truncate  uname</span><br><span class="line">cat    chown  grep  ip        ln    mount  nc   ps    sed  tabs   tar   timeout  touch  tty     which</span><br><span class="line">chgrp  cp     gzip  kill      ls    mountpoint  netstat  pwd   sh   tac    tee   toe    tr   umount</span><br><span class="line"></span><br><span class="line">/usr/bin:</span><br><span class="line">awk  env  groups  head  id  mesg  sort  strace  tail  top  uniq  vi  wc  xargs</span><br></pre></td></tr></table></figure></div>
<p>关于如何做一个chroot的目录，这里有个工具叫<a href="https://wiki.ubuntu.com/DebootstrapChroot" title="Front-end web development">DebootstrapChroot</a>你可以顺着链接去看看（英文的哦）</p>
<h4 id="User-Namespace"><a href="#User-Namespace" class="headerlink" title="User Namespace"></a>User Namespace</h4><p>User Namespace主要是用了CLONE_NEWUSER的参数。使用了这个参数后，内部看到的UID和GID已经与外部不同了，默认显示为65534。那是因为容器找不到其真正的UID所以，设置上了最大的UID（其设置定义在/proc/sys/kernel/overflowuid）。</p>
<p>要把容器中的uid和真实系统的uid给映射在一起，需要修改 /proc/<pid>/uid_map 和 /proc/<pid>/gid_map 这两个文件。这两个文件的格式为：</pid></pid></p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="TEXT"><figure class="iseeu highlight /text"><table><tr><td class="code"><pre><span class="line">ID-inside-ns ID-outside-ns length</span><br></pre></td></tr></table></figure></div>
<p>其中：</p>
<ul>
<li>第一个字段ID-inside-ns表示在容器显示的UID或GID，</li>
<li>第二个字段ID-outside-ns表示容器外映射的真实的UID或GID。</li>
<li>第三个字段表示映射的范围，一般填1，表示一一对应</li>
</ul>
<p>比如，把真实的uid=1000映射成容器内的uid=0</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> cat /proc/2465/uid_map</span></span><br><span class="line">         0       1000          1</span><br></pre></td></tr></table></figure></div>
<p>再比如下面的示例：表示把namespace内部从0开始的uid映射到外部从0开始的uid，其最大范围是无符号32位整形</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> cat /proc/$$/uid_map</span></span><br><span class="line">         0          0          4294967295</span><br></pre></td></tr></table></figure></div>

<p>另外，需要注意的是：</p>
<ul>
<li>写这两个文件的进程需要这个namespace中的CAP_SETUID (CAP_SETGID)权限（可参看<a href="https://man7.org/linux/man-pages/man7/capabilities.7.html" title="Front-end web development">Capabilities</a>）</li>
<li>写入的进程必须是此user namespace的父或子的user namespace进程。</li>
<li>另外需要满如下条件之一：1）父进程将effective uid/gid映射到子进程的user namespace中，2）父进程如果有CAP_SETUID/CAP_SETGID权限，那么它将可以映射到父进程中的任一uid/gid。</li>
</ul>
<p>这些规则看着都烦，我们来看程序吧：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="C"><figure class="iseeu highlight /c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> _GNU_SOURCE</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/types.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/wait.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/mount.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/capability.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sched.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;signal.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> STACK_SIZE (1024 * 1024)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">char</span> container_stack[STACK_SIZE];</span><br><span class="line"><span class="keyword">char</span>* <span class="keyword">const</span> container_args[] = &#123;</span><br><span class="line">    <span class="string">&quot;/bin/bash&quot;</span>,</span><br><span class="line">    <span class="literal">NULL</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> pipefd[<span class="number">2</span>];</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">set_map</span><span class="params">(<span class="keyword">char</span>* file, <span class="keyword">int</span> inside_id, <span class="keyword">int</span> outside_id, <span class="keyword">int</span> len)</span> </span>&#123;</span><br><span class="line">    FILE* mapfd = fopen(file, <span class="string">&quot;w&quot;</span>);</span><br><span class="line">    <span class="keyword">if</span> (<span class="literal">NULL</span> == mapfd) &#123;</span><br><span class="line">        perror(<span class="string">&quot;open file error&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">fprintf</span>(mapfd, <span class="string">&quot;%d %d %d&quot;</span>, inside_id, outside_id, len);</span><br><span class="line">    fclose(mapfd);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">set_uid_map</span><span class="params">(<span class="keyword">pid_t</span> pid, <span class="keyword">int</span> inside_id, <span class="keyword">int</span> outside_id, <span class="keyword">int</span> len)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">char</span> file[<span class="number">256</span>];</span><br><span class="line">    <span class="built_in">sprintf</span>(file, <span class="string">&quot;/proc/%d/uid_map&quot;</span>, pid);</span><br><span class="line">    set_map(file, inside_id, outside_id, len);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">set_gid_map</span><span class="params">(<span class="keyword">pid_t</span> pid, <span class="keyword">int</span> inside_id, <span class="keyword">int</span> outside_id, <span class="keyword">int</span> len)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">char</span> file[<span class="number">256</span>];</span><br><span class="line">    <span class="built_in">sprintf</span>(file, <span class="string">&quot;/proc/%d/gid_map&quot;</span>, pid);</span><br><span class="line">    set_map(file, inside_id, outside_id, len);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">container_main</span><span class="params">(<span class="keyword">void</span>* arg)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Container [%5d] - inside the container!\n&quot;</span>, getpid());</span><br><span class="line"></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Container: eUID = %ld;  eGID = %ld, UID=%ld, GID=%ld\n&quot;</span>,</span><br><span class="line">            (<span class="keyword">long</span>) geteuid(), (<span class="keyword">long</span>) getegid(), (<span class="keyword">long</span>) getuid(), (<span class="keyword">long</span>) getgid());</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* 等待父进程通知后再往下执行（进程间的同步） */</span></span><br><span class="line">    <span class="keyword">char</span> ch;</span><br><span class="line">    close(pipefd[<span class="number">1</span>]);</span><br><span class="line">    read(pipefd[<span class="number">0</span>], &amp;ch, <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Container [%5d] - setup hostname!\n&quot;</span>, getpid());</span><br><span class="line">    <span class="comment">//set hostname</span></span><br><span class="line">    sethostname(<span class="string">&quot;container&quot;</span>,<span class="number">10</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//remount &quot;/proc&quot; to make sure the &quot;top&quot; and &quot;ps&quot; show container&#x27;s information</span></span><br><span class="line">    mount(<span class="string">&quot;proc&quot;</span>, <span class="string">&quot;/proc&quot;</span>, <span class="string">&quot;proc&quot;</span>, <span class="number">0</span>, <span class="literal">NULL</span>);</span><br><span class="line"></span><br><span class="line">    execv(container_args[<span class="number">0</span>], container_args);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Something&#x27;s wrong!\n&quot;</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">int</span> gid=getgid(), uid=getuid();</span><br><span class="line"></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Parent: eUID = %ld;  eGID = %ld, UID=%ld, GID=%ld\n&quot;</span>,</span><br><span class="line">            (<span class="keyword">long</span>) geteuid(), (<span class="keyword">long</span>) getegid(), (<span class="keyword">long</span>) getuid(), (<span class="keyword">long</span>) getgid());</span><br><span class="line"></span><br><span class="line">    pipe(pipefd);</span><br><span class="line"> </span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Parent [%5d] - start a container!\n&quot;</span>, getpid());</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> container_pid = clone(container_main, container_stack+STACK_SIZE, </span><br><span class="line">            CLONE_NEWUTS | CLONE_NEWPID | CLONE_NEWNS | CLONE_NEWUSER | SIGCHLD, <span class="literal">NULL</span>);</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Parent [%5d] - Container [%5d]!\n&quot;</span>, getpid(), container_pid);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//To map the uid/gid, </span></span><br><span class="line">    <span class="comment">//   we need edit the /proc/PID/uid_map (or /proc/PID/gid_map) in parent</span></span><br><span class="line">    <span class="comment">//The file format is</span></span><br><span class="line">    <span class="comment">//   ID-inside-ns   ID-outside-ns   length</span></span><br><span class="line">    <span class="comment">//if no mapping, </span></span><br><span class="line">    <span class="comment">//   the uid will be taken from /proc/sys/kernel/overflowuid</span></span><br><span class="line">    <span class="comment">//   the gid will be taken from /proc/sys/kernel/overflowgid</span></span><br><span class="line">    set_uid_map(container_pid, <span class="number">0</span>, uid, <span class="number">1</span>);</span><br><span class="line">    set_gid_map(container_pid, <span class="number">0</span>, gid, <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Parent [%5d] - user/group mapping done!\n&quot;</span>, getpid());</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* 通知子进程 */</span></span><br><span class="line">    close(pipefd[<span class="number">1</span>]);</span><br><span class="line"></span><br><span class="line">    waitpid(container_pid, <span class="literal">NULL</span>, <span class="number">0</span>);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Parent - container stopped!\n&quot;</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<p>上面的程序，我们用了一个pipe来对父子进程进行同步，为什么要这样做？因为子进程中有一个execv的系统调用，这个系统调用会把当前子进程的进程空间给全部覆盖掉，我们希望在execv之前就做好user namespace的uid/gid的映射，这样，execv运行的/bin/bash就会因为我们设置了uid为0的inside-uid而变成#号的提示符。</p>
<p>整个程序的运行效果如下：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">hchen@ubuntu:~$ id</span><br><span class="line">uid=1000(hchen) gid=1000(hchen) groups=1000(hchen)</span><br><span class="line"></span><br><span class="line">hchen@ubuntu:~$ ./user #&lt;--以hchen用户运行</span><br><span class="line">Parent: eUID = 1000;  eGID = 1000, UID=1000, GID=1000 </span><br><span class="line">Parent [ 3262] - start a container!</span><br><span class="line">Parent [ 3262] - Container [ 3263]!</span><br><span class="line">Parent [ 3262] - user/group mapping done!</span><br><span class="line">Container [    1] - inside the container!</span><br><span class="line">Container: eUID = 0;  eGID = 0, UID=0, GID=0 #&lt;---Container里的UID/GID都为0了</span><br><span class="line">Container [    1] - setup hostname!</span><br><span class="line"></span><br><span class="line">root@container:~# id #&lt;----我们可以看到容器里的用户和命令行提示符是root用户了</span><br><span class="line">uid=0(root) gid=0(root) groups=0(root),65534(nogroup)</span><br></pre></td></tr></table></figure></div>
<p>虽然容器里是root，但其实这个容器的/bin/bash进程是以一个普通用户hchen来运行的。这样一来，我们容器的安全性会得到提高。</p>
<p>我们注意到，User Namespace是以普通用户运行，但是别的Namespace需要root权限，那么，如果我要同时使用多个Namespace，该怎么办呢？一般来说，我们先用一般用户创建User Namespace，然后把这个一般用户映射成root，在容器内用root来创建其它的Namesapce。</p>
<h4 id="Network-Namespace"><a href="#Network-Namespace" class="headerlink" title="Network Namespace"></a>Network Namespace</h4><p>Network的Namespace比较啰嗦。在Linux下，我们一般用ip命令创建Network Namespace（Docker的源码中，它没有用ip命令，而是自己实现了ip命令内的一些功能——是用了Raw Socket发些“奇怪”的数据，呵呵）。这里，我还是用ip命令讲解一下。</p>
<p>首先，我们先看个图，下面这个图基本上就是Docker在宿主机上的网络示意图（其中的物理网卡并不准确，因为docker可能会运行在一个VM中，所以，这里所谓的“物理网卡”其实也就是一个有可以路由的IP的网卡<br><img src="/2022/06/10/uncatalog/cl483pse2000038r7fnpqhzig/2.jpg" alt="2.jpg"><br>上图中，Docker使用了一个私有网段，172.40.1.0，docker还可能会使用10.0.0.0和192.168.0.0这两个私有网段，关键看你的路由表中是否配置了，如果没有配置，就会使用，如果你的路由表配置了所有私有网段，那么docker启动时就会出错了。</p>
<p>当你启动一个Docker容器后，你可以使用ip link show或ip addr show来查看当前宿主机的网络情况（我们可以看到有一个docker0，还有一个veth22a38e6的虚拟网卡——给容器用的）：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">hchen@ubuntu:~$ ip link show</span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state ... </span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc ...</span><br><span class="line">    link/ether 00:0c:29:b7:67:7d brd ff:ff:ff:ff:ff:ff</span><br><span class="line">3: docker0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 ...</span><br><span class="line">    link/ether 56:84:7a:fe:97:99 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">5: veth22a38e6: &lt;BROADCAST,UP,LOWER_UP&gt; mtu 1500 qdisc ...</span><br><span class="line">    link/ether 8e:30:2a:ac:8c:d1 brd ff:ff:ff:ff:ff:ff</span><br></pre></td></tr></table></figure></div>
<p>那么，要做成这个样子应该怎么办呢？我们来看一组命令：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 首先，我们先增加一个网桥lxcbr0，模仿docker0</span></span></span><br><span class="line">brctl addbr lxcbr0</span><br><span class="line">brctl stp lxcbr0 off</span><br><span class="line">ifconfig lxcbr0 192.168.10.1/24 up #为网桥设置IP地址</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 接下来，我们要创建一个network namespace - ns1</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 增加一个namesapce 命令为 ns1 （使用ip netns add命令）</span></span><br><span class="line">ip netns add ns1 </span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 激活namespace中的loopback，即127.0.0.1（使用ip netns <span class="built_in">exec</span> ns1来操作ns1中的命令）</span></span><br><span class="line">ip netns exec ns1   ip link set dev lo up </span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 然后，我们需要增加一对虚拟网卡</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 增加一个pair虚拟网卡，注意其中的veth类型，其中一个网卡要按进容器中</span></span><br><span class="line">ip link add veth-ns1 type veth peer name lxcbr0.1</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 把 veth-ns1 按到namespace ns1中，这样容器中就会有一个新的网卡了</span></span><br><span class="line">ip link set veth-ns1 netns ns1</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 把容器里的 veth-ns1改名为 eth0 （容器外会冲突，容器内就不会了）</span></span><br><span class="line">ip netns exec ns1  ip link set dev veth-ns1 name eth0 </span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 为容器中的网卡分配一个IP地址，并激活它</span></span><br><span class="line">ip netns exec ns1 ifconfig eth0 192.168.10.11/24 up</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 上面我们把veth-ns1这个网卡按到了容器中，然后我们要把lxcbr0.1添加上网桥上</span></span><br><span class="line">brctl addif lxcbr0 lxcbr0.1</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 为容器增加一个路由规则，让容器可以访问外面的网络</span></span><br><span class="line">ip netns exec ns1     ip route add default via 192.168.10.1</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 在/etc/netns下创建network namespce名称为ns1的目录，</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 然后为这个namespace设置resolv.conf，这样，容器内就可以访问域名了</span></span><br><span class="line">mkdir -p /etc/netns/ns1</span><br><span class="line">echo &quot;nameserver 8.8.8.8&quot; &gt; /etc/netns/ns1/resolv.conf</span><br></pre></td></tr></table></figure></div>
<p>上面基本上就是docker网络的原理了，只不过</p>
<ul>
<li>Docker的resolv.conf没有用这样的方式，而是用了上面讲的的Mount Namesapce的那种方式 </li>
<li>另外，docker是用进程的PID来做Network Namespace的名称的。</li>
</ul>
<p>了解了这些后，你甚至可以为正在运行的docker容器增加一个新的网卡：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">ip link add peerA type veth peer name peerB </span><br><span class="line">brctl addif docker0 peerA </span><br><span class="line">ip link set peerA up </span><br><span class="line">ip link set peerB netns $&#123;container-pid&#125; </span><br><span class="line">ip netns exec $&#123;container-pid&#125; ip link set dev peerB name eth1 </span><br><span class="line">ip netns exec $&#123;container-pid&#125; ip link set eth1 up ; </span><br><span class="line">ip netns exec $&#123;container-pid&#125; ip addr add $&#123;ROUTEABLE_IP&#125; dev eth1 ;</span><br></pre></td></tr></table></figure></div>
<p>上面的示例是我们为正在运行的docker容器，增加一个eth1的网卡，并给了一个静态的可被外部访问到的IP地址。</p>
<p>这个需要把外部的“物理网卡”配置成混杂模式，这样这个eth1网卡就会向外通过ARP协议发送自己的Mac地址，然后外部的交换机就会把到这个IP地址的包转到“物理网卡”上，因为是混杂模式，所以eth1就能收到相关的数据，一看，是自己的，那么就收到。这样，Docker容器的网络就和外部通了。</p>
<p>当然，无论是Docker的NAT方式，还是混杂模式都会有性能上的问题，NAT不用说了，存在一个转发的开销，混杂模式呢，网卡上收到的负载都会完全交给所有的虚拟网卡上，于是就算一个网卡上没有数据，但也会被其它网卡上的数据所影响。</p>
<p>这两种方式都不够完美，我们知道，真正解决这种网络问题需要使用VLAN技术，于是Google的同学们为Linux内核实现了一个IPVLAN的驱动，这基本上就是为Docker量身定制的。</p>
<h3 id="Namespace文件"><a href="#Namespace文件" class="headerlink" title="Namespace文件"></a>Namespace文件</h3><p>上面就是目前Linux Namespace的玩法。 现在，我来看一下其它的相关东西。</p>
<p>让我们运行一下上篇中的那个pid.mnt的程序（也就是PID Namespace中那个mount proc的程序），然后不要退出。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> sudo ./pid.mnt</span> </span><br><span class="line">[sudo] password for hchen: </span><br><span class="line">Parent [ 4599] - start a container!</span><br><span class="line">Container [    1] - inside the container!</span><br></pre></td></tr></table></figure></div>
<p>我们到另一个shell中查看一下父子进程的PID：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">hchen@ubuntu:~$ pstree -p 4599</span><br><span class="line">pid.mnt(4599)───bash(4600)</span><br></pre></td></tr></table></figure></div>
<p>我们可以到proc下（/proc//ns）查看进程的各个namespace的id（内核版本需要3.8以上）。</p>
<p>下面是父进程的：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">hchen@ubuntu:~$ sudo ls -l /proc/4599/ns</span><br><span class="line">total 0</span><br><span class="line">lrwxrwxrwx 1 root root 0  4月  7 22:01 ipc -&gt; ipc:[4026531839]</span><br><span class="line">lrwxrwxrwx 1 root root 0  4月  7 22:01 mnt -&gt; mnt:[4026531840]</span><br><span class="line">lrwxrwxrwx 1 root root 0  4月  7 22:01 net -&gt; net:[4026531956]</span><br><span class="line">lrwxrwxrwx 1 root root 0  4月  7 22:01 pid -&gt; pid:[4026531836]</span><br><span class="line">lrwxrwxrwx 1 root root 0  4月  7 22:01 user -&gt; user:[4026531837]</span><br><span class="line">lrwxrwxrwx 1 root root 0  4月  7 22:01 uts -&gt; uts:[4026531838]</span><br></pre></td></tr></table></figure></div>
<p>下面是子进程的：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">hchen@ubuntu:~$ sudo ls -l /proc/4600/ns</span><br><span class="line">total 0</span><br><span class="line">lrwxrwxrwx 1 root root 0  4月  7 22:01 ipc -&gt; ipc:[4026531839]</span><br><span class="line">lrwxrwxrwx 1 root root 0  4月  7 22:01 mnt -&gt; mnt:[4026532520]</span><br><span class="line">lrwxrwxrwx 1 root root 0  4月  7 22:01 net -&gt; net:[4026531956]</span><br><span class="line">lrwxrwxrwx 1 root root 0  4月  7 22:01 pid -&gt; pid:[4026532522]</span><br><span class="line">lrwxrwxrwx 1 root root 0  4月  7 22:01 user -&gt; user:[4026531837]</span><br><span class="line">lrwxrwxrwx 1 root root 0  4月  7 22:01 uts -&gt; uts:[4026532521]</span><br></pre></td></tr></table></figure></div>
<p>我们可以看到，其中的ipc，net，user是同一个ID，而mnt,pid,uts都是不一样的。如果两个进程指向的namespace编号相同，就说明他们在同一个namespace下，否则则在不同namespace里面。</p>
<p>这些文件还有另一个作用，那就是，一旦这些文件被打开，只要其fd被占用着，那么就算PID所属的所有进程都已经结束，创建的namespace也会一直存在。比如：我们可以通过：mount bind /proc/4600/ns/uts ~/uts 来hold这个namespace。</p>
<p>另外，我们在上篇中讲过一个setns的系统调用，其函数声明如下：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">int setns(int fd, int nstype);</span><br></pre></td></tr></table></figure></div>
<p>其中第一个参数就是一个fd，也就是一个open()系统调用打开了上述文件后返回的fd，比如：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="C"><figure class="iseeu highlight /c"><table><tr><td class="code"><pre><span class="line">fd = open(<span class="string">&quot;/proc/4600/ns/nts&quot;</span>, O_RDONLY);  <span class="comment">// 获取namespace文件描述符</span></span><br><span class="line">setns(fd, <span class="number">0</span>); <span class="comment">// 加入新的namespac</span></span><br></pre></td></tr></table></figure></div>
]]></content>
      <tags>
        <tag>云原生基础系列</tag>
      </tags>
  </entry>
  <entry>
    <title>云原生基础系列之docker(三)docker基础技术:linux cgroup</title>
    <url>/2022/06/10/uncatalog/cl4884cmp000060r7fhji6teg/</url>
    <content><![CDATA[<hr>
<span id="more"></span>
<hr>
<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><blockquote>
<p>Namespace解决的问题主要是环境隔离的问题，这只是虚拟化中最最基础的一步，我们还需要解决对计算机资源使用上的隔离。也就是说，虽然你通过Namespace把我Jail到一个特定的环境中去了，但是我在其中的进程使用用CPU、内存、磁盘等这些计算资源其实还是可以随心所欲的。所以，我们希望对进程进行资源利用上的限制或控制。这就是Linux CGroup出来了的原因。</p>
</blockquote>
<p>Linux CGroup全称Linux Control Group， 是Linux内核的一个功能，用来限制，控制与分离一个进程组群的资源（如CPU、内存、磁盘输入输出等）。这个项目最早是由Google的工程师在2006年发起（主要是Paul Menage和Rohit Seth），最早的名称为进程容器（process containers）。在2007年时，因为在Linux内核中，容器（container）这个名词太过广泛，为避免混乱，被重命名为cgroup，并且被合并到2.6.24版的内核中去。然后，其它开始了他的发展。<br>Linux CGroupCgroup 可让您为系统中所运行任务（进程）的用户定义组群分配资源—比如CPU时间、系统内存、网络带宽或者这些资源的组合。您可以监控您配置的cgroup，拒绝cgroup 访问某些资源，甚至在运行的系统中动态配置您的cgroup。<br>主要提供了如下功能：</p>
<ul>
<li><em>Resource limitation</em>: 限制资源使用，比如内存使用上限以及文件系统的缓存限制。</li>
<li><em>Prioritization</em>: 优先级控制，比如：CPU利用和磁盘IO吞吐。</li>
<li><em>Accounting</em>: 一些审计或一些统计，主要目的是为了计费。</li>
<li><em>Control</em>: 挂起进程，恢复执行进程。<br>使用cgroup，系统管理员可更具体地控制对系统资源的分配、优先顺序、拒绝、管理和监控。可更好地根据任务和用户分配硬件资源，提高总体效率。</li>
</ul>
<p>在实践中，系统管理员一般会利用CGroup做下面这些事（有点像为某个虚拟机分配资源似的）：</p>
<ul>
<li>隔离一个进程集合（比如：nginx的所有进程），并限制他们所消费的资源，比如绑定CPU的核。</li>
<li>为这组进程 分配其足够使用的内存</li>
<li>为这组进程分配相应的网络带宽和磁盘存储限制</li>
<li>限制访问某些设备（通过设置设备的白名单） </li>
</ul>
<p>那么CGroup是怎么干的呢？我们先来点感性认识吧。</p>
<p>首先，Linux把CGroup这个事实现成了一个file system，你可以mount。在我的Ubuntu 14.04下，你输入以下命令你就可以看到cgroup已为你mount好了。<br> <div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">hchen@ubuntu:~$ mount -t cgroup</span><br><span class="line">cgroup on /sys/fs/cgroup/cpuset type cgroup (rw,relatime,cpuset)</span><br><span class="line">cgroup on /sys/fs/cgroup/cpu type cgroup (rw,relatime,cpu)</span><br><span class="line">cgroup on /sys/fs/cgroup/cpuacct type cgroup (rw,relatime,cpuacct)</span><br><span class="line">cgroup on /sys/fs/cgroup/memory type cgroup (rw,relatime,memory)</span><br><span class="line">cgroup on /sys/fs/cgroup/devices type cgroup (rw,relatime,devices)</span><br><span class="line">cgroup on /sys/fs/cgroup/freezer type cgroup (rw,relatime,freezer)</span><br><span class="line">cgroup on /sys/fs/cgroup/blkio type cgroup (rw,relatime,blkio)</span><br><span class="line">cgroup on /sys/fs/cgroup/net_prio type cgroup (rw,net_prio)</span><br><span class="line">cgroup on /sys/fs/cgroup/net_cls type cgroup (rw,net_cls)</span><br><span class="line">cgroup on /sys/fs/cgroup/perf_event type cgroup (rw,relatime,perf_event)</span><br><span class="line">cgroup on /sys/fs/cgroup/hugetlb type cgroup (rw,relatime,hugetlb)</span><br></pre></td></tr></table></figure></div><br>或者使用lssubsys命令：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> lssubsys  -m</span></span><br><span class="line">cpuset /sys/fs/cgroup/cpuset</span><br><span class="line">cpu /sys/fs/cgroup/cpu</span><br><span class="line">cpuacct /sys/fs/cgroup/cpuacct</span><br><span class="line">memory /sys/fs/cgroup/memory</span><br><span class="line">devices /sys/fs/cgroup/devices</span><br><span class="line">freezer /sys/fs/cgroup/freezer</span><br><span class="line">blkio /sys/fs/cgroup/blkio</span><br><span class="line">net_cls /sys/fs/cgroup/net_cls</span><br><span class="line">net_prio /sys/fs/cgroup/net_prio</span><br><span class="line">perf_event /sys/fs/cgroup/perf_event</span><br><span class="line">hugetlb /sys/fs/cgroup/hugetlb</span><br></pre></td></tr></table></figure></div>
<p>我们可以看到，在/sys/fs下有一个cgroup的目录，这个目录下还有很多子目录，比如： cpu，cpuset，memory，blkio……这些，这些都是cgroup的子系统。分别用于干不同的事的。</p>
<p>如果你没有看到上述的目录，你可以自己mount，下面给了一个示例：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">mkdir cgroup</span><br><span class="line">mount -t tmpfs cgroup_root ./cgroup</span><br><span class="line">mkdir cgroup/cpuset</span><br><span class="line">mount -t cgroup -ocpuset cpuset ./cgroup/cpuset/</span><br><span class="line">mkdir cgroup/cpu</span><br><span class="line">mount -t cgroup -ocpu cpu ./cgroup/cpu/</span><br><span class="line">mkdir cgroup/memory</span><br><span class="line">mount -t cgroup -omemory memory ./cgroup/memory/</span><br></pre></td></tr></table></figure></div>
<p>一旦mount成功，你就会看到这些目录下就有好文件了，比如，如下所示的cpu和cpuset的子系统：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">hchen@ubuntu:~$ ls /sys/fs/cgroup/cpu /sys/fs/cgroup/cpuset/ </span><br><span class="line">/sys/fs/cgroup/cpu:</span><br><span class="line">cgroup.clone_children  cgroup.sane_behavior  cpu.shares         release_agent</span><br><span class="line">cgroup.event_control   cpu.cfs_period_us     cpu.stat           tasks</span><br><span class="line">cgroup.procs           cpu.cfs_quota_us      notify_on_release  user</span><br><span class="line"></span><br><span class="line">/sys/fs/cgroup/cpuset/:</span><br><span class="line">cgroup.clone_children  cpuset.mem_hardwall             cpuset.sched_load_balance</span><br><span class="line">cgroup.event_control   cpuset.memory_migrate           cpuset.sched_relax_domain_level</span><br><span class="line">cgroup.procs           cpuset.memory_pressure          notify_on_release</span><br><span class="line">cgroup.sane_behavior   cpuset.memory_pressure_enabled  release_agent</span><br><span class="line">cpuset.cpu_exclusive   cpuset.memory_spread_page       tasks</span><br><span class="line">cpuset.cpus            cpuset.memory_spread_slab       user</span><br><span class="line">cpuset.mem_exclusive   cpuset.mems</span><br></pre></td></tr></table></figure></div>
<p>你可以到/sys/fs/cgroup的各个子目录下去make个dir，你会发现，一旦你创建了一个子目录，这个子目录里又有很多文件了。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">hchen@ubuntu:/sys/fs/cgroup/cpu$ sudo mkdir haoel</span><br><span class="line">[sudo] password for hchen: </span><br><span class="line">hchen@ubuntu:/sys/fs/cgroup/cpu$ ls ./haoel</span><br><span class="line">cgroup.clone_children  cgroup.procs       cpu.cfs_quota_us  cpu.stat           tasks</span><br><span class="line">cgroup.event_control   cpu.cfs_period_us  cpu.shares        notify_on_release</span><br></pre></td></tr></table></figure></div>
<p>好了，我们来看几个示例。</p>
<h3 id="CPU-限制"><a href="#CPU-限制" class="headerlink" title="CPU 限制"></a>CPU 限制</h3><p>假设，我们有一个非常吃CPU的程序，叫deadloop，其源码如下：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="C"><figure class="iseeu highlight /c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> i = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span>(;;) i++;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>用sudo执行起来后，毫无疑问，CPU被干到了100%（下面是top命令的输出）</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"> PID USER      PR  NI    VIRT    RES    SHR S %CPU %MEM     TIME+ COMMAND     </span><br><span class="line">3529 root      20   0    4196    736    656 R 99.6  0.1   0:23.13 deadloop   </span><br></pre></td></tr></table></figure></div>
<p>然后，我们这前不是在/sys/fs/cgroup/cpu下创建了一个haoel的group。我们先设置一下这个group的cpu利用的限制：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">hchen@ubuntu:~# cat /sys/fs/cgroup/cpu/haoel/cpu.cfs_quota_us </span><br><span class="line">-1</span><br><span class="line">root@ubuntu:~# echo 20000 &gt; /sys/fs/cgroup/cpu/haoel/cpu.cfs_quota_us</span><br></pre></td></tr></table></figure></div>
<p>我们看到，这个进程的PID是3529，我们把这个进程加到这个cgroup中：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">echo 3529 &gt;&gt; /sys/fs/cgroup/cpu/haoel/tasks</span><br></pre></td></tr></table></figure></div>
<p>然后，就会在top中看到CPU的利用立马下降成20%了。（前面我们设置的20000就是20%的意思）</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"> PID USER      PR  NI    VIRT    RES    SHR S %CPU %MEM     TIME+ COMMAND     </span><br><span class="line">3529 root      20   0    4196    736    656 R 19.9  0.1   8:06.11 deadloop    </span><br></pre></td></tr></table></figure></div>
<p>下面的代码是一个线程的示例：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="C"><figure class="iseeu highlight /c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> _GNU_SOURCE         <span class="comment">/* See feature_test_macros(7) */</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/stat.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/types.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/syscall.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> NUM_THREADS = <span class="number">5</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> *<span class="title">thread_main</span><span class="params">(<span class="keyword">void</span> *threadid)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">/* 把自己加入cgroup中（syscall(SYS_gettid)为得到线程的系统tid） */</span></span><br><span class="line">    <span class="keyword">char</span> cmd[<span class="number">128</span>];</span><br><span class="line">    <span class="built_in">sprintf</span>(cmd, <span class="string">&quot;echo %ld &gt;&gt; /sys/fs/cgroup/cpu/haoel/tasks&quot;</span>, syscall(SYS_gettid));</span><br><span class="line">    system(cmd); </span><br><span class="line">    <span class="built_in">sprintf</span>(cmd, <span class="string">&quot;echo %ld &gt;&gt; /sys/fs/cgroup/cpuset/haoel/tasks&quot;</span>, syscall(SYS_gettid));</span><br><span class="line">    system(cmd);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">long</span> tid;</span><br><span class="line">    tid = (<span class="keyword">long</span>)threadid;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Hello World! It&#x27;s me, thread #%ld, pid #%ld!\n&quot;</span>, tid, syscall(SYS_gettid));</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">int</span> a=<span class="number">0</span>; </span><br><span class="line">    <span class="keyword">while</span>(<span class="number">1</span>) &#123;</span><br><span class="line">        a++;</span><br><span class="line">    &#125;</span><br><span class="line">    pthread_exit(<span class="literal">NULL</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span> <span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> *argv[])</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> num_threads;</span><br><span class="line">    <span class="keyword">if</span> (argc &gt; <span class="number">1</span>)&#123;</span><br><span class="line">        num_threads = atoi(argv[<span class="number">1</span>]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (num_threads&lt;=<span class="number">0</span> || num_threads&gt;=<span class="number">100</span>)&#123;</span><br><span class="line">        num_threads = NUM_THREADS;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* 设置CPU利用率为50% */</span></span><br><span class="line">    mkdir(<span class="string">&quot;/sys/fs/cgroup/cpu/haoel&quot;</span>, <span class="number">755</span>);</span><br><span class="line">    system(<span class="string">&quot;echo 50000 &gt; /sys/fs/cgroup/cpu/haoel/cpu.cfs_quota_us&quot;</span>);</span><br><span class="line"></span><br><span class="line">    mkdir(<span class="string">&quot;/sys/fs/cgroup/cpuset/haoel&quot;</span>, <span class="number">755</span>);</span><br><span class="line">    <span class="comment">/* 限制CPU只能使用#2核和#3核 */</span></span><br><span class="line">    system(<span class="string">&quot;echo \&quot;2,3\&quot; &gt; /sys/fs/cgroup/cpuset/haoel/cpuset.cpus&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">pthread_t</span>* threads = (<span class="keyword">pthread_t</span>*) <span class="built_in">malloc</span> (<span class="keyword">sizeof</span>(<span class="keyword">pthread_t</span>)*num_threads);</span><br><span class="line">    <span class="keyword">int</span> rc;</span><br><span class="line">    <span class="keyword">long</span> t;</span><br><span class="line">    <span class="keyword">for</span>(t=<span class="number">0</span>; t&lt;num_threads; t++)&#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;In main: creating thread %ld\n&quot;</span>, t);</span><br><span class="line">        rc = pthread_create(&amp;threads[t], <span class="literal">NULL</span>, thread_main, (<span class="keyword">void</span> *)t);</span><br><span class="line">        <span class="keyword">if</span> (rc)&#123;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;ERROR; return code from pthread_create() is %d\n&quot;</span>, rc);</span><br><span class="line">            <span class="built_in">exit</span>(<span class="number">-1</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Last thing that main() should do */</span></span><br><span class="line">    pthread_exit(<span class="literal">NULL</span>);</span><br><span class="line">    <span class="built_in">free</span>(threads);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h3 id="内存使用限制"><a href="#内存使用限制" class="headerlink" title="内存使用限制"></a>内存使用限制</h3><p>我们再来看一个限制内存的例子（下面的代码是个死循环，其它不断的分配内存，每次512个字节，每次休息一秒）：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="C"><figure class="iseeu highlight /c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/types.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> size = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">int</span> chunk_size = <span class="number">512</span>;</span><br><span class="line">    <span class="keyword">void</span> *p = <span class="literal">NULL</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span>(<span class="number">1</span>) &#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> ((p = <span class="built_in">malloc</span>(p, chunk_size)) == <span class="literal">NULL</span>) &#123;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;out of memory!!\n&quot;</span>);</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">memset</span>(p, <span class="number">1</span>, chunk_size);</span><br><span class="line">        size += chunk_size;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;[%d] - memory is allocated [%8d] bytes \n&quot;</span>, getpid(), size);</span><br><span class="line">        sleep(<span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<p>然后，在我们另外一边：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建memory cgroup</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> mkdir /sys/fs/cgroup/memory/haoel</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">echo</span> 64k &gt; /sys/fs/cgroup/memory/haoel/memory.limit_in_bytes</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 把上面的进程的pid加入这个cgroup</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">echo</span> [pid] &gt; /sys/fs/cgroup/memory/haoel/tasks</span> </span><br></pre></td></tr></table></figure></div>
<p>你会看到，一会上面的进程就会因为内存问题被kill掉了。</p>
<h3 id="磁盘I-O限制"><a href="#磁盘I-O限制" class="headerlink" title="磁盘I/O限制"></a>磁盘I/O限制</h3><p>我们先看一下我们的硬盘IO，我们的模拟命令如下：（从/dev/sda1上读入数据，输出到/dev/null上）</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">sudo dd if=/dev/sda1 of=/dev/null</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>
<p>我们通过iotop命令我们可以看到相关的IO速度是55MB/s（虚拟机内）:</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"> TID  PRIO  USER     DISK READ  DISK WRITE  SWAPIN     IO&gt;    COMMAND          </span><br><span class="line">8128 be/4 root       55.74 M/s    0.00 B/s  0.00 % 85.65 % dd if=/de~=/dev/null...</span><br></pre></td></tr></table></figure></div>
<p>然后，我们先创建一个blkio（块设备IO）的cgroup</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">mkdir /sys/fs/cgroup/blkio/haoel</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>
<p>并把读IO限制到1MB/s，并把前面那个dd命令的pid放进去（注：8:0 是设备号，你可以通过ls -l /dev/sda1获得）：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">root@ubuntu:~# echo &#x27;8:0 1048576&#x27;  &gt; /sys/fs/cgroup/blkio/haoel/blkio.throttle.read_bps_device </span><br><span class="line">root@ubuntu:~# echo 8128 &gt; /sys/fs/cgroup/blkio/haoel/tasks</span><br></pre></td></tr></table></figure></div>
<p>再用iotop命令，你马上就能看到读速度被限制到了1MB/s左右。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"> TID  PRIO  USER     DISK READ  DISK WRITE  SWAPIN     IO&gt;    COMMAND          </span><br><span class="line">8128 be/4 root      973.20 K/s    0.00 B/s  0.00 % 94.41 % dd if=/de~=/dev/null...</span><br></pre></td></tr></table></figure></div>

<h3 id="CGroup的子系统"><a href="#CGroup的子系统" class="headerlink" title="CGroup的子系统"></a>CGroup的子系统</h3><p>好了，有了以上的感性认识我们来，我们来看看control group有哪些子系统：</p>
<ul>
<li>blkio — 这个子系统为块设备设定输入/输出限制，比如物理设备（磁盘，固态硬盘，USB 等等）。</li>
<li>cpu — 这个子系统使用调度程序提供对 CPU 的 cgroup 任务访问。</li>
<li>cpuacct — 这个子系统自动生成 cgroup 中任务所使用的 CPU 报告。</li>
<li>cpuset — 这个子系统为 cgroup 中的任务分配独立 CPU（在多核系统）和内存节点。</li>
<li>devices — 这个子系统可允许或者拒绝 cgroup 中的任务访问设备。</li>
<li>freezer — 这个子系统挂起或者恢复 cgroup 中的任务。</li>
<li>memory — 这个子系统设定 cgroup 中任务使用的内存限制，并自动生成内存资源使用报告。</li>
<li>net_cls — 这个子系统使用等级识别符（classid）标记网络数据包，可允许 Linux 流量控制程序（tc）识别从具体 cgroup 中生成的数据包。</li>
<li>net_prio — 这个子系统用来设计网络流量的优先级</li>
<li>hugetlb — 这个子系统主要针对于HugeTLB系统进行限制，这是一个大页文件系统。</li>
</ul>
<p>注意，你可能在Ubuntu 14.04下看不到net_cls和net_prio这两个cgroup，你需要手动mount一下：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> sudo modprobe cls_cgroup</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> sudo mkdir /sys/fs/cgroup/net_cls</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> sudo mount -t cgroup -o net_cls none /sys/fs/cgroup/net_cls</span></span><br><span class="line"></span><br><span class="line"><span class="meta">$</span><span class="bash"> sudo modprobe netprio_cgroup</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> sudo mkdir /sys/fs/cgroup/net_prio</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> sudo mount -t cgroup -o net_prio none /sys/fs/cgroup/net_prio</span></span><br></pre></td></tr></table></figure></div>
<p>关于各个子系统的参数细节，以及更多的Linux CGroup的文档，你可以看看下面的文档：</p>
<ul>
<li><a href="https://www.kernel.org/doc/Documentation/cgroup-v1/">Linux Kernel的官方文档</a></li>
<li><a href="https://access.redhat.com/documentation/zh-cn/red_hat_enterprise_linux/6/html-single/resource_management_guide/index#ch-Subsystems_and_Tunable_Parameters">Redhat的官方文档</a></li>
</ul>
<h3 id="CGroup的术语"><a href="#CGroup的术语" class="headerlink" title="CGroup的术语"></a>CGroup的术语</h3><p>CGroup有下述术语：</p>
<ul>
<li>任务（Tasks）：就是系统的一个进程。</li>
<li>控制组（Control Group）：一组按照某种标准划分的进程，比如官方文档中的Professor和Student，或是WWW和System之类的，其表示了某进程组。Cgroups中的资源控制都是以控制组为单位实现。一个进程可以加入到某个控制组。而资源的限制是定义在这个组上，就像上面示例中我用的haoel一样。简单点说，cgroup的呈现就是一个目录带一系列的可配置文件。</li>
<li>层级（Hierarchy）：控制组可以组织成hierarchical的形式，既一颗控制组的树（目录结构）。控制组树上的子节点继承父结点的属性。简单点说，hierarchy就是在一个或多个子系统上的cgroups目录树。</li>
<li>子系统（Subsystem）：一个子系统就是一个资源控制器，比如CPU子系统就是控制CPU时间分配的一个控制器。子系统必须附加到一个层级上才能起作用，一个子系统附加到某个层级以后，这个层级上的所有控制族群都受到这个子系统的控制。Cgroup的子系统可以有很多，也在不断增加中。</li>
</ul>
<h3 id="下一代的CGroup"><a href="#下一代的CGroup" class="headerlink" title="下一代的CGroup"></a>下一代的CGroup</h3><p>上面，我们可以看到，CGroup的一些常用方法和相关的术语。一般来说，这样的设计在一般情况下还是没什么问题的，除了操作上的用户体验不是很好，但基本满足我们的一般需求了。</p>
<p>不过，对此，有个叫Tejun Heo的同学非常不爽，他在Linux社区里对cgroup吐了一把槽，还引发了内核组的各种讨论。</p>
<p>对于Tejun Heo同学来说，cgroup设计的相当糟糕。他给出了些例子，大意就是说，如果有多种层级关系，也就是说有多种对进程的分类方式，比如，我们可以按用户来分，分成Professor和Student，同时，也有按应用类似来分的，比如WWW和NFS等。那么，当一个进程即是Professor的，也是WWW的，那么就会出现多层级正交的情况，从而出现对进程上管理的混乱。另外，一个case是，如果有一个层级A绑定cpu，而层级B绑定memory，还有一个层级C绑定cputset，而有一些进程有的需要AB，有的需要AC，有的需要ABC，管理起来就相当不易。</p>
<p>层级操作起来比较麻烦，而且如果层级变多，更不易于操作和管理，虽然那种方式很好实现，但是在使用上有很多的复杂度。你可以想像一个图书馆的图书分类问题，你可以有各种不同的分类，分类和图书就是一种多对多的关系。</p>
<p>所以，在Kernel 3.16后，引入了unified hierarchy的新的设计，这个东西引入了一个叫__DEVEL__sane_behavior的特性（这个名字很明显意味目前还在开发试验阶段），它可以把所有子系统都挂载到根层级下，只有叶子节点可以存在tasks，非叶子节点只进行资源控制。</p>
<p>我们mount一下看看：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> sudo mount -t cgroup -o __DEVEL__sane_behavior cgroup ./cgroup</span></span><br><span class="line"></span><br><span class="line"><span class="meta">$</span><span class="bash"> ls ./cgroup</span></span><br><span class="line">cgroup.controllers  cgroup.procs  cgroup.sane_behavior  cgroup.subtree_control </span><br><span class="line"></span><br><span class="line"><span class="meta">$</span><span class="bash"> cat ./cgroup/cgroup.controllers</span></span><br><span class="line">cpuset cpu cpuacct memory devices freezer net_cls blkio perf_event net_prio hugetlb</span><br></pre></td></tr></table></figure></div>
<p>我们可以看到有四个文件，然后，你在这里mkdir一个子目录，里面也会有这四个文件。上级的cgroup.subtree_control控制下级的cgroup.controllers。</p>
<p>举个例子：假设我们有以下的目录结构，b代表blkio，m代码memory，其中，A是root，包括所有的子系统（）。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> A(b,m) - B(b,m) - C (b)</span></span><br><span class="line"><span class="meta">#</span><span class="bash">               \ - D (b) - E</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 下面的命令中， +表示<span class="built_in">enable</span>， -表示<span class="built_in">disable</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 在B上的<span class="built_in">enable</span> blkio</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> <span class="built_in">echo</span> +blkio &gt; A/cgroup.subtree_control</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 在C和D上<span class="built_in">enable</span> blkio</span> </span><br><span class="line"><span class="meta">#</span><span class="bash"> <span class="built_in">echo</span> +blkio &gt; A/B/cgroup.subtree_control</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 在B上<span class="built_in">enable</span> memory</span>  </span><br><span class="line"><span class="meta">#</span><span class="bash"> <span class="built_in">echo</span> +memory &gt; A/cgroup.subtree_control</span></span><br></pre></td></tr></table></figure></div>
<p>在上述的结构中，</p>
<ul>
<li>cgroup只有上线控制下级，无法传递到下下级。所以，C和D中没有memory的限制，E中没有blkio和memory的限制。而本层的cgroup.controllers文件是个只读的，其中的内容就看上级的subtree_control里有什么了。</li>
<li>任何被配置过subtree_control的目录都不能绑定进程，根结点除外。所以，A,C,D,E可以绑上进程，但是B不行。<br>我们可以看到，这种方式干净的区分开了两个事，一个是进程的分组，一个是对分组的资源控制（以前这两个事完全混在一起），在目录继承上增加了些限制，这样可以避免一些模棱两可的情况。</li>
</ul>
<p>当然，这个事还在演化中，cgroup的这些问题这个事目前由cgroup的吐槽人Tejun Heo和华为的Li Zefan同学负责解决中。总之，这是一个系统管理上的问题，而且改变会影响很多东西，但一旦方案确定，老的cgroup方式将一去不复返。</p>
]]></content>
      <tags>
        <tag>云原生基础系列</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes网络系列之(一)网络是怎么连通的</title>
    <url>/2022/06/10/uncatalog/cl48bverj000054r77iq83ab9/</url>
    <content><![CDATA[<hr>
<span id="more"></span>



<hr>
<p>你是一台电脑，你的名字叫 A<br>很久很久之前，你不与任何其他电脑相连接，孤苦伶仃。</p>
<p><img src="/2022/06/10/uncatalog/cl48bverj000054r77iq83ab9/1.png" alt="1.png"></p>
<p>直到有一天，你希望与另一台电脑 B 建立通信，于是你们各开了一个网口，用一根网线连接了起来。</p>
<p><img src="/2022/06/10/uncatalog/cl48bverj000054r77iq83ab9/2.png" alt="2.png"></p>
<p>用一根网线连接起来怎么就能”通信”了呢？我可以给你讲 IO、讲中断、讲缓冲区，但这不是研究网络时该关心的问题。</p>
<p>如果你纠结，要么去研究一下操作系统是如何处理网络 IO 的，要么去研究一下包是如何被网卡转换成电信号发送出去的，要么就仅仅把它当做电脑里有个小人在开枪吧~</p>
<p><img src="/2022/06/10/uncatalog/cl48bverj000054r77iq83ab9/3.gif" alt="3.gif"></p>
<p>反正，你们就是连起来了，并且可以通信。</p>
 <center>第一层</center>


<p>有一天，一个新伙伴 C 加入了，但聪明的你们很快发现，可以每个人开两个网口，用一共三根网线，彼此相连。<br><img src="/2022/06/10/uncatalog/cl48bverj000054r77iq83ab9/4.png" alt="4.png"></p>
<p>随着越来越多的人加入，你发现身上开的网口实在太多了，而且网线密密麻麻，混乱不堪。（而实际上一台电脑根本开不了这么多网口，所以这种连线只在理论上可行，所以连不上的我就用红色虚线表示了，就是这么严谨哈哈~）</p>
<p><img src="/2022/06/10/uncatalog/cl48bverj000054r77iq83ab9/5.png" alt="5.png"></p>
<p>于是你们发明了一个中间设备，你们将网线都插到这个设备上，由这个设备做转发，就可以彼此之间通信了，本质上和原来一样，只不过网口的数量和网线的数量减少了，不再那么混乱。</p>
<p><img src="/2022/06/10/uncatalog/cl48bverj000054r77iq83ab9/6.png" alt="6.png"></p>
<p>你给它取名叫集线器，它仅仅是无脑将电信号转发到所有出口（广播），不做任何处理，你觉得它是没有智商的，因此把人家定性在了物理层。</p>
<p><img src="/2022/06/10/uncatalog/cl48bverj000054r77iq83ab9/7.gif" alt="7.gif"></p>
<p>由于转发到了所有出口，那 BCDE 四台机器怎么知道数据包是不是发给自己的呢？</p>
<p>首先，你要给所有的连接到集线器的设备，都起个名字。原来你们叫 ABCD，但现在需要一个更专业的，全局唯一的名字作为标识，你把这个更高端的名字称为 MAC 地址。</p>
<p>你的 MAC 地址是 aa-aa-aa-aa-aa-aa，你的伙伴 b 的 MAC 地址是 bb-bb-bb-bb-bb-bb，以此类推，不重复就好。</p>
<p>这样，A 在发送数据包给 B 时，只要在头部拼接一个这样结构的数据，就可以了。</p>
<p><img src="/2022/06/10/uncatalog/cl48bverj000054r77iq83ab9/8.png" alt="8.png"></p>
<p>B 在收到数据包后，根据头部的目标 MAC 地址信息，判断这个数据包的确是发给自己的，于是便收下。</p>
<p>其他的 CDE 收到数据包后，根据头部的目标 MAC 地址信息，判断这个数据包并不是发给自己的，于是便丢弃。</p>
<p><img src="/2022/06/10/uncatalog/cl48bverj000054r77iq83ab9/9.gif" alt="9.gif"></p>
<p>虽然集线器使整个布局干净不少，但原来我只要发给电脑 B 的消息，现在却要发给连接到集线器中的所有电脑，这样既不安全，又不节省网络资源。</p>
<center>第二层</center>



<p>如果把这个集线器弄得更智能一些，只发给目标 MAC 地址指向的那台电脑，就好了。</p>
<p><img src="/2022/06/10/uncatalog/cl48bverj000054r77iq83ab9/10.gif" alt="10.gif"></p>
<p>虽然只比集线器多了这一点点区别，但看起来似乎有智能了，你把这东西叫做交换机。也正因为这一点点智能，你把它放在了另一个层级，数据链路层。</p>
<p><img src="/2022/06/10/uncatalog/cl48bverj000054r77iq83ab9/11.png" alt="11.png"></p>
<p>如上图所示，你是这样设计的。</p>
<p>交换机内部维护一张 MAC 地址表，记录着每一个 MAC 地址的设备，连接在其哪一个端口上。</p>
<table>
<thead>
<tr>
<th align="left">MAC 地址</th>
<th align="left">端口</th>
</tr>
</thead>
<tbody><tr>
<td align="left">bb-bb-bb-bb-bb-bb</td>
<td align="left">1</td>
</tr>
<tr>
<td align="left">cc-cc-cc-cc-cc-cc</td>
<td align="left">3</td>
</tr>
<tr>
<td align="left">aa-aa-aa-aa-aa-aa</td>
<td align="left">4</td>
</tr>
<tr>
<td align="left">dd-dd-dd-dd-dd-dd</td>
<td align="left">5</td>
</tr>
<tr>
<td align="left">假如你仍然要发给 B 一个数据包，构造了如下的数据结构从网口出去。</td>
<td align="left"></td>
</tr>
</tbody></table>
<p><img src="/2022/06/10/uncatalog/cl48bverj000054r77iq83ab9/12.png" alt="12.png"></p>
<p>到达交换机时，交换机内部通过自己维护的 MAC 地址表，发现目标机器 B 的 MAC 地址 bb-bb-bb-bb-bb-bb 映射到了端口 1 上，于是把数据从 1 号端口发给了 B，完事~</p>
<p>你给这个通过这样传输方式而组成的小范围的网络，叫做以太网。</p>
<p>当然最开始的时候，MAC 地址表是空的，是怎么逐步建立起来的呢？</p>
<p>假如在 MAC 地址表为空是，你给 B 发送了如下数据</p>
<p><img src="/2022/06/10/uncatalog/cl48bverj000054r77iq83ab9/13.png" alt="13.png"></p>
<p>由于这个包从端口 4 进入的交换机，所以此时交换机就可以在 MAC地址表记录第一条数据：</p>
<p>MAC：aa-aa-aa-aa-aa-aa-aa<br>端口：4</p>
<p>交换机看目标 MAC 地址（bb-bb-bb-bb-bb-bb）在地址表中并没有映射关系，于是将此包发给了所有端口，也即发给了所有机器。</p>
<p>之后，只有机器 B 收到了确实是发给自己的包，于是做出了响应，响应数据从端口 1 进入交换机，于是交换机此时在地址表中更新了第二条数据：</p>
<p>MAC：bb-bb-bb-bb-bb-bb<br>端口：1</p>
<p>过程如下</p>
<p><img src="/2022/06/10/uncatalog/cl48bverj000054r77iq83ab9/14.gif" alt="14.gif"></p>
<p>经过该网络中的机器不断地通信，交换机最终将 MAC 地址表建立完毕~</p>
<p>随着机器数量越多，交换机的端口也不够了，但聪明的你发现，只要将多个交换机连接起来，这个问题就轻而易举搞定~</p>
<p><img src="/2022/06/10/uncatalog/cl48bverj000054r77iq83ab9/15.png" alt="15.png"></p>
<p>你完全不需要设计额外的东西，只需要按照之前的设计和规矩来，按照上述的接线方式即可完成所有电脑的互联，所以交换机设计的这种规则，真的很巧妙。你想想看为什么（比如 A 要发数据给 F）。</p>
<p>但是你要注意，上面那根红色的线，最终在 MAC 地址表中可不是一条记录呀，而是要把 EFGH 这四台机器与该端口（端口6）的映射全部记录在表中。</p>
<p>最终，两个交换机将分别记录 A ~ H 所有机器的映射记录。</p>
<p>左边的交换机</p>
<table>
<thead>
<tr>
<th align="left">MAC 地址</th>
<th align="left">端口</th>
</tr>
</thead>
<tbody><tr>
<td align="left">bb-bb-bb-bb-bb-bb</td>
<td align="left">1</td>
</tr>
<tr>
<td align="left">cc-cc-cc-cc-cc-cc</td>
<td align="left">3</td>
</tr>
<tr>
<td align="left">aa-aa-aa-aa-aa-aa</td>
<td align="left">4</td>
</tr>
<tr>
<td align="left">dd-dd-dd-dd-dd-dd</td>
<td align="left">5</td>
</tr>
<tr>
<td align="left">ee-ee-ee-ee-ee-ee</td>
<td align="left">6</td>
</tr>
<tr>
<td align="left">ff-ff-ff-ff-ff-ff</td>
<td align="left">6</td>
</tr>
<tr>
<td align="left">gg-gg-gg-gg-gg-gg</td>
<td align="left">6</td>
</tr>
<tr>
<td align="left">hh-hh-hh-hh-hh-hh</td>
<td align="left">6</td>
</tr>
</tbody></table>
<p>右边的交换机</p>
<table>
<thead>
<tr>
<th align="left">MAC 地址</th>
<th align="left">端口</th>
</tr>
</thead>
<tbody><tr>
<td align="left">bb-bb-bb-bb-bb-bb</td>
<td align="left">1</td>
</tr>
<tr>
<td align="left">cc-cc-cc-cc-cc-cc</td>
<td align="left">1</td>
</tr>
<tr>
<td align="left">aa-aa-aa-aa-aa-aa</td>
<td align="left">1</td>
</tr>
<tr>
<td align="left">dd-dd-dd-dd-dd-dd</td>
<td align="left">1</td>
</tr>
<tr>
<td align="left">ee-ee-ee-ee-ee-ee</td>
<td align="left">2</td>
</tr>
<tr>
<td align="left">ff-ff-ff-ff-ff-ff</td>
<td align="left">3</td>
</tr>
<tr>
<td align="left">gg-gg-gg-gg-gg-gg</td>
<td align="left">4</td>
</tr>
<tr>
<td align="left">hh-hh-hh-hh-hh-hh</td>
<td align="left">6</td>
</tr>
</tbody></table>
<p>这在只有 8 台电脑的时候还好，甚至在只有几百台电脑的时候，都还好，所以这种交换机的设计方式，已经足足支撑一阵子了。</p>
<p>但很遗憾，人是贪婪的动物，很快，电脑的数量就发展到几千、几万、几十万。</p>
<center>第三层</center>

<p>交换机已经无法记录如此庞大的映射关系了。</p>
<p>此时你动了歪脑筋，你发现了问题的根本在于，连出去的那根红色的网线，后面不知道有多少个设备不断地连接进来，从而使得地址表越来越大。</p>
<p>那我可不可以让那根红色的网线，接入一个新的设备，这个设备就跟电脑一样有自己独立的 MAC 地址，而且同时还能帮我把数据包做一次转发呢？</p>
<p>这个设备就是路由器，它的功能就是，作为一台独立的拥有 MAC 地址的设备，并且可以帮我把数据包做一次转发，你把它定在了网络层。</p>
<p><img src="/2022/06/10/uncatalog/cl48bverj000054r77iq83ab9/16.png" alt="16.png"></p>
<p>注意，路由器的每一个端口，都有独立的 MAC 地址</p>
<p>好了，现在交换机的 MAC 地址表中，只需要多出一条 MAC 地址 ABAB 与其端口的映射关系，就可以成功把数据包转交给路由器了，这条搞定。</p>
<p>那如何做到，把发送给 C 和 D，甚至是把发送给 DEFGH…. 的数据包，统统先发送给路由器呢？</p>
<p>不难想到这样一个点子，假如电脑 C 和 D 的 MAC 地址拥有共同的前缀，比如分别是</p>
<p>C 的 MAC 地址：FFFF-FFFF-CCCC<br>D 的 MAC 地址：FFFF-FFFF-DDDD<br>那我们就可以说，将目标 MAC 地址为 FFFF-FFFF-？开头的，统统先发送给路由器。</p>
<p>这样是否可行呢？答案是否定的。</p>
<p>我们先从现实中 MAC 地址的结构入手，MAC地址也叫物理地址、硬件地址，长度为 48 位，一般这样来表示</p>
<p>00-16-EA-AE-3C-40</p>
<p>它是由网络设备制造商生产时烧录在网卡的EPROM（一种闪存芯片，通常可以通过程序擦写）。其中前 24 位（00-16-EA）代表网络硬件制造商的编号，后 24 位（AE-3C-40）是该厂家自己分配的，一般表示系列号。只要不更改自己的 MAC 地址，MAC 地址在世界是唯一的。形象地说，MAC地址就如同身份证上的身份证号码，具有唯一性。</p>
<p>那如果你希望向上面那样表示将目标 MAC 地址为 FFFF-FFFF-？开头的，统一从路由器出去发给某一群设备（后面会提到这其实是子网的概念），那你就需要要求某一子网下统统买一个厂商制造的设备，要么你就需要要求厂商在生产网络设备烧录 MAC 地址时，提前按照你规划好的子网结构来定 MAC 地址，并且日后这个网络的结构都不能轻易改变。</p>
<p>这显然是不现实的。</p>
<p>于是你发明了一个新的地址，给每一台机器一个 32 位的编号，如：</p>
<p>11000000101010000000000000000001</p>
<p>你觉得有些不清晰，于是把它分成四个部分，中间用点相连。</p>
<p>11000000.10101000.00000000.00000001</p>
<p>你还觉得不清晰，于是把它转换成 10 进制。</p>
<p>192.168.0.1</p>
<p>最后你给了这个地址一个响亮的名字，IP 地址。现在每一台电脑，同时有自己的 MAC 地址，又有自己的 IP 地址，只不过 IP 地址是软件层面上的，可以随时修改，MAC 地址一般是无法修改的。</p>
<p>这样一个可以随时修改的 IP 地址，就可以根据你规划的网络拓扑结构，来调整了。</p>
<p><img src="/2022/06/10/uncatalog/cl48bverj000054r77iq83ab9/17.png" alt="17.png"></p>
<p>如上图所示，假如我想要发送数据包给 ABCD 其中一台设备，不论哪一台，我都可以这样描述，”将 IP 地址为 192.168.0 开头的全部发送给到路由器，之后再怎么转发，交给它！”，巧妙吧。</p>
<p>那交给路由器之后，路由器又是怎么把数据包准确转发给指定设备的呢？</p>
<p>别急我们慢慢来。</p>
<p>我们先给上面的组网方式中的每一台设备，加上自己的 IP 地址</p>
<p><img src="/2022/06/10/uncatalog/cl48bverj000054r77iq83ab9/18.png" alt="18.png"></p>
<p>现在两个设备之间传输，除了加上数据链路层的头部之外，还要再增加一个网络层的头部。</p>
<p>假如 A 给 B 发送数据，由于它们直接连着交换机，所以 A 直接发出如下数据包即可，其实网络层没有体现出作用。</p>
<p><img src="/2022/06/10/uncatalog/cl48bverj000054r77iq83ab9/19.png" alt="19.png"></p>
<p>但假如 A 给 C 发送数据，A 就需要先转交给路由器，然后再由路由器转交给 C。由于最底层的传输仍然需要依赖以太网，所以数据包是分成两段的。</p>
<p>A ~ 路由器这段的包如下：</p>
<p><img src="/2022/06/10/uncatalog/cl48bverj000054r77iq83ab9/20.png" alt="20.png"></p>
<p>路由器到 C 这段的包如下：</p>
<p><img src="/2022/06/10/uncatalog/cl48bverj000054r77iq83ab9/21.png" alt="21.png"></p>
<p>好了，上面说的两种情况（A-&gt;B，A-&gt;C），相信细心的读者应该会有不少疑问，下面我们一个个来展开。</p>
<p>A 给 C 发数据包，怎么知道是否要通过路由器转发呢？</p>
<p>答案：子网</p>
<p>如果源 IP 与目的 IP 处于一个子网，直接将包通过交换机发出去。</p>
<p>如果源 IP 与目的 IP 不处于一个子网，就交给路由器去处理。</p>
<p>好，那现在只需要解决，什么叫处于一个子网就好了。</p>
<ul>
<li><p>192.168.0.1 和 192.168.0.2 处于同一个子网</p>
</li>
<li><p>192.168.0.1 和 192.168.1.1 处于不同子网</p>
</li>
</ul>
<p>这两个是我们人为规定的，即我们想表示，对于 192.168.0.1 来说：</p>
<p>192.168.0.xxx 开头的，就算是在一个子网，否则就是在不同的子网。</p>
<p>那对于计算机来说，怎么表达这个意思呢？于是人们发明了子网掩码的概念</p>
<p>假如某台机器的子网掩码定为 255.255.255.0</p>
<p>这表示，将源 IP 与目的 IP 分别同这个子网掩码进行与运算，相等则是在一个子网，不相等就是在不同子网，就这么简单。</p>
<p>比如</p>
<ul>
<li><p>A电脑：192.168.0.1 &amp; 255.255.255.0 = 192.168.0.0</p>
</li>
<li><p>B电脑：192.168.0.2 &amp; 255.255.255.0 = 192.168.0.0</p>
</li>
<li><p>C电脑：192.168.1.1 &amp; 255.255.255.0 = 192.168.1.0</p>
</li>
<li><p>D电脑：192.168.1.2 &amp; 255.255.255.0 = 192.168.1.0</p>
</li>
</ul>
<p>那么 A 与 B 在同一个子网，C 与 D 在同一个子网，但是 A 与 C 就不在同一个子网，与 D 也不在同一个子网，以此类推。</p>
<p><img src="/2022/06/10/uncatalog/cl48bverj000054r77iq83ab9/22.png" alt="22.png"></p>
<p>所以如果 A 给 C 发消息，A 和 C 的 IP 地址分别 &amp; A 机器配置的子网掩码，发现不相等，则 A 认为 C 和自己不在同一个子网，于是把包发给路由器，就不管了，之后怎么转发，A 不关心。</p>
<blockquote>
<p>A 如何知道，哪个设备是路由器？</p>
</blockquote>
<p>答案：在 A 上要设置默认网关</p>
<p>上一步 A 通过是否与 C 在同一个子网内，判断出自己应该把包发给路由器，那路由器的 IP 是多少呢？</p>
<p>其实说发给路由器不准确，应该说 A 会把包发给默认网关。</p>
<p>对 A 来说，A 只能直接把包发给同处于一个子网下的某个 IP 上，所以发给路由器还是发给某个电脑，对 A 来说也不关心，只要这个设备有个 IP 地址就行。</p>
<p>所以默认网关，就是 A 在自己电脑里配置的一个 IP 地址，以便在发给不同子网的机器时，发给这个 IP 地址。</p>
<p><img src="/2022/06/10/uncatalog/cl48bverj000054r77iq83ab9/23.png" alt="23.png"></p>
<p>仅此而已！</p>
<blockquote>
<p>路由器如何知道C在哪里？</p>
</blockquote>
<p>答案：路由表</p>
<p>现在 A 要给 C 发数据包，已经可以成功发到路由器这里了，最后一个问题就是，路由器怎么知道，收到的这个数据包，该从自己的哪个端口出去，才能直接（或间接）地最终到达目的地 C 呢。</p>
<p>路由器收到的数据包有目的 IP 也就是 C 的 IP 地址，需要转化成从自己的哪个端口出去，很容易想到，应该有个表，就像 MAC 地址表一样。</p>
<p>这个表就叫路由表。</p>
<p>至于这个路由表是怎么出来的，有很多路由算法，本文不展开，因为我也不会哈哈~</p>
<p>不同于 MAC 地址表的是，路由表并不是一对一这种明确关系，我们下面看一个路由表的结构。</p>
<table>
<thead>
<tr>
<th align="left">目的地址</th>
<th align="left">子网掩码</th>
<th align="left">下一跳</th>
<th align="left">端口</th>
</tr>
</thead>
<tbody><tr>
<td align="left">192.168.0.0</td>
<td align="left">255.255.255.0</td>
<td align="left"></td>
<td align="left">0</td>
</tr>
<tr>
<td align="left">192.168.0.254</td>
<td align="left">255.255.255.255</td>
<td align="left"></td>
<td align="left">0</td>
</tr>
<tr>
<td align="left">192.168.1.0</td>
<td align="left">255.255.255.0</td>
<td align="left"></td>
<td align="left">1</td>
</tr>
<tr>
<td align="left">192.168.1.254</td>
<td align="left">255.255.255.255</td>
<td align="left"></td>
<td align="left">1</td>
</tr>
</tbody></table>
<p>我们学习一种新的表示方法，由于子网掩码其实就表示前多少位表示子网的网段，所以如 192.168.0.0（255.255.255.0） 也可以简写为 192.168.0.0/24</p>
<table>
<thead>
<tr>
<th align="left">目的地址</th>
<th align="left">下一跳</th>
<th align="left">端口</th>
</tr>
</thead>
<tbody><tr>
<td align="left">192.168.0.0/24</td>
<td align="left"></td>
<td align="left">0</td>
</tr>
<tr>
<td align="left">192.168.0.254/32</td>
<td align="left"></td>
<td align="left">0</td>
</tr>
<tr>
<td align="left">192.168.1.0/24</td>
<td align="left"></td>
<td align="left">1</td>
</tr>
<tr>
<td align="left">192.168.1.254/32</td>
<td align="left"></td>
<td align="left">1</td>
</tr>
</tbody></table>
<p>这就很好理解了，路由表就表示，192.168.0.xxx 这个子网下的，都转发到 0 号端口，192.168.1.xxx 这个子网下的，都转发到 1 号端口。下一跳列还没有值，我们先不管</p>
<p>配合着结构图来看（这里把子网掩码和默认网关都补齐了）图中 &amp; 笔误，结果应该是 .0</p>
<p><img src="/2022/06/10/uncatalog/cl48bverj000054r77iq83ab9/24.gif" alt="24.gif"></p>
<blockquote>
<p>刚才说的都是 IP 层，但发送数据包的数据链路层需要知道 MAC 地址，可是我只知道 IP 地址该怎么办呢？</p>
</blockquote>
<p>答案：arp</p>
<p>假如你（A）此时不知道你同伴 B 的 MAC 地址（现实中就是不知道的，刚刚我们只是假设已知），你只知道它的 IP 地址，你该怎么把数据包准确传给 B 呢？</p>
<p>答案很简单，在网络层，我需要把 IP 地址对应的 MAC 地址找到，也就是通过某种方式，找到 192.168.0.2 对应的 MAC 地址 BBBB。</p>
<p>这种方式就是 arp 协议，同时电脑 A 和 B 里面也会有一张 arp 缓存表，表中记录着 IP 与 MAC 地址的对应关系。</p>
<table>
<thead>
<tr>
<th align="left">IP 地址</th>
<th align="left">MAC 地址</th>
</tr>
</thead>
<tbody><tr>
<td align="left">192.168.0.2</td>
<td align="left">BBBB</td>
</tr>
</tbody></table>
<p>一开始的时候这个表是空的，电脑 A 为了知道电脑 B（192.168.0.2）的 MAC 地址，将会广播一条 arp 请求，B 收到请求后，带上自己的 MAC 地址给 A 一个响应。此时 A 便更新了自己的 arp 表。</p>
<p>这样通过大家不断广播 arp 请求，最终所有电脑里面都将 arp 缓存表更新完整。</p>
<center>总结一下</center>


<p>好了，总结一下，到目前为止就几条规则</p>
<p>从各个节点的视角来看</p>
<p>电脑视角：</p>
<ul>
<li><p>首先我要知道我的 IP 以及对方的 IP</p>
</li>
<li><p>通过子网掩码判断我们是否在同一个子网</p>
</li>
<li><p>在同一个子网就通过 arp 获取对方 mac 地址直接扔出去</p>
</li>
<li><p>不在同一个子网就通过 arp 获取默认网关的 mac 地址直接扔出去</p>
</li>
</ul>
<p>交换机视角：</p>
<ul>
<li><p>我收到的数据包必须有目标 MAC 地址</p>
</li>
<li><p>通过 MAC 地址表查映射关系</p>
</li>
<li><p>查到了就按照映射关系从我的指定端口发出去</p>
</li>
<li><p>查不到就所有端口都发出去</p>
</li>
</ul>
<p>路由器视角：</p>
<ul>
<li><p>我收到的数据包必须有目标 IP 地址</p>
</li>
<li><p>通过路由表查映射关系</p>
</li>
<li><p>查到了就按照映射关系从我的指定端口发出去（不在任何一个子网范围，走其路由器的默认网关也是查到了）</p>
</li>
<li><p>查不到则返回一个路由不可达的数据包</p>
</li>
</ul>
<p>如果你嗅觉足够敏锐，你应该可以感受到下面这句话：</p>
<p>网络层（IP协议）本身没有传输包的功能，包的实际传输是委托给数据链路层（以太网中的交换机）来实现的。</p>
<p>涉及到的三张表分别是</p>
<ul>
<li><p>交换机中有 MAC 地址表用于映射 MAC 地址和它的端口</p>
</li>
<li><p>路由器中有路由表用于映射 IP 地址(段)和它的端口</p>
</li>
<li><p>电脑和路由器中都有 arp 缓存表用于缓存 IP 和 MAC 地址的映射关系</p>
</li>
</ul>
<p>这三张表是怎么来的</p>
<ul>
<li><p>MAC 地址表是通过以太网内各节点之间不断通过交换机通信，不断完善起来的。</p>
</li>
<li><p>路由表是各种路由算法 + 人工配置逐步完善起来的。</p>
</li>
<li><p>arp 缓存表是不断通过 arp 协议的请求逐步完善起来的。</p>
</li>
</ul>
<p>知道了以上这些，目前网络上两个节点是如何发送数据包的这个过程，就完全可以解释通了！</p>
<p>那接下来我们就放上本章 最后一个 网络拓扑图吧，请做好 战斗 准备！</p>
<p><img src="/2022/06/10/uncatalog/cl48bverj000054r77iq83ab9/25.png" alt="25.png"></p>
<p>这时路由器 1 连接了路由器 2，所以其路由表有了下一条地址这一个概念，所以它的路由表就变成了这个样子。如果匹配到了有下一跳地址的一项，则需要再次匹配，找到其端口，并找到下一跳 IP 的 MAC 地址。</p>
<p>也就是说找来找去，最终必须能映射到一个端口号，然后从这个端口号把数据包发出去。</p>
<table>
<thead>
<tr>
<th align="left">目的地址</th>
<th align="left">下一跳</th>
<th align="left">端口</th>
</tr>
</thead>
<tbody><tr>
<td align="left">192.168.0.0/24</td>
<td align="left"></td>
<td align="left">0</td>
</tr>
<tr>
<td align="left">192.168.0.254/32</td>
<td align="left"></td>
<td align="left">0</td>
</tr>
<tr>
<td align="left">192.168.1.0/24</td>
<td align="left"></td>
<td align="left">1</td>
</tr>
<tr>
<td align="left">192.168.1.254/32</td>
<td align="left"></td>
<td align="left">1</td>
</tr>
<tr>
<td align="left">192.168.2.0/24</td>
<td align="left">192.168.100.5</td>
<td align="left"></td>
</tr>
<tr>
<td align="left">192.168.100.0/24</td>
<td align="left"></td>
<td align="left">2</td>
</tr>
<tr>
<td align="left">192.168.100.4/32</td>
<td align="left"></td>
<td align="left">2</td>
</tr>
</tbody></table>
<p>这时如果 A 给 F 发送一个数据包，能不能通呢？如果通的话整个过程是怎样的呢？</p>
<p><img src="/2022/06/10/uncatalog/cl48bverj000054r77iq83ab9/26.png" alt="26.png"></p>
<p>思考一分钟…</p>
<p>详细过程动画描述：</p>
<p><img src="/2022/06/10/uncatalog/cl48bverj000054r77iq83ab9/27.gif" alt="27.gif"></p>
<p>详细过程文字描述：</p>
<ol>
<li><p>首先 A（192.168.0.1）通过子网掩码（255.255.255.0）计算出自己与 F（192.168.2.2）并不在同一个子网内，于是决定发送给默认网关（192.168.0.254）</p>
</li>
<li><p>A 通过 ARP 找到 默认网关 192.168.0.254 的 MAC 地址。</p>
</li>
<li><p>A 将源 MAC 地址（AAAA）与网关 MAC 地址（ABAB）封装在数据链路层头部，又将源 IP 地址（192.168.0.1）和目的 IP 地址（192.168.2.2）（注意这里千万不要以为填写的是默认网关的 IP 地址，从始至终这个数据包的两个 IP 地址都是不变的，只有 MAC 地址在不断变化）封装在网络层头部，然后发包<br><img src="/2022/06/10/uncatalog/cl48bverj000054r77iq83ab9/28.png" alt="28.png"></p>
</li>
<li><p>交换机 1 收到数据包后，发现目标 MAC 地址是 ABAB，转发给路由器1</p>
</li>
<li><p>数据包来到了路由器 1，发现其目标 IP 地址是 192.168.2.2，查看其路由表，发现了下一跳的地址是 192.168.100.5</p>
</li>
<li><p>所以此时路由器 1 需要做两件事，第一件是再次匹配路由表，发现匹配到了端口为 2，于是将其封装到数据链路层，最后把包从 2 号口发出去。</p>
</li>
<li><p>此时路由器 2 收到了数据包，看到其目的地址是 192.168.2.2，查询其路由表，匹配到端口号为 1，准备从 1 号口把数据包送出去。</p>
</li>
<li><p>但此时路由器 2 需要知道 192.168.2.2 的 MAC 地址了，于是查看其 arp 缓存，找到其 MAC 地址为 FFFF，将其封装在数据链路层头部，并从 1 号端口把包发出去。</p>
</li>
<li><p>交换机 3 收到了数据包，发现目的 MAC 地址为 FFFF，查询其 MAC 地址表，发现应该从其 6 号端口出去，于是从 6 号端口把数据包发出去。</p>
</li>
<li><p>F 最终收到了数据包！并且发现目的 MAC 地址就是自己，于是收下了这个包<br>更详细且精准的过程：<br>读到这相信大家已经很累了，理解上述过程基本上网络层以下的部分主流程就基本疏通了，如果你想要本过程更为专业的过程描述，可以在公众号”低并发编程”后台回复”网络”，获得我模拟这个过程的 Cisco Packet Tracer 源文件。</p>
</li>
</ol>
<p><img src="/2022/06/10/uncatalog/cl48bverj000054r77iq83ab9/29.png" alt="29.png"></p>
<p>每一步包的传输都会有各层的原始数据，以及专业的过程描述</p>
<p><img src="/2022/06/10/uncatalog/cl48bverj000054r77iq83ab9/30.png" alt="30.png"></p>
<p>同时在此基础之上你也可以设计自己的网络拓扑结构，进行各种实验，来加深网络传输过程的理解。</p>
<p>后记</p>
<p>至此，经过物理层、数据链路层、网络层这前三层的协议，以及根据这些协议设计的各种网络设备（网线、集线器、交换机、路由器），理论上只要拥有对方的 IP 地址，就已经将地球上任意位置的两个节点连通了。</p>
<p><img src="/2022/06/10/uncatalog/cl48bverj000054r77iq83ab9/31.png" alt="31.png"></p>
<p>本文经过了很多次的修改，删减了不少影响主流程的内容，就是为了让读者能抓住网络传输前三层的真正核心思想。同时网络相关的知识也是多且杂，我也还有很多搞不清楚的地方，非常欢迎大家与我交流，共同进步。</p>
<p>读到这里都是真爱了，当然要赠一个投票。</p>
]]></content>
      <tags>
        <tag>云原生基础系列</tag>
        <tag>Kubernetes</tag>
        <tag>Kubernetes网络</tag>
      </tags>
  </entry>
  <entry>
    <title>kubernetes读书笔记</title>
    <url>/2022/06/10/uncatalog/cl48eey5y0000owr728gk66p6/</url>
    <content><![CDATA[<hr>
<span id="more"></span>

<hr>
<h3 id="What-is-Kubernetes"><a href="#What-is-Kubernetes" class="headerlink" title="What is Kubernetes?"></a>What is Kubernetes?</h3><p><a href="https://kubernetes.io/docs/concepts/overview/what-is-kubernetes/">官方解释</a>： </p>
<blockquote>
<p>Kubernetes is a portable, extensible, open source platform for managing containerized workloads and services, that facilitates both declarative configuration and automation. It has a large, rapidly growing ecosystem. Kubernetes services, support, and tools are widely available.<br>翻译成大白话就是：“K8S 负责自动化运维管理多个 Docker 程序的集群”。</p>
</blockquote>
<h3 id="Why-is-Kubernetes"><a href="#Why-is-Kubernetes" class="headerlink" title="Why is Kubernetes?"></a>Why is Kubernetes?</h3><p>试想下传统的后端部署办法：把程序包（包括可执行二进制文件、配置文件等）放到服务器上，接着运行启动脚本把程序跑起来，同时启动守护脚本定期检查程序运行状态、必要的话重新拉起程序。<br>有问题吗？显然有！最大的一个问题在于：<strong>如果服务的请求量上来，已部署的服务响应不过来怎么办？</strong>传统的做法往往是，如果请求量、内存、CPU 超过阈值做了告警，运维马上再加几台服务器，部署好服务之后，接入负载均衡来分担已有服务的压力。<br>问题出现了：从监控告警到部署服务，中间需要人力介入！那么，有没有办法自动完成服务的部署、更新、卸载和扩容、缩容呢？这，就是 K8S 要做的事情：自动化运维管理 Docker（容器化）程序。  </p>
<p>软件开发70年历史，软件工程发展了近50年，互联网从出现到现在的蓬勃发展二十多年。软件开发的模型从最早的瀑布模型，到敏捷开发，再到现在的DevOps理念。软件的形态从物理扎线，到打孔编程，再到大机，到微机，到网络时代的C/S、B/S、再到移动互联网时代App。架构的演变经过几十年的进化，在硬件、网络、信息的认知、用户数等都达到条件后，再才发展出了微服务，然后进而才出现了Kubernetes的框架。</p>
<p>绝大部分的人认为Kubernetes只是一个基础平台。但实际大部分人都想不明白，为什么为出现Kubernetes这样的平台。物理机不能跑微服务吗，虚拟机不能跑微服务吗？你想不明白这个问题，你就没法入门Kubernetes，遗憾的是，这一点也是绝大多数Kubernetes所没有关注到的。</p>
<p>Kubernetes的出现是大型互联网公司（Google）在非常庞大的微服务体系下，为了降低维护成本，为了提高维护效率，提高交付效率，更重要是为了服务自治不断思考和实践才开发出来的。IT行业的技术革新，总是会有先驱者为我们艰辛的躺平道路，然后我们再站在巨人的肩膀上借得更高的视野，但是现在很多人都被眼前的树叶给遮挡了，比如目前互联网浮躁的就业环境。</p>
<h3 id="正题：Kubernetes读书笔记"><a href="#正题：Kubernetes读书笔记" class="headerlink" title="正题：Kubernetes读书笔记"></a>正题：Kubernetes读书笔记</h3><h3 id="1，《Kubernetes权威指南：从Docker到Kubernetes实践全接触（第5版）》"><a href="#1，《Kubernetes权威指南：从Docker到Kubernetes实践全接触（第5版）》" class="headerlink" title="1，《Kubernetes权威指南：从Docker到Kubernetes实践全接触（第5版）》"></a>1，《Kubernetes权威指南：从Docker到Kubernetes实践全接触（第5版）》</h3><p><img src="/2022/06/10/uncatalog/cl48eey5y0000owr728gk66p6/1.jpg" alt="1.jpg"><br>这本书或者说Kubernetes,对于当时的我来说，非常的有魔力，现在回想起来，也能不禁笑出声来。<br><img src="/2022/06/10/uncatalog/cl48eey5y0000owr728gk66p6/2.png" alt="2.png"><br>非常适合小白入门，但是也仅限于入门，与其说是权威指南，不如说是入门指南。<br>里面的内容，几乎涵盖了Kubernetes运维相关的的方方面面，广度有余，而深度不足。</p>
<p>或许是因为书名起的调太高，亦或是Kubernetes涉及的知识点过于庞杂，导致内容的翔实层度以及前置知识对于小白的友好程度，并不能十分匹配<strong>权威</strong>二字。<br>虽然如此，但是我还是非常推荐选择这本书作为入门教材。<br>但是，如果想仅凭这本书就入门Kubernetes的话，你至少还需要以下前置知识：</p>
<ul>
<li>微服务架构，及微服务能解决的问题</li>
<li>对应微服务的语言生态，如JAVA、GO、Python等</li>
<li>基础的软件配置管理，如代码管理、CI/CD、版本管理</li>
<li>基础的生产维护管理，如变更管理、流程管理、监控、成本管理等</li>
<li>其它运维知识，如基础网络、中间件、运维工具等</li>
</ul>
<center> 看山是山，看水是水 </center>
如果没有足够上述前置知识，读第一遍，对所有Kubernetes涉及到概念的理解，只会停留在表面。同时，有心的读者还会配合B站上相关的X天入门k8s的教程食用，学完之后会有一种，原来Kubernetes就是这啊，已被我拿下的错觉。
<center> 看山不是山，看水不是水 </center>
读第二遍，你会发现，已经不仅仅是温故而知新了，原来你发现了很多第一遍没有关注到的知识点，当时根本没有深入的思考，于是，第二遍读完之后，你会有种Kubernetes到底是个啥的困惑，这种困惑甚至会让你对自己产生怀疑。
<center> 看山还是山，看水还是水 </center>
如果，第二遍的困惑能激发你的求知欲，带着问题去由点到面的去完成各个支线任务，那么，再回来读第三遍，你会发现:

<blockquote>
<p>Kubernetes是什么？它不是简单的master/worker，controller/apiserver/etcd/scheduler等等一些二进制及配置文件。<br>也不仅仅是pod/deployment/service/daemonset等等一些部署单元，也更不是一个简单的PAAS平台。<br>它是一个体系，包含了软件工程管理、软件开发模型和理念、项目管理、架构设计、运维管理、交付管理等等，除此之外才是一个类PAAS平台。</p>
</blockquote>
<p>原来，Kubernetes确实就像它的简介那样，直接，神奇，而又令人兴奋。</p>
<p>对于运维而言，这本书涉及到的内容，入门已经够了，然而在实际的维护过程中只能算一个操作工，必须参照手册或者由高级工程师指导才能干活。<br>除此之外，对于开发而言，还远远不够，甚至连入门都算不上。<br>正是由于以上这些原因，很多公司并没有足够的技术和人员储备，所以，对上Kubernetes显得尤为谨慎，甚至有些谈K色变。</p>
<h3 id="2，《Kubernetes网络权威指南：基础、原理与实践》"><a href="#2，《Kubernetes网络权威指南：基础、原理与实践》" class="headerlink" title="2，《Kubernetes网络权威指南：基础、原理与实践》"></a>2，《Kubernetes网络权威指南：基础、原理与实践》</h3><p><img src="/2022/06/10/uncatalog/cl48eey5y0000owr728gk66p6/3.png" alt="3.png"><br>阅读上一本书的时候，网络部分的内容几乎是一笔带过，对于网络方面比较薄弱的开发者来说，理解起来比较困难，所以就由点到面的展开，找到了这本书，恶补网络相关的内容。<br>这本书也带有<strong>权威</strong>二字，如果说上一本书<strong>权威</strong>成色不足的话，那这本书就完全是有辱<strong>权威</strong>二字了。<br>云计算的世界里，计算最基础，存储最重要，网络最复杂。对于这么复杂的一个领域，输出一本错误百出、大面积抄袭博客的书籍，实在是对读者的不负责。<br>如果你有Kubernetes网络方面的疑惑，建议你有一定的甄别能力之后，再来读这本书，只有这样，才能去糟取精。</p>
<h3 id="3，《深入剖析Kubernetes》"><a href="#3，《深入剖析Kubernetes》" class="headerlink" title="3，《深入剖析Kubernetes》"></a>3，《深入剖析Kubernetes》</h3><p><img src="/2022/06/10/uncatalog/cl48eey5y0000owr728gk66p6/5.jpg" alt="5.jpg"><br>这本书我没有读过，但是这本书的内容取自同一作者的极客时间的《深入剖析Kubernetes》课程，这个课程我是读过的，作者是张磊，2021年CNCF基金会TOC名单中国内唯一的入选者。CNCF基金会TOC名单，基本上就已经决定了这本书的含金量，<br>唯一的不足，可能是重理论而缺少实践，对于还没有入门的读者来说，非常的不友好，更适合有一定理论和开发基础的读者。</p>
<h3 id="4，《Kubernetes生产化实践之路》"><a href="#4，《Kubernetes生产化实践之路》" class="headerlink" title="4，《Kubernetes生产化实践之路》"></a>4，《Kubernetes生产化实践之路》</h3><p><img src="/2022/06/10/uncatalog/cl48eey5y0000owr728gk66p6/6.jpg" alt="6.jpeg"></p>
<p>未完，待续…</p>
]]></content>
      <tags>
        <tag>读书笔记</tag>
        <tag>云原生基础系列</tag>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes网络系列之(二)网络基本概念</title>
    <url>/2022/06/11/uncatalog/cl49mkqxy0002lwr76770ae47/</url>
    <content><![CDATA[<hr>
<span id="more"></span>



<hr>
<h3 id="电脑主机-Host"><a href="#电脑主机-Host" class="headerlink" title="电脑主机(Host)"></a>电脑主机(Host)</h3><p>一台电脑很简单，一个壳子里面堆了很多玩意。但是你买了电脑，如果没有网络，你觉得这个电脑能做什么？恐怕只能拿U盘拷点东西。如果像实验室这种电脑，连USB口都没(feng)有(diao)的，你只能呵呵。所以你买电脑肯定还需要带上其他的东西，网卡，网线。</p>
<ol>
<li>主机，也就是Host</li>
</ol>
<p><img src="/2022/06/11/uncatalog/cl49mkqxy0002lwr76770ae47/1.jpg" alt="1.jpg"></p>
<p>2.网卡（一般主板自带了）</p>
<p><img src="/2022/06/11/uncatalog/cl49mkqxy0002lwr76770ae47/2.jpg" alt="2.jpg"></p>
<p>3.网线 （别跟我说你用wifi的，掐死你，不准抬杠）</p>
<p><img src="/2022/06/11/uncatalog/cl49mkqxy0002lwr76770ae47/3.jpg" alt="3.jpg"></p>
<p>好了，三大神器基本齐了，接上网络，这才是电脑。</p>
<h3 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h3><p>接上了网络的电脑，就可以从网络上收发报文了，可以与网络中的其他电脑主机（Host）通信。</p>
<p>它就像下面这个样子：（这个模型图比较重要，后面我都会按照这个模型扩展讲解）</p>
<p><img src="/2022/06/11/uncatalog/cl49mkqxy0002lwr76770ae47/4.png" alt="4.png"><br>意思是：主机Host上面运行了程序，这个程序从网卡接收/发送报文。你就想象一个人在一个四四方方的空房子里面，其中的一面墙上有个门，门口那个快递收发员会把包裹从外面运进来。</p>
<p>（我是这么想的 -_-#，求勿鄙视）大概是这个样子：</p>
<p><img src="/2022/06/11/uncatalog/cl49mkqxy0002lwr76770ae47/5.png" alt="5.png"></p>
<p>中间那个人就是你了，你在淘X买了东西，在家里等快递，骚年。</p>
<h3 id="画网络图"><a href="#画网络图" class="headerlink" title="画网络图"></a>画网络图</h3><p>好了，在有以上的模型后，那么两台主机通信，就应该像下面这样了：</p>
<p><img src="/2022/06/11/uncatalog/cl49mkqxy0002lwr76770ae47/6.png" alt="6.png"></p>
<p>注意这根网线也是非常重要的，这个就是宿舍两个人网线直连打魔兽啊。</p>
<p>然后有一天，你突然发现，哇靠，所有的人都有电脑了，大家都想互相连起来，看起来像这样：<br><img src="/2022/06/11/uncatalog/cl49mkqxy0002lwr76770ae47/7.png" alt="7.png"></p>
<p>是的，看起来像这样，实际是做不到的，因为我们找不到长这么奇怪的网线啊！</p>
<p>怎么办？怎么把大家的网线都接一起呢？ 是剪开，一股一股的线拆开拧一起么（跟电线一样）</p>
<p><img src="/2022/06/11/uncatalog/cl49mkqxy0002lwr76770ae47/8.jpg" alt="8.jpg"></p>
<p>这个虽然可行，但是比较麻烦，简单的方式就是买个集线器Hub，大家的网线都插在同一个Hub上就行了。也可以买个路由器（相当于高级Hub）。不过Hub比较便宜啦，相当于接线板，技术含量不高。</p>
<p><img src="/2022/06/11/uncatalog/cl49mkqxy0002lwr76770ae47/9.jpg" alt="9.jpg"></p>
<p>插上，搞定所有的主机互联。注意这里的所有，是指你们宿舍以及隔壁宿舍，不是整个学校。<br><img src="/2022/06/11/uncatalog/cl49mkqxy0002lwr76770ae47/10.png" alt="10.png"></p>
<h3 id="新的挑战"><a href="#新的挑战" class="headerlink" title="新的挑战"></a>新的挑战</h3><p>当很多电脑主机Host连在一起的时候，新的问题出来了。主机Host1，想要与主机Host3通信的时候，怎么保证报文（包裹）是给Host3，而不是给Host2的呢？因为大家都连（住）在一起。</p>
<p>这个很简单嘛，给每台电脑主机设置一个地址，类似门牌号，快递包裹按照地址送货就到了收货方了。这个主机Host地址，说人话就是叫做：IP地址。 快递员送包裹时查看门牌号，就好比路由。</p>
<p>话说这个住在你家门口的这个快递收发员也有个名字，叫做Linux网络协议栈。</p>
<p>由于连在一起的电脑越来越多，整个学校的成百上千台的电脑，送快递时查找地址越来越困难，于是就有了路由咋走的问题。这个我们下节再讲 :-)</p>
]]></content>
      <tags>
        <tag>云原生基础系列</tag>
        <tag>Kubernetes网络</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes网络系列之(三)IP和掩码</title>
    <url>/2022/06/11/uncatalog/cl49muw310005lwr7dukkfz6m/</url>
    <content><![CDATA[<hr>
<span id="more"></span>



<hr>
<h3 id="主机的门牌号（IP地址）"><a href="#主机的门牌号（IP地址）" class="headerlink" title="主机的门牌号（IP地址）"></a>主机的门牌号（IP地址）</h3><p>当接入到网络里面的主机数量越来越多，每台主机都需要的门牌号（IP地址）数量就越来越多，这就会涉及到IP地址的管理问题。一开始大家觉得门牌号不用太多，32位就差不多够用了（事实证明完全不够）。</p>
<p>所以IP地址大概长这样：</p>
<p>192.168.1.1 （对战局域网1-01号主机），192.168.1.2 （对战局域网1-02号主机）。</p>
<p>这种小的网络呢，不用搞太大，大家约定前面三个地址都一样，仅最后一个数字不一样就行了。可以看出这个局域网最多可以接入255太主机，再多就没有IP（门牌）地址分配了。即前三位地址不变时（1幢-1楼-01班级，类似这个不能变），最多允许255台主机连接。</p>
<p>如果其他电脑还想接入网络呢？那么使用：</p>
<p>192.168.2.1 （对战局域网2-01号主机），192.168.2.2 （对战局域网2-02号主机）。</p>
<p>可以看出来 1幢-1楼-02班级 也有255台主机可以连在一起。</p>
<h3 id="掩码Mask"><a href="#掩码Mask" class="headerlink" title="掩码Mask"></a>掩码Mask</h3><p>为了更好的表达一个局域网有多少台机器， 我们举个例子：用帮派大小来描述帮派中有多少个成员。</p>
<p>现在有个帮派：华东帮.杭州分舵.滨江大队.唐疙瘩弄 ， 恩，一看这个名字就知道很小的喽喽团体，成员没几个。</p>
<p>再看上一级帮派：华南帮.深圳分舵 。 哇，感觉是个大帮派，成员很多的样子。</p>
<p>所以一个团体的大小，直接看名号的长短就知道。名号越短，帮派越大。</p>
<p>这个名号就是相当于掩码的作用了，掩码越小，这个局域网就越大。</p>
<p>下图可以看出IP地址的分配，根据前面多少位地址不动，可以大概有这种分类方法：</p>
<p><img src="/2022/06/11/uncatalog/cl49muw310005lwr7dukkfz6m/1.jpg" alt="1.jpg"></p>
<p>A类地址，B类地址，C类地址。其实就是前面有几位地址不动的意思。“前面几位地址不动”这个名字太长了不好记，取个好听的名吧，掩码（Mask），立马高大上了。</p>
<p>再看上图中的C类地址，掩码是多少啊？数一数是3*8=24位。所以 255.255.255.0 也就是 3个8bit是全1=24位的掩码。掩码使用 /数字 表示，例如 /24。</p>
<p>C类地址的帮派名号算是比较长的，是24位的名号，内部成员有限，才255人。那肯定是没有人家16为的名号（掩码）的势力范围大啦。</p>
<h3 id="网络Network"><a href="#网络Network" class="headerlink" title="网络Network"></a>网络Network</h3><p>经过上面的解释，那么01班级的网络就是：192.168.1.0/24。 而02班级的网络就是：192.168.2.0/24。明显的是两个帮派。</p>
<p>其实：IP地址 “与”上 掩码，就是自己所在的网络了。例如：</p>
<p>192.168.1.2 &amp; 255.255.255.0 = 192.168.1.0/24 意思是保留前24位，后面的都抹零。</p>
<p>而掩码大家一般都设置为8，16，24，因为比较好记，你要是设置一个掩码17，后面抹零，你一下子都算不出来数字是多少。</p>
<p>还有一个重要的提示：一旦你知道了掩码的大小，你自己的局域网的大小就知道了。例如掩码24，那么你所在的网络最多能连接255台主机。再多主机只能接到其他班级的网络里。</p>
<h3 id="网络互连"><a href="#网络互连" class="headerlink" title="网络互连"></a>网络互连</h3><p>终于有一天，两大班级不甘于内战，希望班级之间互相切磋下！那得想办法把两个网络给连起来啊。于是找一台土豪主机Host，这个Host有两块网卡，一块通过网线接入网络01，另一块通过网线接入网络02，这样这台主机就有两个IP地址啦，一个是192.168.1.1，还有一个是192.168.2.1，搞定。</p>
<p><img src="/2022/06/11/uncatalog/cl49muw310005lwr7dukkfz6m/2.png" alt="2.png"></p>
<p>于是这台特殊的主机Host-S，它一般不能停机，不然隔壁寝室就有人怒吼，渐渐的这台机子就当做专用机一直开着了。 至于这台机器的配置嘛，网卡牛逼一点喽，操作系统么简单点，能收发报文啥的就行了，搞着搞着这台主机就有了自己特别的名字：路由器。</p>
<p>路由器也是一台电脑，功能比较单一的电脑（不过现在的路由器功能也越来越牛逼了，摆明就是一台比较牛逼的电脑了）。</p>
<p>路由器负责连接两个不同的网络。</p>
<p><img src="/2022/06/11/uncatalog/cl49muw310005lwr7dukkfz6m/3.jpg" alt="3.jpg"></p>
<h3 id="网关"><a href="#网关" class="headerlink" title="网关"></a>网关</h3><p>现在所有01网络的主机Host只要发送报文到02网络的主机Host上去，报文就必须通过这个路由器主机，我们就把这个路由器的地址，叫做网关。所有01网络里面的主机，都把网关地址设置为这台路由器地址。</p>
<p>所以网关有两层含义：</p>
<p>1.对当前主机来说，这是一个特殊的地址，特定的报文都发到这个地址，由它帮忙中转一下。</p>
<p>2.本身来说，可以是一个特殊的设备，例如路由器。</p>
<p>网络模型基本出来了，下一节继续讲路由 :-)</p>
]]></content>
      <tags>
        <tag>云原生基础系列</tag>
        <tag>Kubernetes网络</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes网络系列之(四)router路咋走啊</title>
    <url>/2022/06/11/uncatalog/cl49n9zab0008lwr79y835duy/</url>
    <content><![CDATA[<hr>
<span id="more"></span>



<hr>
<blockquote>
<p>好了，到这里至少你应该能看懂路由表信息了。给你一个目的IP，你也应该知道它会使用哪一条路由了。 路怎么走就看骚年你了~</p>
</blockquote>
<h3 id="路由"><a href="#路由" class="headerlink" title="路由"></a>路由</h3><p>其实关于网络大家遇到最多的问题就是：卧 槽，为什么不通啊！</p>
<p>比这个运气好一点的：卧 槽，过去通，回来不通啊！</p>
<p>不慌，看完这一章节，这种问题下次碰到基本自己就能搞定。首先我们希望两台机子能通，那你得知道通是怎么通的，也就是通的时候，路是怎么走的。</p>
<p>大多数情况你（这里的你是指你的报文）走过去的路，跟走回来的路是一样的。</p>
<p>少数情况下，你走大路过去，然后绕小路回来。这个都不影响找路的原理。</p>
<p>举个栗子：当你在杭州，想去黑龙江，应该往北走。一般情况你不会从深圳绕一把。万一线路中断，你从西安绕一下也行。</p>
<p>整体而言：具体报文怎么走，就是路由的问题了。</p>
<h3 id="路由表"><a href="#路由表" class="headerlink" title="路由表"></a>路由表</h3><p>如果有你想要懂网络，这张表是一定要看懂的。</p>
<p>找台Linux主机，输入#route -n</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">Kernel IP routing table</span><br><span class="line">Destination     Gateway    Genmask      Flags  Metric  Ref  Use Iface</span><br><span class="line">0.0.0.0      10.120.174.1  0.0.0.0       UG     0   0   0  eth0</span><br><span class="line">10.120.174.0    0.0.0.0    255.255.254.0    U     0   0   0  eth0</span><br><span class="line">172.17.0.0     0.0.0.0    255.255.0.0     U     0   0   0  docker0</span><br></pre></td></tr></table></figure></div>

<p>注意，这里的-n参数不是必须的，但是建议带上，其他很多网络相关的命令，也都建议带-n参数。</p>
<p>（原因：route命令，默认会把IP地址翻译为hostname，但是IP-&gt;Hostname这个动作，就会去查DNS，有时候DNS配置的不好，例如查不通，那么route命令就会感觉卡住了一样。）</p>
<p>这个表的第一行：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">Destination        Gateway         Genmask    Flags    Metric    Ref     Use    Iface</span><br></pre></td></tr></table></figure></div>

<p>红色部分是基础，含义分别为：</p>
<table>
<thead>
<tr>
<th align="left">Destination</th>
<th align="left">Gateway</th>
<th align="left">Genmask</th>
<th align="left">Iface</th>
</tr>
</thead>
<tbody><tr>
<td align="left">目的IP</td>
<td align="left">网关</td>
<td align="left">掩码</td>
<td align="left">网卡</td>
</tr>
<tr>
<td align="left">目的地</td>
<td align="left">中转站</td>
<td align="left">目的地范围</td>
<td align="left">哪个门出发</td>
</tr>
</tbody></table>
<p>先看中间一条路由记录</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">目的地     中转站     目的地范围，   哪个门出发</span><br><span class="line">10.120.174.0    0.0.0.0         255.255.254.0     eth0</span><br></pre></td></tr></table></figure></div>
<p>首先，目的地址是 10.120.174.0，范围是 255.255.254.0</p>
<p>根据上节的掩码原理，我们知道掩码是23位的，也就是只有前面23不动，只有最后9位可以动。</p>
<p>两者一结合（与），就知道了网络目的范围：<br><img src="/2022/06/11/uncatalog/cl49n9zab0008lwr79y835duy/1.png" alt="image"></p>
<p>（图：目的地址）</p>
<p><img src="/2022/06/11/uncatalog/cl49n9zab0008lwr79y835duy/2.png" alt="image"></p>
<p>（图：目的地范围）</p>
<p>两者结合的范围为：10.120.174.0（可变部分全为0）~ 10.120.175.255（可变部分全为1），总共512个目的地址（IP）。</p>
<p>也就是所有这些目的IP地址在这个范围内的，在选择路由时，都匹配这条路由记录。</p>
<p>那这条记录是这么说的：当匹配到这条记录时，中转站不需要（gateway为0），只管把报文往eth0这个门扔出去就行了（Iface为eth0）。</p>
<p>这是什么意思呢？就是这个IP范围的大家都在一个小的局域网络里面，你喊一声，大家都能知道，不需要中转。</p>
<p><img src="/2022/06/11/uncatalog/cl49n9zab0008lwr79y835duy/3.png" alt="image"></p>
<p>再看最后一条路由记录</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">目的地     中转站     目的地范围，   哪个门出发</span><br><span class="line">172.17.0.0   0.0.0.0    255.255.0.0    docker0</span><br></pre></td></tr></table></figure></div>
<p>这条记录跟上面一条基本一样含义，目的地址 &amp; 目的地范围，结合后得出：</p>
<p>目标地址为 172.17.0.0~172.17.255.255的报文只管往网卡docker0上面扔就是了。</p>
<p><img src="/2022/06/11/uncatalog/cl49n9zab0008lwr79y835duy/4.png" alt="image"></p>
<p>最后看第一条路由记录</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">目的地     中转站     目的地范围，   哪个门出发</span><br><span class="line">0.0.0.0         10.120.174.1    0.0.0.0           eth0</span><br></pre></td></tr></table></figure></div>
<p>这里目的地址为0，表示default默认路由，意思是：当你的目的地址实在是找不到其他能够匹配的路由记录时，就用这一条吧。</p>
<p>而这一条默认的规则的意思是：往eth0网卡丢，先送到中转站 10.120.174.1。 后面的事情你不用管了（意思是让中转站去解决后面的路由）</p>
<p>比如我想要：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">ping 10.184.43.7</span><br></pre></td></tr></table></figure></div>

<p>的时侯，这个目的IP，明显即不符合中间那条记录的范围，也不符合最后一条记录的范围。怎么只能使用这一条默认记录了。</p>
<p>再来细看这条默认路由记录：</p>
<p>这条记录说：当匹配到这条记录时，中转站要设置为10.120.174.1，并且报文要往eth0这个门扔出去（Iface为eth0）。</p>
<p>这里隐含的表示了，中转站你必须能到达，否则网络会不通。</p>
<p><em><strong>报文如何导到中转站</strong></em></p>
<p>好了，那我们来看看报文是怎么与中转站通的。 这里中转站IP为10.120.174.1，要想把报文送到这里去，我们应该怎么走？</p>
<p>咦，又是路怎么走的问题，这不是上面刚学的嘛。</p>
<p>来，跟我一起匹配，第三条行不行？不行。</p>
<p>第二条行不行，行！</p>
<p>刚好是第二条路由记录的范围（10.120.174.0~10.120.175.255），那就用第二条路由指定的方式发送（报文从eth0扔出去就行了）。</p>
<p>很明显的是在递归查找路由表。同时，这也说明中转站就在同一个局域网内嘛。</p>
<p>即报文送到网关，也是要查找路由表的。</p>
<h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><p>通过把所有的路由表都匹配一遍，你会发现，任意的目的IP，都能匹配到路由表中的一条（因为你有一个default规则）。</p>
<p>匹配的过程你就当做是“人工”一个一个的查。如果你连路怎么走都没有设置好，网络又怎么能通呢？</p>
<h3 id="本机IP地址对路由的影响"><a href="#本机IP地址对路由的影响" class="headerlink" title="本机IP地址对路由的影响"></a>本机IP地址对路由的影响</h3><p>先看一下本机的IP信息：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> ifconfig</span></span><br><span class="line">docker0   Link encap:Ethernet  HWaddr 02:42:e6:07:93:34  </span><br><span class="line">inet addr:172.17.0.1  Bcast:0.0.0.0  Mask:255.255.0.0</span><br><span class="line">eth0     Link encap:Ethernet  HWaddr 28:6e:d4:88:f8:64  </span><br><span class="line">inet addr:10.120.175.166  Bcast:10.120.175.255  Mask:255.255.254.0</span><br><span class="line">lo      Link encap:Local Loopback  </span><br><span class="line">inet addr:127.0.0.1  Mask:255.0.0.0</span><br></pre></td></tr></table></figure></div>


<p>你会发现，每个网卡如果有IP，就会在路由表里面增加一条路由记录。比如你把一个网卡down掉，再看route表，就会发现少了一条路由记录。再次up这个网卡的时候，路由记录又回来了。</p>
<p>并且，这条路由的Destination（目的地范围）和你设置的这个IP的掩码是一致的。例如这里，我本机ip为10.120.175.166，掩码为255.255.254.0。所以路由就是IP&amp;掩码=10.120.174.0。</p>
<p>为什么？这个不是很明显么，你新加了一个网卡，插上了网线，还拿到了新IP，说明你这个网卡接入了一个新的局域网啊，你当然多了一条新的路可以走了。</p>
<h3 id="包含问题"><a href="#包含问题" class="headerlink" title="包含问题"></a>包含问题</h3><p>当两条路由记录互相包含时怎么办？</p>
<p>比如：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">172.0.0.0       0.0.0.0         255.0.0.0      U     0      0        0 eth0</span><br><span class="line">172.17.0.0      0.0.0.0         255.255.0.0     U     0      0        0 docker0</span><br></pre></td></tr></table></figure></div>

<p>这个时候，如果想要</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">ping 172.17.0.2</span><br></pre></td></tr></table></figure></div>

<p>是用哪条路由记录呢？</p>
<p>首先，如果你之前的课有认真学习，那么你会知道，这里不同的掩码，就代表了不同的网络。这时脑海中应该会展现两条不同的路。选哪条路，当然是选择最匹配的那一条了 :-)</p>
<p>（例如default记录，其实任意目的IP都能匹配，但它不是最精准匹配的）</p>
<p>其次，如果出现这种情况，说明你的网络规格有待改进，虽然这不会出问题，但是由于会影响人的理解，所以建议不要这样子设置。</p>
<p>除非你非常明确地故意这么规划，例如flannel的网络设置：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">root@k8s-node1:~# route -n</span><br><span class="line">Destination   Gateway    Genmask     Flags Metric Ref  Use   Iface</span><br><span class="line">10.1.0.0    0.0.0.0   255.255.0.0    U    0    0   0   flannel0  // 跨节点容器的包</span><br><span class="line">10.1.15.0    0.0.0.0   255.255.255.0   U    0    0   0   docker0   // 本节点容器的包</span><br></pre></td></tr></table></figure></div>


<p>为了将所有的容器（容器也可以看作一个独立的主机，后面章节会介绍）连在一起，首先把所有主机上面的容器作为大的网络一部分，然后每台互相独立的主机里面的容器又单独划分小的网络。且任意两个单独的小子网不重复。</p>
<p>注意站在本机的角度看来，这是两个独立网络，只是在管理员视角看大家在一个大的网络内。</p>
<p><img src="/2022/06/11/uncatalog/cl49n9zab0008lwr79y835duy/5.png" alt="image"></p>
<p>主机对待报文，是作完全独立的判断：是本机的 or 不是本机的。</p>
<p>所以发给容器的报文，都符合：不是本机的。 那么就要开始匹配路由表啦。匹配过程见上面的课程。</p>
<p>好了，到这里至少你应该能看懂路由表信息了。给你一个目的IP，你也应该知道它会使用哪一条路由了。</p>
<p>路怎么走就看骚年你了~</p>
]]></content>
      <tags>
        <tag>云原生基础系列</tag>
        <tag>Kubernetes网络</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes网络系列之(五)Ping报文</title>
    <url>/2022/06/11/uncatalog/cl49np026000blwr7c4y2ebgu/</url>
    <content><![CDATA[<hr>
<span id="more"></span>



<hr>
<blockquote>
<p>这一章节你的角色是国王，你要派一个小兵去对方打探一下。是站在你的角度看这个小兵。哦，对了，这个小兵的名字叫“喂”</p>
</blockquote>
<h3 id="Ping命令介绍"><a href="#Ping命令介绍" class="headerlink" title="Ping命令介绍"></a>Ping命令介绍</h3><p>ping就是用来检测一下网络能不能跟对方互通，类似：“大哥，在么？”，“哥在。”，于是你就安心了。为啥你就安心了呢，因为你害怕孤单（汗，其实因为网络不通你啥也玩不了）。</p>
<p>上一节你都学会了路怎么走，咱走一个呗？走一个就是派个小兵帮你走一趟，这个小兵名字叫“喂”。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">ping 10.184.43.7</span><br></pre></td></tr></table></figure></div>


<p>这个时候，就从本机发出一个报文“喂”，从哪个网卡发出，走到哪个中转站，都在路怎么走章节说过。</p>
<p>小兵派出后，有好几种命运等着他：</p>
<ol>
<li><p>没有路到达对方，小兵失败而归。相对来说，这种小兵还是很幸福了。</p>
</li>
<li><p>悲催一点，他半路找不着对方，迷路（失）了。</p>
</li>
<li><p>最惨的情况，路上设置了机关，他在半路被杀了。</p>
</li>
<li><p>好一点的，他到达了对方，但是对方派出的使者却没能到你这。</p>
</li>
<li><p>完美，他成功到达对方，对方的回访使者也回来到你这里了。</p>
</li>
</ol>
<p><img src="/2022/06/11/uncatalog/cl49np026000blwr7c4y2ebgu/1.png" alt="image"></p>
<p>其中第二种情况，其实就是对方的“喂”使者出现了3或者4的情况。所以这里大概就三种情况：</p>
<ol>
<li><p>成功</p>
</li>
<li><p>没反应</p>
</li>
<li><p>很明确的不通</p>
</li>
</ol>
<p>1.成功<br>ping报文是ICMP协议中的一种 （就好比TCP协议中的syn，syn报文只是TCP协议中的一种）。</p>
<p>而ICMP协议是与TCP同级的，也就是在IP协议之上的。</p>
<p>ICMP / TCP / UDP 这三个小伙伴，你都熟了以后，一般网络问题都不是问题。</p>
<p><img src="/2022/06/11/uncatalog/cl49np026000blwr7c4y2ebgu/2.png" alt="image"></p>
<p>Mac层 -&gt; IP层 -&gt; 三兄 弟</p>
<ol start="2">
<li>没反应<br>当你ping对方的时候，一直么有反应，卡住了一样：<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">ping 10.184.149.249</span><br><span class="line"></span><br><span class="line">PING 10.184.149.249 (10.184.149.249) 56(84) bytes of data.</span><br><span class="line"></span><br><span class="line">^C</span><br><span class="line"></span><br><span class="line">--- 10.184.149.249  ping statistics ---</span><br></pre></td></tr></table></figure></div></li>
</ol>
<p>107 packets transmitted, 0 received, 100% packet loss, time 106545ms</p>
<p>直到按了 Ctrl + C 才告诉你ping不通（或者直接报 Time Out），现象就是包全部都丢了。</p>
<p>大概意思就是：你这个国王，派出小兵后，一直鸟无音讯，你望眼欲穿啊。。特别令你难过的是，你都派出一堆小兵了啊 T_T~</p>
<p>这种情况就是大家经常遇到的为ping不通的问题，特别是云计算平台里面。基本问题你大概也猜到了，要么你的小兵没能到对方，要么就是对方是回访使者没能回到你这里。那什么情况会导致你的小兵不知道跑哪里去了呢？这种问题，从本机视角是很难发现为什么不通的，也很难知道你的小兵到底跑到哪里被 干掉了，毕竟本机和目的之间可能有很多的中转站。</p>
<p>怎么定位呢？其实也很简单，那就是开启上帝模式，从全局角度去看看小兵到哪里了。直接派上帝（这里就是你自己了）去对方目的地盯着（抓包），看看“喂”报文有没有过来。</p>
<p>有两种情况，分别讨论：</p>
<ol>
<li><p>目的地没有收到“喂”报文</p>
</li>
<li><p>目的地收到了“喂”报文</p>
</li>
</ol>
<p>2.1 没有收到“喂”报文<br>如果目的地没有收到ICMP报文，但是有收到ARP请求（“喂”使者的探路哨兵，ARP章节会介绍），那说明网络连接是好的，只是ICMP不通，八成就是网络安全组把ICMP报文给ban了。</p>
<p>如果目的地很安静，什么都没有收到。那么咱们只能把上帝再往前移一移了，放到中途的中转站看看咱们的这个“喂”使者有没有到达中转站。找出最后能到达的中转站，然后再从这一站开始重新ping目的地。</p>
<p>2.2 有收到“喂”报文<br>如果收到了ICMP报文，那么说明来的路是通的，只是回去受阻。那你就反过来从目的地开始ping一下对方嘛，这个不就是回到了上面提到的定位方法了么。</p>
<p>有人会问，有没有可能A-&gt;ping-&gt;B的时候，B能收到报文，但是响应回不来。反过来从B-&gt;ping-&gt;A，就是通的。或者B-&gt;ping-&gt;A的时候，同样是报文也能到A，但是响应回不到B。</p>
<p>当然有这种情况了，而且经常遇到，A可以ping通B，B却ping不通A。这种情况一般都是网络安全组的设置导致的。（特别在云计算平台中）安全组大都涉及iptables的规则。所以这里就得分析iptable表对报文的丢包统计，把导致阻塞的那条安全组规则放通就可以了。iptables介绍见后续对应章节。</p>
<ol start="3">
<li>目标不可达<br>ping目标的时候，直接结果就是不可达。<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> ping 172.17.10.1</span></span><br><span class="line"></span><br><span class="line">PING 172.17.10.1 (172.17.10.1) 56(84) bytes of data.</span><br><span class="line"></span><br><span class="line">From 10.120.175.166 icmp_seq=1 Destination Host Unreachable</span><br><span class="line"></span><br><span class="line">From 10.120.175.166 icmp_seq=2 Destination Host Unreachable</span><br></pre></td></tr></table></figure></div></li>
</ol>
<p>这个也容易遇到，但其实非常容易解决。这个错误原因就是路由不通，要么是本机路由不通，要么就是中转站的路由不通。</p>
<p>大概意思就是：你这个国王，派出小兵后，虽然期待的对方使者没出现。好歹你的小兵回来了，然后跟你一把眼泪一把鼻涕哭诉：已经走了很多的路，战胜了多少的艰难险阻，但是没能完成出使任务有多么的惭愧。然后求你这个表面上是国王，实际上只是程序猿的家伙去定位一下。</p>
<p>好歹，你大概知道在哪个位置开始不通：</p>
<p>如果是本机直接路由不通，那消息就是：”Destination Host Unreachable,”</p>
<p>如果是中转站路由不通，那消息是：”Reply From &lt; IP address &gt;: Destination Host Unreachable,”</p>
<p>你直接到中转站去ping目的地，中转站就是上面的<IP address>，然后看看为什么路由不通。该中转站后面可能还有很多的中转站，你这个上帝要辛苦一下，把一路上不通的中转站都找出来，加上合理的路由。</IP></p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>ping不通？先看路由！路由肯定没问题，那就是安全组搞怪喽！</p>
<p>怎么定位？开启上帝模式，到处抓包判断“喂”到哪里了~</p>
]]></content>
      <tags>
        <tag>云原生基础系列</tag>
        <tag>Kubernetes网络</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes网络系列之(六)ARP你在哪</title>
    <url>/2022/06/11/uncatalog/cl49nvljx000elwr7fha73lvv/</url>
    <content><![CDATA[<hr>
<span id="more"></span>



<hr>
<blockquote>
<p>这一章节你的角色就是ping报文这个“使者”，你要去往目的地，然后回到本机。然而目的地路漫漫，不知道要经过多少个小地盘(局域网)，没两把刷子也不好行走江湖。所以你作为使者，每到达一个新的地盘，就把ARP这把刷子拿出来吼一吼。这一节就是讲的这把刷子的威力。</p>
</blockquote>
<h3 id="ARP命令介绍"><a href="#ARP命令介绍" class="headerlink" title="ARP命令介绍"></a>ARP命令介绍</h3><p>首先，ARP作为高攻击神器，是片攻击的，一定范围内全杀，而不是单点指向的技能。其攻击范围就是子网的大小，同一个子网内的所有主机都会收到ARP神器的伤害。正因为ARP报文是广播的，所以它是ping使者随身携带、开山问路的不二之刷。</p>
<p>其次，ARP神器基本靠一招走遍天下，发动攻击前吼一句：“谁是小明，请吱一声”，然后声波传遍当前子网各个角落。其中真实的小明乖乖回答：“我在这”。</p>
<p><img src="/2022/06/11/uncatalog/cl49nvljx000elwr7fha73lvv/1.png" alt="image"></p>
<h3 id="Ping报文与ARP结合"><a href="#Ping报文与ARP结合" class="headerlink" title="Ping报文与ARP结合"></a>Ping报文与ARP结合</h3><p>当Ping报文拥有了ARP这个探路神器后，想要到达最终的目的地就相当的easy了。当他处于一个站点，面对一个新的地盘的时候，先吼一声ARP大招，就知道一下站出口在哪里了。然后直接跳到下一站，接着再吼一声ARP找出下一站位置，继续跳到下一站。这样重复N次就到达了最终目的地。</p>
<p><img src="/2022/06/11/uncatalog/cl49nvljx000elwr7fha73lvv/2.png" alt="image"></p>
<p>基于上面的逻辑可以看到，在定位网络不通的时候，使用上一节的方法还找不出原因的情况下，可以看看arp报文有没有到。但是请记住，arp是一段子网一段子网定位的。</p>
<p>ps：一般网络安全组是不会禁止arp协议的，因为它本身是为了查询mac地址，而mac地址是二层的，是网络通信的基础。</p>
<h3 id="ARP报文"><a href="#ARP报文" class="headerlink" title="ARP报文"></a>ARP报文</h3><p>抓个arp报文举例：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">tcpdump -i eth1 -n arp</span></span><br><span class="line"></span><br><span class="line">arp who-has 10.175.10.210 tell 10.175.10.78</span><br><span class="line"></span><br><span class="line">arp reply 10.175.10.210 is-at fa:16:3e:bf:1e:e2</span><br></pre></td></tr></table></figure></div>

<p>这里基本可以看出来，ARP要做的事情就是把IP翻译为MAC地址。实际上在以太网中，同一个局域网中的两台主机要进行通信，必须要知道目标主机的MAC地址。而TCP/IP协议中，网络传输只关心IP地址。所以需要有一种方法将IP地址“翻译”为MAC地址。这也就是ARP要做的事情了。</p>
<h3 id="ARP表"><a href="#ARP表" class="headerlink" title="ARP表"></a>ARP表</h3><p>既然已经知道了IP与MAC的对应关系，为了避免每次找路都得“翻译”一次，那就把它记下来。以后要用的时候直接查本地的对应表就行了。同时为了保证有效性，缓存的记录会在一定时间后失效。这就是ARP表。</p>
<p>当然，也可以设置静态ARP表。只是一般我们懒得这么做。</p>
<p>通过以下命令可以查询当前缓存的arp表：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">arp -a</span></span><br></pre></td></tr></table></figure></div>

<p>ps：定位问题一般不会用到arp表，只需要在目的端抓包看看arp报文有没有到达即可。</p>
]]></content>
      <tags>
        <tag>云原生基础系列</tag>
        <tag>Kubernetes网络</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes网络系列之(七)Tcpdump大杀器抓包</title>
    <url>/2022/06/11/uncatalog/cl49qvoa2000hlwr7bjyn3m3x/</url>
    <content><![CDATA[<hr>
<span id="more"></span>



<hr>
<blockquote>
<p>前面章节的网络协议栈相关的信息建议大家多学习一遍，因为这些都是最基础的东西，想玩好云网络必备基本功。。</p>
</blockquote>
<h3 id="上帝视角"><a href="#上帝视角" class="headerlink" title="上帝视角"></a>上帝视角</h3><p>之前提到过定位问题可以开启上帝视角，那么如何开启就要依靠tcpdump这个工具了。这个工具可以实时看到一台主机的网卡上面的收到或者发送出去的报文信息。简单的说就是抓包。</p>
<p>我们对网卡进行抓包的时候，会使得网卡进入“混杂模式”，所谓混杂模式就是让网卡接收所有到达网卡的报文，因为默认情况下，不是给自己的报文网卡是不要的，要么丢弃要么转发，反正不读取内容，而进入混杂模式后，就可以看一眼报文内容了。</p>
<p><img src="/2022/06/11/uncatalog/cl49qvoa2000hlwr7bjyn3m3x/1.png" alt="image"></p>
<p>使用tcpdump命令可以使网卡自动进入混杂模式，这一点可以从dmesg系统日志中看到：</p>
<p>[311135.760098] device eth0 entered promiscuous mode<br>[311142.852087] device eth0 left promiscuous mode</p>
<p>二、tcpdump命令</p>
<p>由于tcpdump是把经过网卡的报文全部都抓出来，所以数量是非常大的，各种乱七八糟的报文都有，是没办法定位问题的，所以tcpdump一定要配合过滤条件使用。这里只讲平时用得到的几个关键参数，再详细的自己谷歌百度，反正我一般情况下用用是够了的。</p>
<ol>
<li>-n 参数</li>
</ol>
<p>这个我一般都会加上，以前的文章中提过，-n表示不要做DNS翻译，直接显示IP，不要显示为host name。（影响性能，有时候按个ctr+c都停不下来）</p>
<p>用法：tcpdump -n</p>
<ol start="2">
<li>-i 参数</li>
</ol>
<p>-i 参数用于指定需要抓包的网卡，一般都会带上。</p>
<p>用法： tcpdump -n -i eth0</p>
<ol start="3">
<li>指定协议</li>
</ol>
<p>指定协议抓包比较简单，直接要求tcpdump只抓取指定协议的报文。可以指定的协议一般有：arp / icmp / tcp</p>
<p>用法：tcpdump -n -i eth0 arp</p>
<ol start="4">
<li>host 关键字</li>
</ol>
<p>host关键字用来指定只抓取对应IP的报文，表示源地址，或者目的地址。语法为 host+空格+IP地址。</p>
<p>（ps：可以用src或者dst代替host关键字，只抓单边的报文）</p>
<p>用法：tcpdump -n -i eth0 host 10.120.175.167</p>
<ol start="5">
<li>port 关键字</li>
</ol>
<p>port关键字用来指定只抓取对应Port端口的报文，表示源端口，或者目的端口。语法为 port+空格+端口号</p>
<p>用法：tcpdump -n -i eth0 port 53</p>
<ol start="6">
<li>条件组合 and / or</li>
</ol>
<p>如果只指定一个条件进行抓包，有时候抓到的报文数量还是太多，那就需要进行多个条件组合。条件之间通过and连接。</p>
<p>用法：tcpdump -n -i docker0 tcp and host 172.17.0.1 and port 3306</p>
<ol start="7">
<li>-w 写入文件</li>
</ol>
<p>-w 表示将抓到的报文信息写入到指定的pcap文件。然后把pcap文件拷贝到自己电脑上面用Wireshark软件打开分析详情。这里不得不说一下，Wireshark也是一个神器。</p>
<p>用法：tcpdump -n -i docker0 tcp and host 172.17.0.1 and port 3306 -w mypkg.pcap</p>
<ol start="8">
<li>其他条件</li>
</ol>
<p>骚年，上面这几个记住了，行走江湖应该不成问题了。其他高深的语法，需要的时候再google/baidu也不迟。</p>
]]></content>
      <tags>
        <tag>云原生基础系列</tag>
        <tag>Kubernetes网络</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes网络系列之(八)iptables-filter过滤功能</title>
    <url>/2022/06/11/uncatalog/cl49qytpu000klwr7el00gnwf/</url>
    <content><![CDATA[<hr>
<span id="more"></span>



<hr>
<blockquote>
<p>前面的各种协议已经可以把基本可用的物理网络世界给形成了，在正常情况下，它可以玩的很溜。比如组个局域网办公，或者打个联机魔兽争霸，都没有什么问题。</p>
</blockquote>
<h3 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h3><p>前面的各种协议已经可以把基本可用的物理网络世界给形成了，在正常情况下，它可以玩的很溜。比如组个局域网办公，或者打个联机魔兽争霸，都没有什么问题。</p>
<p>可是，网络世界中总是会有邪 恶的“人”出现，它就不按照大家约定好的规则来发送报文。比如扫描整个网络中的开放端口，扒取各种可能的网页/网络信息，发送大量报文进行冲击。仅仅依靠单纯而美好的协议世界无法阻止这种不按约定而来的行为。</p>
<p>还记得我们最开始的网络概念么？</p>
<p><img src="/2022/06/11/uncatalog/cl49qytpu000klwr7el00gnwf/1.png" alt="image"></p>
<p>理想单纯而美好，可是“邪 恶”的报文如入无人之境。无奈诚实的人为了对付恶势力也得武装自己，在大门的入口装起了大量的机关，用来抵抗那些非法的坏报文。</p>
<p><img src="/2022/06/11/uncatalog/cl49qytpu000klwr7el00gnwf/2.png" alt="image"></p>
<p>看上去这是一种不错的方式，守住大门总能防住无理的窥探。这里这个“复杂的机关阵”有个不错的名字，叫做iptables，这也就是它由来的原因，恩，如果不是因为时间关系，我还能继续掰下去。。。 :-)</p>
<h3 id="iptables表"><a href="#iptables表" class="headerlink" title="iptables表"></a>iptables表</h3><p>既然要设计一套八卦阵，那必须看上去十分牛逼才行。先立几道屏障再说，每一个报文要想进来必须要经过这些屏障的严格筛选，才能成为真正的神选之报文。类似这样：</p>
<p><img src="/2022/06/11/uncatalog/cl49qytpu000klwr7el00gnwf/3.png" alt="image"></p>
<p>这样的屏障式设计，就有了原型。</p>
<p>然后在每一道屏障上面再设计很多的规则链，报文必须经过这些规则链的层层检查，有多严格呢？至少要比G20进地铁站还严吧。然后每一条规则链又由多个规则串起来。</p>
<p><img src="/2022/06/11/uncatalog/cl49qytpu000klwr7el00gnwf/4.png" alt="image"></p>
<p>能经过这样子的五行八卦阵的报文，那么咱就勉强认为是良民了，可以被主机上的程序接受。</p>
<p>（当然了，想要出去的报文也一样要经过严格控制，万一坏人已经跑到了内部，是吧）</p>
<h3 id="表和规则链"><a href="#表和规则链" class="headerlink" title="表和规则链"></a>表和规则链</h3><p>iptables一共有四张表(屏障)，但是一般只会用到两个，就是：过滤表-filter，改地址表-nat。这两个记住就行了。</p>
<p>iptables一共有五条基本的规则链： 接收预处理-prerouting，接收-input，转发-forward，发送-output，出口后处理-postrouting。记住名字就行。</p>
<p>这些表和这些链的组合，并不是每张表里面都有5条链的。有些规则链只存在特定的表中。</p>
<p>由于设计者可能比较喜欢爱马仕的关系，他设计的组合方式就是一个大写的字母H。所以倒也比较好记，出去&amp;进来一共4个角，中间一个转发小横杠。如下。</p>
<p><img src="/2022/06/11/uncatalog/cl49qytpu000klwr7el00gnwf/5.png" alt="image"></p>
<p>关于在经过“接收预处理-prerouting”环节后，是进入forward，还是进入input，这个问题。上一章节其实提到过。世界上有两种报文，发给我的，和不是发给我的。（判断是不是自己的报文，就看目的地址是不是本机的就行）。如果不是给我的，那就帮忙转发，走forward。是给自己的，那就走input。</p>
<h3 id="规则链"><a href="#规则链" class="headerlink" title="规则链"></a>规则链</h3><p>用户可以在一张表中任意增加规则链，规则链上面的某个规则如果命中，那么可以要求命中的报文进入到另外的规则链中继续处理。基本长这个样子：</p>
<p><img src="/2022/06/11/uncatalog/cl49qytpu000klwr7el00gnwf/6.png" alt="image"></p>
<p>基本套路如下：条件 + 命中 + 动作， 动作也就是那么几个：</p>
<p>（注意：一旦执行完规则的动作，就结束整个规则链的匹配，不继续往下匹配其他规则了。）</p>
<ol>
<li><p>Accept：接受报文</p>
</li>
<li><p>Drop：丢弃报文</p>
</li>
<li><p>SNAT：把报文的源地址改掉 （需要指定改为什么IP）</p>
</li>
<li><p>DNAT：把报文的目的地址改掉</p>
</li>
<li><p>Masquerade：高级版的SNAT，把报文的源地址改掉，改为发送网卡的IP地址（自动识别改成什么IP）</p>
</li>
<li><p>Redirect：高级版的DNAT，把报文的目的地址改为接收网卡的IP地址。同时可以修改目的端口（其实就是重定向给本机的某个端口）</p>
</li>
<li><p>其他名字：那就代表跳转到另外一条规则链继续匹配。。。（这里的名字就等于指定的目标规则链的名字）</p>
</li>
</ol>
<p>其他高级动作？ 骚年，其他动作解锁靠你自己啦 ：-）</p>
<h3 id="iptables命令"><a href="#iptables命令" class="headerlink" title="iptables命令"></a>iptables命令</h3><p>额，说了这么久，貌似还没提到iptables命令怎么用。一般情况有两种方式查看当前的iptables规则：</p>
<ol>
<li><h1 id="iptables-nL-（或者-iptables-t-nat-nL）"><a href="#iptables-nL-（或者-iptables-t-nat-nL）" class="headerlink" title="iptables -nL （或者 # iptables -t nat -nL）"></a>iptables -nL （或者 # iptables -t nat -nL）</h1></li>
</ol>
<p>列出当前表的所有规则链。</p>
<p>其实一个-L参数就行，但是记得我说过，网络相关的命令最好都加一个“-n”么？是的，-n让它不用做DNS翻译，也就是不要把IP地址翻译为主机名。</p>
<p>-L参数：</p>
<p>列出当前表的所有规则链。注意是大写的L。</p>
<p>-n参数：</p>
<p>不要把IP翻译为主机名</p>
<p>-t参数：</p>
<p>指定要查看的表名。不指定的话，默认查询filter表。</p>
<p>-v参数：</p>
<p>如果要定位查询规则命中的次数，可以加个-v参数，这样子输入：</p>
<h1 id="iptables-nvL-（或者-iptables-t-nat-nvL）"><a href="#iptables-nvL-（或者-iptables-t-nat-nvL）" class="headerlink" title="iptables -nvL （或者 # iptables -t nat -nvL）"></a>iptables -nvL （或者 # iptables -t nat -nvL）</h1><p>一般查看命中次数都要先清空计数，然后再查看，所以清空规则命中计数也要学一下</p>
<p>-Z参数：</p>
<p>可以使用-Z参数清空命中统计次数。注意是大写的Z。</p>
<h1 id="iptables-Z-（或者-iptables-t-nat-Z）"><a href="#iptables-Z-（或者-iptables-t-nat-Z）" class="headerlink" title="iptables -Z （或者 # iptables -t nat -Z）"></a>iptables -Z （或者 # iptables -t nat -Z）</h1><ol start="2">
<li><h1 id="iptables-S-（或者-iptables-t-nat-S）"><a href="#iptables-S-（或者-iptables-t-nat-S）" class="headerlink" title="iptables -S （或者 # iptables -t nat -S）"></a>iptables -S （或者 # iptables -t nat -S）</h1></li>
</ol>
<p>使用编辑模式查询当前表中的规则。恩，也就是看看当前表里面的这些规则是怎么插 入的。</p>
<p>列出来的每一行都是修改iptables的一条记录，这个在要修改iptables规则的时候特别有用。</p>
<p>具体怎么看显示的结果，下一节的iptables nat再细说~</p>
]]></content>
      <tags>
        <tag>云原生基础系列</tag>
        <tag>Kubernetes网络</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes网络系列之(九)网络骗子</title>
    <url>/2022/06/11/uncatalog/cl49r424d000nlwr732iq6tli/</url>
    <content><![CDATA[<hr>
<span id="more"></span>



<hr>
<blockquote>
<p>因为接下来的网络世界变得略显复杂，为了让大家看懂其中的门门道道，为师要教大家一点识别常见骗局小伎俩。</p>
</blockquote>
<h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>因为接下来的网络世界变得略显复杂，为了让大家看懂其中的门门道道，为师要教大家一点识别常见骗局小伎俩。</p>
<h3 id="双簧骗局"><a href="#双簧骗局" class="headerlink" title="双簧骗局"></a>双簧骗局</h3><p>一般大家能够达成共识的是：但凡比较经典的骗局，都是以双簧骗局为多。这种骗局特别容易让受害者晕头转向，轻易地上了套。大概使用如下这种套路：</p>
<p><img src="/2022/06/11/uncatalog/cl49r424d000nlwr732iq6tli/1.png" alt="image"></p>
<p>首先你遇到了一个看着挺和蔼的普通人（这个人可能是刚认识的，也可能是认识很久但也仅限平时业务需要，并不是那么知根知底，此人简称小伙伴）。然后有一天你们一起办点事情，路上遇到了另外一个人（此人简称第三者）：</p>
<p><img src="/2022/06/11/uncatalog/cl49r424d000nlwr732iq6tli/2.png" alt="image"></p>
<p>故事有可能是这个第三者主动来搭讪，也可能是一开始的小伙伴故意带领，但不管怎样，你已经把你自己和一开始的小伙伴当做是一个团体的了。</p>
<p>这时候如果第三者提出需求，并且小伙伴接受了这个需求，但是能力又恰好还差一点点。这时你就会很英勇的站出来帮助你的小伙伴了。因为你很坚信小伙伴跟你是一伙的，会快速还你这一份欠款。殊不知，人家两个才是真正一伙的。</p>
<h3 id="网络骗子"><a href="#网络骗子" class="headerlink" title="网络骗子"></a>网络骗子</h3><p>云网络世界，有很多这样的骗局，我们程序所发出的报文，就是这些双簧骗局的目标。好了，现在我们找一个经典网络骗局扒开来看一看：</p>
<p><img src="/2022/06/11/uncatalog/cl49r424d000nlwr732iq6tli/3.png" alt="image"></p>
<p>在云上，你要发送报文到目标程序。首先在报文出门前，你咨询了一下老朋友（骗子A），他告诉你：哦，你的目的地在xxx，你很相信它，所以你就把报文往xxx发出去了。可是报文刚出门，就遇到了骗子B。哇靠，刚出门就遇到骗子B，为什么这么巧呢？那是因为他一直在这里等你啊。你忘记啦，他跟骗子A是一伙的，是骗子A故意让你把报文往他这里发的。所以你的报文就被骗子B随便宰割啦，发往它所操控的任意地方。</p>
<pre><code>这个骗局中有一个重点可以再回顾一下，不管第一个骗子跟你说了目的地是什么，你的报文都会跑到第二个骗子那里。比如：
</code></pre>
<p>“哦，你的目的地在xxx”。你的报文跑到了第二个骗子那里。</p>
<p>“你这个目的地跟其他人不一样，是在yyy”。你的报文还是跑到了第二个骗子那里。</p>
<p>“这个呢，是在zzz”。还是到第二个骗子那里。</p>
<p>唯一的区别就是第二个骗子，知道你是因为什么原因受骗的。</p>
<p>看到这里，你似乎可以明白，在云上，网络控制做得好，双簧必须演得好。</p>
<h3 id="骗子身份"><a href="#骗子身份" class="headerlink" title="骗子身份"></a>骗子身份</h3><p>那好奇的人会问，两个骗子具体又是什么呢？典型双簧组合 DNS + Load Balancer</p>
<p><img src="/2022/06/11/uncatalog/cl49r424d000nlwr732iq6tli/4.png" alt="image"></p>
<p>云上面对方程序可能有多个实例，并且实例数量可能还随时间变化（比如配有自动扩容策略），所以访问不可能使用传统IP的方式。所以云提供者一般都说：请使用对方名字访问，用对方名字就可以通。</p>
<pre><code>注意了，一旦说到使用名字就可以互通，那就肯定要进入PaaS设定好的双簧骗局啦。更有甚者，直接跳过第一个骗局，直接进入第二个骗局（但是总的来说，没有双簧效果好，对受害人也不够人性化）。
</code></pre>
<p>五、举例</p>
<p>Kubernetes里面的kube-proxy，就很好的利用了这个骗局：</p>
<p><img src="/2022/06/11/uncatalog/cl49r424d000nlwr732iq6tli/5.png" alt="image"></p>
<p>所以在Kubernetes平台上，可以直接使用Service Name互相通信。当你拿着一个“名字”换回来的 clusterIP，其实是一个根本不存在的IP，它的唯一作用是引领你前往骗子B处（也就是kube-proxy），所以clusterIP一般选冷门的IP，万一跟真实存在的IP冲突了骗局就很尴尬了。</p>
<p>说到底，云网络，满满的都是套路啊。</p>
]]></content>
      <tags>
        <tag>云原生基础系列</tag>
        <tag>Kubernetes网络</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes网络系列之(十)iptables-nat穿越功能</title>
    <url>/2022/06/11/uncatalog/cl49r8bkh000qlwr7dta2fv8f/</url>
    <content><![CDATA[<hr>
<span id="more"></span>



<hr>
<blockquote>
<p>知道“网络骗子”是一种套路，那么它具体怎么实现这个套路的呢，我们细细分析NAT的实现<br>我们从最简单的开始：</p>
</blockquote>
<ol>
<li>启动一个Docker容器，带上端口映射的-p选项。（注：-p选项会开启一个端口NAT规则）。<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">docker pull mysql</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">docker run -d -e MYSQL_ROOT_PASSWORD=root -p 3306:3306 mysql</span></span><br></pre></td></tr></table></figure></div></li>
</ol>
<p>在这个mysql的数据库容器就启动好之后，它在主机上是类似这个样子的：</p>
<p><img src="/2022/06/11/uncatalog/cl49r8bkh000qlwr7dta2fv8f/1.png" alt="image"></p>
<p>这里，你可以把本机也看作是“其他Host”。（大概意思可以认为：咱们主机级别的，跟容器不是一个层次的，需要分开考虑），这里可以看到容器与外部世界的交互主要需要是：外面要能通里面，里面要能通外面。</p>
<ol start="2">
<li>然后咱们看看这个最简单的一个容器的NAT具体的规则是怎么设置的：</li>
</ol>
<p><img src="/2022/06/11/uncatalog/cl49r8bkh000qlwr7dta2fv8f/2.png" alt="image"><br>分析上图：</p>
<p>步骤1：为了实现入口与出口的流量控制，打开具体的iptables看看</p>
<p>步骤 2 &amp; 3：DNAT=替换目的IP，主机收到报文（也就是从外部收到报文）时，把目的IP换成对应的容器的，然后转发给对应的容器里面去。（入口流量控制）</p>
<p>步骤4 &amp; 5： MASQUERADE=替换源地址，主机往外发报文时，把原始是容器的源IP，换成源地址为主机的。</p>
<ol start="3">
<li>整个效果就是“其他Host”看到的报文就是来自于另外一台主机，感觉自己只是与另外一台主机在通信：</li>
</ol>
<p><img src="/2022/06/11/uncatalog/cl49r8bkh000qlwr7dta2fv8f/3.png" alt="image"></p>
<p>而报文一旦到达对方主机，对方的主机就咔咔咔一顿处理，然后就转交给主机上对应的容器了。</p>
<p>而我们一般说的容器通信都是这种，只要报文到达对方主机，总能进入对应的容器。因为对方主机在主机上为容器开了一个口子，报文一旦到达这个口子，就进入到了容器。这个口子就是端口，一旦报文是这个端口的，统统转交给对应的容器。</p>
<p>看上面的例子，在主机上开的口子的端口就是3306。任何达到主机的报文，只要目的端口是3306，直接转交给mysql容器。</p>
<ol start="4">
<li>主机上面为容器开口子大概长这个样子：</li>
</ol>
<p><img src="/2022/06/11/uncatalog/cl49r8bkh000qlwr7dta2fv8f/4.png" alt="image"></p>
<p>因为主机的端口数很多，所以可以使得一个主机可以有很多的容器都可以对外暴露地址。</p>
<p>容器对外暴露的地址就是：主机IP+主机Port</p>
<p>这个地址，Kubernetes取了一个好听的名字：NodePort模式。</p>
<ol start="5">
<li>接着我们再来看一个复杂的iptables的NAT穿越</li>
</ol>
<p>我们在Kubernetes的Node节点上面查询nat表信息：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">iptables -t nat -nL</span><br></pre></td></tr></table></figure></div>

<p>会列出很大一片，密密麻麻的，这里肯定贴不下，这里我们就分段分析它的实现。</p>
<p>a） 咱们不看NodePort规则，因为上面已经解释过了</p>
<p>直接找到下面这种样子的规则：</p>
<p><img src="/2022/06/11/uncatalog/cl49r8bkh000qlwr7dta2fv8f/5.png" alt="image"></p>
<p>这里可以看到这些规则很明确：任意源ip，特定的目的IP，直接命中规则。</p>
<p>步骤1：这里的目的IP是一个假的IP，实际不存在的。“网络骗子”章节介绍过，这个假的IP是DNS欺骗你的，是你通过“名字”换回来的。那么规则的意思就是一旦有人访问这个假IP，就命中iptables规则（被捕获）。每一条规则代表捕获一种假IP的访问。</p>
<p>步骤 2：那么我们随便找一条规则来分析，例如名字图中 2这条规则。</p>
<p>当报文匹配到这一条规则后，就跳转到对应名字的规则链里面去。</p>
<p>我们把对应的规则链找出来看看：<br><img src="/2022/06/11/uncatalog/cl49r8bkh000qlwr7dta2fv8f/6.png" alt="image"></p>
<p>步骤3：可以看到这个规则链就一条规则：任意源IP，任意目的IP，命中并跳转到下一条规则链。（任意进入这条链的报文，直接进入下一跳规则链）</p>
<p>那么我们再看看下一条规则链：</p>
<p><img src="/2022/06/11/uncatalog/cl49r8bkh000qlwr7dta2fv8f/7.png" alt="image"></p>
<p>步骤4：这里看到了，规则是这样子的：直接把报文的目的地址改为真实容器的IP。然后规则结束。这样子报文就会直接发给对应的容器了。</p>
<p>总结上面的流程：一旦发现有发给特定的假IP的报文，直接把目的IP换掉，换成这个假IP对应的容器的真实IP。 并且这个过程是强制的，也就是当前主机上所有的报文都得经过这个iptables的检查（即一旦访问肯定会被捕获）。</p>
<p>（这个就是网络骗子行骗的具体伎俩了）</p>
]]></content>
      <tags>
        <tag>云原生基础系列</tag>
        <tag>Kubernetes网络</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes网络系列之(十一)什么是VLAN和VXLAN</title>
    <url>/2022/06/11/uncatalog/cl49s0k3u000tlwr77i2gctw9/</url>
    <content><![CDATA[<hr>
<span id="more"></span>



<hr>
<blockquote>
<p>一、背景敲黑板： VLAN是你理解云网络的门槛石，要想通往云网络的世界，这一扇大门一定得理解透彻。二、为什么需要VLAN在前面的课程里面，我们知道了局域网的概念。一个局域网里面有N台电脑互相通信，ARP广播通知到各家各户。把你想象为村里的一户人家，平时送快递收快递，偶尔村里广播找人，派个人到你家询问询问情况，整体看似挺和谐的。 但是这里注意了哦，广播找人，那可一定是全村每家每户都派人通知到的…</p>
</blockquote>
<h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>敲黑板： VLAN是你理解云网络的门槛石，要想通往云网络的世界，这一扇大门一定得理解透彻。</p>
<h3 id="为什么需要VLAN"><a href="#为什么需要VLAN" class="headerlink" title="为什么需要VLAN"></a>为什么需要VLAN</h3><p>在前面的课程里面，我们知道了局域网的概念。一个局域网里面有N台电脑互相通信，ARP广播通知到各家各户。把你想象为村里的一户人家，平时送快递收快递，偶尔村里广播找人，派个人到你家询问询问情况，整体看似挺和谐的。 但是这里注意了哦，广播找人，那可一定是全村每家每户都派人通知到的。</p>
<p><img src="/2022/06/11/uncatalog/cl49s0k3u000tlwr77i2gctw9/1.png" alt="image"></p>
<p>然而当村子大了，问题就出来了： 就是这个各路的广播通知的大使啊，不停的往你家门口赶啊，一个又一个，无尽的骚扰着你家，已经困扰到你正常的作息了。</p>
<p><img src="/2022/06/11/uncatalog/cl49s0k3u000tlwr77i2gctw9/2.png" alt="image"></p>
<p>那你可能好奇，一个村里面，这个广播大使能有这么多吗？ 嗯，大概你门口就这么多吧（夸张手法）</p>
<p><img src="/2022/06/11/uncatalog/cl49s0k3u000tlwr77i2gctw9/3.jpg" alt="image"></p>
<p>所以这个村子也得分分组了：上半村，下半村。上半村的事情，广播大使，你别来下半村咨询了，上半村跑完了就噢了。</p>
<p>因此，一个局域网里面的电脑的分组需求就开始了。一个物理世界的人，实际上又分成了各个门派，门派之间各不相干。这种抽象决定了你虽然和邻居很近，然而你们互相不认识，也不通信。</p>
<p>VLAN就是用来给村里人分组用的，每个人贴个标签。代表了你是哪个门派。</p>
<h3 id="如何理解VLAN"><a href="#如何理解VLAN" class="headerlink" title="如何理解VLAN"></a>如何理解VLAN</h3><p>站在网络报文的角度，我们重新梳理一下这个里面分组的道道。</p>
<p>最开始，一个网线上面跑着很多运输车(IP报文)，到达目的地后，把IP头去掉，剩下货物交给对方，就像这样：</p>
<p>在对通知大使分组之后，这些报文可就带了标记了，一眼就看出来，这是不同门派的报文。就像这样：</p>
<p><img src="/2022/06/11/uncatalog/cl49s0k3u000tlwr77i2gctw9/4.png" alt="image"></p>
<p>这样一来，每一台机器，只会收到自己门派的报文，不会受到另一个门派的骚扰。一个局域网就这样根据报文的标记，分裂为多个不同的门派。找其中一个门派单独看，它又像是是一个更小的局域网，因为它们只与同一门派的人通信。所以单独的一个门派又叫做“虚拟的”局域网。英文Virtual LAN（也就是VLAN）。</p>
<p>下图显示一个局域网，分裂为两个虚拟的局域网。</p>
<p><img src="/2022/06/11/uncatalog/cl49s0k3u000tlwr77i2gctw9/17.png" alt="image"></p>
<p>那么怎么来给报文打标签区分类别呢？ 搞报文协议的前辈，掐指一算。算了，就给报文头里面加个字段吧，用来写门派号。<br><img src="/2022/06/11/uncatalog/cl49s0k3u000tlwr77i2gctw9/5.png" alt="image"></p>
<p>注意这里VID留了12bit位，也就是最大4095个门派。 搞协议的人觉得，一个局域网里面的电脑嘛，搞那么多门派干嘛，分组数量绝对够了啊。呵呵~都是坑，跟IPV4一样一样的。</p>
<p>带了VLAN头的报文，我们叫VLAN标签。它是一个长得不太一样的报文。</p>
<h3 id="交换机的VLAN口"><a href="#交换机的VLAN口" class="headerlink" title="交换机的VLAN口"></a>交换机的VLAN口</h3><p>在一个局域网里面，分组这件事，你可以任性的随机选电脑分一个组，更多的是按照位置和属性分组。一般为了方便管理，都将一个“虚拟局域网”的电脑放在一起。把它们接入一个交换机的一个网口上面，这个网口对应的下属电脑，属于同一个“虚拟局域网”。</p>
<p><img src="/2022/06/11/uncatalog/cl49s0k3u000tlwr77i2gctw9/6.png" alt="image"></p>
<p>在图上可以看到，一个交换机端口可以设置VLAN属性，代表允许的报文类型(门派)。 那这里有一个深层次的概念：一个端口，报文有进，有出的。分别怎么处理的呢？</p>
<p><img src="/2022/06/11/uncatalog/cl49s0k3u000tlwr77i2gctw9/7.png" alt="image"></p>
<p>这种打上标签，和去除标签的功能，是一个带VLAN功能的常见情况。也就是tag，untag的实际含义。因为也有端口是需要在收到报文的时候untag的，所以这个打标签的活需要注意，门派理清楚。</p>
<h3 id="Trunk又是什么鬼？"><a href="#Trunk又是什么鬼？" class="headerlink" title="Trunk又是什么鬼？"></a>Trunk又是什么鬼？</h3><p>一般情况，一个交换机端口，都是设置为只允许一种VLAN报文通过，这样比较好理解。但是有时候，我们需要设置一个端口，允许N种VLAN报文，都可以通过。</p>
<p>比如：</p>
<p>在一个大的局域网里面（比如学校），我们需要将两个位置的（比例两幢楼）的VLAN电脑通连起来，字母派一个组，数字派一个组。类似图示这样：</p>
<p><img src="/2022/06/11/uncatalog/cl49s0k3u000tlwr77i2gctw9/8.png" alt="image"></p>
<p>这种情况下，如果按照一个端口设置一个VLAN的原则，只需要在两个交换机之间，接额外2根线就行了。像这样：</p>
<p><img src="/2022/06/11/uncatalog/cl49s0k3u000tlwr77i2gctw9/9.png" alt="image"></p>
<p>由于带了VLAN标签的报文，只能通过对于的VLAN端口，所以两个“虚拟局域网”互相不干扰。但是如果门派变多了呢？？</p>
<p>难道每增加一个门派，两个交换机之间就得加一根网线？？</p>
<p>所以聪明的我们就想出来，一个端口允许N种VLAN标签不就行了。意思是各门派均可通过~</p>
<p><img src="/2022/06/11/uncatalog/cl49s0k3u000tlwr77i2gctw9/10.png" alt="image"></p>
<p>这个就是Trunk端口了。</p>
<p><img src="/2022/06/11/uncatalog/cl49s0k3u000tlwr77i2gctw9/11.png" alt="image"></p>
<h3 id="VLAN的不足，大哥VXLAN来帮忙"><a href="#VLAN的不足，大哥VXLAN来帮忙" class="headerlink" title="VLAN的不足，大哥VXLAN来帮忙"></a>VLAN的不足，大哥VXLAN来帮忙</h3><p>之前提过，第一个想出门派的VLAN协议设计者，觉得12bit的标记，也就是4千多种门派就够了。实际情况是，这玩意很好用啊，特别是这种“虚拟的局域网”概念，可以模拟出很多“虚拟的网络”出来给用户使用，特别适合云计算这种一个用户需要自己独立的网络这种场景，所以使用的越来也多，需求量超大。</p>
<p>表面上一根物理网线，可以虚拟出N根“虚拟网线”的效果。</p>
<p><img src="/2022/06/11/uncatalog/cl49s0k3u000tlwr77i2gctw9/12.png" alt="image"></p>
<p>所以结果就是：VLAN这种分出来门派的数量完全不够用啊！ 因为需求量可能比下面的还要多：</p>
<p><img src="/2022/06/11/uncatalog/cl49s0k3u000tlwr77i2gctw9/13.png" alt="image"></p>
<p>所以，一种新的区分报文门派的方法需要出来。所以人们就想方法，最终有两个方法出来：一种就是 VXLAN，X就是扩展的意思； 还有一种是GRE网络。</p>
<p>这两种分门派的方法有一个共同点，就是在小货车运输的货物上打标签。而不再是对货车分类（因为IP报文头已经没有多余字段可用来发挥作用了）。</p>
<ol>
<li>VXLAN分门派方法：</li>
</ol>
<p><img src="/2022/06/11/uncatalog/cl49s0k3u000tlwr77i2gctw9/14.png" alt="image"></p>
<ol start="2">
<li>GRE分门派方法：</li>
</ol>
<p><img src="/2022/06/11/uncatalog/cl49s0k3u000tlwr77i2gctw9/15.png" alt="image"></p>
<h3 id="结束"><a href="#结束" class="headerlink" title="结束"></a>结束</h3><p>因为VLAN技术的出现，使得同一根物理线路上，同时传递2种完全相互隔离的信息。效果看上去似乎是2条独立的线路分别在传递信息。</p>
<p>所以再进一步想象下：抽象的云计算里面的虚拟机，其实就是这种情况，两台虚拟机可能挨很近（运行在同一台物理机上），然而它们之间是完全没关系的，因为是分别被两个不同的人购买的。</p>
<p><img src="/2022/06/11/uncatalog/cl49s0k3u000tlwr77i2gctw9/16.png" alt="image"></p>
<p>云网络的雏形就这样长出来了。敲黑板~</p>
<p>附录：</p>
<p>要是想要深入搞这个VLAN技术，可以看看这篇文章<a href="https://network.51cto.com/article/450885.html">小白都能看明白的VLAN原理解释</a>。仅了解概念，看本文就够了。</p>
]]></content>
      <tags>
        <tag>云原生基础系列</tag>
        <tag>Kubernetes网络</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes网络系列之(十二)GRE</title>
    <url>/2022/06/11/uncatalog/cl49ss3al000wlwr78qw42gtt/</url>
    <content><![CDATA[<hr>
<span id="more"></span>



<hr>
<blockquote>
<p>上一课我们介绍了vlan报文，知道它是实现网络“分组”的元老，也就是实现云网络（虚拟的假象）的基石。今天我来看看网络中的另一位元老，走私鼻祖GRE</p>
</blockquote>
<h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>上一课我们介绍了vlan报文，知道它是实现网络“分组”的元老，也就是实现云网络（虚拟的假象）的基石。今天我来看看网络中的另一位元老，走私鼻祖GRE。</p>
<h3 id="什么是走私"><a href="#什么是走私" class="headerlink" title="什么是走私"></a>什么是走私</h3><p>普通的走私，我们不扣细节的看，走私就是过海关的时候，表面看挺正常，实际里面藏着其你想要携带的东西。</p>
<p>例子很多，比如：</p>
<p><img src="/2022/06/11/uncatalog/cl49ss3al000wlwr78qw42gtt/1.jpg" alt="image"></p>
<p>那网络走私又是什么呢？ 简单的说，就是在一个公开的协议上，传输一些“私有的数据”，从而完成夹带私货。</p>
<p>还是看图展示一下大致流程：</p>
<p><img src="/2022/06/11/uncatalog/cl49ss3al000wlwr78qw42gtt/2.png" alt="image"></p>
<p>当报文的发货方和收货方商量好“规则”之后，中间所有人都不知道他们在传输什么内容了~因为中间检查都是正常的。</p>
<p>上图我们举个具体的例子：</p>
<p><img src="/2022/06/11/uncatalog/cl49ss3al000wlwr78qw42gtt/3.png" alt="image"></p>
<p>IP报文看到自己在传输TCP，正常，放过。</p>
<p>TCP看到自己在传输HTTP，正常，放过。</p>
<p>HTTP检查正常，放过。</p>
<p>谁能知道，我只是通过HTTP走私点“干货”？</p>
<p>这里代表着：只要在网络上，有一种协议是通的，你就无法阻止通过这个公开的协议传输特定的内容。</p>
<p>这就是网络走私了。</p>
<h3 id="GRE是怎么走私的"><a href="#GRE是怎么走私的" class="headerlink" title="GRE是怎么走私的"></a>GRE是怎么走私的</h3><p>先看看GRE报文的格式，然后看看上一章节走私的介绍，就会明白。</p>
<p><img src="/2022/06/11/uncatalog/cl49ss3al000wlwr78qw42gtt/3.jpg" alt="image"></p>
<p>我把我要传输的内容（绿色部分），放在一个公开的IP报文里面（黄色部分）。</p>
<p>这里就好像，黄色部分走正常通道，如黄色地址先从美国发货到中国，正常通过。</p>
<p>在成功到达中国之后，那就是本端内部搞定了。拿出绿色部分，还有一层地址呢，然后国内真正发往想要的客户。至此GRE走私过程完成。</p>
<h3 id="为什么叫GRE隧道"><a href="#为什么叫GRE隧道" class="headerlink" title="为什么叫GRE隧道"></a>为什么叫GRE隧道</h3><p>走私的方式有很多，长期走私的话，隧道是一种比较好的理解是方式。</p>
<p>看我找的图你就明白了：</p>
<p><img src="/2022/06/11/uncatalog/cl49ss3al000wlwr78qw42gtt/5.jpg" alt="image"></p>
<p><img src="/2022/06/11/uncatalog/cl49ss3al000wlwr78qw42gtt/6.jpg" alt="image"></p>
<p><img src="/2022/06/11/uncatalog/cl49ss3al000wlwr78qw42gtt/7.jpg" alt="image"></p>
<p>当你把货物源源不断的从走私通道传输的时候，它就像一个隧道一样，不停的流动起来。这个就是GRE隧道协议了。</p>
<h3 id="GRE隧道和云网络"><a href="#GRE隧道和云网络" class="headerlink" title="GRE隧道和云网络"></a>GRE隧道和云网络</h3><p><img src="/2022/06/11/uncatalog/cl49ss3al000wlwr78qw42gtt/8.png" alt="image"></p>
<p>这种走私方式，用在云网络里面，其实就是张三的货，通过正常通道先从美国发往中国，当到达中国之后，再内部分发，从而完成“走私隧道”。</p>
<p>这样张三走张三的走私隧道，李四走李四的走私通道，在感知上，两个人是互相不相干的，从而形成虚拟网络通信。（在同一个线路上，你走你的，我走我的，互相不感知，可以参见上一节的vlan门派介绍，云网络基石章节）。</p>
<p>VPN隧道，其实用的就是上图这样的模式，把一端的局域网，和远处另一端的局域网，隐含的“桥接”起来。</p>
<p><img src="/2022/06/11/uncatalog/cl49ss3al000wlwr78qw42gtt/9.png" alt="image"><br>左边的人，认为和右边的人在同一个局域网里面。中间的网络只是走私的通道的“载体”而已，看不到，也不用关心。（ps，因为有承载隧道的这种载体能力，也就是可以在一种协议上，跑另一个网络协议。所以这种隧道网络，有时候也可以叫 OverLay 网络）。</p>
<p>这样隧道就有能把多个不同地方的局域网“连接”在一起能力，从而形成了云网络的模型。</p>
<p>把两头的局域网“透明”的接在一起，这个就是隧道的魅力了。可以看到kubernetes里面的flannel网络，用的就是这种隧道原理。</p>
<p><img src="/2022/06/11/uncatalog/cl49ss3al000wlwr78qw42gtt/10.png" alt="image"></p>
<p>你看它可以把每个节点上面的局域网，全部接在一起，让不同节点里面的容器以为自己在一个大的相同的局域网里面</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>你看，从vlan、gre的出现，一开始只是为了解决报文分门别类、互不干扰，到他们逐渐在云网络里面大展身手成为云网络的基石。这里面其实核心的思路就是：所有的云网络，其实都是障眼法。也就是你想让它（虚拟机/容器）看到它以为的样子。即它自己是不能发现自己在真实网络里面还是虚拟网络里面的。这个跟一个app程序，自己是不知道自己跑在虚拟机里面，还是跑在物理机里面是一样的。</p>
<p>这种对于真实世界的模拟，使得目标看到的假象跟真的一样，不仅仅是云网络，更是云的本质。</p>
]]></content>
      <tags>
        <tag>云原生基础系列</tag>
        <tag>Kubernetes网络</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes网络系列之(十三)ip命令</title>
    <url>/2022/06/11/uncatalog/cl49t00i2000zlwr72uaw2411/</url>
    <content><![CDATA[<hr>
<span id="more"></span>



<hr>
<blockquote>
<p>ip命令作为Linux网络控制的魔法棒，使得你可以自如的掌控网络信息。特别是netns子命令，允许你在现实世界挥动档杆，就可以操控那个虚拟出来的“网络世界”里面的各种参数。是未来遨游云网络的必备命令行工具。</p>
</blockquote>
<h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>其实到目前为止，物理世界的网络基本讲的差不多了。但是为了更好的玩转虚拟网络，有必要加强一下在现实世界中的命令行能力。就像你要进入魔法世界之前，先把自身能力打造的棒棒哒一样，这样你在魔法世界里面才不会迷失。</p>
<h3 id="ip命令介绍"><a href="#ip命令介绍" class="headerlink" title="ip命令介绍"></a>ip命令介绍</h3><p>大家知道，要看本机网卡的IP地址，一般使用ifconfig命令。要看本机的路由表用route命令，对吧。但是随着网络功能越来越丰富，甚至虚拟网络的出现，这些分散的Linux命令有些跟不上节奏了。所以后面又新搞出了一个ip命令，这个ip命令功能包含了基础的各类网络控制能力，同时旨在替代早期的那个ifconfig，route等命令。</p>
<p><img src="/2022/06/11/uncatalog/cl49t00i2000zlwr72uaw2411/1.png" alt="image"></p>
<p>使用ip命令，只需一个命令，你就能很轻松地执行一些网络管理任务。但是功能其实太强大，你也不会都用，我这里就说几个我认为值得学会用的几个。</p>
<ul>
<li><p>管理ip地址：    ip addr</p>
</li>
<li><p>管理路由表：    ip route</p>
</li>
<li><p>管理网卡：       ip link</p>
</li>
<li><p>管理网络空间：ip netns</p>
</li>
</ul>
<p>这几个学一学，敲一敲看看。</p>
<h3 id="ip命令举例"><a href="#ip命令举例" class="headerlink" title="ip命令举例"></a>ip命令举例</h3><p>比如看 ip addr 怎么用可以敲：</p>
<p>ip addr help</p>
<p><img src="/2022/06/11/uncatalog/cl49t00i2000zlwr72uaw2411/2.png" alt="image"></p>
<p>然后根据提示，敲入对应的命令，比如我们看看各个网卡的IP地址：</p>
<p><img src="/2022/06/11/uncatalog/cl49t00i2000zlwr72uaw2411/3.png" alt="image"></p>
<p>这一节的ip命令，主要是让大家了解这个命令在未来的虚拟网络里面，非常有用。特别是 addr，link，route，netns 这4个子命令，具体怎么用需要大家自己尝试一下。不用背下来，用的时候，知道有这个工具，然后多敲help就行。</p>
<h3 id="ip-netns-命令"><a href="#ip-netns-命令" class="headerlink" title="ip netns 命令"></a>ip netns 命令</h3><p>本章节的另一个重点就是介绍 ip netns 命令，毕竟其他addr，route这种还有早期的ifconfig等代替代替，而ip netns是你站在物理世界中，指挥虚拟世界的“魔法棒”。你可以在当前机器中，丢个“命令”给那个虚拟空间，让这个“命令”在虚拟空间里面执行起来。</p>
]]></content>
      <tags>
        <tag>云原生基础系列</tag>
        <tag>Kubernetes网络</tag>
      </tags>
  </entry>
  <entry>
    <title>kubernetes网络系列之(十四)网络命名空间Network Namespace</title>
    <url>/2022/06/11/uncatalog/cl49v1eys0012lwr741221o3z/</url>
    <content><![CDATA[<hr>
<span id="more"></span>



<hr>
<blockquote>
<p>通过本课，我们首先了解网络命名空间（network namespace）的概念，然后通过虚拟网线连通这个虚拟空间和主机空间。最后分别“站在”这2个不同世界中，观察这2个空间，并以此判断报文的收发方向</p>
</blockquote>
<h3 id="网络命名空间"><a href="#网络命名空间" class="headerlink" title="网络命名空间"></a>网络命名空间</h3><p>好了，我们先来看下普通的Host主机长什么样：</p>
<p><img src="/2022/06/11/uncatalog/cl49v1eys0012lwr741221o3z/1.jpg" alt="image"></p>
<p>大概如上图这样，你在家里收发着各类包（bao）裹（wen）。</p>
<p>有一天你用神奇的方式，创造了一个“虚拟空间”（什么？你想知道怎么创建的？好吧，这个咱们下一章节再讲，这里你需要先理解概念），这个空间是独立的，里面关于网络相关的东西一应俱全，你有的它都有。（即它拥有完整的Linux网络协议栈）</p>
<p><img src="/2022/06/11/uncatalog/cl49v1eys0012lwr741221o3z/2.jpg" alt="image"></p>
<p>这个时候，你需要找到一个“通道”，使得我们可以与这个独立空间进行交互。</p>
<p>方法呢，就是创建一根“网线”把2个世间给连起来。“网线”加引号是因为这个网线也是虚拟出来的，目前主要有TUN/TAP牌和Veth牌两种。（顺便提一下，目前市面上看到的虚拟机都用Tap/Tun这个牌子的网线，而容器都用Veth这个牌子的网线）。</p>
<p>好了，现在我们手里有一根虚拟网线（关于2种网线的介绍，会单独写，这里再次先略过网线本身的介绍），于是我们通过它，就可以将2个独立的世界连接起来。如下图</p>
<p><img src="/2022/06/11/uncatalog/cl49v1eys0012lwr741221o3z/3.jpg" alt="image"></p>
<p>注意了，在通过网线连通2个世界后，你（作为Host主机）要很公平的看待这个“虚拟世间”，一定要把它当做一个真实存在的实体。</p>
<p>为了更好理解：现在假设你蹲到下图“我”的位置上，然后站在Host“我”的视角看。往左看，有一个网卡；往右看也有一个网卡。</p>
<p><img src="/2022/06/11/uncatalog/cl49v1eys0012lwr741221o3z/4.jpg" alt="image"></p>
<p>所以你看到的世界，可以跟下面这个是一样的。</p>
<p>即通过一根网线，通往了其他节点。</p>
<p><img src="/2022/06/11/uncatalog/cl49v1eys0012lwr741221o3z/5.jpg" alt="image"></p>
<h3 id="报文的方向"><a href="#报文的方向" class="headerlink" title="报文的方向"></a>报文的方向</h3><p>为什么我们一定要认真的对待这个“虚拟世间”，并把它看做一个实际存在的实体呢。因为这个涉及报文方向的问题。（从我自己的经验来看，很多时候，容易搞混报文方向。）</p>
<h4 id="2-1-Host主机视角"><a href="#2-1-Host主机视角" class="headerlink" title="2.1      Host主机视角"></a>2.1      Host主机视角</h4><p>好了，首先让我们先站住主机Host角度看世界，它长成这个样子：</p>
<p><img src="/2022/06/11/uncatalog/cl49v1eys0012lwr741221o3z/6.jpg" alt="image"></p>
<p>从“虚拟空间”发出的报文，经过网卡2到我这里，对我来说，是收到了新报文。 跟通过网卡1收到的报文，没有什么区别。</p>
<p>即：经过安全iptables规则，也是“入”方向的。</p>
<h4 id="2-2-网络空间视角"><a href="#2-2-网络空间视角" class="headerlink" title="2.2      网络空间视角"></a>2.2      网络空间视角</h4><p>好了，现在让我们进入到这个“虚拟空间”，站在里面看世界，它应该长成什么样？</p>
<p>嗯，应该和本文的第一张图片一样，因为它是独立的实例。</p>
<p><img src="/2022/06/11/uncatalog/cl49v1eys0012lwr741221o3z/7.jpg" alt="image"></p>
<p>当然，从“上帝”角度来看，整体大概如下图：</p>
<p><img src="/2022/06/11/uncatalog/cl49v1eys0012lwr741221o3z/8.jpg" alt="image"></p>
<p>记住了：</p>
<p>站在“虚拟空间”角度看，主机Host发给我的报文，对我来说是入方向（是新收到的报文）。而我发给主机的报文，对我来说，是出方向（是发出去的报文）。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>今天我们首先了解网络命名空间（network namespace）的概念。然后知道通过虚拟网线，使之与主机Host世界连通。最后，我们分别“站在”这2个不同世界中，观察这个空间。</p>
<p>（1）在主机Host上，我们发现自己多了一个网卡，这个新网卡连接到另一个独立节点（把新创建的虚拟空间看做实体）。</p>
<p>（2）而在虚拟空间里面，我们就好比待在一个新的主机里面一样。</p>
<p>ps，这个“位置”很重要，因为这个会影响我们判断报文的“接收”还是“发送”的方向。</p>
]]></content>
      <tags>
        <tag>云原生基础系列</tag>
        <tag>Docker</tag>
        <tag>Kubernetes网络</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes网络系列之(十五)Veth网线</title>
    <url>/2022/06/11/uncatalog/cl49vyb870015lwr7gd0l1mz1/</url>
    <content><![CDATA[<hr>
<span id="more"></span>



<hr>
<blockquote>
<p>学习Veth-pair的概念和作用，并实战使用Veth + Network Namespace新建了一个可以独立使用的网络命令空间，从而详细了解了一个完整的网络空间是如何搭建的过程。</p>
</blockquote>
<h3 id="什么是Veth-Pair"><a href="#什么是Veth-Pair" class="headerlink" title="什么是Veth-Pair"></a>什么是Veth-Pair</h3><p>Veth是Linux中一种虚拟出来的网络设备，veth设备总是成对出现，所以一般也叫veth-pair。其作用是反转数据流方向。</p>
<p><img src="/2022/06/11/uncatalog/cl49vyb870015lwr7gd0l1mz1/1.png" alt="image"></p>
<p>例如：如果v-a和v-b是一对veth设备，v-a收到的数据会从v-b发出。相反，v-b收到的数据会从v-a发出。其实说白了，Veth就是一根“网线”，你从一头发数据，当然就从另一头收到数据了。网线的作用不就是这个么，veth也一样，把数据通过一头“复制”到另一头。</p>
<p><img src="/2022/06/11/uncatalog/cl49vyb870015lwr7gd0l1mz1/2.jpg" alt="image"></p>
<p>由于veth的“网线”特性，它常常充当着一个桥梁，连接着各种虚拟网络设备。常见用途是连接两个netwok namespace，或者连接Linux-Bridge、OVS 之类的。</p>
<p><img src="/2022/06/11/uncatalog/cl49vyb870015lwr7gd0l1mz1/3.jpg" alt="image"></p>
<p>Ps：veth的2头都直接连着网络协议栈，所以你创建一个veth对，主机上就会多2个网卡。</p>
<h3 id="实战演练"><a href="#实战演练" class="headerlink" title="实战演练"></a>实战演练</h3><p>现在用我们之前学过的 ip netns 命令来操作 一下我们创建的网络空间。</p>
<p>操作ns相关的输入格式为：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">ip netns exec [哪个命名空间] [具体要执行的命令]</span><br></pre></td></tr></table></figure></div>

<h4 id="首先创造新空间："><a href="#首先创造新空间：" class="headerlink" title="首先创造新空间："></a>首先创造新空间：</h4><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">ip netns add tsj</span><br></pre></td></tr></table></figure></div>

<p>这样就创造了一个新的“网络空间”，可以通过</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">ip netns list</span><br></pre></td></tr></table></figure></div>

<p>命令查看，确实有了一个新的ns空间了：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">tsj</span><br></pre></td></tr></table></figure></div>

<p><img src="/2022/06/11/uncatalog/cl49vyb870015lwr7gd0l1mz1/4.jpg" alt="image"></p>
<p>但是这个时候，咱们还缺少与这个空间进行交互的通道，光有空间，没有入口。</p>
<h4 id="然后创造网线："><a href="#然后创造网线：" class="headerlink" title="然后创造网线："></a>然后创造网线：</h4><p>接着让我们来创造一根Veth牌网线：</p>
<p>命令格式是：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">ip link add [网线一头名字] type veth peer name [网线另一头名字]</span><br></pre></td></tr></table></figure></div>

<p>所以如下：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">ip link add tsj-0 type veth peer name tsj-1</span><br></pre></td></tr></table></figure></div>

<p><img src="/2022/06/11/uncatalog/cl49vyb870015lwr7gd0l1mz1/5.jpg" alt="image"></p>
<h4 id="网线生效："><a href="#网线生效：" class="headerlink" title="网线生效："></a>网线生效：</h4><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">ifconfig tsj-0 up</span><br><span class="line"></span><br><span class="line">ifconfig tsj-1 up</span><br></pre></td></tr></table></figure></div>

<p>（或者：<code>ip link set tsj-0 up</code>，看过以前的ip命令课程的，就知道这2种命令效果是一样的）</p>
<p>这个时候可以通过ifconfig看到这2个网卡了。</p>
<p><img src="/2022/06/11/uncatalog/cl49vyb870015lwr7gd0l1mz1/6.jpg" alt="image"></p>
<h4 id="网线一头伸入到新建的空间"><a href="#网线一头伸入到新建的空间" class="headerlink" title="网线一头伸入到新建的空间"></a>网线一头伸入到新建的空间</h4><p>使用以下命令：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">ip link set tsj-1 netns tsj</span><br></pre></td></tr></table></figure></div>

<p>将<code>tsj-1</code>的网线头子，放入<code>tsj</code>这个虚拟空间中。</p>
<p>注意，网线还有一头<code>tsj-0</code>仍然在Host主机空间中的。</p>
<p><img src="/2022/06/11/uncatalog/cl49vyb870015lwr7gd0l1mz1/7.jpg" alt="image"></p>
<h4 id="把网卡命名为-eth0"><a href="#把网卡命名为-eth0" class="headerlink" title="把网卡命名为 eth0"></a>把网卡命名为 <code>eth0</code></h4><p>重命名网卡：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">ip netns exec tsj ip link set tsj-1 name eth0</span><br></pre></td></tr></table></figure></div>

<p>然后把这个网线头子生效一下：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">ip netns exec tsj ip link set eth0 up</span><br><span class="line"></span><br><span class="line">ip netns exec tsj ip link set lo up #（顺便把local网卡也生效了）</span><br></pre></td></tr></table></figure></div>

<p>查询结果，可以看到新建的虚拟网络空间里面，有一种比较熟悉的感觉。</p>
<p><img src="/2022/06/11/uncatalog/cl49vyb870015lwr7gd0l1mz1/8.jpg" alt="image"></p>
<p><img src="/2022/06/11/uncatalog/cl49vyb870015lwr7gd0l1mz1/9.jpg" alt="image"></p>
<h4 id="给网卡设置IP地址"><a href="#给网卡设置IP地址" class="headerlink" title="给网卡设置IP地址"></a>给网卡设置IP地址</h4><p>tsj空间里面的IP设置为：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">ip netns exec tsj ip addr add 10.254.1.1/24 dev eth0</span><br></pre></td></tr></table></figure></div>

<p>Host主机上面的IP设置为：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">ip addr add 10.254.1.2/24 dev tsj-0</span><br></pre></td></tr></table></figure></div>

<p>OK，当前大家IP都配置好了。现在我们来测试一下连通性。从网络空间，ping 主机空间。</p>
<h4 id="验证连通性"><a href="#验证连通性" class="headerlink" title="验证连通性"></a>验证连通性</h4><p>Host主机这边先监听（新开一个窗口）：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">tcpdump -i tsj-0 -n icmp</span><br></pre></td></tr></table></figure></div>

<p>新建空间里面，发起ping：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">ip netns exec tsj ping 10.254.1.2</span><br></pre></td></tr></table></figure></div>

<p><img src="/2022/06/11/uncatalog/cl49vyb870015lwr7gd0l1mz1/10.jpg" alt="image"></p>
<p>可以看到两边的效果，新建空间里面：（发出ping报文）</p>
<p><img src="/2022/06/11/uncatalog/cl49vyb870015lwr7gd0l1mz1/11.png" alt="image"></p>
<p>主机空间里面：（对Host主机来说，是收到新报文）</p>
<p><img src="/2022/06/11/uncatalog/cl49vyb870015lwr7gd0l1mz1/12.png" alt="image"></p>
<p>好啦，到这里，完整的网络空间基本长成了。</p>
<p>魔法师同志，恭喜学成网络虚拟化第一步。</p>
<p>（ps：Docker创建容器网络，过程原理跟上面是一样的，只是把cli改为使用系统调用，并且做了自动化）</p>
<h3 id="高阶"><a href="#高阶" class="headerlink" title="高阶"></a>高阶</h3><h4 id="在新空间中启动软件"><a href="#在新空间中启动软件" class="headerlink" title="在新空间中启动软件"></a>在新空间中启动软件</h4><p>这里我们在新创建的tsj空间中，启动一个nc服务器。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">ip netns exec tsj nc -lp 1234</span><br></pre></td></tr></table></figure></div>

<p>上面表示启动一个nc的web服务器，监听在1234端口。</p>
<p>这个时候，咱们给它发请求：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">curl -v 10.254.1.1:1234</span><br></pre></td></tr></table></figure></div>

<p>可以正常的访问</p>
<p><img src="/2022/06/11/uncatalog/cl49vyb870015lwr7gd0l1mz1/13.png" alt="image"></p>
<h4 id="查找Veth对的另一端"><a href="#查找Veth对的另一端" class="headerlink" title="查找Veth对的另一端"></a>查找Veth对的另一端</h4><p>如果ns非常多，veth也非常多（比如在OpenStack的网络节点上），怎么查找Veth网线的另一头在哪里呢？</p>
<p>比如，咱们这个tsj新世界里面网卡名eth0，咱们如何知道主机上是tsj-0就是它的对端呢？</p>
<p>答：可以使用 ethtool –S 方法。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">ip netns exec tsj ethtool -S eth0</span><br><span class="line"></span><br><span class="line">NIC statistics:</span><br><span class="line"></span><br><span class="line">     peer_ifindex: 149</span><br></pre></td></tr></table></figure></div>

<p>可以看到对端的index的149。这个时候主机上面敲：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">ip link list</span><br></pre></td></tr></table></figure></div>

<p>可看到idnex为 149 的网卡具体是哪个。</p>
<p><img src="/2022/06/11/uncatalog/cl49vyb870015lwr7gd0l1mz1/14.jpg" alt="image"></p>
<h4 id="删除Veth和NS"><a href="#删除Veth和NS" class="headerlink" title="删除Veth和NS"></a>删除Veth和NS</h4><p>创建了新的世界后，怎么把它抹去呢？</p>
<p>删除网线：（ps：网线2头会同时删除）</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">ip link delete tsj-0</span><br></pre></td></tr></table></figure></div>

<p>删除ns：（ps：直接删除ns，会连带veth一起删除）</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">ip netns delete tsj</span><br></pre></td></tr></table></figure></div>

<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>咱们学习了Veth网线的概念和作用，并实战使用Veth + Network Namespace新建了一个可以独立使用的网络命令空间，从而详细了解了一个完整的网络空间是如何搭建的过程。</p>
]]></content>
      <tags>
        <tag>云原生基础系列</tag>
        <tag>Kubernetes网络</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes网络系列之(十六)TUN/TAP网线</title>
    <url>/2022/06/11/uncatalog/cl49wfzo90018lwr70q7u4yf0/</url>
    <content><![CDATA[<hr>
<span id="more"></span>



<hr>
<blockquote>
<p>介绍TUN/TAP设备的概念和常见作用（即打通VM和Host间的网络），以及和Veth-pair网线的区别。这一节内部比较简单，因为主要内容已经在Veth网线里面讲了</p>
</blockquote>
<h3 id="什么是TUN-TAPr"><a href="#什么是TUN-TAPr" class="headerlink" title="什么是TUN/TAPr"></a>什么是TUN/TAPr</h3><p>TUN/TAP是Linux中一种虚拟出来的网络设备，简单说，它也是一种“网线”，只是这种网线和Veth牌网线有点不同。Veth网线的2头是一样的，都是水晶头。TUN/TAP网线的2头长得不一样，一头是水晶头，另一头是USB的。</p>
<p><img src="/2022/06/11/uncatalog/cl49wfzo90018lwr70q7u4yf0/1.jpg" alt="image"></p>
<p>稍正式一点的描述，它是一种用户空间和内核空间传输报文用的网线。一头是普通的网卡，跟eth0一样，Host主机可以用；另一头则是一个文件描述符，给用户空间的程序用的。</p>
<p><img src="/2022/06/11/uncatalog/cl49wfzo90018lwr70q7u4yf0/2.jpg" alt="image"></p>
<p>大家都知道一个VM本质上是一个qemu进程，所以其实TUN/TAP网线大多都是给VM用的。即上图的右边其实就是VM啦，它里面看到的eth0就是虚拟出来的。</p>
<p>于是你跟Veth网线一样的去理解就行了，那么Host主机网络模型也类似：</p>
<p><img src="/2022/06/11/uncatalog/cl49wfzo90018lwr70q7u4yf0/3.jpg" alt="image"></p>
<p>如果要添加TUNTAP网卡，还是使用咱们的ip命令。</p>
<p><img src="/2022/06/11/uncatalog/cl49wfzo90018lwr70q7u4yf0/4.png" alt="image"></p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">ip tuntap add tap0 mode tap</span><br></pre></td></tr></table></figure></div>

<p>这样就可以用的app程序，去open文件句柄“/dev/net/tun”了，发送&amp;接收报文了。</p>
<p>那当你需要将你创建的这些VM连接起来组成局域网，或者与外界（主机外部）通信时，就需要用上Linux Bridge了。</p>
<p><img src="/2022/06/11/uncatalog/cl49wfzo90018lwr70q7u4yf0/5.jpg" alt="image"></p>
<p>Docker容器也是这样，如果希望将很多容器按组管理，或者容器连通外网，也会需要使用Linux Bridge（上图的 br0）。这个咱们下节课讲</p>
]]></content>
      <tags>
        <tag>云原生基础系列</tag>
        <tag>Kubernetes网络</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes网络系列之(十七)Bridge网桥</title>
    <url>/2022/06/11/uncatalog/cl49wklgu001blwr7a55t1phs/</url>
    <content><![CDATA[<hr>
<span id="more"></span>



<hr>
<blockquote>
<p>已经进入到虚拟化的世界啦。Bridge是网络虚拟化中非常重要的一种设备，快来一起学习Linux-Bridge的作用吧。</p>
</blockquote>
<h3 id="什么是Linux-Bridge"><a href="#什么是Linux-Bridge" class="headerlink" title="什么是Linux-Bridge"></a>什么是Linux-Bridge</h3><p>咱们直接说人话：跟tap/tun、veth-pair是模拟网线的类似，Bridge也是照着物理设备的样子，在Linux系统里面虚拟出来的一种网络设备。</p>
<p>因为它也是网络设备，所以可以配置 IP、MAC 等。然后它模拟的物理设备叫Hub（集线器）。</p>
<p>1.1      物理集线器Hub<br>很多小伙可能没有见过，咱们直接上图：</p>
<p><img src="/2022/06/11/uncatalog/cl49wklgu001blwr7a55t1phs/1.jpg" alt="image"></p>
<p>上面这个东西没见过，可以参考下面这个，原理是一样一样的。</p>
<p><img src="/2022/06/11/uncatalog/cl49wklgu001blwr7a55t1phs/2.jpg" alt="image"></p>
<p>Hub的效果类似于把所有网线都焊在一起的感觉：</p>
<p><img src="/2022/06/11/uncatalog/cl49wklgu001blwr7a55t1phs/3.jpg" alt="image"></p>
<p>也就是不管信号从哪个口子进来，其他口子都能收到。“大喇叭”，“广播桶”，可以这么理解Hub。</p>
<pre><code>我们以前寝室里面打小组游戏，就是大家把网线往集线器一插，然后就是一个mini小局域网了。
</code></pre>
<p>1.2      虚拟集线器Bridge<br>所以呢，Linux里面虚拟出来的这个Bridge也是这个效果。用户可以把很多网卡，插到这个Bridge上面，然后互相之间就能连通了，于是往Bridge发报文，所有插在上面的网卡全都收到这个报文。（目的比较单纯，就是把大家连在一起）</p>
<p>一般用来把 tap/tun、veth-pair网线连到Bridge上面，这样可以把一组容器，或者一组虚机连在一起。比如著名的Docker就是用Bridge把Host里面的容器都连在一起，使得这些容器可以互相访问。也可以把Host上面的物理网卡也加入到Bridge，这样主机的VM就可以和外界通信了。</p>
<p>2      容器使用Bridge<br><img src="/2022/06/11/uncatalog/cl49wklgu001blwr7a55t1phs/4.jpg" alt="image"></p>
<p>按照Docker容器举例，这里会把多个容器的veth网线的一头，插入到Bridge，使得所有容器相当于焊在一起。同时在主机上，我们可以看到的网卡会多1个叫docker0的网卡（docker0就是Bridge网桥）：</p>
<p><img src="/2022/06/11/uncatalog/cl49wklgu001blwr7a55t1phs/5.jpg" alt="image"></p>
<p>Ps：这里有个有意思的地方是，没有把主机上原有的那个eth0也加入到Bridge。而虚机使用Bridge，一般会把原来Host上面的网卡加入到Bridge。（容器不加入，一是因为大量容器的IP，可能会和Host所在网络上，它那些兄弟VM们的IP冲突。二还有容器网络模式可以多种模式选择，保留灵活性。）。</p>
<pre><code>至于容器怎么通过Bridge和外面的世界进行通信，这个咱们在后续的《Docker网络实战》里面详解。
</code></pre>
<p>3      虚机使用Bridge<br><img src="/2022/06/11/uncatalog/cl49wklgu001blwr7a55t1phs/6.jpg" alt="image"></p>
<p>虚机这里不一样的是，一般会把Host自己原来的eth0网卡，也一块加入到Bridge（如果虚机想要联网的话）。相当于上面4个“人”都是兄弟了，大家在一个局域网。</p>
<p>通过Bridge，可以把所有的虚拟机网络连在一起。</p>
<p><img src="/2022/06/11/uncatalog/cl49wklgu001blwr7a55t1phs/7.jpg" alt="image"></p>
<p>上面这些VM以为自己的世界：</p>
<p><img src="/2022/06/11/uncatalog/cl49wklgu001blwr7a55t1phs/8.jpg" alt="image"></p>
<p>后面你可以回到原来物理网络的视角去理解更高级的怎么给VM分组问题（不明白的可以回顾早期课程）。要给VM分帮派，或者说给这些VM们分不同的子网，就需要能给这些VM打VLAN的tag的功能，这个功能Bridge（集线器）就搞不定了，需要引入更高级的“路由器”。</p>
<p>Ps：物理世界也差不多，集线器的价格很便宜，和路由器的价格不是一个档次的。路由器可以设置每个端口的VLAN标记等高级功能。也就是咱们下一期的OVS（Open vSwitch）课程了。</p>
<p>4      怎么查看Bridge信息<br>一般我都用 brctl 这个命令行（ip命令也可以用，但是我感觉brctl更直接），比较方便：</p>
<p><img src="/2022/06/11/uncatalog/cl49wklgu001blwr7a55t1phs/9.jpg" alt="image"></p>
<p>4.1      查询Bridge信息<br>用的最多的就是，查询一个Bridge上面插了哪些网卡：也就是show这个子命令</p>
<p><img src="/2022/06/11/uncatalog/cl49wklgu001blwr7a55t1phs/10.png" alt="image"></p>
<p>上面这个可以看到，有四个veth网卡插在名字为docker0的Bridge网桥上面（其实就是有4个容器连在一起）。</p>
<p>4.2      网卡插入Bridge<br>用的第二多的就是 把一个网卡插入一个Bridge里面。即：addif 子命令</p>
<p>我们可以试一下，先创建一根“网线”</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">ip link add tsj-0 type veth peer name tsj-1</span><br></pre></td></tr></table></figure></div>


<p>然后创建一个Bridge</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">brctl addbr tsj-br</span><br></pre></td></tr></table></figure></div>

<p>然后把网线一头插入这个Bridge。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">brctl addif tsj-br tsj-0</span><br></pre></td></tr></table></figure></div>

<p>查询结果：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">brctl show tsj-br</span><br></pre></td></tr></table></figure></div>

<p><img src="/2022/06/11/uncatalog/cl49wklgu001blwr7a55t1phs/11.png" alt="image"></p>
<p>额，其实“容器世界”也是这么创建出来的</p>
]]></content>
      <tags>
        <tag>云原生基础系列</tag>
        <tag>Kubernetes网络</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes网络系列之(十八)Docker网络实现</title>
    <url>/2022/06/11/uncatalog/cl49wrxfs001elwr7evfs8y08/</url>
    <content><![CDATA[<hr>
<span id="more"></span>



<hr>
<blockquote>
<p>我们来详细观察&amp;理解Docker容器是如何实现它的网络的，以及解析一个容器是如何与本机、本机中的容器、其他Host、其他Host中的容器 等场景下分别是如何进行通信的详细原理<br>本机容器网络大概生成过程：首先每个容器对应创建一个network namespace；然后将所有的容器的network namespace连接到Bridge网桥（docker0）上，使得容器间互相处于一个局域网内，方便连通</p>
</blockquote>
<h3 id="Docker的网络命名空间"><a href="#Docker的网络命名空间" class="headerlink" title="Docker的网络命名空间"></a>Docker的网络命名空间</h3><p>docker使用namespace实现容器网络，但是我们使用ip netns命令却无法在主机上看到任何network namespace，这是因为默认docker把创建的网络命名空间链接文件隐藏起来了。</p>
<p>有2种进入这个“空间”的命令，我们以前的课都讲过。</p>
<p>1.1      通过<code>ip netns exec</code><br>启动一个容器</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">docker run -tid ubuntu:18.04</span><br></pre></td></tr></table></figure></div>

<p>这个时候，查询 network namespace，却发现是空的。</p>
<p>因为 ip netns 是去检查 /var/run/netns 目录的。而Docker这个软件，故意把容器对应的ns信息记录到了 /var/run/docker/netns 目录。所以ip netns查出来就是空的，我们想办法把ns信息翻出来就行。</p>
<p>（1）恢复关联-方式1</p>
<p>所以我们，把这2个目录关联一下：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">ln -s /var/run/docker/netns  /var/run/netns</span><br></pre></td></tr></table></figure></div>

<p>接下来再敲：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">ip netns</span><br></pre></td></tr></table></figure></div>

<p>就可以看到容器的 network namespace 了。</p>
<p>不过可以发现列出来的ns的ID，和对应容器的ID，不是同一个。 它两有一个映射值，可以通过 docker inspect 的结果查到对应关系：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">docker inspect 070044b2738f</span><br></pre></td></tr></table></figure></div>

<p><img src="/2022/06/11/uncatalog/cl49wrxfs001elwr7evfs8y08/1.png" alt="image"></p>
<p>（2）恢复关联-方式2</p>
<p>找到容器主pid：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">pid=$(docker inspect -f &#x27;&#123;&#123;.State.Pid&#125;&#125;&#x27; $&#123;container_id&#125;)</span><br></pre></td></tr></table></figure></div>

<p>创建对应的ns记录：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">mkdir -p /var/run/netns/</span><br><span class="line"></span><br><span class="line">ln -sfT /proc/$pid/ns/net /var/run/netns/$container_id</span><br></pre></td></tr></table></figure></div>

<p><img src="/2022/06/11/uncatalog/cl49wrxfs001elwr7evfs8y08/2.jpg" alt="image"></p>
<p>1.2      通过 nsenter<br>找到容器里app的主pid。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">docker inspect ecf8689d3297</span><br></pre></td></tr></table></figure></div>

<p><img src="/2022/06/11/uncatalog/cl49wrxfs001elwr7evfs8y08/3.jpg" alt="image"></p>
<p>跑到这个pid对应的世界（namespace）里去。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">nsenter -n -t 25977</span><br></pre></td></tr></table></figure></div>

<p>这个时候，就是在容器里面的网络空间角度敲命令啦。</p>
<p>例如：</p>
<p>（1）查询网卡：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">ifconfig</span><br></pre></td></tr></table></figure></div>

<p><img src="/2022/06/11/uncatalog/cl49wrxfs001elwr7evfs8y08/4.jpg" alt="image"></p>
<p>（2）抓包：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">tcpdump -i eth0 -n</span><br></pre></td></tr></table></figure></div>

<p><img src="/2022/06/11/uncatalog/cl49wrxfs001elwr7evfs8y08/5.png" alt="image"></p>
<p>2      Docker 使用的Linux Bridge<br>关于Docker为什么要加个Bridge来连通所有的容器？其实不加Bridge，网络也能通。只是说有了Bridge，就有了覆盖更多复杂场景的能力。</p>
<p>这里直接引用Docker自己的描述：通过Bridge，可以使得连到这个Bridge的容器互相通信；同时和没有连到这个Bridge的容器保持网络隔离。（大意就是：容器可以按网络分组）</p>
<p><img src="/2022/06/11/uncatalog/cl49wrxfs001elwr7evfs8y08/6.jpg" alt="image"></p>
<p>3      我怎么和本机Host主机通信<br>假设我就是那个Docker容器，那么我是如何与主机Host通信的呢。</p>
<p>3.1      本机Host怎么访问我<br>主机Host访问自己节点上的容器，答案是：直接访问就行了。</p>
<p>咱们先来看Host主机的路由表：</p>
<p><img src="/2022/06/11/uncatalog/cl49wrxfs001elwr7evfs8y08/7.png" alt="image"></p>
<p>因为根据路由信息：</p>
<p>所有发往Docker容器的地址（即目标为 172.17.* ）的报文，—&gt; 统统走给 —&gt; docker0 网卡。而根据上面Bridge章节可以知道，这个docker0就是Bridge网桥，它是连着所有容器的Veth网线的。所以这个报文会发送到所有容器里面，那么目标容器就会应答你。</p>
<p><img src="/2022/06/11/uncatalog/cl49wrxfs001elwr7evfs8y08/8.jpg" alt="image"></p>
<p>3.2      我怎么访问所在的Host主机<br>容器访问自己的Host主机，答案也是直接访问。</p>
<p>Docker容器里面，网络很简单，就一个eth0。所以你往外发报文，都是经过eth0网卡。而这个网卡是一个veth网线的一头，所以这个报文就会到达Bridge网桥（即docker0）。而这个网桥就是Host主机的一个网卡，所以就到达了目的地。</p>
<p><img src="/2022/06/11/uncatalog/cl49wrxfs001elwr7evfs8y08/9.jpg" alt="image"></p>
<p>综上，Docker容器和Host主机，是可以自由通信的。</p>
<p>3.3      本机其他容器怎么访问我<br>这个问题，直接去Bridge章节看一下就行了。大家都通过docker0这个Bridge焊在一起，所以直接互访就行了。</p>
<p>4      我怎么和别的Host主机通信<br>别的Host主机，就是“爸爸（所在节点）的兄弟”。</p>
<p>4.1      别的Host怎么访问我<br>跨节点访问容器时，由于不知道目标容器是住在哪台Host主机上（要访问那个容器，必须经过它所在的Host），所以为了访问一个目标容器专门设置一条路由规则（当我访问xxx容器时，请经过yyy虚拟机，这种规则），并不方便。所以一般直接用端口映射来访问。</p>
<p>即：目标容器所在的Host主机IP + 指定端口。然后当报文到达指定目标的Host主机时，通过指定端口Nat进入容器。</p>
<p><img src="/2022/06/11/uncatalog/cl49wrxfs001elwr7evfs8y08/10.jpg" alt="image"></p>
<p>举例：</p>
<p>（1）       在192.168.1.9这台机器上启动一个Nginx容器：注意这里-p参数告诉Host，请将主机上面的80端口，作为进入我的NAT入口。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">docker run -rm  -p 80:80 nginx</span><br></pre></td></tr></table></figure></div>

<p>（2）       然后咱们再另外找一台机器（与刚才192.168.1.9 这一台能连通）。</p>
<p>跨节点访问刚才那个容器：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">curl -vvv 192.168.1.9:80</span><br></pre></td></tr></table></figure></div>

<p><img src="/2022/06/11/uncatalog/cl49wrxfs001elwr7evfs8y08/11.png" alt="image"></p>
<p>这里可以看到，主机跨节点访问容器时，必须通过指定端口NAT进入到目标容器。</p>
<p><img src="/2022/06/11/uncatalog/cl49wrxfs001elwr7evfs8y08/12.jpg" alt="image"></p>
<p>直接访问IP是不通的（没有路由信息）</p>
<p>4.2      我怎么访问别的Host<br>这个答案比较简单：只要我所在的Host能通的地方，我就也能与它连通。<br><img src="/2022/06/11/uncatalog/cl49wrxfs001elwr7evfs8y08/13.jpg" alt="image"></p>
<p>你看主机上有一条：源地址NAT规则。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">iptables -t nat –nL</span><br></pre></td></tr></table></figure></div>

<p>意思是容器里面发出的报文，把源地址改成主机的，然后往外发。意思是跟主机一样往外发报文就完了（不理解的参见以前的NAT课程）。</p>
<p><img src="/2022/06/11/uncatalog/cl49wrxfs001elwr7evfs8y08/14.png" alt="image"></p>
<p>4.3      别的Host上的容器怎么访问我<br>也就跨节点的2个容器怎么互相通信。一般是2种方式：</p>
<p>4.3.1        NAT端口映射。<br>即通过指定目标端口，穿到容器中。</p>
<p>根据4.2章节可知：容器-》目标  == 容器所在Host节点 –》目标。</p>
<p>根据4.1章节可知：访问目标容器 == 指定IP+Port</p>
<p>所以容器里面直接用：指定IP+Port访问目标容器就行了。</p>
<p>举例：</p>
<p>（1）       在192.168.1.9这台机器上启动一个Nginx容器：注意这里-p参数告诉Host，请将主机上面的80端口，作为进入我的NAT入口。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">docker run -rm  -p 80:80 nginx</span><br></pre></td></tr></table></figure></div>

<p>（2）       然后咱们再另外找一台机器（与刚才192.168.1.9 这一台能连通）。</p>
<p>进入一个容器，然后跨节点访问刚才那个容器：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">docker exec -it ea60d3290dd5 /bin/bash</span><br><span class="line"></span><br><span class="line">curl -vvv 192.168.1.9:80</span><br></pre></td></tr></table></figure></div>

<p><img src="/2022/06/11/uncatalog/cl49wrxfs001elwr7evfs8y08/15.png" alt="image"></p>
<p>4.3.2        隧道网络打通所有容器。<br>这种就稍微复杂一点，就是让所有容器处于同一个局域网中。</p>
<p>隧道模式，实现方式基本是各显神通了。除了新版本Docker有自己的实现，各大厂商也都有不一样的实现，比如现在各种flannel，weave，calico等现实。</p>
<p>原理嘛，请参考早期的 隧道课程。（可以照着物理世界去考虑，好比为很多物理机里面的所有VM创建虚拟局域网类似）</p>
<p><img src="/2022/06/11/uncatalog/cl49wrxfs001elwr7evfs8y08/16.jpg" alt="image"></p>
]]></content>
      <tags>
        <tag>云原生基础系列</tag>
        <tag>Kubernetes网络</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes网络系列之(十九)CloudFoundry网络实现</title>
    <url>/2022/06/11/uncatalog/cl49x52lf001hlwr7g9qrfjev/</url>
    <content><![CDATA[<hr>
<span id="more"></span>



<hr>
<blockquote>
<p>在K8s独霸天下之前，CloudFoundry才是那时的PaaS平台一哥呢。虽然你之前可能没了解过CloudFoundry是什么，不过今天，我们可以来回顾一下当年老PaaS是如何实现容器集群中网络分发的，也许还能顺道看下这家伙是如何被后浪拍死在沙滩上的</p>
</blockquote>
<h3 id="简单介绍下CloudFoundry"><a href="#简单介绍下CloudFoundry" class="headerlink" title="简单介绍下CloudFoundry"></a>简单介绍下CloudFoundry</h3><p><img src="/2022/06/11/uncatalog/cl49x52lf001hlwr7g9qrfjev/1.png" alt="image"></p>
<p>Docker解决了单机上面的容器管理，当在大规模集群上面管理容器集群时，则需要依赖PaaS平台。CloudFoundry就是业界首个开源的PaaS平台，那在当年（大概2013~2015）可是叱咤风云，一时风光无限。</p>
<p>后来的故事大家基本也看到了，几个比较有名的PaaS平台起来，然后就是K8s一家独大，然后就没有然后了。（可参考唐老师的《K8S前世今生》文章）</p>
<p><img src="/2022/06/11/uncatalog/cl49x52lf001hlwr7g9qrfjev/2.png" alt="image"></p>
<p>这里提一下，当年的CF用的容器技术，还不是Docker，而是自创的一个叫做Warden的容器技术（原理和Docker差不多，但是没有镜像管理这个功能，所以后面被Docker碾压了）。后来Docker实在太火，CF把底层的容器换成了Docker，不过也来不及了。</p>
<p>2      集群中容器网络怎么打通<br>要访问容器，有2种场景： （1）容器间互相访问。（2）PaaS平台外部访问容器。</p>
<p>CF基本没怎么考虑第（1）种场景，只是对第（2）种场景做了较好的处理。所以我们详细介绍下第（2）种场景：PaaS外部怎么访问容器。</p>
<p>为了从外部可以访问容器，CF新增了一个叫做GoRouter的组件，你就理解成一个自己实现的定制版Nginx。</p>
<p><img src="/2022/06/11/uncatalog/cl49x52lf001hlwr7g9qrfjev/3.png" alt="image"></p>
<p>PaaS集群外部，访问集群里面的容器，都需要一个这样的LB的。定制也好，取第三方也罢。 比如作为后来者，K8s为了偷懒，实现弯道超车CF，直接只做控制逻辑（还取个好听的名字叫Ingress），具体转发动作交给Nginx这种第三方工具去实现了。</p>
<p>回到CF，那我们就详细看下报文是怎么经过GoRouter，到达容器的。</p>
<p><img src="/2022/06/11/uncatalog/cl49x52lf001hlwr7g9qrfjev/4.png" alt="image"></p>
<p>（1）       首先，GoRouter 和 容器所在的节点（DEA），是局域网的VM，互相连通。</p>
<p>（2）       GoRouter记录URL和容器endpoint的映射关系。</p>
<p>（3）       收到请求，将报文转给对应的容器Host节点。这个和K8s是一样的。</p>
<p>2.1      Host节点的容器网络<br>Warden容器出现的比Docker容器早，所以网络模型，也更简单。具体来讲，就是没Bridge网桥，报文直接靠Host路由导入容器。</p>
<p>l  在DEA上运行ifconfig看到的结果：</p>
<p><img src="/2022/06/11/uncatalog/cl49x52lf001hlwr7g9qrfjev/5.png" alt="image"></p>
<p>w-开头的 就是 Veth-pair 网线，没有Bridge网桥。</p>
<p>l  在容器内运行ifconfig看到的结果：</p>
<p><img src="/2022/06/11/uncatalog/cl49x52lf001hlwr7g9qrfjev/6.png" alt="image"></p>
<p>可以看到，warden容器内只有一个接口，就是Veth的另一头。在warden容器中运行的app也只能看到这一个接口。</p>
<p>所以CF为每个容器，创建了一根Veth网线，一头在Host主机（DEA）中，一头在Warden容器中，如下图：</p>
<p><img src="/2022/06/11/uncatalog/cl49x52lf001hlwr7g9qrfjev/7.png" alt="image"></p>
<p>l  DEA如何把app请求交给Warden容器内</p>
<p>前面提到GoRouter转发过来的请求，目的IP都是DEA的，那么DEA是怎么区分请求是给哪个warden容器的呢？ 答案是端口映射（目的IP都一样，不是还有端口不同么）。是的，DEA通过端口来区分不同的warden容器，从而交给不同的app。</p>
<p>DEA做的端口转warden容器IP工作是交给Host的iptables规则来完成的（跟Docker一样）：</p>
<p><img src="/2022/06/11/uncatalog/cl49x52lf001hlwr7g9qrfjev/8.png" alt="image"></p>
<p>所以，之前提到的路由组件（GoRouter）不关心容器（Warden）里面的实际IP，只记录容器所在主机（DEA）的IP就够了。Warden容器之间网络彼此隔离，所以这个Warden容器内部的IP其实并不重要，随机都可以，只要保证所有虚拟Veth网线的IP不重复就能区分不同的Warden容器。</p>
<p>2.2      容器内部网络<br>从容器角度来看，它自己肯定认为自己是完整的世界，所以我们只需要把容器当作普通的主机就行。（容器还是为了模拟出一个“真实”的运行环境）。</p>
<p><img src="/2022/06/11/uncatalog/cl49x52lf001hlwr7g9qrfjev/9.png" alt="image"></p>
<p>对于warden容器内部来说，与外界通信的唯一途径就那根Veth网线，网线的对端就是它的网关（即容器所在的主机），再外部的网络它就一点都不知道了。在这个虚拟世界中（warden容器中）运行的app所看到的网络也是这么的简单：我的世界只有一个网卡，路由也只有一条：</p>
<p><img src="/2022/06/11/uncatalog/cl49x52lf001hlwr7g9qrfjev/10.png" alt="image"></p>
<p>2.3      报文从客户端到达容器<br>这一章节，是上述章节的细化版，有兴趣的看看就行了。</p>
<p>2.3.1        客户端到CF的GoRouter<br><img src="/2022/06/11/uncatalog/cl49x52lf001hlwr7g9qrfjev/11.png" alt="image"></p>
<ol>
<li><p>首先客户端知道app的URL网址。so会先去查询DNS，DNS返回的IP是GoRouter的外部IP（即EIP啦）。</p>
</li>
<li><p>接着客户端访问刚查到的GoRouter的外部EIP（实际就是Openstack的网络节点，IaaS报文都是通过网络节点，转给内部的VM的。）。</p>
</li>
<li><p>Openstack网络节点将外部IP通过NAT转换成内部的IP，交给对应的VM。这里也就是GoRouter所在的节点了。</p>
</li>
</ol>
<p>Ps：因为NAT对客户端用户来说是不感知的，客户端会认为用EIP就是接与GoRouter通信了。</p>
<p>2.3.2        Router到DEA（App所在的VM）<br><img src="/2022/06/11/uncatalog/cl49x52lf001hlwr7g9qrfjev/17.png" alt="image"></p>
<ol start="4">
<li><p>路由组件GoRouter执行L7层终结模式。即先和客户端正常TCP建链，这时还不跟任何后端容器连接通信。等到客户端发起GET的时候，会根据客户端请求的URL，找到“url-app”的关联映射记录，找出是访问哪个app，然后才向目标app发起syn建链。注意这里向容器中的app发起请求时的目的端口已经换了，不再是http默认端口80。</p>
</li>
<li><p>“url-app”记录中app的地址是容器所在的节点（即：目的IP是DEA）。所以GoRouter把报文丢给DEA，其实也是一个VM。</p>
</li>
</ol>
<p>2.3.3        DEA收到的报文<br><img src="/2022/06/11/uncatalog/cl49x52lf001hlwr7g9qrfjev/12.png" alt="image"></p>
<ol start="6">
<li>可以看到GoRouter发其建链报文到达容器所在的Host节点。</li>
</ol>
<p>2.3.4        DEA转发进入容器（App所在的运行环境）<br><img src="/2022/06/11/uncatalog/cl49x52lf001hlwr7g9qrfjev/13.png" alt="image"></p>
<p>dea执行nat，把报文转入到容器里面。</p>
<ol start="7">
<li> DEA根据报文的目的端口，注意是端口，执行NAT动作，将目的IP改成内部容器的IP，交给APP。</li>
</ol>
<p>2.3.5        最终App看的请求<br><img src="/2022/06/11/uncatalog/cl49x52lf001hlwr7g9qrfjev/14.png" alt="image"></p>
<p>app看到的抓包</p>
<p>8 还是一样，NAT行为对客户端来说是不感知的，于是GoRouter路由组件以为自己直接跟容器App通信了。它继续开心的认为“url-app”的映射关系是正确的：</p>
<p><img src="/2022/06/11/uncatalog/cl49x52lf001hlwr7g9qrfjev/15.png" alt="image"></p>
<p>2.3.6        整体图<br><img src="/2022/06/11/uncatalog/cl49x52lf001hlwr7g9qrfjev/16.png" alt="image"></p>
<p>3      总结<br>CF的容器网络实现，和K8s主要3个地方稍有区别。</p>
<p>（1）       K8s用Service概念搞定容器间如何互访问题，CF未考虑容器如何互访。</p>
<p>（2）       外部路由转发的实现，K8s借助第三方组件，CF自己上阵</p>
<p>（3）       容器所在Host组网，Docker带Bridge，CF不带Bridge</p>
<p>第一点：K8s精明的地方，也是一把直接站在了CF的肩膀上。</p>
<p>第二点：App网络主要考虑了集群外部，如何访问容器，即K8s中的Ingress部分。跟K8s-Ingress中只定义“URL-&gt;容器”映射规则，转发则交给Nginx不一样的是。CF搞了个GoRouter路由组件，除了定义映射关系，自己上手做了转发动作。</p>
<p>第三点：容器有没有接入Bridge网桥，其实没太大区别，这个本身还是Docker和Warden的差异。Docker比Warden更通用一些，场景考虑的更周到，所以和K8s时代盖住了CF一样，Warden这种容器，也被Docker盖的死死的。</p>
]]></content>
      <tags>
        <tag>云原生基础系列</tag>
        <tag>Kubernetes网络</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes网络系列之(二十)Kubernetes网络实现</title>
    <url>/2022/06/11/uncatalog/cl49xdzwo001klwr71pcl8mu0/</url>
    <content><![CDATA[<hr>
<span id="more"></span>



<hr>
<blockquote>
<p>当今K8s独霸天下之时，咱们站在更高的角度，好好的看看K8s的网络是以什么理念构筑的。以及一个容器集群的好保姆，是如何分别照顾 南北流量和东西流量的。</p>
</blockquote>
<h3 id="简单介绍下Kubernetes"><a href="#简单介绍下Kubernetes" class="headerlink" title="简单介绍下Kubernetes"></a>简单介绍下Kubernetes</h3><p>1      简单介绍下Kubernetes<br>略。。容器集群管理的事实标准了，不知道要打屁股。</p>
<p>（ps：本章节可参考唐老师的《K8S前世今生》文章）</p>
<p>2      世界上的集群都一个样<br>有点标题党哈，不过我接触过的各种集群也不少，各种各样：</p>
<ul>
<li><p>OpenStack：在一大堆物理机上面，管理（启动/停止）VM的。</p>
</li>
<li><p>SGE，Slurm，PBS：在一大堆电脑集群里面，管理（启动/停止）App的。</p>
</li>
<li><p>Yarn：在一大堆电脑集群里面，管理（启动/停止）大数据App的。</p>
</li>
<li><p>CloudFoundry：在一大堆电脑集群里面，管理（启动/停止）容器的</p>
</li>
<li><p>Kubernetes：在一大堆电脑集群里面，管理（启动/停止）容器的。</p>
</li>
</ul>
<p>它们都有一些共同特点：</p>
<p>2.1      跨节点跑xx程序<br><img src="/2022/06/11/uncatalog/cl49xdzwo001klwr71pcl8mu0/1.png" alt="image"></p>
<p>这个xx程序一定是首先单机可以运行的。比如OpenStack：单机上面可以用qemu启动VM，想跨节点管理VM，就引入了OpenStack。Kubernetes也一样：单机上面可以跑Docker容器；想跨节点管理容器，就得引入集群管理老大的概念。</p>
<p>2.2      有一个管事的老大<br>A）集群管理的老大，负责让手下的某个小弟干活。别管是命令式（直接下命令）的，还是申明式（发告示）的，小弟收到命令后，乖乖干活就是了。</p>
<p>B）       同时，这个集群管理的老大，需要有脑子，不然小弟数量多了管不好。所以它需要拿笔记一记。比如OpenStack的老大得带个Mysql数据库；Kubernetes把笔记记在了ETCD里面（不过ETCD这个本子太小，记得东西不能太大，这是另话）。</p>
<p>C）       不管哪种老大，都得有个军师。一个新活来到老大这里，那么多小弟，指派给谁不是干呀。这活实际分配给哪个小弟，这得军师说了算，所以每中集群软件都自己写了一套 Scheduler 算法，可谓程序员间浪费重复轮子之典型代表。</p>
<p>2.3      小弟上面都有一个Agent<br><img src="/2022/06/11/uncatalog/cl49xdzwo001klwr71pcl8mu0/2.png" alt="image"></p>
<p>这个小弟上面的Agent，时刻向老大汇报自己的状态：活不活着，忙还是闲，方便老大派活。同时，Agent也就是那台电脑里面的地头蛇了，帮忙老大负责各种临时事物。只是大家的取名不一样：</p>
<p>OpenStack：取名Nova</p>
<p>Kubernetes：取名Kubelet</p>
<p>Yarn：取名NodeManager</p>
<p>2.4      老大怎么给小弟发号施令<br>一般老大都是通过：消息队列来，给小弟发号施令的，而不是亲自上门（直连）下达命令。原因么，当然是小弟可能临时出门（故障）了呗~ 直接上门可能不通，放消息队列里面就可靠多了。等小弟出差回来，还能看到老大下达的任务令。</p>
<ul>
<li><p>OpenStack：用 RabbitMQ 发号施令</p>
</li>
<li><p>Kubernetes：用 ETCD 发号施令</p>
</li>
<li><p>CloudFoundry：用 NATS 发号施令</p>
</li>
</ul>
<p>上面这些组件都是带消息通知的功能，区别有些有名，有些没那么出名罢了。</p>
<p>比如我们的K8s：</p>
<p><img src="/2022/06/11/uncatalog/cl49xdzwo001klwr71pcl8mu0/3.png" alt="image"></p>
<p>特别需要提一下：K8s这个老大不简单，找了个ETCD这个好帮手。这小家伙挺神，既能当笔记本记点事情（代替OpenStack中的Mysql），又能当公告牌，通知点消息（代替OpenStack中的Rabbit）。所以K8s这个容器集群管理相对OpenStack这个虚机管理不需要数据库，666~</p>
<p>3      K8s怎么设计容器网络的呢<br>3.1      南北流量<br>要看到K8s诞生的时候，那时是有CloudFoundry和Docker的，且都已经比较成熟。那时作为PaaS一哥的CF对容器网络的抽象：</p>
<p><img src="/2022/06/11/uncatalog/cl49xdzwo001klwr71pcl8mu0/4.png" alt="image"></p>
<p>主要考虑平台外部，怎么访问容器里面的App。而平台内部的App之间如何互相访问，几乎没有太多的设计。</p>
<p>由上图所示，可以看到，平台外部访问，一般都是上下画的，所以也叫做南北流量。我们这么叫，也是便于程序员之间沟通和理解。</p>
<p>Ps：PaaS的基本原型大致都这样：</p>
<p><img src="/2022/06/11/uncatalog/cl49xdzwo001klwr71pcl8mu0/5.png" alt="image"></p>
<p>3.2      东西流量<br>K8s吸取了前辈们的精华，除了平台外部访问App，还新增考虑了平台内部，App之间如何互相访问。</p>
<p><img src="/2022/06/11/uncatalog/cl49xdzwo001klwr71pcl8mu0/6.png" alt="image"></p>
<p>即K8s通过增加一个负载均衡的“LB”设备，来搞定平台内部的App间互相访问。给每个App取个别名，在LB上面登记一下，就可以被内部其他App访问。</p>
<p>由上图所示，可以看到，平台内部访问，一般都是水平画的，所以也叫做东西流量。一个完整的PaaS平台，就是需要南北流量+东西流量，全套治理的。</p>
<p>3.3      Docker原生访问方式<br>还记得唐老师的《Docker网络实现》章节吧，Docker容器可以通过“节点IP+节点Port”的方式访问到容器。原理的容器所在节点，设置了NAT规则。报文一到达节点，根据目的端口，转发进入容器。</p>
<p><img src="/2022/06/11/uncatalog/cl49xdzwo001klwr71pcl8mu0/7.png" alt="image"></p>
<p>3.4      小结：K8s中3种访问容器的通道<br>（1）       通过南北流量（从集群外部访问App）访问App容器</p>
<p>（2）       通过东西流量（集群内App之间）访问App容器</p>
<p>（3）       通过Docker原生自带的方式，访问App容器</p>
<p><img src="/2022/06/11/uncatalog/cl49xdzwo001klwr71pcl8mu0/8.png" alt="image"></p>
<p>下一章节，我们简单介绍下每种方式，K8s分别怎么去实现的。</p>
<p>4      K8s怎么实现容器访问<br>虽然K8s上面，有多种访问App容器的方法。但是不管用什么方式访问，一个App想要能被访问，就得得到K8s的同意。K8s把这个许可证叫做“Service”：也就是不管什么南北流量、东西流量，你的App想要能被访问，就得先申请Service许可证。</p>
<p>4.1      南北流量<br>要实现一个App的访问通道，一定要2个东西：（1）LB负载均衡器 + （2）注册映射关系。</p>
<p>映射关系就是：报文来了，应该转发给哪个App实例？ 即：找到 “哪个App + 哪个实例”。</p>
<p>负载均衡器呢，一般大家爱用Nginx，不过也有其他类型的实现。</p>
<p><img src="/2022/06/11/uncatalog/cl49xdzwo001klwr71pcl8mu0/9.png" alt="image"></p>
<p>K8s比CF聪明的地方是，没有自己去实现LB。而只定义了App需要怎么样才能登记到LB上面。即只定规范，不限制实现（这种思路，在k8s里面好多，比如存储的CSI，运行时的CRI的，容器网络的CNI 都是这样。）</p>
<ul>
<li>4层LB</li>
</ul>
<p>最简单的4层LB实现，K8s取了个名字：LoadBalancer（1）。</p>
<p>即定义：xx协议+xx端口 =》xx应用，具体规则自己去看资料。</p>
<ul>
<li>7层LB</li>
</ul>
<p>为了定义7层LB的规则，K8s给规范取了名字：Ingress（2）。</p>
<p>即定义：xx网址+xx-URL路径 =》xx应用，具体规则也自己看K8s资料。</p>
<p>南北LB都是全局级的，即：全局一个（HA多实例，咱也当一个整体）就行；不需要每个Slaver节点上一个。</p>
<p>4.2      东西流量<br>东西流量，也一样，需要LB+规则注入。这里，K8s设计就比较有意思。</p>
<p><img src="/2022/06/11/uncatalog/cl49xdzwo001klwr71pcl8mu0/10.png" alt="image"></p>
<p>逻辑上，如上图所示。在LB部分的实现上，K8s很巧妙的要求每个节点上面都一个“小LB”。</p>
<p><img src="/2022/06/11/uncatalog/cl49xdzwo001klwr71pcl8mu0/11.png" alt="image"></p>
<p>所以实现上，大致如上图所示。</p>
<ul>
<li>本地LB</li>
</ul>
<p>本地LB，要求每个节点都有。所以最开始的版本，K8s使用了Linux使用广泛的iptables来实现。</p>
<p>后面由于iptables性能不是特别给力，又有了 IPVS 实现。然后其他各式各样的民间实现也有。</p>
<ul>
<li>本地控制器</li>
</ul>
<p>LB需要一个控制器，每个本地“小LB”带配备一个小控制器，一样的，也是每个节点一个。和小LB一一对应。K8s给它取了个名字：Kube-proxy</p>
<p><img src="/2022/06/11/uncatalog/cl49xdzwo001klwr71pcl8mu0/12.png" alt="image"></p>
<ul>
<li>假IP地址</li>
</ul>
<p>每个K8s上的App，都可以申请“行走江湖的名号”，用来代表自己。K8s就会给你的App分配一个Service许可证，许可证上面带着“影子IP”，任何集群内部只要访问这个IP，就等于访问你的App。</p>
<p><img src="/2022/06/11/uncatalog/cl49xdzwo001klwr71pcl8mu0/13.png" alt="image"></p>
<p>实现上：</p>
<ol>
<li><pre><code>先到K8s那登记，说我想要个“名号”
</code></pre>
</li>
<li><pre><code>通过后，K8s会告知每个节点上的本地LB
</code></pre>
</li>
<li><pre><code>从此以后，每个LB都认识这个“影子IP”了，访问它，就代表访问对应App。
</code></pre>
</li>
</ol>
<p><img src="/2022/06/11/uncatalog/cl49xdzwo001klwr71pcl8mu0/14.png" alt="image"></p>
<p>由于这个“名号”是集群颁布的，所以仅在集群内有效。K8s取名：ClusterIP（3）。</p>
<p>关于东西流量的故事，还可以去看看唐老师之前的《网络骗子》篇。</p>
<p>4.3      Docker原生访问方式<br>除了上面几种访问方式，K8s也为原生的Docker访问通道留了个名字：NodePort（4）。</p>
<p>这种方式，在《Docker网络实现》里面说过，靠主机Host转发实现。既然是主机搞定，所以这条路和本地LB实现，就合并一起搞定了。</p>
<p><img src="/2022/06/11/uncatalog/cl49xdzwo001klwr71pcl8mu0/15.png" alt="image"></p>
<p>如上图，K8s下发规则的时候，顺便把这条路的规则也下发下去。</p>
<p>ps：由于每个本地LB都收到了K8s的通告小皮鞭，所以每个K8s的节点，都开通了NodePort通道哦。即：无论哪个Slaver节点的Port都可以通往该App。</p>
<p>4.4      小结<br>K8s在实现容器网络的时候，造了很多概念：</p>
<p>（1）       LoadBalancer</p>
<p>（2）       Ingress</p>
<p>（3）       ClusterIP</p>
<p>（4）       NodePort</p>
<p>本质都是一样的，就是LB+登记规范。 如果你看过《DNS篇》+《Docker网络实现》，这些就比较好理解。</p>
<p>ps：具体本地LB怎么实现？真有兴趣可以去搜搜Kube-proxy的代码解读。我本身不是很关心，因为其实你给每个节点安装一个 Nginx 也可以做到的。</p>
<p>5      总结<br>K8s的网络概念，特别是Service，是K8s里面的精华，务必需要搞明白。</p>
<p>（1）       K8s南北流量，用Loadbalancer（4层）和Ingress（7层）搞定。</p>
<p>（2）       K8s的东西流量，用Service概念搞定。特别的，还给了个“行走江湖用的名号”，取名ClusterIP（一个不存在的假IP地址）。</p>
<p>（3）       容器所在Host组网，存在Docker原生通道，K8s给重新包装了个名字：NodePort。所以只要报文到达Slaver节点，就能通到容器里面。</p>
<p>另外，提一下一直没有说的东西（怕概念太多，影响理解）：K8s的整个网络底座，是要求节点IP和容器IP是能互相连通的（即：在节点上面ping容器IP，是可以通的）。具体则是通过容器网络实现的。这个实现很多，Flannel，Calico等，本质要么隧道，要么子网（可以看看物理网络里面的《VLAN和Vxlan》篇，关于如何划分门派的篇章）</p>
]]></content>
      <tags>
        <tag>云原生基础系列</tag>
        <tag>Kubernetes网络</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes网络系列之(三十)iptables自定义链</title>
    <url>/2022/06/13/uncatalog/cl4cifajw0000pwr7fssa1zca/</url>
    <content><![CDATA[<hr>
<span id="more"></span>

<hr>
<p>前文中，我们一直在定义规则，准确的说，我们一直在iptables的默认链中定义规则，那么此处，我们就来了解一下自定义链。</p>
<p>你可能会问，iptables的默认链就已经能够满足我们了，为什么还需要自定义链呢？</p>
<p>原因如下：</p>
<p>当默认链中的规则非常多时，不方便我们管理。</p>
<p>想象一下，如果INPUT链中存放了200条规则，这200条规则有针对httpd服务的，有针对sshd服务的，有针对私网IP的，有针对公网IP的，假如，我们突然想要修改针对httpd服务的相关规则，难道我们还要从头看一遍这200条规则，找出哪些规则是针对httpd的吗？这显然不合理。</p>
<p>所以，iptables中，可以自定义链，通过自定义链即可解决上述问题。</p>
<p>假设，我们自定义一条链，链名叫IN_WEB，我们可以将所有针对80端口的入站规则都写入到这条自定义链中，当以后想要修改针对web服务的入站规则时，就直接修改IN_WEB链中的规则就好了，即使默认链中有再多的规则，我们也不会害怕了，因为我们知道，所有针对80端口的入站规则都存放在IN_WEB链中，同理，我们可以将针对sshd的出站规则放入到OUT_SSH自定义链中，将针对Nginx的入站规则放入到IN_NGINX自定义链中，这样，我们就能想改哪里改哪里，再也不同担心找不到规则在哪里了。</p>
<p>但是需要注意的是，自定义链并不能直接使用，而是需要被默认链引用才能够使用，空口白话说不明白，等到示例时我们自然会明白。</p>
<p>说了这么多，我们来动手创建一条自定义链，使用-N选项可以创建自定义链，示例如下</p>
<p><img src="/2022/06/13/uncatalog/cl4cifajw0000pwr7fssa1zca/1.png" alt="IMAGE"></p>
<p>如上图所示，”-t filter”表示操作的表为filter表，与之前的示例相同，省略-t选项时，缺省操作的就是filter表。</p>
<p>“-N IN_WEB”表示创建一个自定义链，自定义链的名称为”IN_WEB”</p>
<p>自定义链创建完成后，查看filter表中的链，如上图所示，自定义链已经被创建，而且可以看到，这条自定义链的引用计数为0 (0 references)，也就是说，这条自定义链还没有被任何默认链所引用，所以，即使IN_WEB中配置了规则，也不会生效，我们现在不用在意它，继续聊我们的自定义链。</p>
<p>好了，自定义链已经创建完毕，现在我们就可以直接在自定义链中配置规则了，如下图所示，我们配置一些规则用于举例。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifajw0000pwr7fssa1zca/2.png" alt="IMAGE"></p>
<p>如上图所示，对自定义链的操作与对默认链的操作并没有什么不同，一切按照操作默认链的方法操作自定义链即可。</p>
<p>现在，自定义链中已经有了一些规则，但是目前，这些规则无法匹配到任何报文，因为我们并没有在任何默认链中引用它。</p>
<p>既然IN_WEB链是为了针对web服务的入站规则而创建的，那么这些规则应该去匹配入站的报文，所以，我们应该用INPUT链去引用它。</p>
<p>当然，自定义链在哪里创建，应该被哪条默认链引用，取决于实际的工作场景，因为此处示例的规则是匹配入站报文，所以在INPUT链中引用自定义链。</p>
<p>示例如下。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifajw0000pwr7fssa1zca/3.png" alt="IMAGE"></p>
<p>上图中，我们在INPUT链中添加了一条规则，访问本机80端口的tcp报文将会被这条规则匹配到</p>
<p>而上述规则中的”-j IN_WEB”表示：访问80端口的tcp报文将由自定义链”IN_WEB”中的规则进行处理，没错，在之前的示例中，我们使用”-j”选项指定动作，而此处，我们将”动作”替换为了”自定义链”，当”-j”对应的值为一个自定义链时，就表示被当前规则匹配到的报文将交由对应的自定义链处理，具体怎样处理，取决于自定义链中的规则，当IN_WEB自定义链被INPUT链引用以后，可以发现，IN_WEB链的引用计数已经变为1，表示这条自定义链已经被引用了1次，自定义链还可以引用其他的自定义链，感兴趣的话，动手试试吧。</p>
<p>在之前的文章中，我们说过，”动作”在iptables中被称为”target”，这样描述并不准确，因为target为目标之意，报文被规则匹配到以后，target能是一个”动作”，target也能是一个”自定义链”，当target为一个动作时，表示报文按照指定的动作处理，当target为自定义链时，表示报文由自定义链中的规则处理，现在回过头再理解之前的术语，似乎更加明了了。</p>
<p>那么此刻，我们在192.168.1.139上尝试访问本机的80端口，已经被拒绝访问，证明刚才自定义链中的规则已经生效了。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifajw0000pwr7fssa1zca/4.png" alt="IMAGE"></p>
<p>过了一段时间，我们发现IN_WEB这个名字不太合适，我们想要将这条自定义链重命名，把名字改成WEB，可以吗？必须能啊，示例如下</p>
<p><img src="/2022/06/13/uncatalog/cl4cifajw0000pwr7fssa1zca/5.png" alt="IMAGE"></p>
<p>如上图所示，使用”-E”选项可以修改自定义链名，如上图所示，引用自定义链处的名称会自动发生改变。</p>
<p>好了，我们已经能够创建自定义了，那么怎样删除自定义链呢？</p>
<p>使用”-X”选项可以删除自定义链，但是删除自定义链时，需要满足两个条件：</p>
<p>1、自定义链没有被任何默认链引用，即自定义链的引用计数为0。</p>
<p>2、自定义链中没有任何规则，即自定义链为空。</p>
<p>那么，我们来删除自定义链WEB试试。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifajw0000pwr7fssa1zca/6.png" alt="IMAGE"></p>
<p>如上图所示，使用”-X”选项删除对应的自定义链，但是上例中，并没有成功删除自定义链WEB，提示：Too many links，是因为WEB链已经被默认链所引用，不满足上述条件1，所以，我们需要删除对应的引用规则，示例如下。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifajw0000pwr7fssa1zca/7.png" alt="IMAGE"></p>
<p>如上图所示，删除引用自定义链的规则后，再次尝试删除自定义链，提示：Directory not empty，是因为WEB链中存在规则，不满足上述条件2，所以，我们需要清空对应的自定义链，示例如下</p>
<p>如上图所示，使用”-X”选项可以删除一个引用计数为0的、空的自定义链。</p>
<p>小结<br>为了方便以后回顾，我们将上述命令进行总结。</p>
<p>创建自定义链</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">示例：在filter表中创建IN_WEB自定义链</span></span><br><span class="line">iptables -t filter -N IN_WEB</span><br></pre></td></tr></table></figure></div>


<p>引用自定义链</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">示例：在INPUT链中引用刚才创建的自定义链</span></span><br><span class="line">iptables -t filter -I INPUT -p tcp --dport 80 -j IN_WEB</span><br></pre></td></tr></table></figure></div>


<p>重命名自定义链</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">示例：将IN_WEB自定义链重命名为WEB</span></span><br><span class="line">iptables -E IN_WEB WEB</span><br></pre></td></tr></table></figure></div>


<p>删除自定义链<br>删除自定义链需要满足两个条件</p>
<p>1、自定义链没有被引用</p>
<p>2、自定义链中没有任何规则</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">示例：删除引用计数为0并且不包含任何规则的WEB链</span></span><br><span class="line">iptables -X WEB</span><br></pre></td></tr></table></figure></div>]]></content>
      <tags>
        <tag>云原生基础系列</tag>
        <tag>Kubernetes网络</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes网络系列之(三十一)iptables之网络防火墙</title>
    <url>/2022/06/13/uncatalog/cl4cifajy0001pwr71ippfotz/</url>
    <content><![CDATA[<hr>
<span id="more"></span>

<hr>
<p>阅读这篇文章需要站在前文的基础之上，如果在阅读时遇到障碍，请回顾前文。</p>
<p>我们一起来回顾一下之前的知识，在第一篇介绍iptables的文章中，我们就描述过防火墙的概念，我们说过，防火墙从逻辑上讲，可以分为主机防火墙与网络防火墙。</p>
<p>主机防火墙：针对于单个主机进行防护。</p>
<p>网络防火墙： 往往处于网络入口或边缘，针对于网络入口进行防护，服务于防火墙背后的本地局域网。</p>
<p>在前文的举例中，iptables都是作为主机防火墙的角色出现的，那么，iptables怎样作为网络防火墙呢？这就是我们今天要聊的话题。</p>
<p>回到刚才的概念，网络防火墙往往处于网络的入口或者边缘，那么，如果想要使用iptables充当网络防火墙，iptables所在的主机则需要处于网络入口处，示意图如下。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifajy0001pwr71ippfotz/1.png" alt="iamge"><br>上图中，橘黄色主机为iptables所在主机，此时iptables充当的角色即为网络防火墙，上图中的浅蓝色圆形表示网络防火墙所防护的网络区域，圆形内的蓝色矩形表示网络内的主机。</p>
<p>当外部网络中的主机与网络内部主机通讯时，不管是由外部主机发往内部主机的报文，还是由内部主机发往外部主机的报文，都需要经过iptables所在的主机，由iptables所在的主机进行”过滤并转发”，所以，防火墙主机的主要工作就是”过滤并转发”，那么，说到这里，我们则不得不再次回顾之前的iptables报文流程图了，如下：</p>
<p><img src="/2022/06/13/uncatalog/cl4cifajy0001pwr71ippfotz/2.png" alt="iamge"></p>
<p>前文中，iptables都是作为”主机防火墙”的角色出现的，所以我们举例时，只用到了上图中的INPUT链与OUTPUT链，因为拥有”过滤功能”的链只有3条，INPUT、OUTPUT、FORWARD，当报文发往本机时，如果想要过滤，只能在INPUT链与OUTPUT链中实现，而此时，iptables的角色发生了转变，我们想要将iptables所在的主机打造成”网络防火墙”，而刚才已经说过，网络防火墙的职责就是”过滤并转发”，要想”过滤”，只能在INPUT、OUTPUT、FORWARD三条链中实现，要想”转发”，报文则只会经过FORWARD链（发往本机的报文才会经过INPUT链），所以，综上所述，iptables的角色变为”网络防火墙”时，规则只能定义在FORWARD链中。</p>
<h3 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h3><p>那么为了能够进行实验，我们来设置一下实验场景，如下图所示（后面有对图的解释）</p>
<p><img src="/2022/06/13/uncatalog/cl4cifajy0001pwr71ippfotz/3.png" alt="iamge"></p>
<p>我们假设，上图中圆形所示的网络为内部网络</p>
<p>注：此处所描述的内网、外网与我们平常所说的公网、私网不同。</p>
<p>此处描述的内外部网络你可以理解成两个网段，A网络与B网络，为了方便描述，我们把圆形内的主机称为内部主机，把上图中圆形所表示的网络称为内部网络，把圆形外的网络称为外部网络。</p>
<p>假设，内部网络的网段为10.1.0.0/16，此内部网络中存在主机C，主机C的IP地址为10.1.0.1。</p>
<p>上图中的主机B充当了网络防火墙的角色，主机B也属于内部网络，同时主机B也能与外部网络进行通讯，如上图所示，主机B有两块网卡，网卡1与网卡2，网卡1的IP地址为10.1.0.3，网卡2的IP地址为192.168.1.146，所以，防火墙主机在内部网络中的IP地址为10.1.0.3，防火墙主机与外部网络通讯的IP地址为192.168.1.146。</p>
<p>上图中的主机A充当了”外部网络主机”的角色，A主机的IP地址为192.168.1.147，我们使用主机A访问内部网络中的主机C，但是需要主机B进行转发，主机B在转发报文时会进行过滤，以实现网络防火墙的功能。</p>
<p>我已经准备了3台虚拟机，A、B、C</p>
<p>虚拟机A与虚拟机B的网卡2都使用了桥接模式。</p>
<p>为了能够尽量模拟内部网络的网络入口，我们将虚拟机B的网卡1与虚拟机C同时放在”仅主机模式”的虚拟网络中，虚拟机设置如下图所示</p>
<p>点击vmware编辑菜单，打开虚拟网络编辑器，点击更改设置按钮，添加一个仅主机模式的虚拟网络，下图中的vmnet6为已经添加过的虚拟网络，此处不再重复添加。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifajy0001pwr71ippfotz/4.png" alt="iamge"></p>
<p>由于B主机现在的角色是10.1.0.0中的”网络防火墙”，那么，我们直接将C主机的网关指向B主机的内部网络IP，如下图所示</p>
<p><img src="/2022/06/13/uncatalog/cl4cifajy0001pwr71ippfotz/5.png" alt="iamge"></p>
<p>同时，为了尽量简化路由设置，我们直接将A主机访问10.1网络时的网关指向B主机的网卡2上的IP，如下图所示。</p>
<p>注：route命令配置的路由条目在网络重启后将会失效</p>
<p><img src="/2022/06/13/uncatalog/cl4cifajy0001pwr71ippfotz/6.png" alt="iamge"></p>
<p>现在A主机通往10.1网络的网关已经指向了B主机，那么，现在A主机能够达到10.1.0.0/16网络吗？我们来试试</p>
<p>如下图所示，我们直接在A主机上向C主机发起ping请求，并没有得到任何回应。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifajy0001pwr71ippfotz/7.png" alt="iamge"></p>
<p>那么，我们再来试试B主机上的内部网IP，如下图所示，直接在A主机上向B主机的内部网IP发起ping请求，发现是可以ping通的，这是为什么呢？<br><img src="/2022/06/13/uncatalog/cl4cifajy0001pwr71ippfotz/8.png" alt="iamge"></p>
<p>按照道理来说，10.1.0.1与10.1.0.3都属于10.1.0.0/16网段，为什么B主机上的IP就能通，C主机上的IP却不通呢？</p>
<p>咱们先来聊聊为什么10.1.0.1没有回应。</p>
<p>A主机通过路由表得知，发往10.1.0.0/16网段的报文的网关为B主机，当报文达到B主机时，B主机发现A的目标为10.1.0.1，而自己的IP是10.1.0.3，这时，B主机则需要将这个报文转发给10.1.0.1（也就是C主机），但是，Linux主机在默认情况下，并不会转发报文，如果想要让Linux主机能够转发报文，需要额外的设置，这就是为什么10.1.0.1没有回应的原因，因为B主机压根就没有将A主机的ping请求转发给C主机，C主机压根就没有收到A的ping请求，所以A自然得不到回应。</p>
<p>现在再来聊聊为什么10.1.0.3会回应。</p>
<p>这是因为10.1.0.3这个IP与192.168.1.146这个IP都属于B主机，当A主机通过路由表将ping报文发送到B主机上时，B主机发现自己既是192.168.1.146又是10.1.0.3，所以，B主机就直接回应了A主机，并没有将报文转发给谁，所以A主机得到了10.1.0.3的回应。</p>
<p>我想我应该说明白了，那么，我们应该怎样设置，才能让Linux主机转发报文呢？我们一起来设置一遍就好了。</p>
<p>首先，我们可以查看/proc/sys/net/ipv4/ip_forward文件中的内容，如果文件内容为0，则表示当前主机不支持转发。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifajy0001pwr71ippfotz/9.png" alt="iamge"></p>
<p>如果我们想要让当前主机支持核心转发功能，只需要将此文件中的值设置为1即可，示例如下。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifajy0001pwr71ippfotz/10.png" alt="iamge"></p>
<p>好了，现在我们就开启了B主机的核心转发功能。</p>
<p>除了上述方法，还能使用sysctl命令去设置是否开启核心转发，示例如下。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifajy0001pwr71ippfotz/11.png" alt="iamge"></p>
<p>上述两种方法都能控制是否开启核心转发，但是通过上述两种方法设置后，只能临时生效，当重启网络服务以后，核心转发功能将会失效。</p>
<p>如果想要永久生效，则需要设置/etc/sysctl.conf文件（centos7中配置/usr/lib/sysctl.d/00-system.conf文件），添加（或修改）配置项 net.ipv4.ip_forward = 1 即可，示例如下。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifajy0001pwr71ippfotz/12.png" alt="iamge"></p>
<p>现在，B主机已经具备了核心转发功能，已经可以转发报文了，现在，我们再次回到A主机中，向C主机发起ping请求，如下图所示，已经可以ping通。</p>
<p>注：如果你仍然无法ping通，可能是因为你使用route命令配置了C主机的默认网关，这种情况下，请查看C主机的路由配置是否自动消失了，如果没有对应的路由条目，请重新配置，同时，如果你的主机C如果有多块网卡，可以暂时禁用其他网卡试试</p>
<p><img src="/2022/06/13/uncatalog/cl4cifajy0001pwr71ippfotz/13.png" alt="iamge"><br>同时，从主机C向主机A发起ping请求，也可以ping通，如下图所示</p>
<p><img src="/2022/06/13/uncatalog/cl4cifajy0001pwr71ippfotz/14.png" alt="iamge"></p>
<p>好了，我们的测试环境已经准备完毕，现在可以开始测试了。</p>
<p>但是在开始之前，请确定主机A与主机C上没有对应的iptables规则，因为此处我们主要是用来测试”网络防火墙”的，为了减少主机防火墙带来的影响，我们直接将主机A与主机C上的规则清空。</p>
<h3 id="网络防火墙测试"><a href="#网络防火墙测试" class="headerlink" title="网络防火墙测试"></a>网络防火墙测试</h3><p>之前说过，iptables作为网络防火墙时，主要负责”过滤与转发”，既然要过滤，则需配置filter表，既然要转发，则需在FORWAED链中定义规则，所以，我们应该在filter表中的FORWARD链中配置规则。</p>
<p>那么，我们先来看看主机B上的filter表中是否已经存在规则，如下</p>
<p><img src="/2022/06/13/uncatalog/cl4cifajy0001pwr71ippfotz/15.png" alt="iamge"></p>
<p>从上图可以看出，FORWARD链中没有任何规则，默认策略为ACCEPT，我们可以使用”白名单机制”（如果忘了请回顾前文：黑白名单机制）</p>
<p>在主机B中FORWARD链的末端添加一条默认拒绝的规则，然后将”放行规则”设置在这条”默认拒绝规则”之前即可。</p>
<p>示例如下</p>
<p><img src="/2022/06/13/uncatalog/cl4cifajy0001pwr71ippfotz/16.png" alt="iamge"></p>
<p>好了，配置完上述规则后，主机A与主机C已经无法通讯了，因为它们之间如果想要通讯，则需要靠主机B进行转发，而上述规则设置完成后，所有报文都无法通过FORWARD链了，所以任何经过转发的报文在经过FORWARD链时都会被拒绝，外部主机的报文无法转发到内部主机中，内部网主机的报文也无法转发到外部主机中，因为主机B已经拒绝转发所有报文。</p>
<p>现在，我们同时将A主机与C主机中的web服务启动，以便进行测试。</p>
<p>首先，我们启动A主机的httpd服务</p>
<p><img src="/2022/06/13/uncatalog/cl4cifajy0001pwr71ippfotz/17.png" alt="iamge"></p>
<p>同时，启动C主机的httpd服务</p>
<p><img src="/2022/06/13/uncatalog/cl4cifajy0001pwr71ippfotz/18.png" alt="iamge"></p>
<p>由于刚才已经在主机B中设置了默认拒绝的规则，所以此刻，A主机无法访问C主机的web服务，C主机同样无法访问A主机的web服务。</p>
<p>那么，如果我们想要使内部的主机能够访问外部主机的web服务，我们应该怎样做呢？没错，我们需要在FORWARD链中放行内部主机对外部主机的web请求，只需如下配置即可。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifajy0001pwr71ippfotz/19.png" alt="iamge"></p>
<p>如上图所示，防火墙放行了内部主机的web请求，因为我们将来自内部网络中目标端口为80的报文都放行了，那么此时，我们在C主机上访问A主机的web服务试试</p>
<p>此时，在主机C上访问主机A的web服务，如下</p>
<p><img src="/2022/06/13/uncatalog/cl4cifajy0001pwr71ippfotz/20.png" alt="iamge"><br>可以看到，主机C并无法访问到主机A上的web服务，这是为什么呢？</p>
<p>聪明如你肯定已经想到了，我们只在主机B上放行了内部主机访问80端口的请求，但是并没有放行外部主机的回应报文，虽然内部主机的请求能够通过防火墙主机B转发出去，但是回应的报文则无法进入防火墙，所以，我们仍然需要在主机B上进行如下设置。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifajy0001pwr71ippfotz/21.png" alt="iamge"></p>
<p>如上图所示，当外部主机中的web服务响应内部主机时，目标地址肯定为内部主机，所以，我们需要放行目标IP属于内部主机网段的报文，源端口为80，因为外部主机肯定会使用80端口进行回应。</p>
<p>完成上述配置后，再次回到C主机上，访问A主机的web服务，可以看到，已经能够正常访问了。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifajy0001pwr71ippfotz/22.png" alt="iamge"></p>
<p>从上述示例可以看出，当iptables作为”网络防火墙”时，在配置规则时，往往需要考虑”双向性”，也就是说，我们为了达成一个目的，往往需要两条规则才能完成。</p>
<p>那么此时，A主机能够访问C主机中的web服务吗？我想你已经知道答案了，没错，A主机此时无法访问C主机中的web服务，因为B主机中并没有放行相关报文。</p>
<p>结合之前的知识，我们可以将上述规则配置进行优化，比如，不管是由内而外，还是由外而内，只要是”响应报文”，我们统统放行，配置如下</p>
<p>注：如果你没有明白如下配置的含义，请回顾之前的文章</p>
<p><img src="/2022/06/13/uncatalog/cl4cifajy0001pwr71ippfotz/23.png" alt="iamge"></p>
<p>如上图所示，先将”web响应报文放行规则”删除，同时增加了上图中的规则，只需要在网络防火墙主机的FORWARD链中添加如上一条规则，就可以将绝大多数响应报文放行了，不管是外部响应内部，还是内部响应外部，一条规则就能搞定，当iptables作为网络防火墙时，每次配置规则时都要考虑”双向”的问题，但是配置完上述规则后，我们只要考虑请求报文的方向就行了，而回应报文，上述一条规则就能搞定，这样配置，即使以后有更多服务的响应报文需要放行，我们也不用再去针对响应报文设置规则了（具体原因前文已经详细的总结过），应该会让我们省去不少规则吧。</p>
<p>比如，我们除了想要让内部主机能够访问外部的web服务，还想让内部主机能够访问外部的sshd服务，那么，我们则可以进行如下设置。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifajy0001pwr71ippfotz/24.png" alt="iamge"></p>
<p>如上图所示，我们只要考虑内部主机的请求方向的报文规则即可，因为响应报文的规则已经被之前配置的规则”承包了”。</p>
<p>此刻，使用C主机即可访问A主机的22端口。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifajy0001pwr71ippfotz/25.png" alt="iamge"></p>
<p>目前，我们只允许内部主机访问外部主机的web服务与sshd服务，但是外部主机还无法访问内部主机的服务，那么具体怎么配置我们就不赘述了，就由客官你去负责实现吧。</p>
<p>备注：在之前的一次实验中，使用centos6.8作为网络防火墙，出现了即使开启核心转发，也无法转发报文的情况，具体原因仍未查明，遇到过类似场景的朋友如果有解决方法，欢迎赐教。</p>
<p>小结<br>为了方便以后回顾，我们将上述过程提炼总结一下。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">如果想要iptables作为网络防火墙，iptables所在主机开启核心转发功能，以便能够转发报文。</span></span><br><span class="line"><span class="meta">#</span><span class="bash">使用如下命令查看当前主机是否已经开启了核心转发，0表示未开启，1表示已开启</span></span><br><span class="line">cat /proc/sys/net/ipv4/ip_forward</span><br><span class="line"><span class="meta">#</span><span class="bash">使用如下两种方法均可临时开启核心转发，立即生效，但是重启网络配置后会失效。</span></span><br><span class="line">方法一：echo 1 &gt; /proc/sys/net/ipv4/ip_forward</span><br><span class="line">方法二：sysctl -w net.ipv4.ip_forward=1</span><br><span class="line"><span class="meta">#</span><span class="bash">使用如下方法开启核心转发功能，重启网络服务后永久生效。</span></span><br><span class="line">配置/etc/sysctl.conf文件（centos7中配置/usr/lib/sysctl.d/00-system.conf文件），在配置文件中将 net.ipv4.ip_forward设置为1</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">由于iptables此时的角色为<span class="string">&quot;网络防火墙&quot;</span>，所以需要在filter表中的FORWARD链中设置规则。</span></span><br><span class="line"><span class="meta">#</span><span class="bash">可以使用<span class="string">&quot;白名单机制&quot;</span>，先添加一条默认拒绝的规则，然后再为需要放行的报文设置规则。</span></span><br><span class="line"><span class="meta">#</span><span class="bash">配置规则时需要考虑<span class="string">&quot;方向问题&quot;</span>，针对请求报文与回应报文，考虑报文的源地址与目标地址，源端口与目标端口等。</span></span><br><span class="line"><span class="meta">#</span><span class="bash">示例为允许网络内主机访问网络外主机的web服务与sshd服务。</span></span><br><span class="line">iptables -A FORWARD -j REJECT</span><br><span class="line">iptables -I FORWARD -s 10.1.0.0/16 -p tcp --dport 80 -j ACCEPT</span><br><span class="line">iptables -I FORWARD -d 10.1.0.0/16 -p tcp --sport 80 -j ACCEPT</span><br><span class="line">iptables -I FORWARD -s 10.1.0.0/16 -p tcp --dport 22 -j ACCEPT</span><br><span class="line">iptables -I FORWARD -d 10.1.0.0/16 -p tcp --sport 22 -j ACCEPT</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">可以使用state扩展模块，对上述规则进行优化，使用如下配置可以省略许多<span class="string">&quot;回应报文放行规则&quot;</span>。</span></span><br><span class="line">iptables -A FORWARD -j REJECT</span><br><span class="line">iptables -I FORWARD -s 10.1.0.0/16 -p tcp --dport 80 -j ACCEPT</span><br><span class="line">iptables -I FORWARD -s 10.1.0.0/16 -p tcp --dport 22 -j ACCEPT</span><br><span class="line">iptables -I FORWARD -m state --state ESTABLISHED,RELATED -j ACCEPT</span><br></pre></td></tr></table></figure></div>

<p>一些注意点：</p>
<p>1、当测试网络防火墙时，默认前提为网络已经正确配置。</p>
<p>2、当测试网络防火墙时，如果出现问题，请先确定主机防火墙规则的配置没有问题。</p>
]]></content>
      <tags>
        <tag>云原生基础系列</tag>
        <tag>Kubernetes网络</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes网络系列之(三十二)iptables动作总结之一</title>
    <url>/2022/06/13/uncatalog/cl4cifak10004pwr75tri6w43/</url>
    <content><![CDATA[<hr>
<span id="more"></span>

<hr>
<p>前文一直在介绍iptables的匹配条件，并没有对动作进行过总结，那么此处，我们就来总结一下iptables中的动作。</p>
<p>之前的举例中已经用到了一些常用动作，比如ACCEPT、DROP、REJECT等。</p>
<p>其实，”动作”与”匹配条件”一样，也有”基础”与”扩展”之分。</p>
<p>同样，使用扩展动作也需要借助扩展模块，但是，扩展动作可以直接使用，不用像使用”扩展匹配条件”那样指定特定的模块。</p>
<p>之前用到的ACCEPT与DROP都属于基础动作。</p>
<p>而REJECT则属于扩展动作。</p>
<p>之前举过很多例子，我们知道，使用-j可以指定动作，比如</p>
<ul>
<li><p>-j ACCEPT</p>
</li>
<li><p>-j DROP</p>
</li>
<li><p>-j REJECT</p>
</li>
</ul>
<p>其实，”动作”也有自己的选项，我们可以在使用动作时，设置对应的选项，此处以REJECT为例，展开与”动作”有关的话题。</p>
<h3 id="动作REJECT"><a href="#动作REJECT" class="headerlink" title="动作REJECT"></a>动作REJECT</h3><p>REJECT动作的常用选项为–reject-with</p>
<p>使用–reject-with选项，可以设置提示信息，当对方被拒绝时，会提示对方为什么被拒绝。</p>
<p>可用值如下</p>
<ul>
<li><p>icmp-net-unreachable</p>
</li>
<li><p>icmp-host-unreachable</p>
</li>
<li><p>icmp-port-unreachable,</p>
</li>
<li><p>icmp-proto-unreachable</p>
</li>
<li><p>icmp-net-prohibited</p>
</li>
<li><p>icmp-host-pro-hibited</p>
</li>
<li><p>icmp-admin-prohibited</p>
</li>
</ul>
<p>当不设置任何值时，默认值为icmp-port-unreachable。</p>
<p>我们来动手实践一下，在主机139上设置如下规则，如下图所示，当没有明确设置–reject-with的值时，默认提示信息为icmp-port-unreachable，即端口不可达之意。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifak10004pwr75tri6w43/1.png" alt="iamge"></p>
<p>此时在另一台主机上向主机139发起ping请求，如下图所示，提示目标端口不可达。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifak10004pwr75tri6w43/2.png" alt="iamge"></p>
<p>那么我们将拒绝报文的提示设置为”主机不可达”，示例如下</p>
<p><img src="/2022/06/13/uncatalog/cl4cifak10004pwr75tri6w43/3.png" alt="iamge"></p>
<p>如上图所示，我们在设置拒绝的动作时，使用了–reject-with选项，将提示信息设置为icmp-host-unreachable，完成上述操作后，我们再次在在另一台主机上向主机139发起ping请求。</p>
<p>如下图所示。<br><img src="/2022/06/13/uncatalog/cl4cifak10004pwr75tri6w43/4.png" alt="iamge"></p>
<p>可以看到，ping请求被拒绝时，提示信息已经从”目标端口不可达”变成了”目标主机不可达”。</p>
<h3 id="动作LOG"><a href="#动作LOG" class="headerlink" title="动作LOG"></a>动作LOG</h3><p>在本博客中，前文并没有对LOG动作进行示例，此处我们来了解一下LOG动作。</p>
<p>使用LOG动作，可以将符合条件的报文的相关信息记录到日志中，但当前报文具体是被”接受”，还是被”拒绝”，都由后面的规则控制，换句话说，LOG动作只负责记录匹配到的报文的相关信息，不负责对报文的其他处理，如果想要对报文进行进一步的处理，可以在之后设置具体规则，进行进一步的处理。</p>
<p>示例如下，下例表示将发往22号端口的报文相关信息记录在日志中。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifak10004pwr75tri6w43/5.png" alt="iamge"></p>
<p>如上图所示，上述规则表示所有发往22号端口的tcp报文都符合条件，所以都会被记录到日志中，查看/var/log/messages即可看到对应报文的相关信息，但是上述规则只是用于示例，因为上例中使用的匹配条件过于宽泛，所以匹配到的报文数量将会非常之多，记录到的信息也不利于分析，所以在使用LOG动作时，匹配条件应该尽量写的精确一些，匹配到的报文数量也会大幅度的减少，这样冗余的日志信息就会变少，同时日后分析日志时，日志中的信息可用程度更高。</p>
<p>注：请把刚才用于示例的规则删除。</p>
<p>从刚才的示例中我们已经了解到，LOG动作会将报文的相关信息记录在/var/log/message文件中，当然，我们也可以将相关信息记录在指定的文件中，以防止iptables的相关信息与其他日志信息相混淆，修改/etc/rsyslog.conf文件（或者/etc/syslog.conf），在rsyslog配置文件中添加如下配置即可。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">vim /etc/rsyslog.conf</span></span><br><span class="line"></span><br><span class="line">kern.warning /var/log/iptables.log</span><br></pre></td></tr></table></figure></div>

<p>加入上述配置后，报文的相关信息将会被记录到/var/log/iptables.log文件中。</p>
<p>完成上述配置后，重启rsyslog服务（或者syslogd）</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">service rsyslog restart</span></span><br></pre></td></tr></table></figure></div>

<p>服务重启后，配置即可生效，匹配到的报文的相关信息将被记录到指定的文件中。</p>
<p>LOG动作也有自己的选项，常用选项如下（先列出概念，后面有示例）</p>
<ul>
<li><p>–log-level选项可以指定记录日志的日志级别，可用级别有emerg，alert，crit，error，warning，notice，info，debug。</p>
</li>
<li><p>–log-prefix选项可以给记录到的相关信息添加”标签”之类的信息，以便区分各种记录到的报文信息，方便在分析时进行过滤。</p>
</li>
</ul>
<p>注：–log-prefix对应的值不能超过29个字符。</p>
<p>比如，我想要将主动连接22号端口的报文的相关信息都记录到日志中，并且把这类记录命名为”want-in-from-port-22″,则可以使用如下命令</p>
<p><img src="/2022/06/13/uncatalog/cl4cifak10004pwr75tri6w43/6.png" alt="iamge"></p>
<p>完成上述配置后，我在IP地址为192.168.1.98的客户端机上，尝试使用ssh工具连接上例中的主机，然后查看对应的日志文件（已经将日志文件设置为/var/log/iptables.log）</p>
<p>如上图所示，ssh连接操作的报文的相关信息已经被记录到了iptables.log日志文件中，而且这条日志中包含”标签”：want-in-from-port-22，如果有很多日志记录，我们就能通过这个”标签”进行筛选了，这样方便我们查看日志，同时，从上述记录中还能够得知报文的源IP与目标IP，源端口与目标端口等信息，从上述日志我们能够看出，192.168.1.98这个IP想要在14点11分连接到192.168.1.139（当前主机的IP）的22号端口，报文由eth4网卡进入，eth4网卡的MAC地址为00:0C:29:B7:F4:D1，客户端网卡的mac地址为F4-8E-38-82-B1-29。</p>
<p>除了ACCEPT、DROP、REJECT、LOG等动作，还有一些其他的常用动作，比如DNAT、SNAT等，我们会在之后的文章中对它们进行总结。</p>
]]></content>
      <tags>
        <tag>云原生基础系列</tag>
        <tag>Kubernetes网络</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes网络系列之(二十一)iptables概念</title>
    <url>/2022/06/13/uncatalog/cl4cifak60008pwr77vkbd1sn/</url>
    <content><![CDATA[<hr>
<span id="more"></span>



<hr>
<blockquote>
<p>这篇文章会尽量以通俗易懂的方式描述iptables的相关概念，请耐心的读完它</p>
</blockquote>
<h3 id="防火墙相关概念"><a href="#防火墙相关概念" class="headerlink" title="防火墙相关概念"></a>防火墙相关概念</h3><p>此处先描述一些相关概念。</p>
<p>从逻辑上讲。防火墙可以大体分为主机防火墙和网络防火墙。</p>
<p>主机防火墙：针对于单个主机进行防护。</p>
<p>网络防火墙：往往处于网络入口或边缘，针对于网络入口进行防护，服务于防火墙背后的本地局域网。</p>
<p>网络防火墙和主机防火墙并不冲突，可以理解为，网络防火墙主外（集体）， 主机防火墙主内（个人）。</p>
<p>从物理上讲，防火墙可以分为硬件防火墙和软件防火墙。</p>
<p>硬件防火墙：在硬件级别实现部分防火墙功能，另一部分功能基于软件实现，性能高，成本高。</p>
<p>软件防火墙：应用软件处理逻辑运行于通用硬件平台之上的防火墙，性能低，成本低。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifak60008pwr77vkbd1sn/1.png" alt="image"></p>
<p>那么在此处，我们就来聊聊Linux的iptables</p>
<p>iptables其实不是真正的防火墙，我们可以把它理解成一个客户端代理，用户通过iptables这个代理，将用户的安全设定执行到对应的”安全框架”中，这个”安全框架”才是真正的防火墙，这个框架的名字叫netfilter</p>
<p>netfilter才是防火墙真正的安全框架（framework），netfilter位于内核空间。</p>
<p>iptables其实是一个命令行工具，位于用户空间，我们用这个工具操作真正的框架。</p>
<p>netfilter/iptables（下文中简称为iptables）组成Linux平台下的包过滤防火墙，与大多数的Linux软件一样，这个包过滤防火墙是免费的，它可以代替昂贵的商业防火墙解决方案，完成封包过滤、封包重定向和网络地址转换（NAT）等功能。</p>
<p>Netfilter是Linux操作系统核心层内部的一个数据包处理模块，它具有如下功能：</p>
<p>网络地址转换(Network Address Translate)</p>
<p>数据包内容修改</p>
<p>以及数据包过滤的防火墙功能</p>
<p>所以说，虽然我们使用service iptables start启动iptables”服务”，但是其实准确的来说，iptables并没有一个守护进程，所以并不能算是真正意义上的服务，而应该算是内核提供的功能。</p>
<h3 id="iptables基础"><a href="#iptables基础" class="headerlink" title="iptables基础"></a>iptables基础</h3><p>我们知道iptables是按照规则来办事的，我们就来说说规则（rules），规则其实就是网络管理员预定义的条件，规则一般的定义为”如果数据包头符合这样的条件，就这样处理这个数据包”。规则存储在内核空间的信息包过滤表中，这些规则分别指定了源地址、目的地址、传输协议（如TCP、UDP、ICMP）和服务类型（如HTTP、FTP和SMTP）等。当数据包与规则匹配时，iptables就根据规则所定义的方法来处理这些数据包，如放行（accept）、拒绝（reject）和丢弃（drop）等。配置防火墙的主要工作就是添加、修改和删除这些规则。</p>
<p>这样说可能并不容易理解，我们来换个容易理解的角度，从头说起.</p>
<p>当客户端访问服务器的web服务时，客户端发送报文到网卡，而tcp/ip协议栈是属于内核的一部分，所以，客户端的信息会通过内核的TCP协议传输到用户空间中的web服务中，而此时，客户端报文的目标终点为web服务所监听的套接字（IP：Port）上，当web服务需要响应客户端请求时，web服务发出的响应报文的目标终点则为客户端，这个时候，web服务所监听的IP与端口反而变成了原点，我们说过，netfilter才是真正的防火墙，它是内核的一部分，所以，如果我们想要防火墙能够达到”防火”的目的，则需要在内核中设置关卡，所有进出的报文都要通过这些关卡，经过检查后，符合放行条件的才能放行，符合阻拦条件的则需要被阻止，于是，就出现了input关卡和output关卡，而这些关卡在iptables中不被称为”关卡”,而被称为”链”。<br><img src="/2022/06/13/uncatalog/cl4cifak60008pwr77vkbd1sn/2.png" alt="image"></p>
<p>其实我们上面描述的场景并不完善，因为客户端发来的报文访问的目标地址可能并不是本机，而是其他服务器，当本机的内核支持IP_FORWARD时，我们可以将报文转发给其他服务器，所以，这个时候，我们就会提到iptables中的其他”关卡”，也就是其他”链”，他们就是  “路由前”、”转发”、”路由后”，他们的英文名是</p>
<p>PREROUTING、FORWARD、POSTROUTING</p>
<p>也就是说，当我们启用了防火墙功能时，报文需要经过如下关卡，也就是说，根据实际情况的不同，报文经过”链”可能不同。如果报文需要转发，那么报文则不会经过input链发往用户空间，而是直接在内核空间中经过forward链和postrouting链转发出去的。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifak60008pwr77vkbd1sn/3.png" alt="image"></p>
<p>所以，根据上图，我们能够想象出某些常用场景中，报文的流向：</p>
<p>到本机某进程的报文：PREROUTING –&gt; INPUT</p>
<p>由本机转发的报文：PREROUTING –&gt; FORWARD –&gt; POSTROUTING</p>
<p>由本机的某进程发出报文（通常为响应报文）：OUTPUT –&gt; POSTROUTING</p>
<h3 id="链的概念"><a href="#链的概念" class="headerlink" title="链的概念"></a>链的概念</h3><p>现在，我们想象一下，这些”关卡”在iptables中为什么被称作”链”呢？我们知道，防火墙的作用就在于对经过的报文匹配”规则”，然后执行对应的”动作”,所以，当报文经过这些关卡的时候，则必须匹配这个关卡上的规则，但是，这个关卡上可能不止有一条规则，而是有很多条规则，当我们把这些规则串到一个链条上的时候，就形成了”链”,所以，我们把每一个”关卡”想象成如下图中的模样  ，这样来说，把他们称为”链”更为合适，每个经过这个”关卡”的报文，都要将这条”链”上的所有规则匹配一遍，如果有符合条件的规则，则执行规则对应的动作。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifak60008pwr77vkbd1sn/4.png" alt="image"></p>
<h3 id="表的概念"><a href="#表的概念" class="headerlink" title="表的概念"></a>表的概念</h3><p>我们再想想另外一个问题，我们对每个”链”上都放置了一串规则，但是这些规则有些很相似，比如，A类规则都是对IP或者端口的过滤，B类规则是修改报文，那么这个时候，我们是不是能把实现相同功能的规则放在一起呢，必须能的。</p>
<p>我们把具有相同功能的规则的集合叫做”表”，所以说，不同功能的规则，我们可以放置在不同的表中进行管理，而iptables已经为我们定义了4种表，每种表对应了不同的功能，而我们定义的规则也都逃脱不了这4种功能的范围，所以，学习iptables之前，我们必须先搞明白每种表 的作用。</p>
<p>iptables为我们提供了如下规则的分类，或者说，iptables为我们提供了如下”表”</p>
<p>filter表：负责过滤功能，防火墙；内核模块：iptables_filter</p>
<p>nat表：network address translation，网络地址转换功能；内核模块：iptable_nat</p>
<p>mangle表：拆解报文，做出修改，并重新封装 的功能；iptable_mangle</p>
<p>raw表：关闭nat表上启用的连接追踪机制；iptable_raw</p>
<p>也就是说，我们自定义的所有规则，都是这四种分类中的规则，或者说，所有规则都存在于这4张”表”中。</p>
<h3 id="表链关系"><a href="#表链关系" class="headerlink" title="表链关系"></a>表链关系</h3><p>但是我们需要注意的是，某些”链”中注定不会包含”某类规则”，就像某些”关卡”天生就不具备某些功能一样，比如，A”关卡”只负责打击陆地敌人，没有防空能力，B”关卡”只负责打击空中敌人，没有防御步兵的能力，C”关卡”可能比较NB，既能防空，也能防御陆地敌人，D”关卡”最屌，海陆空都能防。</p>
<p>那让我们来看看，每个”关卡”都有哪些能力，或者说，让我们看看每个”链”上的规则都存在于哪些”表”中。</p>
<p>我们还是以图为例，先看看prerouting”链”上的规则都存在于哪些表中。</p>
<p>注意：下图只用于说明prerouting链上的规则存在于哪些表中，并没有描述表的顺序。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifak60008pwr77vkbd1sn/5.png" alt="image"></p>
<p>这幅图是什么意思呢？它的意思是说，prerouting”链”只拥有nat表、raw表和mangle表所对应的功能，所以，prerouting中的规则只能存放于nat表、raw表和mangle表中。</p>
<p>那么，根据上述思路，我们来总结一下，每个”关卡”都拥有什么功能，</p>
<p>或者说，每个”链”中的规则都存在于哪些”表”中。</p>
<p>PREROUTING      的规则可以存在于：raw表，mangle表，nat表。</p>
<p>INPUT          的规则可以存在于：mangle表，filter表，（centos7中还有nat表，centos6中没有）。</p>
<p>FORWARD         的规则可以存在于：mangle表，filter表。</p>
<p>OUTPUT         的规则可以存在于：raw表mangle表，nat表，filter表。</p>
<p>POSTROUTING      的规则可以存在于：mangle表，nat表。</p>
<p>但是，我们在实际的使用过程中，往往是通过”表”作为操作入口，对规则进行定义的，之所以按照上述过程介绍iptables，是因为从”关卡”的角度更容易从入门的角度理解，但是为了以便在实际使用的时候，更加顺畅的理解它们，此处我们还要将各”表”与”链”的关系罗列出来，</p>
<p>表（功能）&lt;–&gt;   链（钩子）：</p>
<p>raw     表中的规则可以被哪些链使用：PREROUTING，OUTPUT</p>
<p>mangle  表中的规则可以被哪些链使用：PREROUTING，INPUT，FORWARD，OUTPUT，POSTROUTING</p>
<p>nat     表中的规则可以被哪些链使用：PREROUTING，OUTPUT，POSTROUTING（centos7中还有INPUT，centos6中没有）</p>
<p>filter  表中的规则可以被哪些链使用：INPUT，FORWARD，OUTPUT</p>
<p>其实我们还需要注意一点，因为数据包经过一个”链”的时候，会将当前链的所有规则都匹配一遍，但是匹配时总归要有顺序，我们应该一条一条的去匹配，而且我们说过，相同功能类型的规则会汇聚在一张”表”中，那么，哪些”表”中的规则会放在”链”的最前面执行呢，这时候就需要有一个优先级的问题，我们还拿prerouting”链”做图示。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifak60008pwr77vkbd1sn/6.png" alt="image"></p>
<p>prerouting链中的规则存放于三张表中，而这三张表中的规则执行的优先级如下：</p>
<p>raw –&gt; mangle –&gt; nat</p>
<p>但是我们知道，iptables为我们定义了4张”表”,当他们处于同一条”链”时，执行的优先级如下。</p>
<p>优先级次序（由高而低）：</p>
<p>raw –&gt; mangle –&gt; nat –&gt; filter</p>
<p>但是我们前面说过，某些链天生就不能使用某些表中的规则，所以，4张表中的规则处于同一条链的目前只有output链，它就是传说中海陆空都能防守的关卡。</p>
<p>为了更方便的管理，我们还可以在某个表里面创建自定义链，将针对某个应用程序所设置的规则放置在这个自定义链中，但是自定义链接不能直接使用，只能被某个默认的链当做动作去调用才能起作用，我们可以这样想象，自定义链就是一段比较”短”的链子，这条”短”链子上的规则都是针对某个应用程序制定的，但是这条短的链子并不能直接使用，而是需要”焊接”在iptables默认定义链子上，才能被IPtables使用，这就是为什么默认定义的”链”需要把”自定义链”当做”动作”去引用的原因。这是后话，后面再聊，在实际使用时我们即可更加的明白。</p>
<h3 id="数据经过防火墙的流程"><a href="#数据经过防火墙的流程" class="headerlink" title="数据经过防火墙的流程"></a>数据经过防火墙的流程</h3><p>结合上述所有的描述，我们可以将数据包通过防火墙的流程总结为下图：</p>
<p><img src="/2022/06/13/uncatalog/cl4cifak60008pwr77vkbd1sn/7.png" alt="image"></p>
<p>我们在写Iptables规则的时候，要时刻牢记这张路由次序图，灵活配置规则。</p>
<p>我们将经常用到的对应关系重新写在此处，方便对应图例查看。</p>
<p>链的规则存放于哪些表中（从链到表的对应关系）：</p>
<p>PREROUTING   的规则可以存在于：raw表，mangle表，nat表。</p>
<p>INPUT        的规则可以存在于：mangle表，filter表，（centos7中还有nat表，centos6中没有）。</p>
<p>FORWARD      的规则可以存在于：mangle表，filter表。</p>
<p>OUTPUT       的规则可以存在于：raw表mangle表，nat表，filter表。</p>
<p>POSTROUTING  的规则可以存在于：mangle表，nat表。</p>
<p>表中的规则可以被哪些链使用（从表到链的对应关系）：</p>
<p>raw     表中的规则可以被哪些链使用：PREROUTING，OUTPUT</p>
<p>mangle  表中的规则可以被哪些链使用：PREROUTING，INPUT，FORWARD，OUTPUT，POSTROUTING</p>
<p>nat     表中的规则可以被哪些链使用：PREROUTING，OUTPUT，POSTROUTING（centos7中还有INPUT，centos6中没有）</p>
<p>filter  表中的规则可以被哪些链使用：INPUT，FORWARD，OUTPUT</p>
<p>下图中nat表在centos7中的情况就不再标明。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifak60008pwr77vkbd1sn/8.png" alt="image"></p>
<h3 id="规则的概念"><a href="#规则的概念" class="headerlink" title="规则的概念"></a>规则的概念</h3><p>说了一圈又说回来了，在上述描述中我们一直在提规则，可是没有细说，现在说说它。</p>
<p>先说说规则的概念，然后再通俗的解释它。</p>
<p>规则：根据指定的匹配条件来尝试匹配每个流经此处的报文，一旦匹配成功，则由规则后面指定的处理动作进行处理；</p>
<p>那么我们来通俗的解释一下什么是iptables的规则，之前打过一个比方，每条”链”都是一个”关卡”，每个通过这个”关卡”的报文都要匹配这个关卡上的规则，如果匹配，则对报文进行对应的处理，比如说，你我二人此刻就好像两个”报文”，你我二人此刻都要入关，可是城主有命，只有器宇轩昂的人才能入关，不符合此条件的人不能入关，于是守关将士按照城主制定的”规则”，开始打量你我二人，最终，你顺利入关了，而我已被拒之门外，因为你符合”器宇轩昂”的标准，所以把你”放行”了，而我不符合标准，所以没有被放行，其实，”器宇轩昂”就是一种”匹配条件”，”放行”就是一种”动作”，”匹配条件”与”动作”组成了规则。</p>
<p>了解了规则的概念，那我们来聊聊规则的组成部分,此处只是大概的将规则的结构列出，后面的文章中会单独对规则进行总结。</p>
<p>规则由匹配条件和处理动作组成。</p>
<h4 id="匹配条件"><a href="#匹配条件" class="headerlink" title="匹配条件"></a>匹配条件</h4><p>匹配条件分为基本匹配条件与扩展匹配条件</p>
<h4 id="基本匹配条件："><a href="#基本匹配条件：" class="headerlink" title="基本匹配条件："></a>基本匹配条件：</h4><p>源地址Source IP，目标地址 Destination IP</p>
<p>上述内容都可以作为基本匹配条件。</p>
<h4 id="扩展匹配条件："><a href="#扩展匹配条件：" class="headerlink" title="扩展匹配条件："></a>扩展匹配条件：</h4><p>除了上述的条件可以用于匹配，还有很多其他的条件可以用于匹配，这些条件泛称为扩展条件，这些扩展条件其实也是netfilter中的一部分，只是以模块的形式存在，如果想要使用这些条件，则需要依赖对应的扩展模块。</p>
<p>源端口Source Port, 目标端口Destination Port</p>
<p>上述内容都可以作为扩展匹配条件</p>
<h4 id="处理动作"><a href="#处理动作" class="headerlink" title="处理动作"></a>处理动作</h4><p>处理动作在iptables中被称为target（这样说并不准确，我们暂且这样称呼），动作也可以分为基本动作和扩展动作。</p>
<p>此处列出一些常用的动作，之后的文章会对它们进行详细的示例与总结：</p>
<ul>
<li><p>ACCEPT：允许数据包通过。</p>
</li>
<li><p>DROP：直接丢弃数据包，不给任何回应信息，这时候客户端会感觉自己的请求泥牛入海了，过了超时时间才会有反应。</p>
</li>
<li><p>REJECT：拒绝数据包通过，必要时会给数据发送端一个响应的信息，客户端刚请求就会收到拒绝的信息。</p>
</li>
<li><p>SNAT：源地址转换，解决内网用户用同一个公网地址上网的问题。</p>
</li>
<li><p>MASQUERADE：是SNAT的一种特殊形式，适用于动态的、临时会变的ip上。</p>
</li>
<li><p>DNAT：目标地址转换。</p>
</li>
<li><p>REDIRECT：在本机做端口映射。</p>
</li>
<li><p>LOG：在/var/log/messages文件中记录日志信息，然后将数据包传递给下一条规则，也就是说除了记录以外不对数据包做任何其他操作，仍然让下一条规则去匹配。</p>
</li>
</ul>
]]></content>
      <tags>
        <tag>云原生基础系列</tag>
        <tag>Kubernetes网络</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes网络系列之(二十七)iptables扩展之udp扩展与icmp扩展</title>
    <url>/2022/06/13/uncatalog/cl4cifak7000apwr7hgyg2fgs/</url>
    <content><![CDATA[<hr>
<span id="more"></span>

<hr>
<p>前文中总结了iptables的tcp扩展模块，此处，我们来总结一下另外两个跟协议有关的常用的扩展模块，udp扩展与icmp扩展。</p>
<h3 id="udp扩展"><a href="#udp扩展" class="headerlink" title="udp扩展"></a>udp扩展</h3><p>我们先来说说udp扩展模块，这个扩展模块中能用的匹配条件比较少，只有两个，就是–sport与–dport，即匹配报文的源端口与目标端口。</p>
<p>没错，tcp模块中也有这两个选项，名称都一模一样。</p>
<p>只不过udp扩展模块的–sport与–dport是用于匹配UDP协议报文的源端口与目标端口，比如，放行samba服务的137与138这两个UDP端口，示例如下</p>
<p><img src="/2022/06/13/uncatalog/cl4cifak7000apwr7hgyg2fgs/1.png" alt="image"></p>
<p>前文说明过，当使用扩展匹配条件时，如果未指定扩展模块，iptables会默认调用与”-p”对应的协议名称相同的模块，所以，当使用”-p udp”时，可以省略”-m udp”，示例如下。</p>
<p>udp扩展中的–sport与–dport同样支持指定一个连续的端口范围，示例如下</p>
<p><img src="/2022/06/13/uncatalog/cl4cifak7000apwr7hgyg2fgs/2.png" alt="image"></p>
<p>上图中的配置表示137到157之间的所有udp端口全部对外开放，其实与tcp扩展中的使用方法相同。<br><img src="/2022/06/13/uncatalog/cl4cifak7000apwr7hgyg2fgs/3.png" alt="image"><br>但是udp中的–sport与–dport也只能指定连续的端口范围，并不能一次性指定多个离散的端口，没错，聪明如你一定想到，使用之前总结过的multiport扩展模块，即可指定多个离散的UDP端口，如果你忘了multiport模块怎样使用，请回顾前文。</p>
<p>总之有了前文的基础，再理解上述示例就容易多了，此处不再对udp模块的–sport与–dport进行赘述。</p>
<h3 id="icmp扩展"><a href="#icmp扩展" class="headerlink" title="icmp扩展"></a>icmp扩展</h3><p>最常用的tcp扩展、udp扩展已经总结完毕，现在聊聊icmp扩展，没错，看到icmp，你肯定就想到了ping命令，因为ping命令使用的就是icmp协议。</p>
<p>ICMP协议的全称为Internet Control Message Protocol，翻译为互联网控制报文协议，它主要用于探测网络上的主机是否可用，目标是否可达，网络是否通畅，路由是否可用等。</p>
<p>我们平常使用ping命令ping某主机时，如果主机可达，对应主机会对我们的ping请求做出回应（此处不考虑禁ping等情况），也就是说，我们发出ping请求，对方回应ping请求，虽然ping请求报文与ping回应报文都属于ICMP类型的报文，但是如果在概念上细分的话，它们所属的类型还是不同的，我们发出的ping请求属于类型8的icmp报文，而对方主机的ping回应报文则属于类型0的icmp报文，根据应用场景的不同，icmp报文被细分为如下各种类型。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifak7000apwr7hgyg2fgs/4.png" alt="image"></p>
<p>从上图可以看出，所有表示”目标不可达”的icmp报文的type码为3，而”目标不可达”又可以细分为多种情况，是网络不可达呢？还是主机不可达呢？再或者是端口不可达呢？所以，为了更加细化的区分它们，icmp对每种type又细分了对应的code，用不同的code对应具体的场景，  所以，我们可以使用type/code去匹配具体类型的ICMP报文，比如可以使用”3/1″表示主机不可达的icmp报文。</p>
<p>上图中的第一行就表示ping回应报文，它的type为0，code也为0，从上图可以看出，ping回应报文属于查询类（query）的ICMP报文，从大类上分，ICMP报文还能分为查询类与错误类两大类，目标不可达类的icmp报文则属于错误类报文。</p>
<p>而我们发出的ping请求报文对应的type为8，code为0。</p>
<p>了解完上述概念，就好办了，我们来看一些应用场景。</p>
<p>假设，我们现在想要禁止所有icmp类型的报文进入本机，那么我们可以进行如下设置。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifak7000apwr7hgyg2fgs/5.png" alt="image"><br>上例中，我们并没有使用任何扩展匹配条件，我们只是使用”-p icmp”匹配了所有icmp协议类型的报文。</p>
<p>如果进行了上述设置，别的主机向我们发送的ping请求报文无法进入防火墙，我们向别人发送的ping请求对应的回应报文也无法进入防火墙。所以，我们既无法ping通别人，别人也无法ping通我们。</p>
<p>假设，此刻需求有变，我们只想要ping通别人，但是不想让别人ping通我们，刚才的配置就不能满足我们了，我们则可以进行如下设置（此处不考虑禁ping的情况）</p>
<p><img src="/2022/06/13/uncatalog/cl4cifak7000apwr7hgyg2fgs/6.png" alt="image"><br>上图中，使用”-m icmp”表示使用icmp扩展，因为上例中使用了”-p icmp”，所以”-m icmp”可以省略，使用”–icmp-type”选项表示根据具体的type与code去匹配对应的icmp报文，而上图中的”–icmp-type 8/0″表示icmp报文的type为8，code为0才会被匹配到，也就是只有ping请求类型的报文才能被匹配到，所以，别人对我们发起的ping请求将会被拒绝通过防火墙，而我们之所以能够ping通别人，是因为别人回应我们的报文的icmp type为0，code也为0，所以无法被上述规则匹配到，所以我们可以看到别人回应我们的信息。</p>
<p>因为type为8的类型下只有一个code为0的类型，所以我们可以省略对应的code，示例如下</p>
<p><img src="/2022/06/13/uncatalog/cl4cifak7000apwr7hgyg2fgs/7.png" alt="image"></p>
<p>除了能够使用对应type/code匹配到具体类型的icmp报文以外，我们还能用icmp报文的描述名称去匹配对应类型的报文，示例如下</p>
<p>没错，上例中使用的 –icmp-type “echo-request”与 –icmp-type 8/0的效果完全相同，参考本文最上方的表格即可获取对应的icmp类型的描述名称。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifak7000apwr7hgyg2fgs/8.png" alt="image"><br>注意：名称中的”空格”需要替换为”-“。</p>
<p>小结<br>udp扩展<br>常用的扩展匹配条件</p>
<ul>
<li><p>–sport：匹配udp报文的源地址</p>
</li>
<li><p>–dport：匹配udp报文的目标地址</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">示例</span></span><br><span class="line">iptables -t filter -I INPUT -p udp -m udp --dport 137 -j ACCEPT</span><br><span class="line">iptables -t filter -I INPUT -p udp -m udp --dport 137:157 -j ACCEPT</span><br><span class="line"><span class="meta">#</span><span class="bash">可以结合multiport模块指定多个离散的端口</span></span><br></pre></td></tr></table></figure></div></li>
</ul>
<p>icmp扩展<br>常用的扩展匹配条件</p>
<p>–icmp-type：匹配icmp报文的具体类型</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">示例</span></span><br><span class="line">iptables -t filter -I INPUT -p icmp -m icmp --icmp-type 8/0 -j REJECT</span><br><span class="line">iptables -t filter -I INPUT -p icmp --icmp-type 8 -j REJECT</span><br><span class="line">iptables -t filter -I OUTPUT -p icmp -m icmp --icmp-type 0/0 -j REJECT</span><br><span class="line">iptables -t filter -I OUTPUT -p icmp --icmp-type 0 -j REJECT</span><br><span class="line">iptables -t filter -I INPUT -p icmp --icmp-type &quot;echo-request&quot; -j REJECT</span><br></pre></td></tr></table></figure></div>]]></content>
      <tags>
        <tag>云原生基础系列</tag>
        <tag>Kubernetes网络</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes网络系列之(二十九)iptables的黑白名单机制</title>
    <url>/2022/06/13/uncatalog/cl4cifak8000cpwr739275b4h/</url>
    <content><![CDATA[<hr>
<span id="more"></span>

<hr>
<p>前文中一直在强调一个概念：报文在经过iptables的链时，会匹配链中的规则，遇到匹配的规则时，就执行对应的动作，如果链中的规则都无法匹配到当前报文，则使用链的默认策略（默认动作），链的默认策略通常设置为ACCEPT或者DROP。</p>
<p>那么，当链的默认策略设置为ACCEPT时，如果对应的链中没有配置任何规则，就表示接受所有的报文，如果对应的链中存在规则，但是这些规则没有匹配到报文，报文还是会被接受。</p>
<p>同理，当链的默认策略设置为DROP时，如果对应的链中没有配置任何规则，就表示拒绝所有报文，如果对应的链中存在规则，但是这些规则没有匹配到报文，报文还是会被拒绝。</p>
<p>所以，当链的默认策略设置为ACCEPT时，按照道理来说，我们在链中配置规则时，对应的动作应该设置为DROP或者REJECT，为什么呢？</p>
<p>因为默认策略已经为ACCEPT了，如果我们在设置规则时，对应动作仍然为ACCEPT，那么所有报文都会被放行了，因为不管报文是否被规则匹配到都会被ACCEPT，所以就失去了访问控制的意义。</p>
<p>所以，当链的默认策略为ACCEPT时，链中的规则对应的动作应该为DROP或者REJECT，表示只有匹配到规则的报文才会被拒绝，没有被规则匹配到的报文都会被默认接受，这就是”黑名单”机制。</p>
<p>同理，当链的默认策略为DROP时，链中的规则对应的动作应该为ACCEPT，表示只有匹配到规则的报文才会被放行，没有被规则匹配到的报文都会被默认拒绝，这就是”白名单”机制。</p>
<p>如果使用白名单机制，我们就要把所有人都当做坏人，只放行好人。</p>
<p>如果使用黑名单机制，我们就要把所有人都当成好人，只拒绝坏人。</p>
<p>白名单机制似乎更加安全一些，黑名单机制似乎更加灵活一些。</p>
<p>那么，我们就来做一个简单的白名单吧，也就是说，只放行被规则匹配到的报文，其他报文一律拒绝，那么，我们先来配置规则。</p>
<p>假设，我想要放行ssh远程连接相关的报文，也想要放行web服务相关的报文，那么，我们在INPUT链中添加如下规则。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifak8000cpwr739275b4h/1.png" alt="image"></p>
<p>如上图所示，我们已经放行了特定的报文，只有上述两条规则匹配到的报文才会被放行，现在，我们只要将INPUT链的默认策略改为DROP，即可实现白名单机制。</p>
<p>示例如下。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifak8000cpwr739275b4h/2.png" alt="image"></p>
<p>上图中，我们已经将INPUT链的默认策略改为DROP，并且已经实现了所谓的白名单机制，即默认拒绝所有报文，只放行特定的报文。</p>
<p>如果此时，我不小心执行了”iptables -F”操作，根据我们之前学到的知识去判断，我们还能够通过ssh工具远程到服务器上吗？</p>
<p>我想你已经判断出了正确答案，没错，按照上图中的情况，如果此时执行”iptables -F”操作，filter表中的所有链中的所有规则都会被清空，而INPUT链的默认策略为DROP，所以所有报文都会被拒绝，不止ssh远程请求会被拒绝，其他报文也会被拒绝，我们来实验一下。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifak8000cpwr739275b4h/3.png" alt="image"></p>
<p>如上图所示，在当前ssh远程工具中执行”iptables -F”命令后，由于INPUT链中已经不存在任何规则，所以，所有报文都被拒绝了，包括当前的ssh远程连接。</p>
<p>这就是默认策略设置为DROP的缺点，在对应的链中没有设置任何规则时，这样使用默认策略为DROP是非常不明智的，因为管理员也会把自己拒之门外，即使对应的链中存在放行规则，当我们不小心使用”iptables -F”清空规则时，放行规则被删除，则所有数据包都无法进入，这个时候就相当于给管理员挖了个坑，所以，我们如果想要使用”白名单”的机制，最好将链的默认策略保持为”ACCEPT”，然后将”拒绝所有请求”这条规则放在链的尾部，将”放行规则”放在前面，这样做，既能实现”白名单”机制，又能保证在规则被清空时，管理员还有机会连接到主机，示例如下。</p>
<p>因为刚才的ssh连接已经被拒绝，所以，此时直接在控制台中设置iptables规则</p>
<p><img src="/2022/06/13/uncatalog/cl4cifak8000cpwr739275b4h/4.png" alt="image"></p>
<p>如上图所示，先将INPUT链的默认策略设置为ACCEPT</p>
<p>然后继续配置需要放行的报文的规则，如下图所示，当所有放行规则设置完成后，在INPUT链的尾部，设置一条拒绝所有请求的规则。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifak8000cpwr739275b4h/5.png" alt="image"></p>
<p>上图中的设置，既将INPUT链的默认策略设置为了ACCEPT，同时又使用了白名单机制，因为如果报文符合放行条件，则会被前面的放行规则匹配到，如果报文不符合放行条件，则会被最后一条拒绝规则匹配到，此刻，即使我们误操作，执行了”iptables -F”操作，也能保证管理员能够远程到主机上进行维护，因为默认策略仍然是ACCEPT。</p>
]]></content>
      <tags>
        <tag>云原生基础系列</tag>
        <tag>Kubernetes网络</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes网络系列之(二十二)iptables实际操作之规则查询</title>
    <url>/2022/06/13/uncatalog/cl4cifak9000epwr7cx322y2s/</url>
    <content><![CDATA[<hr>
<span id="more"></span>



<hr>
<p>如果你是一个新手，在阅读如下文章时，请坚持读到最后，读的过程中可能会有障碍，但是在读完以后，你会发现你已经明白了。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifak9000epwr7cx322y2s/1.jpg" alt="image"></p>
<p>在进行iptables实验时，请务必在测试机上进行。</p>
<p>之前在iptables的概念中已经提到过，在实际操作iptables的过程中，是以”表”作为操作入口的，如果你经常操作关系型数据库，那么当你听到”表”这个词的时候，你可能会联想到另一个词—-“增删改查”，当我们定义iptables规则时，所做的操作其实类似于”增删改查”，那么，我们就先从最简单的”查”操作入手，开始实际操作iptables。</p>
<p>在之前的文章中，我们已经总结过，iptables为我们预定义了4张表，它们分别是raw表、mangle表、nat表、filter表，不同的表拥有不同的功能。</p>
<p>filter负责过滤功能，比如允许哪些IP地址访问，拒绝哪些IP地址访问，允许访问哪些端口，禁止访问哪些端口，filter表会根据我们定义的规则进行过滤，filter表应该是我们最常用到的表了，所以此处，我们以filter表为例，开始学习怎样实际操作iptables。</p>
<p>怎样查看filter表中的规则呢？使用如下命令即可查看。<br><img src="/2022/06/13/uncatalog/cl4cifak9000epwr7cx322y2s/2.png" alt="image"></p>
<p>上例中，我们使用-t选项，指定要操作的表，使用-L选项，查看-t选项对应的表的规则，-L选项的意思是，列出规则，所以，上述命令的含义为列出filter表的所有规则，注意，上图中显示的规则（绿色标注的部分为规则）是Centos6启动iptables以后默认设置的规则，我们暂且不用在意它们，上图中，显示出了3条链（蓝色标注部分为链），INPUT链、FORWARD链、OUTPUT链，每条链中都有自己的规则，前文中，我们打过一个比方，把”链”比作”关卡”，不同的”关卡”拥有不同的能力，所以，从上图中可以看出，INPUT链、FORWARD链、OUTPUT链都拥有”过滤”的能力，所以，当我们要定义某条”过滤”的规则时，我们会在filter表中定义，但是具体在哪条”链”上定义规则呢？这取决于我们的工作场景。比如，我们需要禁止某个IP地址访问我们的主机，我们则需要在INPUT链上定义规则。因为，我们在理论总结中已经提到过，报文发往本机时，会经过PREROUTING链与INPUT链（如果你没有明白，请回顾前文），所以，如果我们想要禁止某些报文发往本机，我们只能在PREROUTING链和INPUT链中定义规则，但是PREROUTING链并不存在于filter表中，换句话说就是，PREROUTING关卡天生就没有过滤的能力，所以，我们只能在INPUT链中定义，当然，如果是其他工作场景，可能需要在FORWARD链或者OUTPUT链中定义过滤规则。</p>
<p>话说回来，我们继续聊怎样查看某张表中的规则。</p>
<p>刚才提到，我们可以使用iptables -t filter -L命令列出filter表中的所有规则，那么举一反三，我们也可以查看其它表中的规则，示例如下。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">iptables -t raw -L</span><br><span class="line"></span><br><span class="line">iptables -t mangle -L</span><br><span class="line"></span><br><span class="line">iptables -t nat -L</span><br></pre></td></tr></table></figure></div>

<p>其实，我们可以省略-t filter，当没有使用-t选项指定表时，默认为操作filter表，即iptables -L表示列出filter表中的所有规则。</p>
<p>我们还可以只查看指定表中的指定链的规则，比如，我们只查看filter表中INPUT链的规则，示例如下（注意大小写）。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifak9000epwr7cx322y2s/3.png" alt="image"></p>
<p>上图中只显示了filter表中INPUT链中的规则（省略-t选项默认为filter表），当然，你也可以指定只查看其他链，其实，我们查看到的信息还不是最详细的信息，我们可以使用-v选项，查看出更多的、更详细的信息，示例如下。<br><img src="/2022/06/13/uncatalog/cl4cifak9000epwr7cx322y2s/4.png" alt="image"></p>
<p>可以看到，使用-v选项后，iptables为我们展示的信息更多了，那么，这些字段都是什么意思呢？我们来总结一下，看不懂没关系，等到实际使用的时候，自然会明白，此处大概了解一下即可。</p>
<p>其实，这些字段就是规则对应的属性，说白了就是规则的各种信息，那么我们来总结一下这些字段的含义。</p>
<ul>
<li><p>pkts:对应规则匹配到的报文的个数。</p>
</li>
<li><p>bytes:对应匹配到的报文包的大小总和。</p>
</li>
<li><p>target:规则对应的target，往往表示规则对应的”动作”，即规则匹配成功后需要采取的措施。</p>
</li>
<li><p>prot:表示规则对应的协议，是否只针对某些协议应用此规则。</p>
</li>
<li><p>opt:表示规则对应的选项。</p>
</li>
<li><p>in:表示数据包由哪个接口(网卡)流入，即从哪个网卡来。</p>
</li>
<li><p>out:表示数据包将由哪个接口(网卡)流出，即到哪个网卡去。</p>
</li>
<li><p>source:表示规则对应的源头地址，可以是一个IP，也可以是一个网段。</p>
</li>
<li><p>destination:表示规则对应的目标地址。可以是一个IP，也可以是一个网段。</p>
</li>
</ul>
<p>细心如你一定发现了，上图中的源地址与目标地址都为anywhere，看来，iptables默认为我们进行了名称解析，但是在规则非常多的情况下如果进行名称解析，效率会比较低，所以，在没有此需求的情况下，我们可以使用-n选项，表示不对IP地址进行名称反解，直接显示IP地址，示例如下。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifak9000epwr7cx322y2s/5.png" alt="image"></p>
<p>如上图所示，规则中的源地址与目标地址已经显示为IP，而非转换后的名称。</p>
<p>当然，我们也可以只查看某个链的规则，并且不让IP进行反解，这样更清晰一些，比如 iptables -nvL INPUT</p>
<p>如果你习惯了查看有序号的列表，你在查看iptables表中的规则时肯定会很不爽，没有关系，满足你，使用–line-numbers即可显示规则的编号，示例如下。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifak9000epwr7cx322y2s/6.png" alt="image"></p>
<p>–line-numbers选项并没有对应的短选项，不过我们缩写成–line时，centos中的iptables也可以识别。</p>
<p>我知道你目光如炬，你可能早就发现了，表中的每个链的后面都有一个括号，括号里面有一些信息，如下图红色标注位置，那么这些信息都代表了什么呢？我们来看看。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifak9000epwr7cx322y2s/7.png" alt="image"></p>
<p>上图中INPUT链后面的括号中包含policy ACCEPT ，0 packets，0bytes 三部分。</p>
<ul>
<li><p>policy表示当前链的默认策略，policy ACCEPT表示上图中INPUT的链的默认动作为ACCEPT，换句话说就是，默认接受通过INPUT关卡的所有请求，所以我们在配置INPUT链的具体规则时，应该将需要拒绝的请求配置到规则中，说白了就是”黑名单”机制，默认所有人都能通过，只有指定的人不能通过，当我们把INPUT链默认动作设置为接受(ACCEPT)，就表示所有人都能通过这个关卡，此时就应该在具体的规则中指定需要拒绝的请求，就表示只有指定的人不能通过这个关卡，这就是黑名单机制，但是，你一定发现了，上图中所显示出的规则，大部分都是接受请求(ACCEPT)，并不是想象中的拒绝请求(DROP或者REJECT)，这与我们所描述的黑名单机制不符啊，按照道理来说，默认动作为接受，就应该在具体的规则中配置需要拒绝的人，但是上图中并不是这样的，之所以出现上图中的情况，是因为IPTABLES的工作机制导致到，上例其实是利用了这些”机制”，完成了所谓的”白名单”机制，并不是我们所描述的”黑名单”机制，我们此处暂时不用关注这一点，之后会进行详细的举例并解释，此处我们只要明白policy对应的动作为链的默认动作即可，或者换句话说，我们只要理解，policy为链的默认策略即可。</p>
</li>
<li><p>packets表示当前链（上例为INPUT链）默认策略匹配到的包的数量，0 packets表示默认策略匹配到0个包。</p>
</li>
<li><p>bytes表示当前链默认策略匹配到的所有包的大小总和。</p>
</li>
</ul>
<p>其实，我们可以把packets与bytes称作”计数器”，上图中的计数器记录了默认策略匹配到的报文数量与总大小，”计数器”只会在使用-v选项时，才会显示出来。</p>
<p>当被匹配到的包达到一定数量时，计数器会自动将匹配到的包的大小转换为可读性较高的单位，如下图所示。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifak9000epwr7cx322y2s/8.png" alt="image"></p>
<p>如果你想要查看精确的计数值，而不是经过可读性优化过的计数值，那么你可以使用-x选项，表示显示精确的计数值，示例如下。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifak9000epwr7cx322y2s/9.png" alt="image"></p>
<p>每张表中的每条链都有自己的计数器，链中的每个规则也都有自己的计数器，没错，就是每条规则对应的pkts字段与bytes字段的信息。</p>
<p>命令小节<br>好了，我们已经会使用命令简单的查看iptables表的规则了，为了方便以后回顾，我们将上文中的相关命令总结一下。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">iptables -t 表名 -L</span><br></pre></td></tr></table></figure></div>
<p>查看对应表的所有规则，-t选项指定要操作的表，省略”-t 表名”时，默认表示操作filter表，-L表示列出规则，即查看规则。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">iptables -t 表名 -L 链名</span><br></pre></td></tr></table></figure></div>

<p>查看指定表的指定链中的规则。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">iptables -t 表名 -v -L</span><br></pre></td></tr></table></figure></div>
<p>查看指定表的所有规则，并且显示更详细的信息（更多字段），-v表示verbose，表示详细的，冗长的，当使用-v选项时，会显示出”计数器”的信息，由于上例中使用的选项都是短选项，所以一般简写为iptables -t 表名 -vL</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">iptables -t 表名 -n -L</span><br></pre></td></tr></table></figure></div>
<p>表示查看表的所有规则，并且在显示规则时，不对规则中的IP或者端口进行名称反解，-n选项表示不解析IP地址。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">iptables --line-numbers -t 表名 -L</span><br></pre></td></tr></table></figure></div>
<p>表示查看表的所有规则，并且显示规则的序号，–line-numbers选项表示显示规则的序号，注意，此选项为长选项，不能与其他短选项合并，不过此选项可以简写为–line，注意，简写后仍然是两条横杠，仍然是长选项。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">iptables -t 表名 -v -x -L</span><br></pre></td></tr></table></figure></div>
<p>表示查看表中的所有规则，并且显示更详细的信息(-v选项)，不过，计数器中的信息显示为精确的计数值，而不是显示为经过可读优化的计数值，-x选项表示显示计数器的精确值。</p>
<p>实际使用中，为了方便，往往会将短选项进行合并，所以，如果将上述选项都糅合在一起，可以写成如下命令，此处以filter表为例。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">iptables --line -t filter -nvxL</span><br></pre></td></tr></table></figure></div>
<p>当然，也可以只查看某张表中的某条链，此处以filter表的INPUT链为例</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">iptables --line -t filter -nvxL INPUT</span><br></pre></td></tr></table></figure></div>
<p>好了，怎样使用iptables命令进行基本的查看操作，就先总结到这里吧，下一篇文章会总结iptables规则的”增、删、改”操作，直达链接如下：</p>
]]></content>
      <tags>
        <tag>云原生基础系列</tag>
        <tag>Kubernetes网络</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes网络系列之(二十八)iptables扩展模块之state扩展</title>
    <url>/2022/06/13/uncatalog/cl4cifaka000gpwr787db5toi/</url>
    <content><![CDATA[<hr>
<span id="more"></span>

<hr>
<p>当我们通过http的url访问某个网站的网页时，客户端向服务端的80端口发起请求，服务端再通过80端口响应我们的请求，于是，作为客户端，我们似乎应该理所应当的放行80端口，以便服务端回应我们的报文可以进入客户端主机，于是，我们在客户端放行了80端口，同理，当我们通过ssh工具远程连接到某台服务器时，客户端向服务端的22号端口发起请求，服务端再通过22号端口响应我们的请求，于是我们理所应当的放行了所有22号端口，以便远程主机的响应请求能够通过防火墙，但是，作为客户端，如果我们并没有主动向80端口发起请求，也没有主动向22号端口发起请求，那么其他主机通过80端口或者22号端口向我们发送数据时，我们可以接收到吗？应该是可以的，因为我们为了收到http与ssh的响应报文，已经放行了80端口与22号端口，所以，不管是”响应”我们的报文，还是”主动发送”给我们的报文，应该都是可以通过这两个端口的，那么仔细想想，这样是不是不太安全呢？如果某些与你敌对的人，利用这些端口”主动”连接到你的主机，你肯定会不爽的吧，一般都是我们主动请求80端口，80端口回应我们，但是一般不会出现80端口主动请求我们的情况吧。</p>
<p>你心里可能会这样想：我知道哪些主机是安全的，我只要针对这些安全的主机放行对应的端口就行了，其他IP一律拒绝，比如，我知道IP为123的主机是安全的，所以，我对123主机开放了22号端口，以便123主机能够通过22号端口响应我们的ssh请求，那么，如果你需要管理的主机越来越多呢？你是不是每次都要为新的主机配置这些规则呢？如果有30台主机呢？如果有300台主机呢？80端口就更别提了，难道你每次访问一个新的网址，都要对这个网址添加信任吗？这显然不太合理。</p>
<p>你心里可能又会想：针对对应的端口，我用–tcp-flags去匹配tcp报文的标志位，把外来的”第一次握手”的请求拒绝，是不是也可以呢？那么如果对方使用的是UDP协议或者ICMP协议呢？似乎总是有一些不完美的地方。</p>
<p>那么我们仔细的思考一下，造成上述问题的”根源”在哪里，我们为了让”提供服务方”能够正常的”响应”我们的请求，于是在主机上开放了对应的端口，开放这些端口的同时，也出现了问题，别人利用这些开放的端口，”主动”的攻击我们，他们发送过来的报文并不是为了响应我们，而是为了主动攻击我们，好了，我们似乎找到了问题所在？</p>
<p>问题就是：怎样判断这些报文是为了回应我们之前发出的报文，还是主动向我们发送的报文呢？</p>
<p>我们可以通过iptables的state扩展模块解决上述问题，但是我们需要先了解一些state模块的相关概念，然后再回过头来解决上述问题。</p>
<p>从字面上理解，state可以译为状态，但是我们也可以用一个高大上的词去解释它，state模块可以让iptables实现”连接追踪”机制。</p>
<p>那么，既然是”连接追踪”，则必然要有”连接”。</p>
<p>咱们就来聊聊什么是连接吧，一说到连接，你可能会下意识的想到tcp连接，但是，对于state模块而言的”连接”并不能与tcp的”连接”画等号，在TCP/IP协议簇中，UDP和ICMP是没有所谓的连接的，但是对于state模块来说，tcp报文、udp报文、icmp报文都是有连接状态的，我们可以这样认为，对于state模块而言，只要两台机器在”你来我往”的通信，就算建立起了连接，如下图所示</p>
<p><img src="/2022/06/13/uncatalog/cl4cifaka000gpwr787db5toi/1.png" alt="image"></p>
<p>而报文在这个所谓的链接中是什么状态的呢？这是我们后面讨论的话题。</p>
<p>对于state模块的连接而言，”连接”其中的报文可以分为5种状态，报文状态可以为NEW、ESTABLISHED、RELATED、INVALID、UNTRACKED</p>
<p>那么上述报文的状态都代表什么含义呢？我们先来大概的了解一下概念，然后再结合示例说明。</p>
<p>注意：如下报文状态都是对于state模块来说的。</p>
<p>NEW：连接中的第一个包，状态就是NEW，我们可以理解为新连接的第一个包的状态为NEW。</p>
<p>ESTABLISHED：我们可以把NEW状态包后面的包的状态理解为ESTABLISHED，表示连接已建立。</p>
<p>或许用图说话更容易被人理解</p>
<p><img src="/2022/06/13/uncatalog/cl4cifaka000gpwr787db5toi/2.png" alt="image"></p>
<p>RELATED：从字面上理解RELATED译为关系，但是这样仍然不容易理解，我们举个例子。</p>
<p>比如FTP服务，FTP服务端会建立两个进程，一个命令进程，一个数据进程。</p>
<p>命令进程负责服务端与客户端之间的命令传输（我们可以把这个传输过程理解成state中所谓的一个”连接”，暂称为”命令连接”）。</p>
<p>数据进程负责服务端与客户端之间的数据传输 ( 我们把这个过程暂称为”数据连接” )。</p>
<p>但是具体传输哪些数据，是由命令去控制的，所以，”数据连接”中的报文与”命令连接”是有”关系”的。</p>
<p>那么，”数据连接”中的报文可能就是RELATED状态，因为这些报文与”命令连接”中的报文有关系。</p>
<p>(注：如果想要对ftp进行连接追踪，需要单独加载对应的内核模块nf_conntrack_ftp，如果想要自动加载，可以配置/etc/sysconfig/iptables-config文件)</p>
<p>INVALID：如果一个包没有办法被识别，或者这个包没有任何状态，那么这个包的状态就是INVALID，我们可以主动屏蔽状态为INVALID的报文。</p>
<p>UNTRACKED：报文的状态为untracked时，表示报文未被追踪，当报文的状态为Untracked时通常表示无法找到相关的连接。</p>
<p>上述5种状态的详细解释可以参考<a href="http://www.iptables.info/en/connection-state.html">User-land states</a>章节</p>
<p>好了，我们已经大致了解了state模块中所定义的5种状态，那么现在，我们回过头想想刚才的问题。</p>
<p>刚才问题的根源就是：怎样判断报文是否是为了回应之前发出的报文。</p>
<p>刚才举例中的问题即可使用state扩展模块解决，我们只要放行状态为ESTABLISHED的报文即可，因为如果报文的状态为ESTABLISHED，那么报文肯定是之前发出的报文的回应，如果你还不放心，可以将状态为RELATED或ESTABLISHED的报文都放行，这样，就表示只有回应我们的报文能够通过防火墙，如果是别人主动发送过来的新的报文，则无法通过防火墙，示例如下。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifaka000gpwr787db5toi/3.png" alt="image"></p>
<p>当前主机IP为104，当放行ESTABLISHED与RELATED状态的包以后，并没有影响通过本机远程ssh到IP为77的主机上，但是无法从77上使用22端口主动连接到104上。</p>
<p>对于其他端口与IP来说，也是相同的，可以从104主动发送报文，并且能够收到响应报文，但是其他主机并不能主动向104发起请求。</p>
<p>好了，state模块就总结到这里，希望这篇文章能够对你有所帮助。</p>
]]></content>
      <tags>
        <tag>云原生基础系列</tag>
        <tag>Kubernetes网络</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes网络系列之(二十六)iptables扩展匹配条件之[–tcp-flags]</title>
    <url>/2022/06/13/uncatalog/cl4cifakc000ipwr7bhs4dux2/</url>
    <content><![CDATA[<hr>
<span id="more"></span>

<hr>
<p>如果你看过前文，那么你一定知道，前文已经对”tcp扩展模块”做过总结，但是只总结了tcp扩展模块中的”–sport”与”–dport”选项，并没有总结”–tcp-flags”选项，那么此处，我们就来认识一下tcp扩展模块中的”–tcp-flags”。</p>
<p>注：阅读这篇文章之前，需要对tcp协议的基础知识有一定的了解，比如：tcp头的结构、tcp三次握手的过程。</p>
<p>见名知义，”–tcp-flags”指的就是tcp头中的标志位，看来，在使用iptables时，我们可以通过此扩展匹配条件，去匹配tcp报文的头部的标识位，然后根据标识位的实际情况实现访问控制的功能。</p>
<p>既然说到了tcp头中的标志位，那么我们就来回顾一下tcp头的结构，如下图所示。<br><img src="/2022/06/13/uncatalog/cl4cifakc000ipwr7bhs4dux2/1.png" alt="image"></p>
<p>在使用iptables时，使用tcp扩展模块的”–tcp-flags”选项，即可对上图中的标志位进行匹配，判断指定的标志位的值是否为”1″，而tcp header的结构不是我们今天讨论的重点，我们继续聊tcp的标识位，在tcp协议建立连接的过程中，需要先进行三次握手，而三次握手就要依靠tcp头中的标志位进行。</p>
<p>为了更加具象化的描述这个过程，我们可以抓包查看ssh建立连接的过程，如下图所示（使用wireshark在ssh客户端抓包，跟踪对应的tcp流）：</p>
<p><img src="/2022/06/13/uncatalog/cl4cifakc000ipwr7bhs4dux2/2.png" alt="image"></p>
<p>上图为tcp三次握手中的第一次握手，客户端（IP为98）使用本地的随机端口54808向服务端（IP为137）发起连接请求，tcp头的标志位中，只有SYN位被标识为1，其他标志位均为0。</p>
<p>在上图的下方可以看到”[TCP Flags: ··········S·]”，其中的”S”就表示SYN位，整体表示只有SYN位为1。</p>
<p>上图为tcp三次握手中第一次握手的tcp头中的标志位，下图是第二次握手的，服务端回应刚才的请求，将自己的tcp头的SYN标志位也设置为1，同时将ACK标志位也设置为1，如下图所示。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifakc000ipwr7bhs4dux2/3.png" alt="image"></p>
<p>上图中的下方显示的标志位列表也变成了，[TCP Flags: ·······A··S·]，表示只有ACK标志位与SYN标志位为1，如上图所示，第三次握手我就不再截图了，说到这里，就已经能够引出我们今天要说的话题了，就是”–tcp-flags”选项，假设，我现在想要匹配到上文中提到的”第一次握手”的报文，则可以使用如下命令：</p>
<p><img src="/2022/06/13/uncatalog/cl4cifakc000ipwr7bhs4dux2/4.png" alt="image"></p>
<p>上图中，”-m tcp –dport 22″的含义在前文中已经总结过，表示使用tcp扩展模块，指定目标端口为22号端口(ssh默认端口)，”–tcp-flags”就是我们今天要讨论的扩展匹配条件，用于匹配报文tcp头部的标志位，”SYN,ACK,FIN,RST,URG,PSH SYN”是什么意思呢？这串字符就是用于配置我们要匹配的标志位的，我们可以把这串字符拆成两部分去理解，第一部分为”SYN,ACK,FIN,RST,URG,PSH”，第二部分为”SYN”。</p>
<p>第一部分表示：我们需要匹配报文tcp头中的哪些标志位，那么上例的配置表示，我们需要匹配报文tcp头中的6个标志位，这6个标志位分别为为”SYN、ACK、FIN、RST、URG、PSH”，我们可以把这一部分理解成需要匹配的标志位列表。</p>
<p>第二部分表示：第一部分的标志位列表中，哪些标志位必须为1，上例中，第二部分为SYN，则表示，第一部分需要匹配的标志位列表中，SYN标志位的值必须为1，其他标志位必须为0。</p>
<p>所以，上例中的”SYN,ACK,FIN,RST,URG,PSH SYN”表示，需要匹配报文tcp头中的”SYN、ACK、FIN、RST、URG、PSH”这些标志位，其中SYN标志位必须为1，其他的5个标志位必须为0，这与上文中wireshark抓包时的情况相同，正是tcp三次握手时第一次握手时的情况，上文中第一次握手的报文的tcp头中的标志位如下：</p>
<p><img src="/2022/06/13/uncatalog/cl4cifakc000ipwr7bhs4dux2/5.png" alt="image"></p>
<p>其实，–tcp-flags的表示方法与wireshark的表示方法有异曲同工之妙，只不过，wireshark中，标志位为0的用”点”表示，标志位为1的用对应字母表示，在–tcp-flags中，需要先指明需要匹配哪些标志位，然后再指明这些标志位中，哪些必须为1，剩余的都必须为0。</p>
<p>那么，聪明如你一定想到了，如果我想要匹配tcp头中的第二次握手时的标志位的情况，该怎么表示呢？</p>
<p>示例如下（此处省略对源地址与目标地址的匹配，重点在于对tcp-flags的示例）</p>
<p><img src="/2022/06/13/uncatalog/cl4cifakc000ipwr7bhs4dux2/6.png" alt="image"></p>
<p>上图中，第一条命令匹配到的报文是第一次握手的报文，第二条命令匹配到的报文是第二次握手的报文。</p>
<p>综上所述，只要我们能够灵活的配置上例中的标志位，即可匹配到更多的应用场景中。</p>
<p>其实，上例中的两条命令还可以简写为如下模样</p>
<p><img src="/2022/06/13/uncatalog/cl4cifakc000ipwr7bhs4dux2/7.png" alt="image"></p>
<p>没错，我们可以用ALL表示”SYN,ACK,FIN,RST,URG,PSH”。</p>
<p>其实，tcp扩展模块还为我们专门提供了一个选项，可以匹配上文中提到的”第一次握手”，那就是–syn选项</p>
<p>使用”–syn”选项相当于使用”–tcp-flags SYN,RST,ACK,FIN  SYN”，也就是说，可以使用”–syn”选项去匹配tcp新建连接的请求报文。</p>
<p>示例如下：</p>
<p><img src="/2022/06/13/uncatalog/cl4cifakc000ipwr7bhs4dux2/8.png" alt="image"></p>
<p>小结<br>结合之前的文章，我们把tcp模块的常用扩展匹配条件再总结一遍，方便以后回顾。</p>
<p>tcp扩展模块常用的扩展匹配条件如下：</p>
<p>–sport<br>用于匹配tcp协议报文的源端口，可以使用冒号指定一个连续的端口范围</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">示例</span></span><br><span class="line">iptables -t filter -I OUTPUT -d 192.168.1.146 -p tcp -m tcp --sport 22 -j REJECT</span><br><span class="line">iptables -t filter -I OUTPUT -d 192.168.1.146 -p tcp -m tcp --sport 22:25 -j REJECT</span><br><span class="line">iptables -t filter -I OUTPUT -d 192.168.1.146 -p tcp -m tcp ! --sport 22 -j ACCEPT</span><br></pre></td></tr></table></figure></div>


<p>–dport<br>用于匹配tcp协议报文的目标端口，可以使用冒号指定一个连续的端口范围</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">示例</span></span><br><span class="line">iptables -t filter -I INPUT -s 192.168.1.146 -p tcp -m tcp --dport 22:25 -j REJECT</span><br><span class="line">iptables -t filter -I INPUT -s 192.168.1.146 -p tcp -m tcp --dport :22 -j REJECT</span><br><span class="line">iptables -t filter -I INPUT -s 192.168.1.146 -p tcp -m tcp --dport 80: -j REJECT</span><br></pre></td></tr></table></figure></div>


<p>–tcp-flags<br>用于匹配报文的tcp头的标志位</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">示例</span></span><br><span class="line">iptables -t filter -I INPUT -p tcp -m tcp --dport 22 --tcp-flags SYN,ACK,FIN,RST,URG,PSH SYN -j REJECT</span><br><span class="line">iptables -t filter -I OUTPUT -p tcp -m tcp --sport 22 --tcp-flags SYN,ACK,FIN,RST,URG,PSH SYN,ACK -j REJECT</span><br><span class="line">iptables -t filter -I INPUT -p tcp -m tcp --dport 22 --tcp-flags ALL SYN -j REJECT</span><br><span class="line">iptables -t filter -I OUTPUT -p tcp -m tcp --sport 22 --tcp-flags ALL SYN,ACK -j REJECT</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>

<p>–syn<br>用于匹配tcp新建连接的请求报文，相当于使用”–tcp-flags SYN,RST,ACK,FIN  SYN”</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">示例</span></span><br><span class="line">iptables -t filter -I INPUT -p tcp -m tcp --dport 22 --syn -j REJECT</span><br></pre></td></tr></table></figure></div>]]></content>
      <tags>
        <tag>云原生基础系列</tag>
        <tag>Kubernetes网络</tag>
      </tags>
  </entry>
  <entry>
    <title>云原生系列文章目录页</title>
    <url>/2022/06/13/uncatalog/cl4cifal9000rpwr7ffrw6e1h/</url>
    <content><![CDATA[<hr>
<span id="more"></span>
<font size="1">

<blockquote>
<p>在Kubernetes已经成为云原生代名词的今天，市面上介绍Kubernetes的书籍已经很多，然而限于篇幅、 术业有专攻和Kubernetes涉及知识面过于庞大等诸多主客观因素，包括《Kubernetes权威指南：从Docker到Kubernetes实践全接触》在内，至今没有出现一套或者一系列能够让初学者，特别是云原生开发者，从入门到进阶再到入土的教程，这就造成了众多初学者，在查找资料由点到面的学习过程中走上了从入门到放弃的道路。<br>然而，对于以上现象，并不是一个人所能改变的，所以我把自己的云原生求索过程记录一下，希望能够帮到其他人省下查找资料的时间，如果还能够起到少走弯路的作用，那就再好不过了。</p>
</blockquote>
<p><strong>云原生基础系列之Docker系列</strong>主要包括Docker概念的介绍、理解和实践，将包括以下部分：</p>
<ul>
<li><a href="https://bugkillerpro.github.io/2022/06/10/uncatalog/cl483pse2000038r7fnpqhzig/" title="Front-end web development">docker基础技术之linux namespace</a></li>
<li><a href="https://bugkillerpro.github.io/2022/06/10/uncatalog/cl4884cmp000060r7fhji6teg/" title="Front-end web development">docker基础技术之linux cgroup</a></li>
<li><a href="https://bugkillerpro.github.io/2022/06/09/uncatalog/cl46zbgi6000y7or7g7cnd6w6/" title="Front-end web development">docker基础</a></li>
<li><a href="https://bugkillerpro.github.io/2022/06/09/uncatalog/cl46zffyz00127or72j1r80ti/" title="Front-end web development">docker进阶</a></li>
</ul>
<p><strong>云原生基础系列之Kubernetes</strong>内容风格和《Kubernetes权威指南：从Docker到Kubernetes实践全接触》类似，将包括以下部分：</p>
<ul>
<li><a href="https://bugkillerpro.github.io/2022/06/09/uncatalog/cl46zoo76000028r79whb5rff/" title="Front-end web development">Kubernetes介绍</a></li>
<li><a href="https://bugkillerpro.github.io/2022/06/09/uncatalog/cl46zkqb400157or761km2b46/" title="Front-end web development">集群环境搭建</a></li>
<li><a href="https://bugkillerpro.github.io/2022/06/09/uncatalog/cl46zbaxk00017or7fpbp30br/" title="Front-end web development">资源管理</a></li>
<li><a href="https://bugkillerpro.github.io/2022/06/09/uncatalog/cl46zbayd000p7or77mughk0e/" title="Front-end web development">实战入门</a></li>
<li><a href="https://bugkillerpro.github.io/2022/06/09/uncatalog/cl46zbayg000v7or7a4o0f4yd/" title="Front-end web development">Pod详解</a></li>
<li><a href="https://bugkillerpro.github.io/2022/06/09/uncatalog/cl46zbaye000q7or7bx6mhrl3/" title="Front-end web development">Pod控制器详解</a></li>
<li><a href="https://bugkillerpro.github.io/2022/06/09/uncatalog/cl46zbay9000j7or7b2e4b2pr/" title="Front-end web development">Service详解</a></li>
<li><a href="https://bugkillerpro.github.io/2022/06/09/uncatalog/cl46zbay9000k7or71j4vcb8a/" title="Front-end web development">数据存储</a></li>
<li><a href="https://bugkillerpro.github.io/2022/06/09/uncatalog/cl46zbaxw00037or72v2f9efa/" title="Front-end web development">安全认证</a></li>
<li><a href="https://bugkillerpro.github.io/2022/06/09/uncatalog/cl46zbaxy00047or77oe22gjt/" title="Front-end web development">DashBoard</a></li>
</ul>
<p><strong>Kubernetes网络系列</strong>云计算的世界里，计算最基础，存储最重要，网络最复杂。 所以将一些  必须具备的前置网络知识和k8s网络插件部分单独拿出来作为一个系列，将包括以下部分：</p>
<ul>
<li><a href="https://bugkillerpro.github.io/2022/06/10/uncatalog/cl48bverj000054r77iq83ab9/" title="Front-end web development">网络是怎么连通的</a></li>
<li><a href="https://bugkillerpro.github.io/2022/06/11/uncatalog/cl49mkqxy0002lwr76770ae47/" title="Front-end web development">网络基本概念</a></li>
<li><a href="https://bugkillerpro.github.io/2022/06/11/uncatalog/cl49muw310005lwr7dukkfz6m/" title="Front-end web development">IP和掩码</a></li>
<li><a href="https://bugkillerpro.github.io/2022/06/11/uncatalog/cl49n9zab0008lwr79y835duy/" title="Front-end web development">router路咋走啊</a></li>
<li><a href="https://bugkillerpro.github.io/2022/06/11/uncatalog/cl49np026000blwr7c4y2ebgu/" title="Front-end web development">Ping报文</a></li>
<li><a href="https://bugkillerpro.github.io/2022/06/11/uncatalog/cl49nvljx000elwr7fha73lvv/" title="Front-end web development">ARP你在哪</a></li>
<li><a href="https://bugkillerpro.github.io/2022/06/11/uncatalog/cl49qvoa2000hlwr7bjyn3m3x/" title="Front-end web development">Tcpdump大杀器抓包</a></li>
<li><a href="https://bugkillerpro.github.io/2022/06/11/uncatalog/cl49qytpu000klwr7el00gnwf/" title="Front-end web development">iptables-filter过滤功能</a></li>
<li><a href="https://bugkillerpro.github.io/2022/06/11/uncatalog/cl49r424d000nlwr732iq6tli/" title="Front-end web development">网络骗子</a></li>
<li><a href="https://bugkillerpro.github.io/2022/06/11/uncatalog/cl49r8bkh000qlwr7dta2fv8f/" title="Front-end web development">iptables-nat穿越功能</a></li>
<li><a href="https://bugkillerpro.github.io/2022/06/11/uncatalog/cl49s0k3u000tlwr77i2gctw9/" title="Front-end web development">什么是VLAN和VXLAN</a></li>
<li><a href="https://bugkillerpro.github.io/2022/06/11/uncatalog/cl49ss3al000wlwr78qw42gtt/" title="Front-end web development">GRE</a></li>
<li><a href="https://bugkillerpro.github.io/2022/06/11/uncatalog/cl49t00i2000zlwr72uaw2411/" title="Front-end web development">ip命令</a></li>
<li><a href="https://bugkillerpro.github.io/2022/06/11/uncatalog/cl49v1eys0012lwr741221o3z/" title="Front-end web development">网络命名空间Network Namespace</a></li>
<li><a href="https://bugkillerpro.github.io/2022/06/11/uncatalog/cl49vyb870015lwr7gd0l1mz1/" title="Front-end web development">Veth网线</a></li>
<li><a href="https://bugkillerpro.github.io/2022/06/11/uncatalog/cl49wfzo90018lwr70q7u4yf0/" title="Front-end web development">TUN/TAP网线</a></li>
<li><a href="https://bugkillerpro.github.io/2022/06/11/uncatalog/cl49wklgu001blwr7a55t1phs/" title="Front-end web development">Bridge网桥</a></li>
<li><a href="https://bugkillerpro.github.io/2022/06/11/uncatalog/cl49wrxfs001elwr7evfs8y08/" title="Front-end web development">Docker网络实现</a></li>
<li><a href="https://bugkillerpro.github.io/2022/06/11/uncatalog/cl49x52lf001hlwr7g9qrfjev/" title="Front-end web development">CloudFoundry网络实现</a></li>
<li><a href="https://bugkillerpro.github.io/2022/06/11/uncatalog/cl49xdzwo001klwr71pcl8mu0/" title="Front-end web development">Kubernetes网络实现</a></li>
<li><a href="https://bugkillerpro.github.io/2022/06/13/uncatalog/cl4cifak60008pwr77vkbd1sn/" title="Front-end web development">iptables概念</a></li>
<li><a href="https://bugkillerpro.github.io/2022/06/13/uncatalog/cl4cifak9000epwr7cx322y2s/" title="Front-end web development">iptables实际操作之规则查询</a></li>
<li><a href="https://bugkillerpro.github.io/2022/06/13/uncatalog/cl4cifap3000vpwr7cqad5sgx/" title="Front-end web development">iptables规则管理</a></li>
<li><a href="https://bugkillerpro.github.io/2022/06/13/uncatalog/cl4cifap5000zpwr721cugaqx/" title="Front-end web development">iptables匹配条件总结之一</a></li>
<li><a href="https://bugkillerpro.github.io/2022/06/13/uncatalog/cl4cifap4000xpwr7gg0bhm2w/" title="Front-end web development">iptables匹配条件总结之二(常用扩展模块)</a></li>
<li><a href="https://bugkillerpro.github.io/2022/06/13/uncatalog/cl4cifakc000ipwr7bhs4dux2/" title="Front-end web development">iptables扩展匹配条件之(–tcp-flags)</a></li>
<li><a href="https://bugkillerpro.github.io/2022/06/13/uncatalog/cl4cifak7000apwr7hgyg2fgs/" title="Front-end web development">iptables扩展之udp扩展与icmp扩展</a></li>
<li><a href="https://bugkillerpro.github.io/2022/06/13/uncatalog/cl4cifaka000gpwr787db5toi/" title="Front-end web development">iptables扩展模块之state扩展</a></li>
<li><a href="https://bugkillerpro.github.io/2022/06/13/uncatalog/cl4cifak8000cpwr739275b4h/" title="Front-end web development">iptables的黑白名单机制</a></li>
<li><a href="https://bugkillerpro.github.io/2022/06/13/uncatalog/cl4cifajw0000pwr7fssa1zca/" title="Front-end web development">iptables自定义链</a></li>
<li><a href="https://bugkillerpro.github.io/2022/06/13/uncatalog/cl4cifajy0001pwr71ippfotz/" title="Front-end web development">iptables之网络防火墙</a></li>
<li><a href="https://bugkillerpro.github.io/2022/06/13/uncatalog/cl4cifak10004pwr75tri6w43/" title="Front-end web development">iptables动作总结之一</a></li>
<li><a href="https://bugkillerpro.github.io/2022/06/13/uncatalog/cl4cifaoy000upwr7fsyw1c87/" title="Front-end web development">iptables动作总结之二</a></li>
<li><a href="https://bugkillerpro.github.io/2022/06/13/uncatalog/cl4cisjv20000f8r79ldw1df5/" title="Front-end web development">iptables小结之常用套路</a></li>
<li><a href="https://www.google.com/" title="Front-end web development">待更新…</a></li>
</ul>
<p><strong>云原生进阶系列</strong>主要包括云原生开发、service mesh和其他CNCF相关的内容，面向云原生开发人员。将包括以下部分：</p>
<ul>
<li><a href="https://www.google.com/" title="Front-end web development">待更新…</a></li>
</ul>
<p><strong>云原生其他相关</strong>主要包括我在云原生学习过程中的一些心得体会和读书笔记等。</p>
<ul>
<li><a href="https://bugkillerpro.github.io/2022/06/10/uncatalog/cl48eey5y0000owr728gk66p6/" title="Front-end web development">kubernetes读书笔记</a></li>
<li><a href="https://www.google.com/" title="Front-end web development">待更新…</a></li>
</ul>
</font>

<hr>
]]></content>
      <tags>
        <tag>云原生基础系列</tag>
        <tag>Kubernetes网络</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes网络系列之(三十三)iptables动作总结之二</title>
    <url>/2022/06/13/uncatalog/cl4cifaoy000upwr7fsyw1c87/</url>
    <content><![CDATA[<hr>
<span id="more"></span>

<hr>
<h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>阅读这篇文章需要站在前文的基础上，如果你在阅读时遇到障碍，请参考之前的文章。</p>
<p>前文中，我们已经了解了如下动作</p>
<p>ACCEPT、DROP、REJECT、LOG</p>
<p>今天，我们来认识几个新动作，它们是：</p>
<p>SNAT、DNAT、MASQUERADE、REDIRECT</p>
<p>在认识它们之前，我们先来聊聊NAT，如果你对NAT的相关概念已经滚瓜烂熟，可以跳过如下场景描述。</p>
<p>NAT是Network Address Translation的缩写，译为”网络地址转换”，NAT说白了就是修改报文的IP地址，NAT功能通常会被集成到路由器、防火墙、或独立的NAT设备中。</p>
<p>为什么要修改报文的IP地址呢？我们来描述一些场景，即可知道为什么有这方面的需求了。</p>
<h4 id="场景1："><a href="#场景1：" class="headerlink" title="场景1："></a>场景1：</h4><p>假设，网络内部有10台主机，它们有各自的IP地址，当网络内部的主机与其他网络中的主机通讯时，则会暴露自己的IP地址，如果我们想要隐藏这些主机的IP地址，该怎么办呢？可以这样办，如下。</p>
<p>当网络内部的主机向网络外部主机发送报文时，报文会经过防火墙或路由器，当报文经过防火墙或路由器时，将报文的源IP修改为防火墙或者路由器的IP地址，当其他网络中的主机收到这些报文时，显示的源IP地址则是路由器或者防火墙的，而不是那10台主机的IP地址，这样，就起到隐藏网络内部主机IP的作用，当网络内部主机的报文经过路由器时，路由器会维护一张NAT表，表中记录了报文来自于哪个内部主机的哪个进程（内部主机IP+端口），当报文经过路由器时，路由器会将报文的内部主机源IP替换为路由器的IP地址，把源端口也映射为某个端口，NAT表会把这种对应关系记录下来。</p>
<p>示意图如下：</p>
<p> <img src="/2022/06/13/uncatalog/cl4cifaoy000upwr7fsyw1c87/1.png" alt="img"></p>
<p>于是，外部主机收到报文时，源IP与源端口显示的都是路由的IP与端口，当外部网络中的主机进行回应时，外部主机将响应报文发送给路由器，路由器根据刚才NAT表中的映射记录，将响应报文中的目标IP与目标端口再改为内部主机的IP与端口号，然后再将响应报文发送给内部网络中的主机。整个过程中，外部主机都不知道内部主机的IP地址，内部主机还能与外部主机通讯，于是起到了隐藏网络内主机IP的作用。</p>
<p>上述整个过程中，就用到了NAT功能，准确的说是用到了NAPT功能，NAPT是NAT的一种，全称为Network Address Port Translation，说白了就是映射报文IP地址的同时还会映射其端口号，就像刚才描述的过程一样。</p>
<p>刚才描述的过程中，”IP地址的转换”一共发生了两次。</p>
<p>内部网络的报文发送出去时，报文的源IP会被修改，也就是源地址转换：Source Network Address Translation，缩写为SNAT。</p>
<p>外部网络的报文响应时，响应报文的目标IP会再次被修改，也就是目标地址转换：Destinationnetwork address translation，缩写为DNAT。</p>
<p>但是，上述”整个过程”被称为SNAT，因为”整个过程”的前半段使用了SNAT，如果上述”整个过程”的前半段使用了DNAT，则整个过程被称为DNAT，也就是说，整个过程被称为SNAT还是DNAT，取决于整个过程的前半段使用了SNAT还是DNAT。</p>
<p>其实刚才描述的场景不仅仅能够隐藏网络内部主机的IP地址，还能够让局域网内的主机共享公网IP，让使用私网IP的主机能够访问互联网。</p>
<p>比如，整个公司只有一个公网IP，但是整个公司有10台电脑，我们怎样能让这10台电脑都访问互联网呢？我们可以为这10台电脑都配置上各自的私网IP，比如”192.168″这种私网IP，但是互联网是不会路由私网IP的，如果想要访问互联网，则必须使用公网IP，那么，我们就需要想办法，能让这10台主机共享公司仅有的一个公网IP，没错，这与刚才描述的场景其实完全一致，我们只要在路由器上配置公网IP，在私网主机访问公网服务时，报文经过路由器，路由器将报文中的私网IP与端口号进行修改和映射，将其映射为公网IP与端口号，这时，内网主机即可共享公网IP访问互联网上的服务了，NAT表示意图如下</p>
<p><img src="/2022/06/13/uncatalog/cl4cifaoy000upwr7fsyw1c87/2.png" alt="img"></p>
<p>综上所述，SNAT不仅能够隐藏网内的主机IP，还能够共享公网IP，这在IPV4地址较为紧张的今天，是非常有用的。</p>
<h4 id="场景2："><a href="#场景2：" class="headerlink" title="场景2："></a>场景2：</h4><p>场景1中，我们描述的过程为SNAT的过程，虽然其过程中也牵扯到DNAT，但是由于整个过程的前半段使用了SNAT，所以整个过程称之为SNAT，那么在什么情况下，整个过程能称之为DNAT呢？</p>
<p>没错，当整个过程的前半段使用了DNAT时，整个过程被称为DNAT，具体场景如下。</p>
<p>公司有自己的局域网，网络中有两台主机作为服务器，主机1提供web服务，主机2提供数据库服务，但是这两台服务器在局域网中使用私有IP地址，只能被局域网内的主机访问，互联网无法访问到这两台服务器，整个公司只有一个可用的公网IP，怎样通过这个公网IP访问到内网中的这些服务呢？我们可以将这个公网IP配置到公司的某台主机或路由器上，然后对外宣称，这个IP地址对外提供web服务与数据库服务，于是互联网主机将请求报文发送给这公网 IP地址，也就是说，此时报文中的目标IP为公网IP，当路由器收到报文后，将报文的目标地址改为对应的私网地址，比如，如果报文的目标IP与端口号为：公网IP+3306，我们就将报文的目标地址与端口改为：主机2的私网IP+3306，同理，公网IP+80端口映射为主机1的私网IP+80端口，当私网中的主机回应对应请求报文时，再将回应报文的源地址从私网IP+端口号映射为公网IP+端口号，再由路由器或公网主机发送给互联网中的主机。</p>
<p>上述过程也牵扯到DNAT与SNAT，但是由于整个过程的前半段使用了DNAT，所以上述过程被称为DNAT</p>
<p>其实，不管是SNAT还是DNAT，都起到了隐藏内部主机IP的作用。</p>
<h3 id="实验环境准备"><a href="#实验环境准备" class="headerlink" title="实验环境准备"></a>实验环境准备</h3><p>好了，我们已经了解了SNAT与DNAT的相关概念，那么现在，我们可以动动手了，首先，准备一下实验环境</p>
<p>大致的实验环境是这样的，公司局域网使用的网段为10.1.0.0/16，目前公司只有一个公网IP，局域网内的主机需要共享这个IP与互联网上的主机进行通讯。</p>
<p>由于我们没有真正的公网IP，所以，我们使用私网IP：192.168.1.146模拟所谓的公网IP，示意图如下</p>
<p><img src="/2022/06/13/uncatalog/cl4cifaoy000upwr7fsyw1c87/3.png" alt="img"></p>
<p>如上述示意图所示，实验使用4台虚拟机，A、B、C、D</p>
<ul>
<li><p>主机A：扮演公网主机，尝试访问公司提供的服务，IP地址为192.168.1.147</p>
</li>
<li><p>主机B：扮演了拥有NAT功能的防火墙或路由器，充当网关，并且负责NAT，公网、私网通讯的报文通过B主机时，报文会被NAT</p>
</li>
<li><p>主机C：扮演内网web服务器</p>
</li>
<li><p>主机D：扮演内网windows主机</p>
</li>
</ul>
<p>上图中圆形所示的逻辑区域表示公司内网，网段为10.1.0.0/16，主机B、C、D都属于内网主机，主机B比较特殊，同时扮演了网关与防火墙，主机B持有公司唯一的公网IP（我们用了一个假的公网IP），局域网内主机如果想与公网主机通讯，需要共享此公网IP，由B主机进行NAT，所以，我们为主机B准备了两块网卡，公网IP与私网IP分别配置到这两块网卡中，同时，在虚拟机中设置了一个”仅主机模式”的虚拟网络，以模拟公司局域网。</p>
<p>聪明如你，应该已经发现了，上述实验环境与之前描述的”网络防火墙”的实验环境相差无几，只不过之前的环境并没有公网，私网的概念，而此刻，圆形逻辑区域之内为私网，圆形逻辑区域之外为公网。</p>
<p>环境具体准备过程如下</p>
<p>首先，创建一个虚拟网络，模拟公司内网。</p>
<p>点击vmware虚拟机的编辑菜单，打开”虚拟网络编辑器”，点击更改设置，添加”仅主机模式”的虚拟网络，下图中的VMnet6为已经添加过的虚拟网络，此处不再重复操作。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifaoy000upwr7fsyw1c87/4.png" alt="img"></p>
<p>主机C与主机D的网关都指向主机B的私网IP，如下图所示</p>
<p><img src="/2022/06/13/uncatalog/cl4cifaoy000upwr7fsyw1c87/5.png" alt="img"><br><img src="/2022/06/13/uncatalog/cl4cifaoy000upwr7fsyw1c87/6.png" alt="img"></p>
<p>主机B有两块网卡，分别配置了私网IP与公网IP，私网IP为10.1.0.3，私网IP所在的网卡也存在于vmnet6中，模拟公网的IP为192.168.1.146，B主机的公网IP所在的网卡与A主机都使用桥接模式的虚拟网络，所以，B主机既能与私网主机通讯，也能与公网主机通讯。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifaoy000upwr7fsyw1c87/7.png" alt="img"></p>
<p>由于B主机此时需要负责对报文的修改与转发，所以，需要开启B主机中的核心转发功能，Linux主机默认不会开启核心转发，这在前文中已经详细的描述过，此处不再赘述，如果你还不明白为什么，请回顾前文，使用临时生效的方法开启B主机的核心转发功能，如下图所示。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifaoy000upwr7fsyw1c87/8.png" alt="img"></p>
<p>A主机的IP地址如下，可以与B主机进行通讯，但是不能与C、D进行通讯，因为此刻，A是公网主机，B既是公网主机又是私网主机，C、D是私网的主机，A是不可能访问到C和D的。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifaoy000upwr7fsyw1c87/9.png" alt="img"></p>
<p>为了能够更好的区分公网服务与私网服务，我们分别在主机A与主机C上启动httpd服务，如下图所示。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifaoy000upwr7fsyw1c87/10.png" alt="img"></p>
<p>好了，实验环境准备完毕，我们来一起动动手，实际操作一下。</p>
<h3 id="动作：SNAT"><a href="#动作：SNAT" class="headerlink" title="动作：SNAT"></a>动作：SNAT</h3><p>在文章开头的场景中，我们已经描述过，网络内部的主机可以借助SNAT隐藏自己的IP地址，同时还能够共享合法的公网IP，让局域网内的多台主机共享公网IP访问互联网。</p>
<p>而此时的主机B就扮演了拥有NAT功能的设备，我们使用iptables的SNAT动作达到刚才所说的目的。</p>
<p>连接到B主机，添加如下规则。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifaoy000upwr7fsyw1c87/11.png" alt="img"></p>
<p>如上图所示，上图中的规则表示将来自于10.1.0.0/16网段的报文的源地址改为公司的公网IP地址。</p>
<p>“-t nat”表示操作nat表，我们之前一直在灌输一个概念，就是不同的表有不同的功能，filter表的功能是过滤，nat表的功能就是地址转换，所以我们需要在nat表中定义nat规则。</p>
<p>“-A POSTROUTING”表示将SNAT规则添加到POSTROUTING链的末尾，在centos7中，SNAT规则只能存在于POSTROUTING链与INPUT链中，在centos6中，SNAT规则只能存在于POSTROUTING链中。</p>
<p>你可能会问，为什么SNAT规则必须定义在POSTROUTING链中，我们可以这样认为，POSTROUTING链是iptables中报文发出的最后一个”关卡”，我们应该在报文马上发出之前，修改报文的源地址，否则就再也没有机会修改报文的源地址了，在centos7中，SNAT规则也可以定义在INPUT链中，我们可以这样理解，发往本机的报文经过INPUT链以后报文就到达了本机，如果再不修改报文的源地址，就没有机会修改了。</p>
<p>“-s 10.1.0.0/16″表示报文来自于10.1.0.0/16网段，前文中一直在使用这个匹配条件，我想此处应该不用赘述了。</p>
<p>“-j SNAT”表示使用SNAT动作，对匹配到的报文进行处理，对匹配到的报文进行源地址转换。</p>
<p>“–to-source 192.168.1.146″表示将匹配到的报文的源IP修改为192.168.1.146，前文中，我们已经总结过，某些动作会有自己的选项，”–to-source”就是SNAT动作的常用选项，用于指定SNAT需要将报文的源IP修改为哪个IP地址。</p>
<p>好了，只要站在前文的基础上，理解上述语句应该是分分钟的事情，聪明如你应该已经学会了，那么我们来测试一下。</p>
<p>目前来说，我们只配置了一条SNAT规则，并没有设置任何DNAT，现在，我们从内网主机上ping外网主机，看看能不能ping通，登录内网主机C，在C主机上向A主机的外网IP发送ping请求(假外网IP)，示例如下</p>
<p><img src="/2022/06/13/uncatalog/cl4cifaoy000upwr7fsyw1c87/12.png" alt="img"><br>如上图所示，”内网主机”已经可以依靠SNAT访问”互联网”了。</p>
<p>为了更加清晰的理解整个SNAT过程，在C主机上抓包看看，查看一下请求报文与响应报文的IP地址，如下，在C主机上同时打开两个命令窗口，一个命令窗口中向A主机发送ping请求，另一个窗口中，使用tcpdump命令对指定的网卡进行抓包，抓取icmp协议的包。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifaoy000upwr7fsyw1c87/13.png" alt="img"></p>
<p>从上图可以看到，10.1.0.1发出ping包，192.168.1.147进行回应，正是A主机的IP地址（用于模拟公网IP的IP地址）</p>
<p>看来，只是用于配置SNAT的话，我们并不用 手动的进行DNAT设置，iptables会自动维护NAT表，并将响应报文的目标地址转换回来。</p>
<p>那么，我们去A主机上再次重复一遍刚才的操作，在A主机上抓包看看，如下图所示，C主机上继续向A主机的公网IP发送ping请求，在主机A的网卡上抓包看看。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifaoy000upwr7fsyw1c87/14.png" alt="img"></p>
<p>从上图可以看出，C主机向A主机发起ping请求时得到了回应，但是在A主机上，并不知道是C主机发来的ping请求，A主机以为是B主机发来的ping请求，从抓包的信息来看，A主机以为B主机通过公网IP：192.168.1.146向自己发起了ping请求，而A主机也将响应报文回应给了B主机，所以，整个过程，A主机都不知道C主机的存在，都以为是B主机在向自己发送请求，即使不是在公网私网的场景中，我们也能够使用这种方法，隐藏网络内的主机，只不过此处，我们所描述的环境就是私网主机共享公网IP访问互联网，那么可以看到，私网中的主机已经共享了192.168.1.146这个”伪公网IP”，那么真的共享了吗？我们使用内网主机D试试，主机D是一台windows虚拟机，我们使用它向主机A发送ping请求，看看能不能ping通。如下</p>
<p><img src="/2022/06/13/uncatalog/cl4cifaoy000upwr7fsyw1c87/15.png" alt="img"></p>
<p>windows主机也ping通了外网主机，在A主机上抓包，看到的仍然是B主机的IP地址。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifaoy000upwr7fsyw1c87/101.png" alt="img"></p>
<p>那么，C主机与D主机能够访问外网服务吗？我们来看看。</p>
<p>在C主机上访问A主机的web服务，如下图所示，访问正常。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifaoy000upwr7fsyw1c87/102.png" alt="img"><br>同理，在windows主机中访问A主机的web服务，如下图所示，访问正常。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifaoy000upwr7fsyw1c87/103.png" alt="img"></p>
<p>好了，源地址转换，已经完成了，我们只依靠了一条iptables规则，就能够使内网主机能够共享公网IP访问互联网了。</p>
<h3 id="动作DNAT"><a href="#动作DNAT" class="headerlink" title="动作DNAT"></a>动作DNAT</h3><p>公司只有一个公网IP，但是公司的内网中却有很多服务器提供各种服务，我们想要通过公网访问这些服务，改怎么办呢？</p>
<p>没错，使用DNAT即可，我们对外宣称，公司的公网IP上既提供了web服务，也提供了windows远程桌面，不管是访问web服务还是远程桌面，只要访问这个公网IP就行了，我们利用DNAT，将公网客户端发送过来的报文的目标地址与端口号做了映射，将访问web服务的报文转发到了内网中的C主机中，将访问远程桌面的报文转发到了内网中的D主机中。</p>
<p>好了，理论说完了，来动手实践一下。</p>
<p>如果我们想要实现刚才描述的场景，则需要在B主机中进行如下配置。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifaoy000upwr7fsyw1c87/16.png" alt="img"><br>如上图所示，我们先将nat表中的规则清空了，从头来过，清空nat表规则后，定义了一条DNAT规则。</p>
<ul>
<li><p>-t nat -I PREROUTING”表示在nat表中的PREROUTING链中配置DNAT规则，DNAT规则只配置在PREROUTING链与OUTPUT链中。</p>
</li>
<li><p>“-d 192.168.1.146 -p tcp –dport 3389″表示报文的目标地址为公司的公网IP地址，目标端口为tcp的3389号端口，而我们知道，windows远程桌面使用的默认端口号就是3389，当外部主机访问公司公网IP的3389号端口时，报文则符合匹配条件。</p>
</li>
<li><p>“-j DNAT –to-destination 10.1.0.6:3389″表示将符合条件的报文进行DNAT，也就是目标地址转换，将符合条件的报文的目标地址与目标端口修改为10.1.0.6:3389，”–to-destination”就是动作DNAT的常用选项。</p>
</li>
</ul>
<p>那么综上所述，上图中定义的规则的含义为，当外网主机访问公司公网IP的3389时，其报文的目标地址与端口将会被映射到10.1.0.6:3389上。</p>
<p>好了，DNAT规则定义完了，现在能够直接使用外网主机访问私网中的服务了吗？</p>
<p>理论上只要完成上述DNAT配置规则即可，但是在测试时，只配置DNAT规则后，并不能正常DNAT，经过测试发现，将相应的SNAT规则同时配置后，即可正常DNAT，于是我们又配置了SNAT</p>
<p>示例如下。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifaoy000upwr7fsyw1c87/17.png" alt="img"></p>
<p>注：理论上只配置DNAT规则即可，但是如果在测试时无法正常DNAT，可以尝试配置对应的SNAT，此处按照配置SNAT的流程进行。</p>
<p>没错，与刚才定义SNAT时使用的规则完全一样。</p>
<p>好了，完成上述配置后，我们则可以通过B主机的公网IP，连接D主机（windows主机）的远程桌面了，示例如下。</p>
<p>找到公网中的一台windows主机，打开远程程序</p>
<p><img src="/2022/06/13/uncatalog/cl4cifaoy000upwr7fsyw1c87/18.png" alt="img"></p>
<p>输入公司的公网IP，点击连接按钮</p>
<p>注意：没有指定端口的情况下，默认使用3389端口进行连接，同时，为了确保能够连接到windows虚拟主机，请将windows虚拟主机设置为允许远程连接。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifaoy000upwr7fsyw1c87/19.png" alt="img"></p>
<p>输入远程连接用户的密码以后，即可连接到windows主机</p>
<p><img src="/2022/06/13/uncatalog/cl4cifaoy000upwr7fsyw1c87/20.png" alt="img"><br>连接以后，远程连接程序显示我们连接到了公司的公网IP，但是当我们查看IP地址时，发现被远程机器的IP地址其实是公司私网中的D主机的IP地址。</p>
<p>上图证明，我们已经成功的通过公网IP访问到了内网中的服务。</p>
<p>同理，使用类似的方法，我们也能够在外网中访问到C主机提供的web服务。</p>
<p>示例如下。<br><img src="/2022/06/13/uncatalog/cl4cifaoy000upwr7fsyw1c87/21.png" alt="img"></p>
<p>如上图所示，我们将公司公网IP的801号端口映射到了公司内网中C主机的80端口，所以，当外网主机访问公司公网IP的801端口时，报文将会发送到C主机的80端口上。</p>
<p>这次，我们不用再次定义SNAT规则了，因为之前已经定义过SNAT规则，上次定义的SNAT规则只要定义一次就行，而DNAT规则则需要根据实际的情况去定义。</p>
<p>好了，完成上述DNAT映射后，我们在A主机上访问B主机的801端口试试，如下</p>
<p><img src="/2022/06/13/uncatalog/cl4cifaoy000upwr7fsyw1c87/22.png" alt="img"></p>
<p>可以看到，我们访问的是B主机的公网IP，但是返回结果显示的却是C主机提供的服务内容，证明DNAT已经成功。</p>
<p>而上述过程中，外网主机A访问的始终都是公司的公网IP，但是提供服务的却是内网主机，但是我们可以对外宣称，公网IP上提供了某些服务，快来访问吧！</p>
<p>我觉得我说明白了，你听明白了吗？</p>
<h3 id="动作MASQUERADE"><a href="#动作MASQUERADE" class="headerlink" title="动作MASQUERADE"></a>动作MASQUERADE</h3><p>上文中，我们已经描述了SNAT，也就是源地址转换，那么我们现在来认识一个与SNAT类似的动作：MASQUERADE</p>
<p>当我们拨号网上时，每次分配的IP地址往往不同，不会长期分给我们一个固定的IP地址，如果这时，我们想要让内网主机共享公网IP上网，就会很麻烦，因为每次IP地址发生变化以后，我们都要重新配置SNAT规则，这样显示不是很人性化，我们通过MASQUERADE即可解决这个问题，MASQUERADE会动态的将源地址转换为可用的IP地址，其实与SNAT实现的功能完全一致，都是修改源地址，只不过SNAT需要指明将报文的源地址改为哪个IP，而MASQUERADE则不用指定明确的IP，会动态的将报文的源地址修改为指定网卡上可用的IP地址，示例如下：</p>
<p><img src="/2022/06/13/uncatalog/cl4cifaoy000upwr7fsyw1c87/23.png" alt="img"></p>
<p>如上图所示，我们指定，通过外网网卡出去的报文在经过POSTROUTING链时，会自动将报文的源地址修改为外网网卡上可用的IP地址，这时，即使外网网卡中的公网IP地址发生了改变，也能够正常的、动态的将内部主机的报文的源IP映射为对应的公网IP。</p>
<p>可以把MASQUERADE理解为动态的、自动化的SNAT，如果没有动态SNAT的需求，没有必要使用MASQUERADE，因为SNAT更加高效。</p>
<h3 id="动作REDIRECT"><a href="#动作REDIRECT" class="headerlink" title="动作REDIRECT"></a>动作REDIRECT</h3><p>使用REDIRECT动作可以在本机上进行端口映射</p>
<p>比如，将本机的80端口映射到本机的8080端口上</p>
<p>iptables -t nat -A PREROUTING -p tcp –dport 80 -j REDIRECT –to-ports 8080</p>
<p>经过上述规则映射后，当别的机器访问本机的80端口时，报文会被重定向到本机的8080端口上。</p>
<p>REDIRECT规则只能定义在PREROUTING链或者OUTPUT链中。</p>
<h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>为了方便以后回顾，我们对上述命令进行总结。</p>
<p>如果想要NAT功能能够正常使用，需要开启Linux主机的核心转发功能。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">echo 1 &gt; /proc/sys/net/ipv4/ip_forward</span><br></pre></td></tr></table></figure></div>


<h4 id="SNAT相关操作"><a href="#SNAT相关操作" class="headerlink" title="SNAT相关操作"></a>SNAT相关操作</h4><p>配置SNAT，可以隐藏网内主机的IP地址，也可以共享公网IP，访问互联网，如果只是共享IP的话，只配置如下SNAT规则即可。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">iptables -t nat -A POSTROUTING -s 10.1.0.0/16 -j SNAT --to-source 公网IP</span><br></pre></td></tr></table></figure></div>


<p>如果公网IP是动态获取的，不是固定的，则可以使用MASQUERADE进行动态的SNAT操作，如下命令表示将10.1网段的报文的源IP修改为eth0网卡中可用的地址。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">iptables -t nat -A POSTROUTING -s 10.1.0.0/16 -o eth0 -j MASQUERADE</span><br></pre></td></tr></table></figure></div>


<h4 id="DNAT相关操作"><a href="#DNAT相关操作" class="headerlink" title="DNAT相关操作"></a>DNAT相关操作</h4><p>配置DNAT，可以通过公网IP访问局域网内的服务。</p>
<p>注：理论上来说，只要配置DNAT规则，不需要对应的SNAT规则即可达到DNAT效果。</p>
<p>但是在测试DNAT时，对应SNAT规则也需要配置，才能正常DNAT，可以先尝试只配置DNAT规则，如果无法正常DNAT，再尝试添加对应的SNAT规则，SNAT规则配置一条即可，DNAT规则需要根据实际情况配置不同的DNAT规则。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">iptables -t nat -I PREROUTING -d 公网IP -p tcp --dport 公网端口 -j DNAT --to-destination 私网IP:端口号</span><br><span class="line">iptables -t nat -I PREROUTING -d 公网IP -p tcp --dport 8080 -j DNAT --to-destination 10.1.0.1:80</span><br><span class="line">iptables -t nat -A POSTROUTING -s 10.1.0.0/16 -j SNAT --to-source 公网IP</span><br></pre></td></tr></table></figure></div>


<p>在本机进行目标端口映射时可以使用REDIRECT动作。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">iptables -t nat -A PREROUTING -p tcp --dport 80 -j REDIRECT --to-ports 8080</span><br></pre></td></tr></table></figure></div>
<p>配置完成上述规则后，其他机器访问本机的80端口时，会被映射到8080端口。</p>
]]></content>
      <tags>
        <tag>云原生基础系列</tag>
        <tag>Kubernetes网络</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes网络系列之(二十三)iptables规则管理</title>
    <url>/2022/06/13/uncatalog/cl4cifap3000vpwr7cqad5sgx/</url>
    <content><![CDATA[<hr>
<span id="more"></span>

<hr>
<p>上一篇文章中，我们已经学会了怎样使用iptables命令查看规则，那么这篇文章我们就来总结一下，怎样管理规则。</p>
<p>之前，我们把查看iptables规则的操作比作”增删改查”当中的”查”，那么在这篇文章中，我们就聊聊怎样对iptables进行”增、删、改”操作。</p>
<p>注意：在参照本文进行iptables实验时，请务必在个人的测试机上进行，因为如果iptables规则设置不当，有可能使你无法连接到远程主机中。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifap3000vpwr7cqad5sgx/1.png" alt="image"></p>
<p>首先，我们来回顾一下什么是iptables的规则。</p>
<p>之前打过一个比方，每条”链”都是一个”关卡”，每个通过这个”关卡”的报文都要匹配这个关卡上的规则，如果匹配，则对报文进行对应的处理，比如说，你我二人此刻就好像两个”报文”，你我二人此刻都要入关，可是城主有命，只有器宇轩昂之人才能入关，不符合此条件的人不能入关，于是守关将士按照城主制定的”规则”，开始打量你我二人，最终，你顺利入关了，而我已被拒之门外，因为你符合”器宇轩昂”的标准，所以把你”放行”了，而我不符合标准，所以没有被放行，其实，”器宇轩昂”就是一种”匹配条件”，”放行”就是一种”动作”，”匹配条件”与”动作”组成了规则。</p>
<p>只不过，在iptables的世界中，最常用的匹配条件并不是”器宇轩昂”，而是报文的”源地址”、”目标地址”、”源端口”、”目标端口”等，在iptables的世界中，最常用的动作有ACCEPT（接受）、DROP（丢弃）、REJECT（拒绝），其中ACCEPT就与我们举例中的”放行”类似，但是，我们刚才提到的这些并不是全部的匹配条件与动作，只是最常用的一些罢了，具体的匹配条件与动作不是我们今天讨论的重点，我们会在以后的文章中再做总结。</p>
<p>好了，我们已经回顾了规则的概念，并且已经明白了，规则大致由两个逻辑单元组成，匹配条件与动作，那么多说无益，我们来动手定义一条规则，此处仍然以filter表中的INPUT链为例，因为filter表负责”过滤”功能，而所有发往本机的报文如果需要被过滤，首先会经过INPUT链（PREROUTING链没有过滤功能），这与我们所比喻的”入关”场景非常相似，所以，使用filter表的INPUT链为例，有助于我们进行理解。</p>
<p>首先，查看一下filter表中的INPUT链中的规则，查看规则的相关命令在前文已经总结了，此处不再赘述，如果你忘了，请回顾前文。</p>
<p>使用如下命令查看filter表INPUT链的规则，下图中的规则为centos6默认添加的规则。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifap3000vpwr7cqad5sgx/2.png" alt="image"></p>
<p>注意：在参照本文进行iptables实验时，请务必在个人的测试机上进行。</p>
<p>为了准备一个从零开始的环境，我们将centos6默认提供的规则清空，以便我们进行实验，使用iptables -F INPUT命令清空filter表INPUT链中的规则，后面我们会单独对清除规则的相关命令进行总结，此处不用纠结此命令。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifap3000vpwr7cqad5sgx/3.png" alt="image"></p>
<p>清空INPUT链以后，filter表中的INPUT链已经不存在任何的规则，但是可以看出，INPUT链的默认策略是ACCEPT，也就是说，INPUT链默认”放行”所有发往本机的报文，当没有任何规则时，会接受所有报文，当报文没有被任何规则匹配到时，也会默认放行报文。</p>
<p>那么此刻，我们就在另外一台机器上，使用ping命令，向当前机器发送报文，如下图所示，ping命令可以得到回应，证明ping命令发送的报文已经正常的发送到了防火墙所在的主机，ping命令所在机器IP地址为146，当前测试防火墙主机的IP地址为156，我们就用这样的环境，对iptables进行操作演示。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifap3000vpwr7cqad5sgx/4.png" alt="image"></p>
<h3 id="增加规则"><a href="#增加规则" class="headerlink" title="增加规则"></a>增加规则</h3><p>那么此处，我们就在156上配置一条规则，拒绝192.168.1.146上的所有报文访问当前机器，之前一直在说，规则由匹配条件与动作组成，那么”拒绝192.168.1.146上的所有报文访问当前机器”这条规则中，报文的”源地址为192.168.1.146″则属于匹配条件，如果报文来自”192.168.1.146″，则表示满足匹配条件，而”拒绝”这个报文，就属于对应的动作，好了，那么怎样用命令去定义这条规则呢？使用如下命令即可</p>
<p><img src="/2022/06/13/uncatalog/cl4cifap3000vpwr7cqad5sgx/5.png" alt="image"></p>
<p>上图中，使用 -t选项指定了要操作的表，此处指定了操作filter表，与之前的查看命令一样，不使用-t选项指定表时，默认为操作filter表。</p>
<p>使用-I选项，指明将”规则”插入至哪个链中，-I表示insert，即插入的意思，所以-I INPUT表示将规则插入于INPUT链中，即添加规则之意。</p>
<p>使用-s选项，指明”匹配条件”中的”源地址”，即如果报文的源地址属于-s对应的地址，那么报文则满足匹配条件，-s为source之意，表示源地址。</p>
<p>使用-j选项，指明当”匹配条件”被满足时，所对应的动作，上例中指定的动作为DROP，在上例中，当报文的源地址为192.168.1.146时，报文则被DROP（丢弃）。</p>
<p>再次查看filter表中的INPUT链，发现规则已经被添加了，在iptables中，动作被称之为”target”，所以，上图中taget字段对应的动作为DROP。</p>
<p>那么此时，我们再通过192.168.1.146去ping主机156，看看能否ping通。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifap3000vpwr7cqad5sgx/6.png" alt="image"></p>
<p>如上图所示，ping 156主机时，PING命令一直没有得到回应，看来我们的iptables规则已经生效了，ping发送的报文压根没有被156主机接受，而是被丢弃了，所以更不要说什么回应了，好了，我们已经成功的配置了一条iptables规则，看来，我们已经入门了。</p>
<p>还记得我们在前文中说过的”计数器”吗？此时，我们再次查看iptables中的规则，可以看到，已经有24个包被对应的规则匹配到，总计大小2016bytes。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifap3000vpwr7cqad5sgx/7.png" alt="image"></p>
<p>此刻，我们来做一个实验。</p>
<p>现在INPUT链中已经存在了一条规则，它拒绝了所有来自192.168.1.146主机中的报文，如果此时，我们在这条规则之后再配置一条规则，后面这条规则规定，接受所有来自192.168.1.146主机中的报文，那么，iptables是否会接受来自146主机的报文呢？我们动手试试。</p>
<p>使用如下命令在filter表的INPUT链中追加一条规则，这条规则表示接受所有来自192.168.1.146的发往本机的报文。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifap3000vpwr7cqad5sgx/8.png" alt="image"></p>
<p>上图中的命令并没有使用-t选项指定filter表，我们一直在说，不使用-t选项指定表时表示默认操作filter表。</p>
<p>上图中，使用-A选项，表示在对应的链中”追加规则”，-A为append之意，所以，-A INPUT则表示在INPUT链中追加规则，而之前示例中使用的-I选项则表示在链中”插入规则”，聪明如你一定明白了，它们的本意都是添加一条规则，只是-A表示在链的尾部追加规则，-I表示在链的首部插入规则而已。</p>
<p>使用-j选项，指定当前规则对应的动作为ACCEPT。</p>
<p>执行完添加规则的命令后，再次查看INPUT链，发现规则已经成功”追加”至INPUT链的末尾，那么现在，第一条规则指明了丢弃所有来自192.168.1.146的报文，第二条规则指明了接受所有来自192.168.1.146的报文，那么结果到底是怎样的呢？实践出真知，在146主机上再次使用ping命令向156主机发送报文，发现仍然是ping不通的，看来第二条规则并没有生效。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifap3000vpwr7cqad5sgx/9.png" alt="image"></p>
<p>而且从上图中第二条规则的计数器可以看到，根本没有任何报文被第二条规则匹配到。</p>
<p>聪明如你一定在猜想，发生上述情况，会不会与规则的先后顺序有关呢？测试一下不就知道了，我们再添加一条规则，新规则仍然规定接受所有来自192.168.1.146主机中的报文，只是这一次，我们将新规则添加至INPUT链的最前面试试。</p>
<p>在添加这条规则之前，我们先把146上的ping命令强制停止了，然后使用如下命令，在filter表的INPUT链的前端添加新规则。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifap3000vpwr7cqad5sgx/10.png" alt="image"></p>
<p>好了，现在第一条规则就是接受所有来自192.168.1.146的报文，而且此时计数是0，此刻，我们再从146上向156发起ping请求。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifap3000vpwr7cqad5sgx/11.png" alt="image"></p>
<p>146上已经可以正常的收到响应报文了，那么回到156查看INPUT链的规则，第一条规则的计数器已经显示出了匹配到的报文数量。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifap3000vpwr7cqad5sgx/12.png" alt="image"><br>看来，规则的顺序很重要。</p>
<p>如果报文已经被前面的规则匹配到，iptables则会对报文执行对应的动作，即使后面的规则也能匹配到当前报文，很有可能也没有机会再对报文执行相应的动作了，就以上图为例，报文先被第一条规则匹配到了，于是当前报文被”放行”了，因为报文已经被放行了，所以，即使上图中的第二条规则即使能够匹配到刚才”放行”的报文，也没有机会再对刚才的报文进行丢弃操作了。这就是iptables的工作机制。</p>
<p>之前在总结查看命令时提到过，使用–line-number选项可以列出规则的序号，如下图所示<br><img src="/2022/06/13/uncatalog/cl4cifap3000vpwr7cqad5sgx/13.png" alt="image"></p>
<p>我们也可以在添加规则时，指定新增规则的编号，这样我们就能在任意位置插入规则了，我们只要把刚才的命令稍作修改即可，如下。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifap3000vpwr7cqad5sgx/14.png" alt="image"></p>
<p>仍然使用-I选项进行插入规则操作，-I INPUT 2表示在INPUT链中新增规则，新增的规则的编号为2，好了，自己动手试试吧。</p>
<h3 id="删除规则"><a href="#删除规则" class="headerlink" title="删除规则"></a>删除规则</h3><p>注意：在参照本文进行iptables实验时，请务必在个人的测试机上进行。</p>
<p>此刻，如果我们想要删除filter表中INPUT中的一条规则，该怎么做呢？</p>
<p>有两种办法</p>
<p>方法一：根据规则的编号去删除规则</p>
<p>方法二：根据具体的匹配条件与动作删除规则</p>
<p>那么我们先看看方法一，先查看一下filter表中INPUT链中的规则</p>
<p><img src="/2022/06/13/uncatalog/cl4cifap3000vpwr7cqad5sgx/15.png" alt="image"></p>
<p>假如我们想要删除上图中的第3条规则，则可以使用如下命令。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifap3000vpwr7cqad5sgx/16.png" alt="image"></p>
<p>上例中，使用了-t选项指定了要操作的表（没错，省略-t默认表示操作filter表），使用-D选项表示删除指定链中的某条规则，-D INPUT 3表示删除INPUT链中的第3条规则。</p>
<p>当然，我们也可以根据具体的匹配条件与动作去删除规则，比如，删除下图中源地址为192.168.1.146，动作为ACCEPT的规则，于是，删除规则的命令如下。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifap3000vpwr7cqad5sgx/17.png" alt="image"></p>
<p>上图中，删除对应规则时，仍然使用-D选项，-D INPUT表示删除INPUT链中的规则，剩下的选项与我们添加规则时一毛一样，-s表示以对应的源地址作为匹配条件，-j ACCEPT表示对应的动作为接受，所以，上述命令表示删除INPUT链中源地址为192.168.1.146，动作为ACCEPT的规则。</p>
<p>而删除指定表中某条链中的所有规则的命令，我们在一开始就使用到了，就是”iptables -t 表名 -F 链名”</p>
<p>-F选项为flush之意，即冲刷指定的链，即删除指定链中的所有规则，但是注意，此操作相当于删除操作，在没有保存iptables规则的情况下，请慎用。</p>
<p>其实，-F选项不仅仅能清空指定链上的规则，其实它还能清空整个表中所有链上的规则，不指定链名，只指定表名即可删除表中的所有规则，命令如下</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">iptables -t 表名 -F</span><br></pre></td></tr></table></figure></div>

<p>不过再次强调，在没有保存iptables规则时，请勿随便清空链或者表中的规则，除非你明白你在干什么。</p>
<h3 id="修改规则"><a href="#修改规则" class="headerlink" title="修改规则"></a>修改规则</h3><p>注意：在参照本文进行iptables实验时，请务必在个人的测试机上进行。</p>
<p>那么，我们怎样修改某条规则中的动作呢？比如，我想把如下规则中的动作从DROP改为REJECT，改怎么办呢？</p>
<p><img src="/2022/06/13/uncatalog/cl4cifap3000vpwr7cqad5sgx/18.png" alt="image"></p>
<p>我们可以使用-R选项修改指定的链中的规则，在修改规则时指定规则对应的编号即可(有坑，慎行)，示例命令如下</p>
<p><img src="/2022/06/13/uncatalog/cl4cifap3000vpwr7cqad5sgx/19.png" alt="image"></p>
<p>上例中，-R选项表示修改指定的链，使用-R INPUT 1表示修改INPUT链的第1条规则，使用-j REJECT表示将INPUT链中的第一条规则的动作修改为REJECT，注意：上例中， -s选项以及对应的源地址不可省略，即使我们已经指定了规则对应的编号，但是在使用-R选项修改某个规则时，必须指定规则对应的原本的匹配条件（如果有多个匹配条件，都需要指定）。</p>
<p>如果上例中的命令没有使用-s指定对应规则中原本的源地址，那么在修改完成后，你修改的规则中的源地址会自动变为0.0.0.0/0（此IP表示匹配所有网段的IP地址），而此时，-j对应的动作又为REJECT，所以在执行上述命令时如果没有指明规则原本的源地址，那么所有IP的请求都被拒绝了（因为没有指定原本的源地址，当前规则的源地址自动变为0.0.0.0/0），如果你正在使用ssh远程到服务器上进行iptables设置，那么你的ssh请求也将会被阻断。</p>
<p>既然使用-R选项修改规则时，必须指明规则原本的匹配条件，那么我们则可以理解为，只能通过-R选项修改规则对应的动作了，所以我觉得，如果你想要修改某条规则，还不如先将这条规则删除，然后在同样位置再插入一条新规则，这样更好，当然，如果你只是为了修改某条规则的动作，那么使用-R选项时，不要忘了指明规则原本对应的匹配条件。</p>
<p>好了，上例中，我们已经将规则中的动作从DROP改为了REJECT，那么DROP与REJECT有什么不同呢？从字面上理解，DROP表示丢弃，REJECT表示拒绝，REJECT表达的意思好像更坚决一点，我们再次从146主机上向156主机上发起ping请求，看看与之前动作为DROP时有什么不同。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifap3000vpwr7cqad5sgx/20.png" alt="image"></p>
<p>如上图所示，当156主机中的iptables规则对应的动作为REJECT时，从146上进行ping操作时，直接就提示”目标不可达”，并没有像之前那样卡在那里，看来，REJECT比DROP更加”干脆”。</p>
<p>其实，我们还可以修改指定链的”默认策略”，没错，就是下图中标注的默认策略。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifap3000vpwr7cqad5sgx/21.png" alt="image"></p>
<p>每张表的每条链中，都有自己的默认策略，我们也可以理解为默认”动作”。</p>
<p>当报文没有被链中的任何规则匹配到时，或者，当链中没有任何规则时，防火墙会按照默认动作处理报文，我们可以修改指定链的默认策略，使用如下命令即可。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifap3000vpwr7cqad5sgx/22.png" alt="image"></p>
<p>使用-t指定要操作的表，使用-P选项指定要修改的链，上例中，-P FORWARD DROP表示将表中FORWRD链的默认策略改为DROP。</p>
<h3 id="保存规则"><a href="#保存规则" class="headerlink" title="保存规则"></a>保存规则</h3><p>在默认的情况下，我们对”防火墙”所做出的修改都是”临时的”，换句话说就是，当重启iptables服务或者重启服务器以后，我们平常添加的规则或者对规则所做出的修改都将消失，为了防止这种情况的发生，我们需要将规则”保存”。</p>
<p>centos7与centos6中的情况稍微有些不同，我们先说centos6中怎样保存iptables规则。</p>
<p>centos6中，使用”service iptables save”命令即可保存规则，规则默认保存在/etc/sysconfig/iptables文件中，如果你刚刚安装完centos6，在刚开始使用iptables时，会发现filter表中会有一些默认的规则，这些默认提供的规则其实就保存在/etc/sysconfig/iptables中，  保存规则的示例如下。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifap3000vpwr7cqad5sgx/23.png" alt="image"></p>
<p>如上图所示，文件中保存了filter表中每条链的默认策略，以及每条链中的规则，由于其他表中并没有设置规则，也没有使用过其他表，所以文件中只保存了filter表中的规则。</p>
<p>当我们对规则进行了修改以后，如果想要修改永久生效，必须使用service iptables save保存规则，当然，如果你误操作了规则，但是并没有保存，那么使用service iptables restart命令重启iptables以后，规则会再次回到上次保存/etc/sysconfig/iptables文件时的模样。</p>
<p>从现在开始，最好养成及时保存规则的好习惯。</p>
<p>centos7中，已经不再使用init风格的脚本启动服务，而是使用unit文件，所以，在centos7中已经不能再使用类似service iptables start这样的命令了，所以service iptables save也无法执行，同时，在centos7中，使用firewall替代了原来的iptables service，不过不用担心，我们只要通过yum源安装iptables与iptables-services即可（iptables一般会被默认安装，但是iptables-services在centos7中一般不会被默认安装），在centos7中安装完iptables-services后，即可像centos6中一样，通过service iptables save命令保存规则了，规则同样保存在/etc/sysconfig/iptables文件中。</p>
<p>此处给出centos7中配置iptables-service的步骤</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">配置好yum源以后安装iptables-service</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> yum install -y iptables-services</span></span><br><span class="line"><span class="meta">#</span><span class="bash">停止firewalld</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> systemctl stop firewalld</span></span><br><span class="line"><span class="meta">#</span><span class="bash">禁止firewalld自动启动</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> systemctl <span class="built_in">disable</span> firewalld</span></span><br><span class="line"><span class="meta">#</span><span class="bash">启动iptables</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> systemctl start iptables</span></span><br><span class="line"><span class="meta">#</span><span class="bash">将iptables设置为开机自动启动，以后即可通过iptables-service控制iptables服务</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> systemctl <span class="built_in">enable</span> iptables</span></span><br></pre></td></tr></table></figure></div>


<p>上述配置过程只需一次，以后即可在centos7中愉快的使用service iptables save命令保存iptables规则了。</p>
<h3 id="其他通用方法"><a href="#其他通用方法" class="headerlink" title="其他通用方法"></a>其他通用方法</h3><p>还可以使用另一种方法保存iptables规则，就是使用iptables-save命令</p>
<p>使用iptables-save并不能保存当前的iptables规则，但是可以将当前的iptables规则以”保存后的格式”输出到屏幕上。</p>
<p>所以，我们可以使用iptables-save命令，再配合重定向，将规则重定向到/etc/sysconfig/iptables文件中即可。</p>
<p>iptables-save &gt; /etc/sysconfig/iptables</p>
<p>我们也可以将/etc/sysconfig/iptables中的规则重新载入为当前的iptables规则，但是注意，未保存入/etc/sysconfig/iptables文件中的修改将会丢失或者被覆盖。</p>
<p>使用iptables-restore命令可以从指定文件中重载规则，示例如下</p>
<p>iptables-restore &lt; /etc/sysconfig/iptables</p>
<p>再次提醒：重载规则时，现有规则将会被覆盖。</p>
<h3 id="命令小结"><a href="#命令小结" class="headerlink" title="命令小结"></a>命令小结</h3><p>上文已经详细的举例并描述了怎样进行iptables规则管理，为了以后能够快速的回顾，我们把上述命令总结一下。</p>
<h4 id="添加规则"><a href="#添加规则" class="headerlink" title="添加规则"></a>添加规则</h4><p>注意点：添加规则时，规则的顺序非常重要</p>
<p>在指定表的指定链的尾部添加一条规则，-A选项表示在对应链的末尾添加规则，省略-t选项时，表示默认操作filter表中的规则</p>
<p>命令语法：iptables -t 表名 -A 链名 匹配条件 -j 动作<br>示例：iptables -t filter -A INPUT -s 192.168.1.146 -j DROP</p>
<p>在指定表的指定链的首部添加一条规则，-I选型表示在对应链的开头添加规则</p>
<p>命令语法：iptables -t 表名 -I 链名 匹配条件 -j 动作<br>示例：iptables -t filter -I INPUT -s 192.168.1.146 -j ACCEPT</p>
<p>在指定表的指定链的指定位置添加一条规则</p>
<p>命令语法：iptables -t 表名 -I 链名 规则序号 匹配条件 -j 动作<br>示例：iptables -t filter -I INPUT 5 -s 192.168.1.146 -j REJECT</p>
<p>设置指定表的指定链的默认策略（默认动作），并非添加规则。</p>
<p>命令语法：iptables -t 表名 -P 链名 动作<br>示例：iptables -t filter -P FORWARD ACCEPT<br>上例表示将filter表中FORWARD链的默认策略设置为ACCEPT</p>
<h4 id="删除规则-1"><a href="#删除规则-1" class="headerlink" title="删除规则"></a>删除规则</h4><p>注意点：如果没有保存规则，删除规则时请慎重</p>
<p>按照规则序号删除规则，删除指定表的指定链的指定规则，-D选项表示删除对应链中的规则。</p>
<p>命令语法：iptables -t 表名 -D 链名 规则序号<br>示例：iptables -t filter -D INPUT 3<br>上述示例表示删除filter表中INPUT链中序号为3的规则。</p>
<p>按照具体的匹配条件与动作删除规则，删除指定表的指定链的指定规则。</p>
<p>命令语法：iptables -t 表名 -D 链名 匹配条件 -j 动作<br>示例：iptables -t filter -D INPUT -s 192.168.1.146 -j DROP<br>上述示例表示删除filter表中INPUT链中源地址为192.168.1.146并且动作为DROP的规则。</p>
<p>删除指定表的指定链中的所有规则，-F选项表示清空对应链中的规则，执行时需三思。</p>
<p>命令语法：iptables -t 表名 -F 链名<br>示例：iptables -t filter -F INPUT</p>
<p>删除指定表中的所有规则，执行时需三思。</p>
<p>命令语法：iptables -t 表名 -F<br>示例：iptables -t filter -F</p>
<h4 id="修改规则-1"><a href="#修改规则-1" class="headerlink" title="修改规则"></a>修改规则</h4><p>注意点：如果使用-R选项修改规则中的动作，那么必须指明原规则中的原匹配条件，例如源IP，目标IP等。</p>
<p>修改指定表中指定链的指定规则，-R选项表示修改对应链中的规则，使用-R选项时要同时指定对应的链以及规则对应的序号，并且规则中原本的匹配条件不可省略。</p>
<p>命令语法：iptables -t 表名 -R 链名 规则序号 规则原本的匹配条件 -j 动作<br>示例：iptables -t filter -R INPUT 3 -s 192.168.1.146 -j ACCEPT<br>上述示例表示修改filter表中INPUT链的第3条规则，将这条规则的动作修改为ACCEPT， -s 192.168.1.146为这条规则中原本的匹配条件，如果省略此匹配条件，修改后的规则中的源地址可能会变为0.0.0.0/0。</p>
<p>其他修改规则的方法：先通过编号删除规则，再在原编号位置添加一条规则。</p>
<p>修改指定表的指定链的默认策略（默认动作），并非修改规则，可以使用如下命令。</p>
<p>命令语法：iptables -t 表名 -P 链名 动作<br>示例：iptables -t filter -P FORWARD ACCEPT<br>上例表示将filter表中FORWARD链的默认策略修改为ACCEPT</p>
<h4 id="保存规则-1"><a href="#保存规则-1" class="headerlink" title="保存规则"></a>保存规则</h4><p>保存规则命令如下，表示将iptables规则保存至/etc/sysconfig/iptables文件中，如果对应的操作没有保存，那么当重启iptables服务以后</p>
<p>service iptables save<br>注意点：centos7中使用默认使用firewalld，如果想要使用上述命令保存规则，需要安装iptables-services，具体配置过程请回顾上文。</p>
<p>或者使用如下方法保存规则</p>
<p>iptables-save &gt; /etc/sysconfig/iptables<br>可以使用如下命令从指定的文件载入规则，注意：重载规则时，文件中的规则将会覆盖现有规则。</p>
<p>iptables-restore &lt; /etc/sysconfig/iptables</p>
<p>好了，这篇文章已经总结了怎样添加、删除、修改 iptables规则，与前文结合起来，我们已经掌握了对iptables规则的”增删改查”，同时，这篇文章也总结了如何设置链的默认策略，以及怎样保存iptables规则。</p>
<p>我想，你已经入门了，对吗？如果你是一个新手，希望这篇文章能对你有所帮助。</p>
]]></content>
      <tags>
        <tag>云原生基础系列</tag>
        <tag>Kubernetes网络</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes网络系列之(二十五)iptables匹配条件总结之二(常用扩展模块)</title>
    <url>/2022/06/13/uncatalog/cl4cifap4000xpwr7gg0bhm2w/</url>
    <content><![CDATA[<hr>
<span id="more"></span>

<hr>
<p>前文已经总结了iptables中的基本匹配条件，以及简单的扩展匹配条件，此处，我们来认识一些新的扩展模块。</p>
<h3 id="iprange扩展模块"><a href="#iprange扩展模块" class="headerlink" title="iprange扩展模块"></a>iprange扩展模块</h3><p>之前我们已经总结过，在不使用任何扩展模块的情况下，使用-s选项或者-d选项即可匹配报文的源地址与目标地址，而且在指定IP地址时，可以同时指定多个IP地址，每个IP用”逗号”隔开，但是，-s选项与-d选项并不能一次性的指定一段连续的IP地址范围，如果我们需要指定一段连续的IP地址范围，可以使用iprange扩展模块。</p>
<p>使用iprange扩展模块可以指定”一段连续的IP地址范围”，用于匹配报文的源地址或者目标地址。</p>
<p>iprange扩展模块中有两个扩展匹配条件可以使用</p>
<ul>
<li><p>–src-range</p>
</li>
<li><p>–dst-range</p>
</li>
</ul>
<p>没错，见名知意，上述两个选项分别用于匹配报文的源地址所在范围与目标地址所在范围。</p>
<p>示例如下：</p>
<p><img src="/2022/06/13/uncatalog/cl4cifap4000xpwr7gg0bhm2w/1.png" alt="image"></p>
<p>上例表示如果报文的源IP地址如果在192.168.1.127到192.168.1.146之间，则丢弃报文，IP段的始末IP使用”横杠”连接，–src-range与–dst-range和其他匹配条件一样，能够使用”!”取反，有了前文中的知识作为基础，此处就不再赘述了。</p>
<h3 id="string扩展模块"><a href="#string扩展模块" class="headerlink" title="string扩展模块"></a>string扩展模块</h3><p>使用string扩展模块，可以指定要匹配的字符串，如果报文中包含对应的字符串，则符合匹配条件。</p>
<p>比如，如果报文中包含字符”OOXX”，我们就丢弃当前报文。</p>
<p>首先，我们在IP为146的主机上启动http服务，然后在默认的页面目录中添加两个页面，页面中的内容分别为”OOXX”和”Hello World”，如下图所示，在没有配置任何规则时，126主机可以正常访问146主机上的这两个页面。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifap4000xpwr7gg0bhm2w/2.png" alt="image"></p>
<p>那么，我们想要达到的目的是，如果报文中包含”OOXX”字符，我们就拒绝报文进入本机，所以，我们可以在126上进行如下配置。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifap4000xpwr7gg0bhm2w/3.png" alt="image"></p>
<p>上图中，’-m string’表示使用string模块，’–algo bm’表示使用bm算法去匹配指定的字符串，’ –string “OOXX” ‘则表示我们想要匹配的字符串为”OOXX”</p>
<p>设置完上图中的规则后，由于index.html中包含”OOXX”字符串，所以，146的回应报文无法通过126的INPUT链，所以无法获取到页面对应的内容。</p>
<p>那么，我们来总结一下string模块的常用选项</p>
<ul>
<li><p>–algo：用于指定匹配算法，可选的算法有bm与kmp，此选项为必须选项，我们不用纠结于选择哪个算法，但是我们必须指定一个。</p>
</li>
<li><p>–string：用于指定需要匹配的字符串。</p>
</li>
</ul>
<h3 id="time扩展模块"><a href="#time扩展模块" class="headerlink" title="time扩展模块"></a>time扩展模块</h3><p>我们可以通过time扩展模块，根据时间段区匹配报文，如果报文到达的时间在指定的时间范围以内，则符合匹配条件。</p>
<p>比如，”我想要自我约束，每天早上9点到下午6点不能看网页”，擦，多么残忍的规定，如果你想要这样定义，可以尝试使用如下规则。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifap4000xpwr7gg0bhm2w/4.png" alt="image"></p>
<p>上图中”-m time”表示使用time扩展模块，–timestart选项用于指定起始时间，–timestop选项用于指定结束时间。</p>
<p>如果你想要换一种约束方法，只有周六日不能看网页，那么可以使用如下规则。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifap4000xpwr7gg0bhm2w/5.png" alt="image"></p>
<p>没错，如你所见，使用–weekdays选项可以指定每个星期的具体哪一天，可以同时指定多个，用逗号隔开，除了能够数字表示”星期几”,还能用缩写表示，例如：Mon, Tue, Wed, Thu, Fri, Sat, Sun</p>
<p>当然，你也可以将上述几个选项结合起来使用，比如指定只有周六日的早上9点到下午6点不能浏览网页。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifap4000xpwr7gg0bhm2w/6.png" alt="image"></p>
<p>聪明如你一定想到了，既然有–weekdays选项了，那么有没有–monthdays选项呢？必须有啊！</p>
<p>使用–monthdays选项可以具体指定的每个月的哪一天，比如，如下图设置表示指明每月的22号，23号。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifap4000xpwr7gg0bhm2w/7.png" alt="image"></p>
<p>前文已经总结过，当一条规则中同时存在多个条件时，多个条件之间默认存在”与”的关系，所以，下图中的设置表示匹配的时间必须为星期5，并且这个”星期5″同时还需要是每个月的22号到28号之间的一天，所以，下图中的设置表示每个月的第4个星期5</p>
<p><img src="/2022/06/13/uncatalog/cl4cifap4000xpwr7gg0bhm2w/9.png" alt="image"></p>
<p>除了使用–weekdays选项与–monthdays选项，还可以使用–datestart 选项与-datestop选项，指定具体的日期范围，如下。<br><img src="/2022/06/13/uncatalog/cl4cifap4000xpwr7gg0bhm2w/10.png" alt="image"></p>
<p>上图中指定的日期范围为2017年12月24日到2017年12月27日</p>
<p>上述选项中，–monthdays与–weekdays可以使用”!”取反，其他选项不能取反。</p>
<h3 id="connlimit扩展模块"><a href="#connlimit扩展模块" class="headerlink" title="connlimit扩展模块"></a>connlimit扩展模块</h3><p>使用connlimit扩展模块，可以限制每个IP地址同时链接到server端的链接数量，注意：我们不用指定IP，其默认就是针对”每个客户端IP”，即对单IP的并发连接数限制。</p>
<p>比如，我们想要限制，每个IP地址最多只能占用两个ssh链接远程到server端，我们则可以进行如下限制。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifap4000xpwr7gg0bhm2w/11.png" alt="image"></p>
<p>上例中，使用”-m connlimit”指定使用connlimit扩展，使用”–connlimit-above 2″表示限制每个IP的链接数量上限为2，再配合-p tcp –dport 22，即表示限制每个客户端IP的ssh并发链接数量不能高于2。</p>
<p>centos6中，我们可以对–connlimit-above选项进行取反，没错，老规矩，使用”!”对此条件进行取反，示例如下<br><img src="/2022/06/13/uncatalog/cl4cifap4000xpwr7gg0bhm2w/12.png" alt="image"></p>
<p>上例表示，每个客户端IP的ssh链接数量只要不超过两个，则允许链接。</p>
<p>但是聪明如你一定想到了，上例的规则并不能表示：每个客户端IP的ssh链接数量超过两个则拒绝链接（与前文中的举例原理相同，此处不再赘述，如果你不明白，请参考之前的文章）。也就是说，即使我们配置了上例中的规则，也不能达到”限制”的目的，所以我们通常并不会对此选项取反，因为既然使用了此选项，我们的目的通常就是”限制”连接数量。</p>
<p>centos7中iptables为我们提供了一个新的选项，–connlimit-upto，这个选项的含义与”! –commlimit-above”的含义相同，即链接数量未达到指定的连接数量之意，所以综上所述，–connlimit-upto选项也不常用。</p>
<p>刚才说过，–connlimit-above默认表示限制”每个IP”的链接数量，其实，我们还可以配合–connlimit-mask选项，去限制”某类网段”的链接数量，示例如下：</p>
<p>（注：下例需要一定的网络知识基础，如果你还不了解它们，可以选择先跳过此选项或者先去学习部分的网络知识）</p>
<p><img src="/2022/06/13/uncatalog/cl4cifap4000xpwr7gg0bhm2w/13.png" alt="image"><br>上例中，”–connlimit-mask 24″表示某个C类网段，没错，mask为掩码之意，所以将24转换成点分十进制就表示255.255.255.0，所以，上图示例的规则表示，一个最多包含254个IP的C类网络中，同时最多只能有2个ssh客户端连接到当前服务器，看来资源很紧俏啊！254个IP才有2个名额，如果一个IP同时把两个连接名额都占用了，那么剩下的253个IP连一个连接名额都没有了，那么，我们再看看下例，是不是就好多了。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifap4000xpwr7gg0bhm2w/14.png" alt="image"></p>
<p>上例中，”–connlimit-mask 27″表示某个C类网段，通过计算后可以得知，这个网段中最多只能有30台机器（30个IP），这30个IP地址最多只能有10个ssh连接同时连接到服务器端，是不是比刚才的设置大方多了，当然，这样并不能避免某个IP占用所有连接的情况发生，假设，报文来自192.168.1.40这个IP，按照掩码为27进行计算，这个IP属于192.168.1.32/27网段，如果192.168.1.40同时占用了10个ssh连接，那么当192.168.1.51这个IP向服务端发起ssh连接请求时，同样会被拒绝，因为192.168.1.51这个IP按照掩码为27进行计算，也是属于192.168.1.32/27网段，所以他们共享这10个连接名额。</p>
<p>聪明如你一定明白了，在不使用–connlimit-mask的情况下，连接数量的限制是针对”每个IP”而言的，当使用了–connlimit-mask选项以后，则可以针对”某类IP段内的一定数量的IP”进行连接数量的限制，这样就能够灵活许多，不是吗？</p>
<h3 id="limit扩展模块"><a href="#limit扩展模块" class="headerlink" title="limit扩展模块"></a>limit扩展模块</h3><p>刚才认识了connlimit模块，现在来认识一下limit模块。</p>
<p>connlimit模块是对连接数量进行限制的，limit模块是对”报文到达速率”进行限制的。</p>
<p>用大白话说就是，如果我想要限制单位时间内流入的包的数量，就能用limit模块。</p>
<p>我们可以以秒为单位进行限制，也可以以分钟、小时、天作为单位进行限制。</p>
<p>比如，限制每秒中最多流入3个包，或者限制每分钟最多流入30个包，都可以。</p>
<p>那么，我们来看一个最简单的示例，假设，我们想要限制，外部主机对本机进行ping操作时，本机最多每6秒中放行一个ping包，那么，我们可以进行如下设置（注意，只进行如下设置有可能无法实现限制功能，请看完后面的内容）</p>
<p><img src="/2022/06/13/uncatalog/cl4cifap4000xpwr7gg0bhm2w/16.png" alt="image"></p>
<p>上例中，”-p icmp”表示我们针对ping请求添加了一条规则（ping使用icmp协议），”-m limit”表示使用limit模块， “–limit 10/minute -j ACCEPT”表示每分钟最多放行10个包，就相当于每6秒钟最多放行一个包，换句话说，就是每过6秒钟放行一个包，那么配置完上述规则后，我们在另外一台机器上对当前机器进行ping操作，看看是否能够达到限制的目的，如下图所示。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifap4000xpwr7gg0bhm2w/15.png" alt="image"></p>
<p>我们发现，刚才配置的规则并没有如我们想象中的一样，ping请求的响应速率完全没有发生任何变化，为什么呢？我们一起来分析一下。</p>
<p>我们再来回顾一下刚才配置的规则。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifap4000xpwr7gg0bhm2w/16.png" alt="image"></p>
<p>其实，我们可以把上图中的规则理解为如下含义。</p>
<p>每6秒放行一个包，那么iptables就会计时，每6秒一个轮次，到第6秒时，达到的报文就会匹配到对应的规则，执行对应的动作，而上图中的动作是ACCEPT。</p>
<p>那么在第6秒之前到达的包，则无法被上述规则匹配到。</p>
<p>之前总结过，报文会匹配链中的每一条规则，如果没有任何一条规则能够匹配到，则匹配默认动作（链的默认策略）。</p>
<p>既然第6秒之前的包没有被上述规则匹配到，而我们又没有在INPUT链中配置其他规则，所以，第6秒之前的包肯定会被默认策略匹配到，那么我们看看默认策略是什么。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifap4000xpwr7gg0bhm2w/17.png" alt="image"></p>
<p>现在再想想，我想你应该明白为什么刚才的ping的响应速率没有变化了。</p>
<p>因为，上例中，第六秒的报文的确被对应的规则匹配到了，于是执行了”放行”操作，第6秒之前的报文没有被上图中配置的规则匹配到，但是被默认策略匹配到了，而恰巧，默认动作也是ACCEPT，所以，相当于所有的ping报文都被放行了，怪不得与没有配置规则时的速率一毛一样了。</p>
<p>那么，知错就改，聪明如你一定想到了，我们可以修改INPUT链的默认策略，或者在上例限制规则的后面再加入一条规则，将”漏网之鱼”匹配到即可，示例如下。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifap4000xpwr7gg0bhm2w/18.png" alt="image"></p>
<p>如上图所示，第一条规则表示每分钟最多放行10个icmp包，也就是6秒放行一个，第6秒的icmp包会被上例中的第一条规则匹配到，第6秒之前的包则不会被第一条规则匹配到，于是被后面的拒绝规则匹配到了，那么，此刻，我们再来试试，看看ping的报文放行速率有没有发生改变。</p>
<p>如下图所示<br><img src="/2022/06/13/uncatalog/cl4cifap4000xpwr7gg0bhm2w/19.png" alt="image"></p>
<p>刚开始还真吓我一跳，难道配置的规则还是有问题？</p>
<p>结果发现，只有前5个ping包没有受到限制，之后的ping包已经开始受到了规则的限制了。</p>
<p>从上图可以看出，除了前5个ping包以外，之后的ping包差不多每6秒才能ping通一次，看来，之后的ping包已经受到了规则的控制，被限制了流入防火墙的速率了，那么，前5个ping包是什么鬼？为什么它们不受规则限制呢？其实，这个现象正好引出另一个话题，出现上图中的情况，是因为另一个选项：”–limit-burst”</p>
<p>limit-burst选项是干什么用的呢？我们先用不准确的大白话描述一遍，”–limit-burst”可以指定”空闲时可放行的包的数量”，其实，这样说并不准确，但是我们可以先这样大概的理解，在不使用”–limit-burst”选项明确指定放行包的数量时，默认值为5，所以，才会出现上图中的情况，前5个ping包并没有受到任何速率限制，之后的包才受到了规则的限制。</p>
<p>如果想要彻底了解limit模块的工作原理，我们需要先了解一下”令牌桶”算法，因为limit模块使用了令牌桶算法。</p>
<p>我们可以这样想象，有一个木桶，木桶里面放了5块令牌，而且这个木桶最多也只能放下5块令牌，所有报文如果想要出关入关，都必须要持有木桶中的令牌才行，这个木桶有一个神奇的功能，就是每隔6秒钟会生成一块新的令牌，如果此时，木桶中的令牌不足5块，那么新生成的令牌就存放在木桶中，如果木桶中已经存在5块令牌，新生成的令牌就无处安放了，只能溢出木桶（令牌被丢弃），如果此时有5个报文想要入关，那么这5个报文就去木桶里找令牌，正好一人一个，于是他们5个手持令牌，快乐的入关了，此时木桶空了，再有报文想要入关，已经没有对应的令牌可以使用了，但是，过了6秒钟，新的令牌生成了，此刻，正好来了一个报文想要入关，于是，这个报文拿起这个令牌，就入关了，在这个报文之后，如果很长一段时间内没有新的报文想要入关，木桶中的令牌又会慢慢的积攒了起来，直到达到5个令牌，并且一直保持着5个令牌，直到有人需要使用这些令牌，这就是令牌桶算法的大致逻辑。</p>
<p>那么，就拿刚才的”令牌桶”理论类比我们的命令，”–limit”选项就是用于指定”多长时间生成一个新令牌的”，”–limit-burst”选项就是用于指定”木桶中最多存放几个令牌的”，现在，你明白了吗？？示例如下</p>
<p><img src="/2022/06/13/uncatalog/cl4cifap4000xpwr7gg0bhm2w/20.png" alt="image"></p>
<p>上例表示，令牌桶中最多能存放3个令牌，每分钟生成10个令牌（即6秒钟生成一个令牌）。</p>
<p>之前说过，使用”–limit”选项时，可以选择的时间单位有多种，如下</p>
<ul>
<li><p>/second</p>
</li>
<li><p>/minute</p>
</li>
<li><p>/hour</p>
</li>
<li><p>/day</p>
</li>
</ul>
<p>比如，3/second表示每秒生成3个”令牌”，30/minute表示没分钟生成30个”令牌”。</p>
<p>我不知道我到底解释清楚没有，我感觉我解释清楚了，哥们儿你赶紧动手试试吧。</p>
<h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>老规矩，为了方便以后回顾，我们将上文中提到的命令总结如下。</p>
<p>iprange模块<br>包含的扩展匹配条件如下</p>
<ul>
<li><p>–src-range：指定连续的源地址范围</p>
</li>
<li><p>–dst-range：指定连续的目标地址范围</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">示例</span></span><br><span class="line">iptables -t filter -I INPUT -m iprange --src-range 192.168.1.127-192.168.1.146 -j DROP</span><br><span class="line">iptables -t filter -I OUTPUT -m iprange --dst-range 192.168.1.127-192.168.1.146 -j DROP</span><br><span class="line">iptables -t filter -I INPUT -m iprange ! --src-range 192.168.1.127-192.168.1.146 -j DROP</span><br><span class="line"></span><br></pre></td></tr></table></figure></div></li>
</ul>
<p>string模块<br>常用扩展匹配条件如下</p>
<ul>
<li><p>–algo：指定对应的匹配算法，可用算法为bm、kmp，此选项为必需选项。</p>
</li>
<li><p>–string：指定需要匹配的字符串</p>
</li>
</ul>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">示例</span></span><br><span class="line">iptables -t filter -I INPUT -p tcp --sport 80 -m string --algo bm --string &quot;OOXX&quot; -j REJECT</span><br><span class="line">iptables -t filter -I INPUT -p tcp --sport 80 -m string --algo bm --string &quot;OOXX&quot; -j REJECT</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>

<p>time模块<br>常用扩展匹配条件如下</p>
<ul>
<li><p>–timestart：用于指定时间范围的开始时间，不可取反</p>
</li>
<li><p>–timestop：用于指定时间范围的结束时间，不可取反</p>
</li>
<li><p>–weekdays：用于指定”星期几”，可取反</p>
</li>
<li><p>–monthdays：用于指定”几号”，可取反</p>
</li>
<li><p>–datestart：用于指定日期范围的开始日期，不可取反</p>
</li>
<li><p>–datestop：用于指定日期范围的结束时间，不可取反</p>
</li>
</ul>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">示例</span></span><br><span class="line">iptables -t filter -I OUTPUT -p tcp --dport 80 -m time --timestart 09:00:00 --timestop 19:00:00 -j REJECT</span><br><span class="line">iptables -t filter -I OUTPUT -p tcp --dport 443 -m time --timestart 09:00:00 --timestop 19:00:00 -j REJECT</span><br><span class="line">iptables -t filter -I OUTPUT -p tcp --dport 80  -m time --weekdays 6,7 -j REJECT</span><br><span class="line">iptables -t filter -I OUTPUT -p tcp --dport 80  -m time --monthdays 22,23 -j REJECT</span><br><span class="line">iptables -t filter -I OUTPUT -p tcp --dport 80  -m time ! --monthdays 22,23 -j REJECT</span><br><span class="line">iptables -t filter -I OUTPUT -p tcp --dport 80  -m time --timestart 09:00:00 --timestop 18:00:00 --weekdays 6,7 -j REJECT</span><br><span class="line">iptables -t filter -I OUTPUT -p tcp --dport 80  -m time --weekdays 5 --monthdays 22,23,24,25,26,27,28 -j REJECT</span><br><span class="line">iptables -t filter -I OUTPUT -p tcp --dport 80  -m time --datestart 2017-12-24 --datestop 2017-12-27 -j REJECT</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>

<p>connlimit 模块<br>常用的扩展匹配条件如下</p>
<ul>
<li><p>–connlimit-above：单独使用此选项时，表示限制每个IP的链接数量。</p>
</li>
<li><p>–connlimit-mask：此选项不能单独使用，在使用–connlimit-above选项时，配合此选项，则可以针对”某类IP段内的一定数量的IP”进行连接数量的限制，如果不明白可以参考上文的详细解释。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">示例</span></span><br><span class="line">iptables -I INPUT -p tcp --dport 22 -m connlimit --connlimit-above 2 -j REJECT</span><br><span class="line">iptables -I INPUT -p tcp --dport 22 -m connlimit --connlimit-above 20 --connlimit-mask 24 -j REJECT</span><br><span class="line">iptables -I INPUT -p tcp --dport 22 -m connlimit --connlimit-above 10 --connlimit-mask 27 -j REJECT</span><br><span class="line"></span><br></pre></td></tr></table></figure></div></li>
</ul>
<p>limit模块<br>常用的扩展匹配条件如下</p>
<ul>
<li><p>–limit-burst：类比”令牌桶”算法，此选项用于指定令牌桶中令牌的最大数量，上文中已经详细的描述了”令牌桶”的概念，方便回顾。</p>
</li>
<li><p>–limit：类比”令牌桶”算法，此选项用于指定令牌桶中生成新令牌的频率，可用时间单位有second、minute 、hour、day。</p>
</li>
</ul>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">示例</span> </span><br><span class="line"><span class="meta">#</span><span class="bash">注意，如下两条规则需配合使用，具体原因上文已经解释过，忘记了可以回顾。</span></span><br><span class="line">iptables -t filter -I INPUT -p icmp -m limit --limit-burst 3 --limit 10/minute -j ACCEPT</span><br><span class="line">iptables -t filter -A INPUT -p icmp -j REJECT</span><br></pre></td></tr></table></figure></div>]]></content>
      <tags>
        <tag>云原生基础系列</tag>
        <tag>Kubernetes网络</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes网络系列之(二十四)iptables匹配条件总结之一</title>
    <url>/2022/06/13/uncatalog/cl4cifap5000zpwr721cugaqx/</url>
    <content><![CDATA[<hr>
<span id="more"></span>

<hr>
<p>经过前文的总结，我们已经能够熟练的管理规则了，但是我们使用过的”匹配条件”少得可怜，之前的示例中，我们只使用过一种匹配条件，就是将”源地址”作为匹配条件。</p>
<p>那么这篇文章中，我们就来了解一下更多的匹配条件，以及匹配条件的更多用法。</p>
<p>注意：在参照本文进行iptables实验时，请务必在个人的测试机上进行，因为如果iptables规则设置不当，有可能使你无法连接到远程主机中。</p>
<h3 id="匹配条件的更多用法"><a href="#匹配条件的更多用法" class="headerlink" title="匹配条件的更多用法"></a>匹配条件的更多用法</h3><p>还是从我们最常用的”源地址”说起吧，我们知道，使用-s选项作为匹配条件，可以匹配报文的源地址，但是之前的示例中，我们每次指定源地址，都只是指定单个IP，示例如下。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifap5000zpwr721cugaqx/1.png" alt="image"></p>
<p>其实，我们也可以在指定源地址时，一次指定多个，用”逗号”隔开即可，示例如下。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifap5000zpwr721cugaqx/2.png" alt="image"></p>
<p>可以看出，上例中，一次添加了两条规则，两条规则只是源地址对应的IP不同，注意，上例中的”逗号”两侧均不能包含空格，多个IP之间必须与逗号相连。</p>
<p>除了能指定具体的IP地址，还能指定某个网段，示例如下</p>
<p><img src="/2022/06/13/uncatalog/cl4cifap5000zpwr721cugaqx/3.png" alt="image"></p>
<p>上例表示，如果报文的源地址IP在10.6.0.0/16网段内，当报文经过INPUT链时就会被DROP掉。</p>
<p>其实，我们还可以对匹配条件取反，先看示例，如下。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifap5000zpwr721cugaqx/4.png" alt="image"></p>
<p>上图中，使用”! -s 192.168.1.146″表示对 -s 192.168.1.146这个匹配条件取反， -s 192.168.1.146表示报文源IP地址为192.168.1.146即可满足匹配条件，使用 “!” 取反后则表示，报文源地址IP只要不为192.168.1.146即满足条件，那么，上例中规则表达的意思就是，只要发往本机的报文的源地址不是192.168.1.146，就接受报文。</p>
<p>此刻，你猜猜，按照上例中的配置，如果此时从146主机上向防火墙所在的主机发送ping请求，146主机能得到回应吗？（此处不考虑其他链，只考虑filter表的INPUT链）</p>
<p>为了给你思考的空间，我把答案写的远一点。</p>
<p><br><br><br><br><br><br><br><br></p>
<p>答案是：能，也就是说，按照上例的配置，146主机仍然能够ping通当前主机，为什么呢？我们来分析一下。</p>
<p>上例中，filter表的INPUT链中只有一条规则，这条规则要表达的意思就是：</p>
<p>只要报文的源IP不是192.168.1.146，那么就接受此报文，但是，某些小伙伴可能会误会，把上例中的规则理解成如下含义，</p>
<p>只要报文的源IP是192.168.1.146，那么就不接受此报文，这种理解与上述理解看似差别不大，其实完全不一样，这样理解是错误的，上述理解才是正确的。</p>
<p>换句话说就是，报文的源IP不是192.168.1.146时，会被接收，并不能代表，报文的源IP是192.168.1.146时，会被拒绝。</p>
<p>上例中，因为并没有任何一条规则指明源IP是192.168.1.146时，该执行怎样的动作，所以，当来自192.168.1.146的报文经过INPUT链时，并不能匹配上例中的规则，于是，此报文就继续匹配后面的规则，可是，上例中只有一条规则，这条规则后面没有其他可以匹配的规则，于是，此报文就会去匹配当前链的默认动作(默认策略)，而上例中，INPUT链的默认动作为ACCEPT，所以，来自146的ping报文就被接收了，如果，把上例中INPUT链的默认策略改为DROP，那么，146的报文将会被丢弃，146上的ping命令将得不到任何回应，但是如果将INPUT链的默认策略设置为DROP，当INPUT链中没有任何规则时，所有外来报文将会被丢弃，包括我们ssh远程连接。</p>
<p>好了，我们通过上例，不仅了解到了怎样对匹配条件取反，还加深了我们对默认策略的了解，一举两得，我们继续聊。</p>
<h3 id="匹配条件：目标IP地址"><a href="#匹配条件：目标IP地址" class="headerlink" title="匹配条件：目标IP地址"></a>匹配条件：目标IP地址</h3><p>除了可以通过-s选项指定源地址作为匹配条件，我们还可以使用-d选项指定”目标地址”作为匹配条件。</p>
<p>源地址表示报文从哪里来，目标地址表示报文要到哪里去。</p>
<p>除了127.0.0.1回环地址以外，当前机器有两个IP地址，IP如下。<br><img src="/2022/06/13/uncatalog/cl4cifap5000zpwr721cugaqx/5.png" alt="image"></p>
<p>假设，我们想要拒绝146主机发来的报文，但是我们只想拒绝146向156这个IP发送报文，并不想要防止146向101这个IP发送报文，我们就可以指定目标地址作为匹配条件，示例如下。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifap5000zpwr721cugaqx/6.png" alt="image"></p>
<p>上例表示只丢弃从146发往156这个IP的报文，但是146发往101这个IP的报文并不会被丢弃，如果我们不指定任何目标地址，则目标地址默认为0.0.0.0/0，同理，如果我们不指定源地址，源地址默认为0.0.0.0/0，0.0.0.0/0表示所有IP，示例如下。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifap5000zpwr721cugaqx/7.png" alt="image"></p>
<p>上例表示，所有IP发送往101的报文都将被丢弃。</p>
<p>与-s选项一样，-d选项也可以使用”叹号”进行取反，也能够同时指定多个IP地址，使用”逗号”隔开即可。</p>
<p>但是请注意，不管是-s选项还是-d选项，取反操作与同时指定多个IP的操作不能同时使用。</p>
<p>需要明确的一点就是：当一条规则中有多个匹配条件时，这多个匹配条件之间，默认存在”与”的关系。</p>
<p>说白了就是，当一条规则中存在多个匹配条件时，报文必须同时满足这些条件，才算做被规则匹配。</p>
<p>就如下例所示，下图中的规则包含有两个匹配条件，源地址与目标地址，报文必须同时能被这两个条件匹配，才算作被当前规则匹配，也就是说，下例中，报文必须来自146，同时报文的目标地址必须为101，才会被如下规则匹配，两个条件必须同时满足。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifap5000zpwr721cugaqx/8.png" alt="image"></p>
<p>我们除了能够使用-s选项和-d选项匹配源IP与目标IP以外，还能够匹配”源端口”与”目标端口”，但是我们一会儿再聊怎样匹配端口，我们先聊聊其他选项。</p>
<h3 id="匹配条件：协议类型"><a href="#匹配条件：协议类型" class="headerlink" title="匹配条件：协议类型"></a>匹配条件：协议类型</h3><p>我们可以使用-p选项，指定需要匹配的报文的协议类型。</p>
<p>假设，我们只想要拒绝来自146的tcp类型的请求，那么可以进行如下设置</p>
<p><img src="/2022/06/13/uncatalog/cl4cifap5000zpwr721cugaqx/9.png" alt="image"></p>
<p>上图中，防火墙拒绝了来自146的tcp报文发往156这个IP，那么我们来测试一下，我们在146上使用ssh连接101这个IP试试（ssh协议的传输层协议属于tcp协议类型）</p>
<p><img src="/2022/06/13/uncatalog/cl4cifap5000zpwr721cugaqx/10.png" alt="image"></p>
<p>如上图所示，ssh连接被拒绝了，那么我们使用ping命令试试 (ping命令使用icmp协议)，看看能不能ping通156。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifap5000zpwr721cugaqx/11.png" alt="image"></p>
<p>可以看到，PING命令可以ping通156，证明icmp协议并没有被规则匹配到，只有tcp类型的报文被匹配到了。</p>
<p>那么，-p选项都支持匹配哪些协议呢？我们总结一下</p>
<p>centos6中，-p选项支持如下协议类型</p>
<p>tcp, udp, udplite, icmp, esp, ah, sctp</p>
<p>centos7中，-p选项支持如下协议类型</p>
<p>tcp, udp, udplite, icmp, icmpv6,esp, ah, sctp, mh</p>
<p>当不使用-p指定协议类型时，默认表示所有类型的协议都会被匹配到，与使用-p all的效果相同。</p>
<h3 id="匹配条件：网卡接口"><a href="#匹配条件：网卡接口" class="headerlink" title="匹配条件：网卡接口"></a>匹配条件：网卡接口</h3><p>我们再来认识一个新的匹配条件，当本机有多个网卡时，我们可以使用 -i 选项去匹配报文是通过哪块网卡流入本机的。</p>
<p>我们先动手做个小例子，对-i选项有一个初步的了解以后，再结合理论去看。</p>
<p>当前主机的网卡名称为eth4，如下图</p>
<p><img src="/2022/06/13/uncatalog/cl4cifap5000zpwr721cugaqx/12.png" alt="image"></p>
<p>假设想要拒绝由网卡eth4流入的ping请求报文，则可以进行如下设置。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifap5000zpwr721cugaqx/13.png" alt="image"></p>
<p>上图中，使用-i选项，指定网卡名称，使用-p选项，指定了需要匹配的报文协议类型，上例表示丢弃由eth4网卡流入的icmp类型的报文。</p>
<p>是不是很容易理解，但是，我们需要考虑一个问题，-i选项是用于匹配报文流入的网卡的，也就是说，从本机发出的报文是不可能会使用到-i选项的，因为这些由本机发出的报文压根不是从网卡流入的，而是要通过网卡发出的，从这个角度考虑，-i选项的使用是有限制的。</p>
<p>为了更好的解释-i选项，我们回顾一下在理论总结中的一张iptables全局报文流向图，如下。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifap5000zpwr721cugaqx/14.png" alt="image"></p>
<p>既然-i选项是用于判断报文是从哪个网卡流入的，那么，-i选项只能用于上图中的PREROUTING链、INPUT链、FORWARD链，这是-i选项的特殊性，因为它只是用于判断报文是从哪个网卡流入的，所以只能在上图中”数据流入流向”的链中与FORWARD链中存在，而上图中的”数据发出流向”经过的链中，是不可能使用-i选项的，比如上图中的OUTPUT链与POSTROUTING链，他们都不能使用-i选项。</p>
<p>理解完-i选项，再来理解-o选项就好办了。</p>
<p>当主机有多块网卡时，可以使用-o选项，匹配报文将由哪块网卡流出，没错，-o选项与-i选项是相对的，-i选项用于匹配报文从哪个网卡流入，-o选项用于匹配报文将从哪个网卡流出。</p>
<p>聪明如你，一定想到了，-i选项只能用于PREROUTING链、INPUT链、FORWARD链，那么-o选项只能用于FORWARD链、OUTPUT链、POSTROUTING链。</p>
<p>因为-o选项是用于匹配报文将由哪个网卡”流出”的，所以与上图中的”数据进入流向”中的链没有任何缘分，所以，-o选项只能用于FORWARD链、OUTPUT链、POSTROUTING链中。</p>
<p>看来，FORWARD链属于”中立国”，它能同时使用-i选项与-o选项。</p>
<h3 id="扩展匹配条件"><a href="#扩展匹配条件" class="headerlink" title="扩展匹配条件"></a>扩展匹配条件</h3><p>好了，现在，我们就要聊聊，怎样匹配报文的”源端口”与”目标端口”。</p>
<p>在上文中，我们总结了”源地址”与”目标地址”以后，就顺便提到了”源端口”与”目标端口”，但是，为什么刚才不介绍”源端口”与”目标端口”，非要现在介绍呢？这是因为”源端口”与”目标端口”属于扩展匹配条件，”源地址”与”目标地址”属于基本匹配条件，上文中介绍到的匹配条件，都属于基本匹配条件，所以，我们单独把”源端口”与”目标端口”，放在后面总结，是为了引出扩展匹配条件的概念。</p>
<p>那么，先来了解一下，什么是扩展匹配条件。</p>
<p>不是基本匹配条件的就是扩展匹配条件，这样说好像是句废话，我们可以这样理解，基本匹配条件我们可以直接使用，而如果想要使用扩展匹配条件，则需要依赖一些扩展模块，或者说，在使用扩展匹配条件之前，需要指定相应的扩展模块才行，这样说不容易明白，我们做个例子，就能够明白。</p>
<p>我们知道，sshd服务的默认端口为22，当我们使用ssh工具远程连接主机时，默认会连接服务端的22号端口，假设，我们现在想要使用iptables设置一条规则，拒绝来自192.168.1.146的ssh请求，我们就可以拒绝146上的报文能够发往本机的22号端口，这个时候，就需要用到”目标端口”选项。</p>
<p>使用选项–dport可以匹配报文的目标端口，–dport意为destination-port，即表示目标端口。</p>
<p>注意，与之前的选项不同，–dport前有两条”横杠”，而且，使用–dport选项时，必须事先指定了使用哪种协议，即必须先使用-p选项，示例如下</p>
<p><img src="/2022/06/13/uncatalog/cl4cifap5000zpwr721cugaqx/15.png" alt="image"></p>
<p>上图中，我们就使用了扩展匹配条件–dport，指定了匹配报文的目标端口，如果外来报文的目标端口为本机的22号端口（ssh默认端口），则拒绝之，而在使用–dport之前，我们使用-m选项，指定了对应的扩展模块为tcp，也就是说，如果想要使用–dport这个扩展匹配条件，则必须依靠某个扩展模块完成，上例中，这个扩展模块就是tcp扩展模块，最终，我们使用的是tcp扩展模块中的dport扩展匹配条件。</p>
<p>现在，我们再回过头来看看扩展匹配条件的概念，就更加明白了。</p>
<p>扩展匹配条件被使用时，则需要依赖一些扩展模块，或者说，在使用扩展匹配条件之前，需要指定相应的扩展模块才行。</p>
<p>现在你明白了吗？ -m tcp表示使用tcp扩展模块，–dport表示tcp扩展模块中的一个扩展匹配条件，可用于匹配报文的目标端口。</p>
<p>注意，-p tcp与 -m tcp并不冲突，-p用于匹配报文的协议，-m 用于指定扩展模块的名称，正好，这个扩展模块也叫tcp。</p>
<p>其实，上例中，我们可以省略-m选项，示例如下。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifap5000zpwr721cugaqx/16.png" alt="image"></p>
<p>当使用-p选项指定了报文的协议时，如果在没有使用-m指定对应的扩展模块名称的情况下，使用了扩展匹配条件，  iptables默认会调用与-p选项对应的协议名称相同的模块。</p>
<p>上例中，我们使用-p选项指定了协议名称，使用扩展匹配条件–dport指定了目标端口，在使用扩展匹配条件的时候，如果没有使用-m指定使用哪个扩展模块，iptables会默认使用”-m 协议名”，而协议名就是-p选项对应的协议名，上例中，-p 对应的值为tcp，所以默认调用的扩展模块就为-m tcp，如果-p对应的值为udp，那么默认调用的扩展模块就为-m udp。</p>
<p>所以，上例中，其实”隐式”的指定了扩展模块，只是没有表现出来罢了。</p>
<p>所以，在使用扩展匹配条件时，一定要注意，如果这个扩展匹配条件所依赖的扩展模块名正好与-p对应的协议名称相同，那么则可省略-m选项，否则则不能省略-m选项，必须使用-m选项指定对应的扩展模块名称，这样说可能还是不是特别明了，在后续的举例中，我们会更加明了的理解这些概念。</p>
<p>有”目标端口”，就有”源端口”，代表”源端口”的扩展匹配条件为–sport</p>
<p>使用–sport可以判断报文是否从指定的端口发出，即匹配报文的源端口是否与指定的端口一致，–sport表示source-port，即表示源端口之意。</p>
<p>因为我们已经搞明白了dport，那么sport我就不再赘述了，示例如下</p>
<p><img src="/2022/06/13/uncatalog/cl4cifap5000zpwr721cugaqx/17.png" alt="image"></p>
<p>上例中，隐含了”-m tcp”之意，表示使用了tcp扩展模块的–sport扩展匹配条件。</p>
<p>扩展匹配条件是可以取反的，同样是使用”!”进行取反，比如 “! –dport 22″，表示目标端口不是22的报文将会被匹配到。</p>
<p>不管是–sport还是–dsport，都能够指定一个端口范围，比如，–dport 22:25表示目标端口为22到25之间的所有端口，即22端口、23端口、24端口、25端口，示例如下</p>
<p><img src="/2022/06/13/uncatalog/cl4cifap5000zpwr721cugaqx/18.png" alt="image"></p>
<p>也可以写成如下图中的模样，下图中第一条规则表示匹配0号到22号之间的所有端口，下图中的第二条规则表示匹配80号端口以及其以后的所有端口（直到65535）。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifap5000zpwr721cugaqx/19.png" alt="image"></p>
<p>刚才聊到的两个扩展匹配条件都是tcp扩展模块的，其实，tcp扩展模块还有一个比较有用的扩展匹配条件叫做”–tcp-flags”，但是由于篇幅原因，以后再对这个扩展匹配条件进行总结。</p>
<p>借助tcp扩展模块的–sport或者–dport都可以指定一个连续的端口范围，但是无法同时指定多个离散的、不连续的端口，如果想要同时指定多个离散的端口，需要借助另一个扩展模块，”multiport”模块。</p>
<p>我们可以使用multiport模块的–sports扩展条件同时指定多个离散的源端口。</p>
<p>我们可以使用multiport模块的–dports扩展条件同时指定多个离散的目标端口。</p>
<p>示例如下</p>
<p><img src="/2022/06/13/uncatalog/cl4cifap5000zpwr721cugaqx/20.png" alt="image"></p>
<p>上图示例表示，禁止来自146的主机上的tcp报文访问本机的22号端口、36号端口以及80号端口。</p>
<p>上图中，”-m multiport –dports 22,36,80″表示使用了multiport扩展模块的–dports扩展条件，以同时指定了多个离散的端口，每个端口之间用逗号隔开。</p>
<p>上图中的-m multiport是不能省略的，如果你省略了-m multiport，就相当于在没有指定扩展模块的情况下，使用了扩展条件（”–dports”），那么上例中，iptables会默认调用”-m tcp”，但是，”–dports扩展条件”并不属于”tcp扩展模块”,而是属于”multiport扩展模块”，所以，这时就会报错。</p>
<p>综上所述，当使用–dports或者–sports这种扩展匹配条件时，必须使用-m指定模块的名称。</p>
<p>其实，使用multiport模块的–sports与–dpors时，也可以指定连续的端口范围，并且能够在指定连续的端口范围的同时，指定离散的端口号，示例如下。</p>
<p><img src="/2022/06/13/uncatalog/cl4cifap5000zpwr721cugaqx/21.png" alt="image"></p>
<p>上例中的命令表示拒绝来自192.168.1.146的tcp报文访问当前主机的22号端口以及80到88之间的所有端口号，是不是很方便？有没有很灵活？</p>
<p>不过需要注意，multiport扩展只能用于tcp协议与udp协议，即配合-p tcp或者-p udp使用。</p>
<p>再回过头看之前的概念，我想，你应该就更加明白了。</p>
<p>今天，我们只是初步的认识了扩展模块，以及扩展匹配条件，还有一些模块我们并没有总结，好饭不怕晚，后续会有对它们的总结。</p>
<h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>这篇文章中，我们主要总结了一些常用的”基础匹配条件”，并且初步的认识了两个”扩展模块”以及这两个扩展模块中一些常用的扩展条件，为了方便以后回顾，我们将它们总结如下。</p>
<p>首先我们要明确一点，当规则中同时存在多个匹配条件时，多个条件之间默认存在”与”的关系，即报文必须同时满足所有条件，才能被规则匹配。</p>
<p>基本匹配条件总结<br>-s用于匹配报文的源地址,可以同时指定多个源地址，每个IP之间用逗号隔开，也可以指定为一个网段。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">示例如下</span></span><br><span class="line">iptables -t filter -I INPUT -s 192.168.1.111,192.168.1.118 -j DROP</span><br><span class="line">iptables -t filter -I INPUT -s 192.168.1.0/24 -j ACCEPT</span><br><span class="line">iptables -t filter -I INPUT ! -s 192.168.1.0/24 -j ACCEPT</span><br></pre></td></tr></table></figure></div>


<p>-d用于匹配报文的目标地址,可以同时指定多个目标地址，每个IP之间用逗号隔开，也可以指定为一个网段。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">示例如下</span></span><br><span class="line">iptables -t filter -I OUTPUT -d 192.168.1.111,192.168.1.118 -j DROP</span><br><span class="line">iptables -t filter -I INPUT -d 192.168.1.0/24 -j ACCEPT</span><br><span class="line">iptables -t filter -I INPUT ! -d 192.168.1.0/24 -j ACCEPT</span><br></pre></td></tr></table></figure></div>


<p>-p用于匹配报文的协议类型,可以匹配的协议类型tcp、udp、udplite、icmp、esp、ah、sctp等（centos7中还支持icmpv6、mh）。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">示例如下</span></span><br><span class="line">iptables -t filter -I INPUT -p tcp -s 192.168.1.146 -j ACCEPT</span><br><span class="line">iptables -t filter -I INPUT ! -p udp -s 192.168.1.146 -j ACCEPT</span><br></pre></td></tr></table></figure></div>


<p>-i用于匹配报文是从哪个网卡接口流入本机的，由于匹配条件只是用于匹配报文流入的网卡，所以在OUTPUT链与POSTROUTING链中不能使用此选项。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">示例如下</span></span><br><span class="line">iptables -t filter -I INPUT -p icmp -i eth4 -j DROP</span><br><span class="line">iptables -t filter -I INPUT -p icmp ! -i eth4 -j DROP</span><br></pre></td></tr></table></figure></div>


<p>-o用于匹配报文将要从哪个网卡接口流出本机，于匹配条件只是用于匹配报文流出的网卡，所以在INPUT链与PREROUTING链中不能使用此选项。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">示例如下</span></span><br><span class="line">iptables -t filter -I OUTPUT -p icmp -o eth4 -j DROP</span><br><span class="line">iptables -t filter -I OUTPUT -p icmp ! -o eth4 -j DROP</span><br></pre></td></tr></table></figure></div>


<p>扩展匹配条件总结<br>我们来总结一下今天认识的两个扩展模块，以及其中的扩展条件（并非全部，只是这篇文章中介绍过的）</p>
<p>tcp扩展模块</p>
<p>常用的扩展匹配条件如下：</p>
<p>-p tcp -m tcp –sport 用于匹配tcp协议报文的源端口，可以使用冒号指定一个连续的端口范围</p>
<p>-p tcp -m tcp –dport 用于匹配tcp协议报文的目标端口，可以使用冒号指定一个连续的端口范围</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">示例如下</span></span><br><span class="line">iptables -t filter -I OUTPUT -d 192.168.1.146 -p tcp -m tcp --sport 22 -j REJECT</span><br><span class="line">iptables -t filter -I INPUT -s 192.168.1.146 -p tcp -m tcp --dport 22:25 -j REJECT</span><br><span class="line">iptables -t filter -I INPUT -s 192.168.1.146 -p tcp -m tcp --dport :22 -j REJECT</span><br><span class="line">iptables -t filter -I INPUT -s 192.168.1.146 -p tcp -m tcp --dport 80: -j REJECT</span><br><span class="line">iptables -t filter -I OUTPUT -d 192.168.1.146 -p tcp -m tcp ! --sport 22 -j ACCEPT</span><br></pre></td></tr></table></figure></div>


<p>multiport扩展模块</p>
<p>常用的扩展匹配条件如下：</p>
<p>-p tcp -m multiport –sports 用于匹配报文的源端口，可以指定离散的多个端口号,端口之间用”逗号”隔开</p>
<p>-p udp -m multiport –dports 用于匹配报文的目标端口，可以指定离散的多个端口号，端口之间用”逗号”隔开</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">示例如下</span></span><br><span class="line">iptables -t filter -I OUTPUT -d 192.168.1.146 -p udp -m multiport --sports 137,138 -j REJECT</span><br><span class="line">iptables -t filter -I INPUT -s 192.168.1.146 -p tcp -m multiport --dports 22,80 -j REJECT</span><br><span class="line">iptables -t filter -I INPUT -s 192.168.1.146 -p tcp -m multiport ! --dports 22,80 -j REJECT</span><br><span class="line">iptables -t filter -I INPUT -s 192.168.1.146 -p tcp -m multiport --dports 80:88 -j REJECT</span><br><span class="line">iptables -t filter -I INPUT -s 192.168.1.146 -p tcp -m multiport --dports 22,80:88 -j REJECT</span><br></pre></td></tr></table></figure></div>
]]></content>
      <tags>
        <tag>云原生基础系列</tag>
        <tag>Kubernetes网络</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes网络系列之(三十四)iptables小结之常用套路</title>
    <url>/2022/06/13/uncatalog/cl4cisjv20000f8r79ldw1df5/</url>
    <content><![CDATA[<hr>
<span id="more"></span>

<hr>
<p>不知不觉，已经总结了13篇IPTABLES文章，这些文章中有一些需要注意的地方。</p>
<p>此处，我们对前文中的一些注意点进行总结，我们可以理解为对”常用套路”的总结。</p>
<p>记住这些套路，能让我们事半功倍。</p>
<p>阅读这篇文章之前，请确定你已经阅读了之前的文章，否则你有可能会不理解为什么要这样做。</p>
<h3 id="规则的顺序非常重要。"><a href="#规则的顺序非常重要。" class="headerlink" title="规则的顺序非常重要。"></a>规则的顺序非常重要。</h3><p>如果报文已经被前面的规则匹配到，IPTABLES则会对报文执行对应的动作，通常是ACCEPT或者REJECT，报文被放行或拒绝以后，即使后面的规则也能匹配到刚才放行或拒绝的报文，也没有机会再对报文执行相应的动作了（前面规则的动作为LOG时除外），所以，针对相同服务的规则，更严格的规则应该放在前面。</p>
<h3 id="当规则中有多个匹配条件时，条件之间默认存在”与”的关系。"><a href="#当规则中有多个匹配条件时，条件之间默认存在”与”的关系。" class="headerlink" title="当规则中有多个匹配条件时，条件之间默认存在”与”的关系。"></a>当规则中有多个匹配条件时，条件之间默认存在”与”的关系。</h3><p>如果一条规则中包含了多个匹配条件，那么报文必须同时满足这个规则中的所有匹配条件，报文才能被这条规则匹配到。</p>
<h3 id="在不考虑1的情况下，应该将更容易被匹配到的规则放置在前面。"><a href="#在不考虑1的情况下，应该将更容易被匹配到的规则放置在前面。" class="headerlink" title="在不考虑1的情况下，应该将更容易被匹配到的规则放置在前面。"></a>在不考虑1的情况下，应该将更容易被匹配到的规则放置在前面。</h3><p>比如，你写了两条规则，一条针对sshd服务，一条针对web服务。</p>
<p>假设，一天之内，有20000个请求访问web服务，有200个请求访问sshd服务，</p>
<p>那么，应该将针对web服务的规则放在前面，针对sshd的规则放在后面，因为访问web服务的请求频率更高。</p>
<p>如果将sshd的规则放在前面，当报文是访问web服务时，sshd的规则也要白白的验证一遍，由于访问web服务的频率更高，白白耗费的资源就更多。</p>
<p>如果web服务的规则放在前面，由于访问web服务的频率更高，所以无用功会比较少。</p>
<p>换句话说就是，在没有顺序要求的情况下，不同类别的规则，被匹配次数多的、匹配频率高的规则应该放在前面。</p>
<h3 id="当IPTABLES所在主机作为网络防火墙时"><a href="#当IPTABLES所在主机作为网络防火墙时" class="headerlink" title="当IPTABLES所在主机作为网络防火墙时"></a>当IPTABLES所在主机作为网络防火墙时</h3><p>在配置规则时，应着重考虑方向性，双向都要考虑，从外到内，从内到外。</p>
<h3 id="在配置IPTABLES白名单时"><a href="#在配置IPTABLES白名单时" class="headerlink" title="在配置IPTABLES白名单时"></a>在配置IPTABLES白名单时</h3><p>往往会将链的默认策略设置为ACCEPT，通过在链的最后设置REJECT规则实现白名单机制，而不是将链的默认策略设置为DROP，如果将链的默认策略设置为DROP，当链中的规则被清空时，管理员的请求也将会被DROP掉。</p>
]]></content>
      <tags>
        <tag>云原生基础系列</tag>
        <tag>Kubernetes网络</tag>
      </tags>
  </entry>
  <entry>
    <title>一个web框架--less</title>
    <url>/2022/06/13/uncatalog/cl4cnypz40000z4r77k3khkjx/</url>
    <content><![CDATA[<hr>
<span id="more"></span>
<p><a href="https://github.com/BugKillerPro/less">项目地址</a></p>
<h2 id="一，背景"><a href="#一，背景" class="headerlink" title="一，背景"></a>一，背景</h2><blockquote>
<p>实现一个go web框架，是我从java转go的第一个项目，当时团队人手紧缺，业务线原有的java项目重构需求非常紧急，对于为这些项目提供支撑的web框架，给的开发时间更是少得可怜，更让人抓狂的是，这么紧急的框架开发任务，人员配置就我一个，哈哈哈哈。 当时，看了下httprouter的源码，还没来得及学习下gin beego等知名web框架，就直接上手干了。<br>现在回想起来，虽然该有的功能都有了，但是从细节设计和代码结构上看，还有不少可以优化的地方，并且当时很多涉及到的知识点还没有来得及由点到面的展开，也就没有来得及应用到项目中去。所以决定从零开始，再写一个web框架，同时把一些比较值得记录的地方，以文字的形式做一个输出和总结，希望能够对看到这篇文章的你起到一定的帮助。</p>
</blockquote>
<h3 id="1，当时为什么不用现有的gin-、beego、kit、echo和gorilla等web框架，而是要重复造轮子？"><a href="#1，当时为什么不用现有的gin-、beego、kit、echo和gorilla等web框架，而是要重复造轮子？" class="headerlink" title="1，当时为什么不用现有的gin 、beego、kit、echo和gorilla等web框架，而是要重复造轮子？"></a>1，当时为什么不用现有的<code>gin</code> 、<code>beego</code>、<code>kit</code>、<code>echo</code>和<code>gorilla</code>等<code>web</code>框架，而是要重复造轮子？</h3><ul>
<li>第一，也是最重要的原因–练手。了解一个领域/知识点，最好的办法就是实现它，当时刚从java转go，急需一个项目练手。</li>
<li>第二，拿web框架作为练手项目，除了需要扎实的基础之外，难度方面，不高不低，非常合适。</li>
<li>第三，团队内部关于现有轮子的争论无法达成一致，最终决定自己开发满足定制化需求的轻量级框架。</li>
<li>第四，有plan B，也就是兜底方案。如果开发失败，就直接上现有的轮子，对于业务线，几乎没有切换成本。</li>
</ul>
<h3 id="2，哪个框架更好？"><a href="#2，哪个框架更好？" class="headerlink" title="2，哪个框架更好？"></a>2，哪个框架更好？</h3><p>开源框架很多，不知道应该学习选择什么框架。相信大多数gopher都有遇到过这种困扰。 我的建议是不要被框架绑架，搞清楚事情的本质，才是解决问题的王道。 现在技术更新是日新月异的，框架更是如此，隔一段时间换一个，不同的公司很大可能采用不同的框架，所以你换新工作之后，一般都得重新学习一门新框架，如果新公司用的框架你不会，那如何做到快速上手将会是一个比学习框架更大的挑战。<br>其实这些表面现象的本质只有一个，那就是：框架只是一个工具而已！不止框架是工具，我们的编程语言也可以是工具。所以框架可以一个个的换，编程语言也可以，现在很多服务已经使用 Go 语言替代 Java、Python 了。<br>那么基于这个本质，我该怎么做呢？</p>
<ul>
<li>打牢基础。编程语言本身的功能、概念、语法、模式等，它是编程的地基，不会随着框架的改变而改变。</li>
<li>精通原理。就拿web框架来说，主要负责的就是三件事：接收请求、找到用户处理逻辑调用一下、再把响应写回去。简单点就是：接受请求、分发请求、写回响应。同一类框架，底层原理都是差不多的，区别主要表现在实现方式、用户体验（开发者是用户）、周边生态等方面。</li>
<li>多实践。实践是检验真理的唯一标准，积极参与公司新项目，多向大佬学习。</li>
</ul>
<h3 id="3，名字less的由来？"><a href="#3，名字less的由来？" class="headerlink" title="3，名字less的由来？"></a>3，名字<code>less</code>的由来？</h3><p>   <code>less is more</code></p>
<h3 id="4，理解less，需要了解哪些前置知识？"><a href="#4，理解less，需要了解哪些前置知识？" class="headerlink" title="4，理解less，需要了解哪些前置知识？"></a>4，理解<code>less</code>，需要了解哪些前置知识？</h3><h4 id="4-1，认真读懂net-http标准库，其中大致的逻辑如下"><a href="#4-1，认真读懂net-http标准库，其中大致的逻辑如下" class="headerlink" title="4.1，认真读懂net/http标准库，其中大致的逻辑如下:"></a>4.1，认真读懂<code>net/http</code>标准库，其中大致的逻辑如下:</h4><ul>
<li>标准库创建 HTTP 服务是通过创建一个 Server 数据结构完成的</li>
<li>Server 数据结构在 for 循环中不断监听每一个连接</li>
<li>每个连接默认开启一个 Goroutine 为其服务</li>
<li>serverHandler 结构代表请求对应的处理逻辑，并且通过这个结构进行具体业务逻辑处理</li>
<li>Server 数据结构如果没有设置处理函数 Handler，默认使用DefaultServerMux 处理请求</li>
<li>DefaultServerMux 是使用 map 结构来存储和查找路由规则</li>
</ul>
<blockquote>
<p>很显然，聪明而又熟悉<code>RESTful</code>的你肯定已经发现，最后一步”DefaultServerMux 是使用 map 结构来存储和查找路由规则”是一个可优化的点，这也是众多go web框架需要自己实现的一个地方，当然<code>less</code>也不例外。</p>
</blockquote>
<h4 id="4-2-理解Context的设计思路，在less中，我们将设计一个实现Context接口的custom-context，并将被应用于以下方面："><a href="#4-2-理解Context的设计思路，在less中，我们将设计一个实现Context接口的custom-context，并将被应用于以下方面：" class="headerlink" title="4.2,理解Context的设计思路，在less中，我们将设计一个实现Context接口的custom context，并将被应用于以下方面："></a>4.2,理解<code>Context</code>的设计思路，在<code>less</code>中，我们将设计一个实现<code>Context</code>接口的<code>custom context</code>，并将被应用于以下方面：</h4><ul>
<li>日常开发中我们大概率会遇到超时控制的场景，比如一个批量耗时任务、网络请求等；一个良好的超时控制可以有效的避免一些问题（比如 goroutine 泄露、资源不释放等）</li>
<li>一个请求，从接受到返回过程中的信息传递和共享</li>
<li>超时控制groutine和业务逻辑groutine并发写<code>ResponseWriter</code>问题的处理</li>
<li>超时控制groutine，触发超时，写入<code>ResponseWriter</code>超时响应之后，业务逻辑groutine重复写<code>ResponseWriter</code>的问题处理</li>
</ul>
<p>Context设计思想及使用实践，可以参考我的这篇<a href="https://bugkillerpro.github.io/2022/06/16/uncatalog/cl4gopymv00009or79u472iwp/">Context设计思想及使用实践</a></p>
<h3 id="4-3，熟悉http协议，推荐阅读《HTTP权威指南》，如果时间充裕还可以读一下《TCP-IP详解》系列。"><a href="#4-3，熟悉http协议，推荐阅读《HTTP权威指南》，如果时间充裕还可以读一下《TCP-IP详解》系列。" class="headerlink" title="4.3，熟悉http协议，推荐阅读《HTTP权威指南》，如果时间充裕还可以读一下《TCP/IP详解》系列。"></a>4.3，熟悉<code>http</code>协议，推荐阅读《HTTP权威指南》，如果时间充裕还可以读一下《TCP/IP详解》系列。</h3><h3 id="4-4，熟悉http-ResponseWriter和-http-Request这两大信息载体的结构和方法，不然的话，连从哪里读取query-values和-form-data以及往哪里写response都不知道，那就尴尬了。"><a href="#4-4，熟悉http-ResponseWriter和-http-Request这两大信息载体的结构和方法，不然的话，连从哪里读取query-values和-form-data以及往哪里写response都不知道，那就尴尬了。" class="headerlink" title="4.4，熟悉http.ResponseWriter和*http.Request这两大信息载体的结构和方法，不然的话，连从哪里读取query values和 form data以及往哪里写response都不知道，那就尴尬了。"></a>4.4，熟悉<code>http.ResponseWriter</code>和<code>*http.Request</code>这两大信息载体的结构和方法，不然的话，连从哪里读取<code>query values</code>和 <code>form data</code>以及往哪里写<code>response</code>都不知道，那就尴尬了。</h3><h3 id="4-5，熟悉设计模式。"><a href="#4-5，熟悉设计模式。" class="headerlink" title="4.5，熟悉设计模式。"></a>4.5，熟悉设计模式。</h3><p>巧妙而又优雅，几乎是所有架构设计的基本准则，<code>less</code>也不例外，如果你来不及认真研读23种设计模式，可以认真阅读我的这篇<a href="https://bugkillerpro.github.io/2022/06/17/uncatalog/cl4i43q7u00005sr70tpnfrfg/">面向对象设计六大原则</a>，如果能够做到融会贯通，那么由此衍化而来的设计模式，你也可以做到信手拈来。</p>
<h3 id="4-6，one-more-thing"><a href="#4-6，one-more-thing" class="headerlink" title="4.6，one more thing"></a>4.6，one more thing</h3><p><em><strong>为了降低less框架的阅读难度，建议先看懂这个示例级别的小框架，</strong></em> <a href="https://github.com/BugKillerPro/less/tree/less_easy_demo">源码在此</a>。<br>为什么要强调上面链接里的框架是示例级别？原因在于，这个示例框架只能用于个人开发，不能用于生产，而less的目标是打造成一个生产级别的框架。<br>那么生产级别和示例级别有哪些明显的差异呢？<br>答：细节和生态<br>具体体现在一下几点:</p>
<ul>
<li>核心模块。服务启动方式、路由分发机制、context封装性和中间件机制等的设计</li>
<li>功能完备性。日志模块、命令行工具和缓存机制等功能是否提供</li>
<li>框架扩展性。是否支持扩展，扩展方式是否友好</li>
<li>框架性能。qps等性能</li>
<li>文档/社区。</li>
</ul>
<p>很显然，示例级别的框架，并不满足以上几点。除此之外，一个人完成完美契合以上几点的生产级别的框架也是不可能的，所以需要学会站在巨人的肩膀上思考，向巨人借力，因此，less在关键代码的设计上，会借鉴已经经过千锤百炼、反复迭代升级过的gin的做法，只有这样，才能做出功能完备、性能优良的生产级框架。</p>
<h3 id="4-7，Last-but-not-least-–-了解包括但不限于以下开源库，这些开源库将会被引用到less"><a href="#4-7，Last-but-not-least-–-了解包括但不限于以下开源库，这些开源库将会被引用到less" class="headerlink" title="4.7，Last but not least – 了解包括但不限于以下开源库，这些开源库将会被引用到less"></a>4.7，Last but not least – 了解包括但不限于以下开源库，这些开源库将会被引用到less</h3><ul>
<li><a href="https://github.com/spf13/cobra">cobra</a></li>
<li><a href="https://github.com/spf13/cast">cast</a> (这两个库的作者是google的大佬Steve Francia)</li>
<li><a href="https://github.com/AlecAivazis/survey">survey</a></li>
<li><a href="https://github.com/sevlyar/go-daemon">go-daemon</a></li>
<li><a href="https://github.com/src-d/go-git">go-git</a></li>
<li><a href="https://github.com/julienschmidt/httprouter">httprouter</a>  </li>
<li><a href="https://github.com/gin-gonic/contrib">gin-gonic/contrib</a></li>
<li><a href="https://github.com/google/uuid">uuid</a></li>
<li><a href="https://github.com/google/go-github">go-github</a></li>
<li><a href="https://github.com/swaggo/swag">swag</a> </li>
<li><a href="https://github.com/ErikDubbelboer/gspt">gspt</a></li>
<li><a href="github.com/mitchellh/mapstructure">mapstructure</a></li>
</ul>
<h2 id="二，重要结构-web框架三大件：context-router-middleware"><a href="#二，重要结构-web框架三大件：context-router-middleware" class="headerlink" title="二，重要结构(web框架三大件：context,router,middleware)"></a>二，重要结构(web框架三大件：context,router,middleware)</h2><blockquote>
<p>框架中的某个模块，比如说路由，实现的方法不止一种，每一个模块要实现的功能也各有不同，所以用哪一种方法来实现，以及要实现哪些功能，都是一种选择。 而每种选择的背后，其实都是方向问题，因为这些选择共同构成了一个框架的倾向性，也就是设计感。设计感非常考验开发者的综合技能和项目经验，也是考核框架质量的一个重要维度。</p>
</blockquote>
<h3 id="核心模块"><a href="#核心模块" class="headerlink" title="核心模块"></a>核心模块</h3><blockquote>
<p>一个框架最核心的模块：context,router,middleware，它们的设计感会影响到整个框架的性能和表现，也最能直接体现出框架作者的开发水平。</p>
</blockquote>
<h4 id="1-context"><a href="#1-context" class="headerlink" title="1.context"></a>1.context</h4><p>关于<a href="https://bugkillerpro.github.io/2022/06/16/uncatalog/cl4gopymv00009or79u472iwp/">Context设计思想及使用实践</a>，我在这片文章里已经讲得很详细了。在less框架里，我们主要要了解的是context的应用和自定义context的最佳实践。less框架里的自定义context结构如下：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">type</span> Context <span class="keyword">struct</span> &#123;</span><br><span class="line"><span class="comment">// 服务容器</span></span><br><span class="line">container less.Container</span><br><span class="line"></span><br><span class="line">writermem responseWriter</span><br><span class="line">Request   *http.Request</span><br><span class="line">Writer    ResponseWriter</span><br><span class="line"></span><br><span class="line">Params   Params</span><br><span class="line">handlers HandlersChain</span><br><span class="line">index    <span class="keyword">int8</span></span><br><span class="line">fullPath <span class="keyword">string</span></span><br><span class="line"></span><br><span class="line">engine *Engine</span><br><span class="line">params *Params</span><br><span class="line"></span><br><span class="line"><span class="comment">// This mutex protect Keys map</span></span><br><span class="line">mu sync.RWMutex</span><br><span class="line"></span><br><span class="line"><span class="comment">// Keys is a key/value pair exclusively for the context of each request.</span></span><br><span class="line">Keys <span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">interface</span>&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Errors is a list of errors attached to all the handlers/middlewares who used this context.</span></span><br><span class="line">Errors errorMsgs</span><br><span class="line"></span><br><span class="line"><span class="comment">// Accepted defines a list of manually accepted formats for content negotiation.</span></span><br><span class="line">Accepted []<span class="keyword">string</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// queryCache use url.ParseQuery cached the param query result from c.Request.URL.Query()</span></span><br><span class="line">queryCache url.Values</span><br><span class="line"></span><br><span class="line"><span class="comment">// formCache use url.ParseQuery cached PostForm contains the parsed form data from POST, PATCH,</span></span><br><span class="line"><span class="comment">// or PUT body parameters.</span></span><br><span class="line">formCache url.Values</span><br><span class="line"></span><br><span class="line"><span class="comment">// SameSite allows a server to define a cookie attribute making it impossible for</span></span><br><span class="line"><span class="comment">// the browser to send this cookie along with cross-site requests.</span></span><br><span class="line">sameSite http.SameSite</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h4 id="2-router"><a href="#2-router" class="headerlink" title="2.router"></a>2.router</h4><p>首选，对于一个web框架来说，router必须要满足以下需求：</p>
<ul>
<li>http method 匹配</li>
<li>静态路由匹配</li>
<li>路由批量通用前缀</li>
<li>动态路由匹配</li>
</ul>
<p>所以在路由存储结构的设计选型上，需要花些时间去思考的，毕竟该结构除了要满足上述需求外，还要有比较高的查找效率。常见的数据结构：</p>
<table>
<thead>
<tr>
<th align="left">数据结构</th>
<th align="left">查找时间复杂度</th>
<th align="left">是否满足路由匹配4点要求</th>
</tr>
</thead>
<tbody><tr>
<td align="left">数据组</td>
<td align="left">O(n)</td>
<td align="left">满足，匹配都需要遍历，时间复杂度O(n)</td>
</tr>
<tr>
<td align="left">哈希表</td>
<td align="left">O(1)</td>
<td align="left">满足，动态路由匹配需要遍历，时间复杂度O(n)</td>
</tr>
<tr>
<td align="left">队列</td>
<td align="left">O(n)</td>
<td align="left">满足，匹配都需要遍历，时间复杂度O(n)</td>
</tr>
<tr>
<td align="left">栈</td>
<td align="left">O(n)</td>
<td align="left">满足，匹配都需要遍历，时间复杂度O(n)</td>
</tr>
<tr>
<td align="left">链表</td>
<td align="left">O(n)</td>
<td align="left">满足，匹配都需要遍历，时间复杂度O(n)</td>
</tr>
<tr>
<td align="left">堆</td>
<td align="left">O(n)</td>
<td align="left">满足，匹配都需要遍历，时间复杂度O(n)</td>
</tr>
<tr>
<td align="left">图</td>
<td align="left">O(n^2)</td>
<td align="left">满足，匹配都需要遍历，时间复杂度O(n)</td>
</tr>
<tr>
<td align="left">树</td>
<td align="left">O(logn)</td>
<td align="left">满足，匹配不需要遍历</td>
</tr>
</tbody></table>
<p>所以，从对比可以得出我们的选型结果，那就是–树。了解树这个数据结构的人都应该知道，树的查找时间复杂度和树高是负相关的，树高越高，查找的效率越低，当树的左右子树极度不平衡的时候，就会退化为链表，时间复杂度为O(n)。所以，还需要对树的结构和节点上存储的数据做一些设计和优化，来提高查找性能。我们可以参考下gin所采取的方案–httprouter。我的这篇博客<a href="https://bugkillerpro.github.io/2022/06/22/uncatalog/cl4pdun8r0000rsr7bninemtl/">httprouter源码解析</a>分析了httprouter的源码，可以移步查阅，在此就不做重复叙述了。<br>我们的less也会采用httprouter作为路由管理的解决方案。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> methodTrees []methodTree</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> methodTree <span class="keyword">struct</span> &#123;</span><br><span class="line">    method <span class="keyword">string</span></span><br><span class="line">    root   *node</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> node <span class="keyword">struct</span> &#123;</span><br><span class="line">    path      <span class="keyword">string</span></span><br><span class="line">    indices   <span class="keyword">string</span></span><br><span class="line">    wildChild <span class="keyword">bool</span></span><br><span class="line">    nType     nodeType</span><br><span class="line">    priority  <span class="keyword">uint32</span></span><br><span class="line">    children  []*node <span class="comment">// child nodes, at most 1 :param style node at the end of the array</span></span><br><span class="line">    handlers  HandlersChain</span><br><span class="line">    fullPath  <span class="keyword">string</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h3 id="设计思想"><a href="#设计思想" class="headerlink" title="设计思想"></a>设计思想</h3><h4 id="1，一切皆服务"><a href="#1，一切皆服务" class="headerlink" title="1，一切皆服务"></a>1，一切皆服务</h4><p>理解这种设计，需要对面向对象、面向接口有一定的了解，同时，如果真正应用的业务开发中，又需要你对DDD能够做到融会贯通。<br>在less框架里面，我们几乎所有的模块(配置、缓存、日志和web服务等)都会被设计为一种服务，包括使用方，在做业务开发的时候，我们也建议按功能把业务划分为不同的服务来设计，然后把这些服务注册到我们框架定义的服务容器中就可以。 就像堆积积木，只要想好了一个服务的接口，我们逐步实现服务之后，这一个服务就是一块积木，之后可以用相同的思路实现各种服务的积木块，用它们来拼出我们需要的业务逻辑。这就是“一切皆服务”思想带来的便利。</p>
<p>框架方面：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// NewInstance 定义了如何创建一个新实例，所有服务容器的创建服务</span></span><br><span class="line"><span class="keyword">type</span> NewInstance <span class="function"><span class="keyword">func</span><span class="params">(...<span class="keyword">interface</span>&#123;&#125;)</span> <span class="params">(<span class="keyword">interface</span>&#123;&#125;, error)</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// ServiceProvider 定义一个服务提供者需要实现的接口</span></span><br><span class="line"><span class="keyword">type</span> ServiceProvider <span class="keyword">interface</span> &#123;</span><br><span class="line">	<span class="comment">// Register 在服务容器中注册了一个实例化服务的方法，是否在注册的时候就实例化这个服务，需要参考IsDefer接口。</span></span><br><span class="line">	Register(Container) NewInstance</span><br><span class="line">	<span class="comment">// Boot 在调用实例化服务的时候会调用，可以把一些准备工作：基础配置，初始化参数的操作放在这个里面。</span></span><br><span class="line">	<span class="comment">// 如果Boot返回error，整个服务实例化就会实例化失败，返回错误</span></span><br><span class="line">	Boot(Container) error</span><br><span class="line">	<span class="comment">// IsDefer 决定是否在注册的时候实例化这个服务，如果不是注册的时候实例化，那就是在第一次make的时候进行实例化操作</span></span><br><span class="line">	<span class="comment">// false表示不需要延迟实例化，在注册的时候就实例化。true表示延迟实例化</span></span><br><span class="line">	IsDefer() <span class="keyword">bool</span></span><br><span class="line">	<span class="comment">// Params params定义传递给NewInstance的参数，可以自定义多个，建议将container作为第一个参数</span></span><br><span class="line">	Params(Container) []<span class="keyword">interface</span>&#123;&#125;</span><br><span class="line">	<span class="comment">// Name 代表了这个服务提供者的凭证</span></span><br><span class="line">	Name() <span class="keyword">string</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<p>日志provider,实现provider接口提供各种log service:</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// LogServiceProvider 服务提供者</span></span><br><span class="line"><span class="keyword">type</span> LogServiceProvider <span class="keyword">struct</span> &#123;</span><br><span class="line">	framework.ServiceProvider</span><br><span class="line"></span><br><span class="line">	Driver <span class="keyword">string</span> <span class="comment">// Driver</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">// 日志级别</span></span><br><span class="line">	Level contract.LogLevel</span><br><span class="line">	<span class="comment">// 日志输出格式方法</span></span><br><span class="line">	Formatter contract.Formatter</span><br><span class="line">	<span class="comment">// 日志context上下文信息获取函数</span></span><br><span class="line">	CtxFielder contract.CtxFielder</span><br><span class="line">	<span class="comment">// 日志输出信息</span></span><br><span class="line">	Output io.Writer</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>业务方面，实现provider接口提供各种业务service:</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> DemoProvider <span class="keyword">struct</span> &#123;</span><br><span class="line">	framework.ServiceProvider</span><br><span class="line"></span><br><span class="line">	c framework.Container</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(sp *DemoProvider)</span> <span class="title">Name</span><span class="params">()</span> <span class="title">string</span></span> &#123;</span><br><span class="line">	<span class="keyword">return</span> DemoKey</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(sp *DemoProvider)</span> <span class="title">Register</span><span class="params">(c framework.Container)</span> <span class="title">framework</span>.<span class="title">NewInstance</span></span> &#123;</span><br><span class="line">	<span class="keyword">return</span> NewService</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(sp *DemoProvider)</span> <span class="title">IsDefer</span><span class="params">()</span> <span class="title">bool</span></span> &#123;</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">false</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(sp *DemoProvider)</span> <span class="title">Params</span><span class="params">(c framework.Container)</span> []<span class="title">interface</span></span>&#123;&#125; &#123;</span><br><span class="line">	<span class="keyword">return</span> []<span class="keyword">interface</span>&#123;&#125;&#123;sp.c&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(sp *DemoProvider)</span> <span class="title">Boot</span><span class="params">(c framework.Container)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	sp.c = c</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>
<h4 id="2，服务容器"><a href="#2，服务容器" class="headerlink" title="2，服务容器"></a>2，服务容器</h4><p>设计详见注释</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Container 是一个服务容器，提供绑定服务和获取服务的功能</span></span><br><span class="line"><span class="keyword">type</span> Container <span class="keyword">interface</span> &#123;</span><br><span class="line">	<span class="comment">// Bind 绑定一个服务提供者，如果关键字凭证已经存在，会进行替换操作，返回error</span></span><br><span class="line">	Bind(provider ServiceProvider) error</span><br><span class="line">	<span class="comment">// IsBind 关键字凭证是否已经绑定服务提供者</span></span><br><span class="line">	IsBind(key <span class="keyword">string</span>) <span class="keyword">bool</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">// Make 根据关键字凭证获取一个服务，</span></span><br><span class="line">	Make(key <span class="keyword">string</span>) (<span class="keyword">interface</span>&#123;&#125;, error)</span><br><span class="line">	<span class="comment">// MustMake 根据关键字凭证获取一个服务，如果这个关键字凭证未绑定服务提供者，那么会panic。</span></span><br><span class="line">	<span class="comment">// 所以在使用这个接口的时候请保证服务容器已经为这个关键字凭证绑定了服务提供者。</span></span><br><span class="line">	MustMake(key <span class="keyword">string</span>) <span class="keyword">interface</span>&#123;&#125;</span><br><span class="line">	<span class="comment">// MakeNew 根据关键字凭证获取一个服务，只是这个服务并不是单例模式的</span></span><br><span class="line">	<span class="comment">// 它是根据服务提供者注册的启动函数和传递的params参数实例化出来的</span></span><br><span class="line">	<span class="comment">// 这个函数在需要为不同参数启动不同实例的时候非常有用</span></span><br><span class="line">	MakeNew(key <span class="keyword">string</span>, params []<span class="keyword">interface</span>&#123;&#125;) (<span class="keyword">interface</span>&#123;&#125;, error)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<h4 id="3，命令工具"><a href="#3，命令工具" class="headerlink" title="3，命令工具"></a>3，命令工具</h4><p>less引入著名的cobra库来实现扩展命令行功能,Cron、CronSpecs和container使我们新加入的定制化功能。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> Command <span class="keyword">struct</span> &#123;</span><br><span class="line">	<span class="comment">// Command支持cron，只在RootCommand中有这个值</span></span><br><span class="line">	Cron *cron.Cron</span><br><span class="line">	<span class="comment">// 对应Cron命令的说明文档</span></span><br><span class="line">	CronSpecs []CronSpec</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 服务容器</span></span><br><span class="line">	container Container</span><br><span class="line">	<span class="comment">// Use is the one-line usage message.</span></span><br><span class="line">	<span class="comment">// Recommended syntax is as follow:</span></span><br><span class="line">	<span class="comment">//   [ ] identifies an optional argument. Arguments that are not enclosed in brackets are required.</span></span><br><span class="line">	<span class="comment">//   ... indicates that you can specify multiple values for the previous argument.</span></span><br><span class="line">	<span class="comment">//   |   indicates mutually exclusive information. You can use the argument to the left of the separator or the</span></span><br><span class="line">	<span class="comment">//       argument to the right of the separator. You cannot use both arguments in a single use of the command.</span></span><br><span class="line">	<span class="comment">//   &#123; &#125; delimits a set of mutually exclusive arguments when one of the arguments is required. If the arguments are</span></span><br><span class="line">	<span class="comment">//       optional, they are enclosed in brackets ([ ]).</span></span><br><span class="line">	<span class="comment">// Example: add [-F file | -D dir]... [-f format] profile</span></span><br><span class="line">	Use <span class="keyword">string</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">// Aliases is an array of aliases that can be used instead of the first word in Use.</span></span><br><span class="line">	Aliases []<span class="keyword">string</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">// SuggestFor is an array of command names for which this command will be suggested -</span></span><br><span class="line">	<span class="comment">// similar to aliases but only suggests.</span></span><br><span class="line">	SuggestFor []<span class="keyword">string</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">// Short is the short description shown in the &#x27;help&#x27; output.</span></span><br><span class="line">	Short <span class="keyword">string</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">// Long is the long message shown in the &#x27;help &lt;this-command&gt;&#x27; output.</span></span><br><span class="line">	Long <span class="keyword">string</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">// Example is examples of how to use the command.</span></span><br><span class="line">	Example <span class="keyword">string</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">// ValidArgs is list of all valid non-flag arguments that are accepted in shell completions</span></span><br><span class="line">	ValidArgs []<span class="keyword">string</span></span><br><span class="line">	<span class="comment">// ValidArgsFunction is an optional function that provides valid non-flag arguments for shell completion.</span></span><br><span class="line">	<span class="comment">// It is a dynamic version of using ValidArgs.</span></span><br><span class="line">	<span class="comment">// Only one of ValidArgs and ValidArgsFunction can be used for a command.</span></span><br><span class="line">	ValidArgsFunction <span class="function"><span class="keyword">func</span><span class="params">(cmd *Command, args []<span class="keyword">string</span>, toComplete <span class="keyword">string</span>)</span> <span class="params">([]<span class="keyword">string</span>, ShellCompDirective)</span></span></span><br><span class="line"></span><br><span class="line">	<span class="comment">// Expected arguments</span></span><br><span class="line">	Args PositionalArgs</span><br><span class="line"></span><br><span class="line">	<span class="comment">// ArgAliases is List of aliases for ValidArgs.</span></span><br><span class="line">	<span class="comment">// These are not suggested to the user in the shell completion,</span></span><br><span class="line">	<span class="comment">// but accepted if entered manually.</span></span><br><span class="line">	ArgAliases []<span class="keyword">string</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">// BashCompletionFunction is custom bash functions used by the legacy bash autocompletion generator.</span></span><br><span class="line">	<span class="comment">// For portability with other shells, it is recommended to instead use ValidArgsFunction</span></span><br><span class="line">	BashCompletionFunction <span class="keyword">string</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">// Deprecated defines, if this command is deprecated and should print this string when used.</span></span><br><span class="line">	Deprecated <span class="keyword">string</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">// Annotations are key/value pairs that can be used by applications to identify or</span></span><br><span class="line">	<span class="comment">// group commands.</span></span><br><span class="line">	Annotations <span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">string</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">// Version defines the version for this command. If this value is non-empty and the command does not</span></span><br><span class="line">	<span class="comment">// define a &quot;version&quot; flag, a &quot;version&quot; boolean flag will be added to the command and, if specified,</span></span><br><span class="line">	<span class="comment">// will print content of the &quot;Version&quot; variable. A shorthand &quot;v&quot; flag will also be added if the</span></span><br><span class="line">	<span class="comment">// command does not define one.</span></span><br><span class="line">	Version <span class="keyword">string</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">// The *Run functions are executed in the following order:</span></span><br><span class="line">	<span class="comment">//   * PersistentPreRun()</span></span><br><span class="line">	<span class="comment">//   * PreRun()</span></span><br><span class="line">	<span class="comment">//   * Run()</span></span><br><span class="line">	<span class="comment">//   * PostRun()</span></span><br><span class="line">	<span class="comment">//   * PersistentPostRun()</span></span><br><span class="line">	<span class="comment">// All functions get the same args, the arguments after the command name.</span></span><br><span class="line">	<span class="comment">//</span></span><br><span class="line">	<span class="comment">// PersistentPreRun: children of this command will inherit and execute.</span></span><br><span class="line">	PersistentPreRun <span class="function"><span class="keyword">func</span><span class="params">(cmd *Command, args []<span class="keyword">string</span>)</span></span></span><br><span class="line">	<span class="comment">// PersistentPreRunE: PersistentPreRun but returns an error.</span></span><br><span class="line">	PersistentPreRunE <span class="function"><span class="keyword">func</span><span class="params">(cmd *Command, args []<span class="keyword">string</span>)</span> <span class="title">error</span></span></span><br><span class="line">	<span class="comment">// PreRun: children of this command will not inherit.</span></span><br><span class="line">	PreRun <span class="function"><span class="keyword">func</span><span class="params">(cmd *Command, args []<span class="keyword">string</span>)</span></span></span><br><span class="line">	<span class="comment">// PreRunE: PreRun but returns an error.</span></span><br><span class="line">	PreRunE <span class="function"><span class="keyword">func</span><span class="params">(cmd *Command, args []<span class="keyword">string</span>)</span> <span class="title">error</span></span></span><br><span class="line">	<span class="comment">// Run: Typically the actual work function. Most commands will only implement this.</span></span><br><span class="line">	Run <span class="function"><span class="keyword">func</span><span class="params">(cmd *Command, args []<span class="keyword">string</span>)</span></span></span><br><span class="line">	<span class="comment">// RunE: Run but returns an error.</span></span><br><span class="line">	RunE <span class="function"><span class="keyword">func</span><span class="params">(cmd *Command, args []<span class="keyword">string</span>)</span> <span class="title">error</span></span></span><br><span class="line">	<span class="comment">// PostRun: run after the Run command.</span></span><br><span class="line">	PostRun <span class="function"><span class="keyword">func</span><span class="params">(cmd *Command, args []<span class="keyword">string</span>)</span></span></span><br><span class="line">	<span class="comment">// PostRunE: PostRun but returns an error.</span></span><br><span class="line">	PostRunE <span class="function"><span class="keyword">func</span><span class="params">(cmd *Command, args []<span class="keyword">string</span>)</span> <span class="title">error</span></span></span><br><span class="line">	<span class="comment">// PersistentPostRun: children of this command will inherit and execute after PostRun.</span></span><br><span class="line">	PersistentPostRun <span class="function"><span class="keyword">func</span><span class="params">(cmd *Command, args []<span class="keyword">string</span>)</span></span></span><br><span class="line">	<span class="comment">// PersistentPostRunE: PersistentPostRun but returns an error.</span></span><br><span class="line">	PersistentPostRunE <span class="function"><span class="keyword">func</span><span class="params">(cmd *Command, args []<span class="keyword">string</span>)</span> <span class="title">error</span></span></span><br><span class="line"></span><br><span class="line">	<span class="comment">// args is actual args parsed from flags.</span></span><br><span class="line">	args []<span class="keyword">string</span></span><br><span class="line">	<span class="comment">// flagErrorBuf contains all error messages from pflag.</span></span><br><span class="line">	flagErrorBuf *bytes.Buffer</span><br><span class="line">	<span class="comment">// flags is full set of flags.</span></span><br><span class="line">	flags *flag.FlagSet</span><br><span class="line">	<span class="comment">// pflags contains persistent flags.</span></span><br><span class="line">	pflags *flag.FlagSet</span><br><span class="line">	<span class="comment">// lflags contains local flags.</span></span><br><span class="line">	lflags *flag.FlagSet</span><br><span class="line">	<span class="comment">// iflags contains inherited flags.</span></span><br><span class="line">	iflags *flag.FlagSet</span><br><span class="line">	<span class="comment">// parentsPflags is all persistent flags of cmd&#x27;s parents.</span></span><br><span class="line">	parentsPflags *flag.FlagSet</span><br><span class="line">	<span class="comment">// globNormFunc is the global normalization function</span></span><br><span class="line">	<span class="comment">// that we can use on every pflag set and children commands</span></span><br><span class="line">	globNormFunc <span class="function"><span class="keyword">func</span><span class="params">(f *flag.FlagSet, name <span class="keyword">string</span>)</span> <span class="title">flag</span>.<span class="title">NormalizedName</span></span></span><br><span class="line"></span><br><span class="line">	<span class="comment">// usageFunc is usage func defined by user.</span></span><br><span class="line">	usageFunc <span class="function"><span class="keyword">func</span><span class="params">(*Command)</span> <span class="title">error</span></span></span><br><span class="line">	<span class="comment">// usageTemplate is usage template defined by user.</span></span><br><span class="line">	usageTemplate <span class="keyword">string</span></span><br><span class="line">	<span class="comment">// flagErrorFunc is func defined by user and it&#x27;s called when the parsing of</span></span><br><span class="line">	<span class="comment">// flags returns an error.</span></span><br><span class="line">	flagErrorFunc <span class="function"><span class="keyword">func</span><span class="params">(*Command, error)</span> <span class="title">error</span></span></span><br><span class="line">	<span class="comment">// helpTemplate is help template defined by user.</span></span><br><span class="line">	helpTemplate <span class="keyword">string</span></span><br><span class="line">	<span class="comment">// helpFunc is help func defined by user.</span></span><br><span class="line">	helpFunc <span class="function"><span class="keyword">func</span><span class="params">(*Command, []<span class="keyword">string</span>)</span></span></span><br><span class="line">	<span class="comment">// helpCommand is command with usage &#x27;help&#x27;. If it&#x27;s not defined by user,</span></span><br><span class="line">	<span class="comment">// cobra uses default help command.</span></span><br><span class="line">	helpCommand *Command</span><br><span class="line">	<span class="comment">// versionTemplate is the version template defined by user.</span></span><br><span class="line">	versionTemplate <span class="keyword">string</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">// inReader is a reader defined by the user that replaces stdin</span></span><br><span class="line">	inReader io.Reader</span><br><span class="line">	<span class="comment">// outWriter is a writer defined by the user that replaces stdout</span></span><br><span class="line">	outWriter io.Writer</span><br><span class="line">	<span class="comment">// errWriter is a writer defined by the user that replaces stderr</span></span><br><span class="line">	errWriter io.Writer</span><br><span class="line"></span><br><span class="line">	<span class="comment">//FParseErrWhitelist flag parse errors to be ignored</span></span><br><span class="line">	FParseErrWhitelist FParseErrWhitelist</span><br><span class="line"></span><br><span class="line">	<span class="comment">// CompletionOptions is a set of options to control the handling of shell completion</span></span><br><span class="line">	CompletionOptions CompletionOptions</span><br><span class="line"></span><br><span class="line">	<span class="comment">// commandsAreSorted defines, if command slice are sorted or not.</span></span><br><span class="line">	commandsAreSorted <span class="keyword">bool</span></span><br><span class="line">	<span class="comment">// commandCalledAs is the name or alias value used to call this command.</span></span><br><span class="line">	commandCalledAs <span class="keyword">struct</span> &#123;</span><br><span class="line">		name   <span class="keyword">string</span></span><br><span class="line">		called <span class="keyword">bool</span></span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	ctx context.Context</span><br><span class="line"></span><br><span class="line">	<span class="comment">// commands is the list of commands supported by this program.</span></span><br><span class="line">	commands []*Command</span><br><span class="line">	<span class="comment">// parent is a parent command for this command.</span></span><br><span class="line">	parent *Command</span><br><span class="line">	<span class="comment">// Max lengths of commands&#x27; string lengths for use in padding.</span></span><br><span class="line">	commandsMaxUseLen         <span class="keyword">int</span></span><br><span class="line">	commandsMaxCommandPathLen <span class="keyword">int</span></span><br><span class="line">	commandsMaxNameLen        <span class="keyword">int</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">// TraverseChildren parses flags on all parents before executing child command.</span></span><br><span class="line">	TraverseChildren <span class="keyword">bool</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">// Hidden defines, if this command is hidden and should NOT show up in the list of available commands.</span></span><br><span class="line">	Hidden <span class="keyword">bool</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">// SilenceErrors is an option to quiet errors down stream.</span></span><br><span class="line">	SilenceErrors <span class="keyword">bool</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">// SilenceUsage is an option to silence usage when an error occurs.</span></span><br><span class="line">	SilenceUsage <span class="keyword">bool</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">// DisableFlagParsing disables the flag parsing.</span></span><br><span class="line">	<span class="comment">// If this is true all flags will be passed to the command as arguments.</span></span><br><span class="line">	DisableFlagParsing <span class="keyword">bool</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">// DisableAutoGenTag defines, if gen tag (&quot;Auto generated by spf13/cobra...&quot;)</span></span><br><span class="line">	<span class="comment">// will be printed by generating docs for this command.</span></span><br><span class="line">	DisableAutoGenTag <span class="keyword">bool</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">// DisableFlagsInUseLine will disable the addition of [flags] to the usage</span></span><br><span class="line">	<span class="comment">// line of a command when printing help or generating docs</span></span><br><span class="line">	DisableFlagsInUseLine <span class="keyword">bool</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">// DisableSuggestions disables the suggestions based on Levenshtein distance</span></span><br><span class="line">	<span class="comment">// that go along with &#x27;unknown command&#x27; messages.</span></span><br><span class="line">	DisableSuggestions <span class="keyword">bool</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">// SuggestionsMinimumDistance defines minimum levenshtein distance to display suggestions.</span></span><br><span class="line">	<span class="comment">// Must be &gt; 0.</span></span><br><span class="line">	SuggestionsMinimumDistance <span class="keyword">int</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>得益于一切皆服务的设计，在less中，结合命令工具，你可以通过命令操作一切服务，比如：启动、停止、查询和重启web。</p>
<h4 id="4，自动化"><a href="#4，自动化" class="headerlink" title="4，自动化"></a>4，自动化</h4><blockquote>
<p>don’t repeat yourself，把一切重复性的劳动自动化。</p>
</blockquote>
<h5 id="4-1，调试模式"><a href="#4-1，调试模式" class="headerlink" title="4.1，调试模式"></a>4.1，调试模式</h5><p>调试模式下，监控文件修改，自动编译，自动运行。</p>
<h5 id="4-2，兼容vue，前后端一体化"><a href="#4-2，兼容vue，前后端一体化" class="headerlink" title="4.2，兼容vue，前后端一体化"></a>4.2，兼容vue，前后端一体化</h5><p>对于web框架来说，这一点并不是刚需，但是对于做偏运维/运营侧产品开发的同学来说，非常得必要。</p>
<h5 id="4-3，发布自动化"><a href="#4-3，发布自动化" class="headerlink" title="4.3，发布自动化"></a>4.3，发布自动化</h5><p>这一点也不是刚需。有很多方式可以将一个服务进行自动化部署，比如现在比较流行的 Docker 化或者 CI/CD 流程。 但是一些比较个人比较小的项目，比如一个博客、一个官网网站，这些部署流程往往都太庞大了，更需要一个服务，能快速将在开发机器上写好、调试好的程序上传到目标服务器，并且更新应用程序。</p>
<h5 id="4-4，其他一系列自动化工具"><a href="#4-4，其他一系列自动化工具" class="headerlink" title="4.4，其他一系列自动化工具"></a>4.4，其他一系列自动化工具</h5><ul>
<li>自动化创建服务工具</li>
<li>自动化创建命令行工具</li>
<li>自动化gin中间件迁移工具</li>
<li>自动化less脚手架工具</li>
</ul>
<h3 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h3><p>talk is cheap,直接看代码吧，注释非常友好</p>
<h3 id="quick-start"><a href="#quick-start" class="headerlink" title="quick start"></a>quick start</h3><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">    <span class="string">&quot;github.com/BugKillerPro/less/app/console&quot;</span></span><br><span class="line">    <span class="string">&quot;github.com/BugKillerPro/less/app/http&quot;</span></span><br><span class="line">    <span class="string">&quot;github.com/BugKillerPro/less/framework&quot;</span></span><br><span class="line">    <span class="string">&quot;github.com/BugKillerPro/less/framework/provider/app&quot;</span></span><br><span class="line">    <span class="string">&quot;github.com/BugKillerPro/less/framework/provider/kernel&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    <span class="comment">// 初始化服务容器</span></span><br><span class="line">    container := framework.NewlessContainer()</span><br><span class="line">    <span class="comment">// 绑定App服务提供者</span></span><br><span class="line">    container.Bind(&amp;app.LessAppProvider&#123;&#125;)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 将HTTP引擎初始化,并且作为服务提供者绑定到服务容器中</span></span><br><span class="line">    <span class="keyword">if</span> engine, err := http.NewHttpEngine(container); err == <span class="literal">nil</span> &#123;</span><br><span class="line">        container.Bind(&amp;kernel.LessKernelProvider&#123;HttpEngine: engine&#125;)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 运行root命令</span></span><br><span class="line">    console.RunCommand(container)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>end</p>
<p><em><strong>参考</strong></em></p>
<blockquote>
<p><a href="https://bugkillerpro.github.io/2022/06/16/uncatalog/cl4gopymv00009or79u472iwp/">Context设计思想及使用实践</a></p>
<p><a href="https://bugkillerpro.github.io/2022/06/17/uncatalog/cl4i43q7u00005sr70tpnfrfg/">面向对象设计六大原则</a></p>
<p><a href="https://bugkillerpro.github.io/2022/06/22/uncatalog/cl4pdun8r0000rsr7bninemtl/">httprouter源码解析</a></p>
</blockquote>
]]></content>
      <tags>
        <tag>手撸一个web框架</tag>
      </tags>
  </entry>
  <entry>
    <title>端口监听情况exporter开发实践</title>
    <url>/2022/06/15/uncatalog/cl4fbnh440000bgr72qu68h03/</url>
    <content><![CDATA[<hr>
<span id="more"></span>

<blockquote>
<p>关于custom exporter的开发方法，前面两篇文章已经讲得很清楚了，今天结合实际应用场景，开发一个开箱即用的port exporter.</p>
</blockquote>
<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p> 开始阅读这篇文章之前，需要你对linux系统有一定的理解，并且理解以下几个文件/目录的用途。</p>
<ul>
<li>/proc/net/tcp</li>
<li>/proc/pid/fd </li>
</ul>
<p>这部分内容篇幅过长，需要读者自己去学习理解。本篇文章主要讲述port exporter的开发。</p>
<h3 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h3><h4 id="目录结构"><a href="#目录结构" class="headerlink" title="目录结构"></a>目录结构</h4><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">exporter/</span><br><span class="line">├── collector</span><br><span class="line">│   ├── port.go</span><br><span class="line">│   └── port_test.go</span><br><span class="line">├── go.mod</span><br><span class="line">├── go.sum</span><br><span class="line">├── main.go</span><br><span class="line">├── metrics</span><br><span class="line">│   └── port</span><br><span class="line">│       ├── port.go</span><br><span class="line">│       ├── port_linux.go</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>

<p><code>main.go</code></p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">	<span class="string">&quot;exporter/collector&quot;</span></span><br><span class="line">	<span class="string">&quot;fmt&quot;</span></span><br><span class="line">	prom <span class="string">&quot;github.com/prometheus/client_golang/prometheus&quot;</span></span><br><span class="line">	<span class="string">&quot;github.com/prometheus/client_golang/prometheus/promhttp&quot;</span></span><br><span class="line">	<span class="string">&quot;net/http&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">	prom.MustRegister(collector.NewCustomPortCollector())</span><br><span class="line">	http.Handle(<span class="string">&quot;/metrics&quot;</span>, promhttp.Handler())</span><br><span class="line">	<span class="keyword">if</span> err := http.ListenAndServe(<span class="string">&quot;:8088&quot;</span>, <span class="literal">nil</span>); err != <span class="literal">nil</span> &#123;</span><br><span class="line">		fmt.Printf(<span class="string">&quot;Error occur when start custom collector on %v %v&quot;</span>,collector.HostName, err)</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<p>根据前两篇讲的exporter开发套路，这里的main函数非常简单，只需要暴露一个固定的url给prometheus访问即可。另外，目前该custom exporter只有一个port exporter功能，所以不需要做其他的过度、超前设计，重点在于port exporter的功能实现和性能上。</p>
<h4 id="核心代码"><a href="#核心代码" class="headerlink" title="核心代码"></a>核心代码</h4><p>代码地址–<a href="https://github.com/BugKillerPro/exporter">custom exporter</a></p>
<p>采集：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p PortCollector)</span> <span class="title">Collect</span><span class="params">(c <span class="keyword">chan</span>&lt;- prometheus.Metric)</span></span> &#123;</span><br><span class="line">	tabs, err := port.TCPSockets(<span class="function"><span class="keyword">func</span><span class="params">(s *port.SocketEntry)</span> <span class="title">bool</span></span> &#123;</span><br><span class="line">		<span class="keyword">return</span> s.State == port.Listen</span><br><span class="line">	&#125;)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span></span><br><span class="line">	&#125;</span><br><span class="line">	lookup := <span class="function"><span class="keyword">func</span><span class="params">(skaddr *port.SocketAddr)</span> <span class="title">string</span></span> &#123;</span><br><span class="line">		<span class="keyword">const</span> IPv4Strlen = <span class="number">17</span></span><br><span class="line">		addr := skaddr.IP.String()</span><br><span class="line">		names, err := net.LookupAddr(addr)</span><br><span class="line">		<span class="keyword">if</span> err == <span class="literal">nil</span> &amp;&amp; <span class="built_in">len</span>(names) &gt; <span class="number">0</span> &#123;</span><br><span class="line">			addr = names[<span class="number">0</span>]</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">if</span> <span class="built_in">len</span>(addr) &gt; IPv4Strlen &#123;</span><br><span class="line">			addr = addr[:IPv4Strlen]</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">return</span> fmt.Sprintf(<span class="string">&quot;%s:%d&quot;</span>, addr, skaddr.Port)</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">for</span> _, e := <span class="keyword">range</span> tabs &#123;</span><br><span class="line">		exec := <span class="string">&quot;&quot;</span></span><br><span class="line">		<span class="keyword">if</span> e.Process != <span class="literal">nil</span> &#123;</span><br><span class="line">			exec = e.Process.ExecName()</span><br><span class="line">		&#125;</span><br><span class="line">		saddr := lookup(e.LocalAddr)</span><br><span class="line">		c &lt;- prometheus.MustNewConstMetric(</span><br><span class="line">			prometheus.NewDesc(</span><br><span class="line">				<span class="string">&quot;custom_port_exporter&quot;</span>,</span><br><span class="line">				<span class="string">&quot;custom_port_exporter scrape node port state info&quot;</span>,</span><br><span class="line">				[]<span class="keyword">string</span>&#123;<span class="string">&quot;host&quot;</span>,<span class="string">&quot;app&quot;</span>,<span class="string">&quot;port&quot;</span>,<span class="string">&quot;state&quot;</span>,<span class="string">&quot;pid&quot;</span>&#125;,</span><br><span class="line">				<span class="literal">nil</span>,</span><br><span class="line">			),</span><br><span class="line">			prometheus.UntypedValue,</span><br><span class="line">			e.Process.PidFloatValue(),</span><br><span class="line">			[]<span class="keyword">string</span>&#123; HostName, exec, <span class="string">&quot;tcp &quot;</span>+saddr, e.State.String(), e.Process.PidValue()&#125;...,</span><br><span class="line">		)</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<p>这个方法的核心是<code>port.TCPSockets</code>，经过层层穿透，<code>port.TCPSockets</code>主要实现是依赖<code>metrics/port/port_linux.go</code>的<code>netstat(path string, fn filterFunc) ([]SocketEntry, error)</code>:</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">netstat</span><span class="params">(path <span class="keyword">string</span>, fn filterFunc)</span> <span class="params">([]SocketEntry, error)</span></span> &#123;</span><br><span class="line">	f, err := os.Open(path)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">	&#125;</span><br><span class="line">	tabs, err := readSocket(f, fn)</span><br><span class="line">	f.Close()</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">	&#125;</span><br><span class="line">	getPidAndExec(tabs)</span><br><span class="line">	<span class="keyword">return</span> tabs, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<p>其中，<code>readSocket</code>主要是实现对<code>/proc/net/tcp</code>的读取和解析。内容结构参考这边分析<a href="https://guanjunjian.github.io/2017/11/09/study-8-proc-net-tcp-analysis/">文章</a>,具体的解析过程代码如下：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">readSocket</span><span class="params">(r io.Reader, accept filterFunc)</span> <span class="params">([]SocketEntry, error)</span></span> &#123;</span><br><span class="line">	br := bufio.NewScanner(r)</span><br><span class="line">	tab := <span class="built_in">make</span>([]SocketEntry, <span class="number">0</span>, <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">	<span class="comment">// Discard title</span></span><br><span class="line">	br.Scan()</span><br><span class="line"></span><br><span class="line">	<span class="keyword">for</span> br.Scan() &#123;</span><br><span class="line">		<span class="keyword">var</span> e SocketEntry</span><br><span class="line">		line := br.Text()</span><br><span class="line">		<span class="comment">// Skip comments</span></span><br><span class="line">		<span class="keyword">if</span> i := strings.Index(line, <span class="string">&quot;#&quot;</span>); i &gt;= <span class="number">0</span> &#123;</span><br><span class="line">			line = line[:i]</span><br><span class="line">		&#125;</span><br><span class="line">		fields := strings.Fields(line)</span><br><span class="line">		<span class="keyword">if</span> <span class="built_in">len</span>(fields) &lt; <span class="number">12</span> &#123;</span><br><span class="line">			<span class="keyword">return</span> <span class="literal">nil</span>, fmt.Errorf(<span class="string">&quot;netstat: not enough fields: %v, %v&quot;</span>, <span class="built_in">len</span>(fields), fields)</span><br><span class="line">		&#125;</span><br><span class="line">		addr, err := parseAddr(fields[<span class="number">1</span>])</span><br><span class="line">		<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">			<span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">		&#125;</span><br><span class="line">		e.LocalAddr = addr</span><br><span class="line">		addr, err = parseAddr(fields[<span class="number">2</span>])</span><br><span class="line">		<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">			<span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">		&#125;</span><br><span class="line">		e.RemoteAddr = addr</span><br><span class="line">		u, err := strconv.ParseUint(fields[<span class="number">3</span>], <span class="number">16</span>, <span class="number">8</span>)</span><br><span class="line">		<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">			<span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">		&#125;</span><br><span class="line">		e.State = SocketState(u)</span><br><span class="line">		u, err = strconv.ParseUint(fields[<span class="number">7</span>], <span class="number">10</span>, <span class="number">32</span>)</span><br><span class="line">		<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">			<span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">		&#125;</span><br><span class="line">		e.UID = <span class="keyword">uint32</span>(u)</span><br><span class="line">		e.ino = fields[<span class="number">9</span>]</span><br><span class="line">		<span class="keyword">if</span> accept(&amp;e) &#123;</span><br><span class="line">			tab = <span class="built_in">append</span>(tab, e)</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> tab, br.Err()</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>
<p><code>getPidAndExec</code>主要是实现对<code>/proc/pid/fd </code>的读取和解析。内容结构参考这边分析<a href="https://blog.csdn.net/enweitech/article/details/53391567">文章</a>,具体的解析过程代码如下：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *procFd)</span> <span class="title">readFdDir</span><span class="params">()</span></span> &#123;</span><br><span class="line">	<span class="comment">// link name is of the form socket:[5860846]</span></span><br><span class="line">	fddir := path.Join(p.base, <span class="string">&quot;/fd&quot;</span>)</span><br><span class="line">	fi, err := ioutil.ReadDir(fddir)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">var</span> buf [<span class="number">128</span>]<span class="keyword">byte</span></span><br><span class="line"></span><br><span class="line">	<span class="keyword">for</span> _, file := <span class="keyword">range</span> fi &#123;</span><br><span class="line">		fd := path.Join(fddir, file.Name())</span><br><span class="line">		lname, err := os.Readlink(fd)</span><br><span class="line">		<span class="keyword">if</span> err != <span class="literal">nil</span> || !strings.HasPrefix(lname, sockPrefix) &#123;</span><br><span class="line">			<span class="keyword">continue</span></span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		<span class="keyword">for</span> i := <span class="keyword">range</span> p.sktab &#123;</span><br><span class="line">			sk := &amp;p.sktab[i]</span><br><span class="line">			ss := sockPrefix + sk.ino + <span class="string">&quot;]&quot;</span></span><br><span class="line">			<span class="keyword">if</span> ss != lname &#123;</span><br><span class="line">				<span class="keyword">continue</span></span><br><span class="line">			&#125;</span><br><span class="line">			<span class="keyword">if</span> p.p == <span class="literal">nil</span> &#123;</span><br><span class="line">				stat, err := os.Open(path.Join(p.base, <span class="string">&quot;stat&quot;</span>))</span><br><span class="line">				<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">					<span class="keyword">return</span></span><br><span class="line">				&#125;</span><br><span class="line">				n, err := stat.Read(buf[:])</span><br><span class="line">				stat.Close()</span><br><span class="line">				<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">					<span class="keyword">return</span></span><br><span class="line">				&#125;</span><br><span class="line">				z := bytes.SplitN(buf[:n], []<span class="keyword">byte</span>(<span class="string">&quot; &quot;</span>), <span class="number">3</span>)</span><br><span class="line">				name := getProcName(z[<span class="number">1</span>])</span><br><span class="line">				p.p = &amp;Proc&#123;p.pid, name&#125;</span><br><span class="line">			&#125;</span><br><span class="line">			sk.Process = p.p</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h3 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h3><h4 id="查看数据，访问ip-8088-metrics-如果能看类似以下的数据，则正常："><a href="#查看数据，访问ip-8088-metrics-如果能看类似以下的数据，则正常：" class="headerlink" title="查看数据，访问ip:8088/metrics,如果能看类似以下的数据，则正常："></a>查看数据，访问<code>ip:8088/metrics</code>,如果能看类似以下的数据，则正常：</h4><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="TEXT"><figure class="iseeu highlight /text"><table><tr><td class="code"><pre><span class="line">custom_port_exporter&#123;app=&quot;docker-proxy&quot;,host=&quot;ip&quot;,pid=&quot;1814&quot;,port=&quot;tcp 0.0.0.0:8080&quot;,state=&quot;10&quot;&#125; 1814</span><br><span class="line">custom_port_exporter&#123;app=&quot;etcd&quot;,host=&quot;ip&quot;,pid=&quot;3063&quot;,port=&quot;tcp localhost:2379&quot;,state=&quot;10&quot;&#125; 3063</span><br><span class="line">custom_port_exporter&#123;app=&quot;etcd&quot;,host=&quot;ip&quot;,pid=&quot;3063&quot;,port=&quot;tcp localhost:2381&quot;,state=&quot;10&quot;&#125; 3063</span><br></pre></td></tr></table></figure></div>
<h4 id="把port-exporter的信息加入到prometheus的配置文件"><a href="#把port-exporter的信息加入到prometheus的配置文件" class="headerlink" title="把port exporter的信息加入到prometheus的配置文件:"></a>把port exporter的信息加入到prometheus的配置文件:</h4><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">scrape_configs:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;custom exporter&#x27;</span></span><br><span class="line">    <span class="attr">static_configs:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">targets:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">localhost:8088</span></span><br></pre></td></tr></table></figure></div>
<p>以后如果有其他好玩的需求，会持续更新到<a href="https://github.com/BugKillerPro/exporter">custom exporter</a><br>(完)</p>
]]></content>
      <tags>
        <tag>prometheus</tag>
        <tag>源码阅读</tag>
        <tag>exporter开发</tag>
      </tags>
  </entry>
  <entry>
    <title>Context设计思想及使用实践</title>
    <url>/2022/06/16/uncatalog/cl4gopymv00009or79u472iwp/</url>
    <content><![CDATA[<hr>
<span id="more"></span>

<hr>
<h3 id="先抛出一个问题"><a href="#先抛出一个问题" class="headerlink" title="先抛出一个问题?"></a>先抛出一个问题?</h3><p>在go的context源码中，有这样一段话：</p>
<blockquote>
<p>Do not store Contexts inside a struct type; instead, pass a Context<br>explicitly to each function that needs it. The Context should be the first<br>parameter, typically named ctx:</p>
<pre><code>func DoSomething(ctx context.Context, arg Arg) error &#123;
    // ... use ctx ...
</code></pre>
<p>   }</p>
</blockquote>
<p>为什么会有这同样的规定呢？看完这篇文章，你就会找到答案。</p>
<h3 id="Context"><a href="#Context" class="headerlink" title="Context"></a>Context</h3><blockquote>
<p>不建议翻译为：上下文。毕竟语境和语义并不能十分契合<code>信雅达</code>的翻译标准。</p>
</blockquote>
<p>context.Context在Go语言中用来设置截止日期、同步信号，传递请求相关值的结构体。Context与 Goroutine 有比较密切的关系，是Go语言中独特的设计，在其他编程语言中我们很少见到类似的概念。 context.Context是Go语言在1.7版本中引入标准库的接口：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 去掉注释之后的结构</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Context <span class="keyword">interface</span> &#123;</span><br><span class="line">	Deadline() (deadline time.Time, ok <span class="keyword">bool</span>)</span><br><span class="line">	Done() &lt;-<span class="keyword">chan</span> <span class="keyword">struct</span>&#123;&#125;</span><br><span class="line">	Err() error</span><br><span class="line">	Value(key <span class="keyword">interface</span>&#123;&#125;) <span class="keyword">interface</span>&#123;&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>

<p>该接口定义了四个需要实现的方法，其中包括：</p>
<ul>
<li>Deadline — 返回 context.Context 被取消的时间，也就是完成工作的截止日期；</li>
<li>Done — 返回一个 Channel，这个 Channel 会在当前工作完成或者context被取消后关闭，多次调用 Done 方法会返回同一个 Channel；</li>
<li>Err — 返回 context.Context 结束的原因，它只会在 Done 方法对应的 Channel 关闭时返回非空的值；<ul>
<li>如果 context.Context 被取消，会返回 Canceled 错误；</li>
<li>如果 context.Context 超时，会返回 DeadlineExceeded 错误；</li>
</ul>
</li>
<li>Value — 从 context.Context 中获取键对应的值，对于同一个context来说，多次调用 Value 并传入相同的 Key 会返回相同的结果，该方法可以用来传递请求特定的数据；</li>
</ul>
<p>context 包中提供的 context.Background、context.TODO、context.WithDeadline 和 context.WithValue 函数会返回实现该接口的私有结构体，我们会在后面详细介绍它们的工作原理；</p>
<h3 id="设计原理"><a href="#设计原理" class="headerlink" title="设计原理"></a>设计原理</h3><p>在 Goroutine 构成的树形结构中对信号进行同步以减少计算资源的浪费是 context.Context 的最大作用。Go 服务的每一个请求都是通过单独的 Goroutine 处理的2，HTTP/RPC 请求的处理器会启动新的 Goroutine 访问数据库和其他服务。</p>
<p>如下图所示，我们可能会创建多个 Goroutine 来处理一次请求，而 context.Context 的作用是在不同 Goroutine 之间同步请求特定数据、取消信号以及处理请求的截止日期。<br><img src="/2022/06/16/uncatalog/cl4gopymv00009or79u472iwp/1.png" alt="img"><br>每一个 context.Context 都会从最顶层的 Goroutine 一层一层传递到最下层。context.Context 可以在上层 Goroutine 执行出现错误时，将信号及时同步给下层。<br><img src="/2022/06/16/uncatalog/cl4gopymv00009or79u472iwp/2.png" alt="img"><br>如上图所示，当最上层的 Goroutine 因为某些原因执行失败时，下层的 Goroutine 由于没有接收到这个信号所以会继续工作；但是当我们正确地使用 context.Context 时，就可以在下层及时停掉无用的工作以减少额外资源的消耗：<br><img src="/2022/06/16/uncatalog/cl4gopymv00009or79u472iwp/3.png" alt="img"><br>我们可以通过一个代码片段了解 context.Context 是如何对信号进行同步的。在这段代码中，我们创建了一个过期时间为 1s 的Context，并向context传入 handle 函数，该方法会使用 500ms 的时间处理传入的请求：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">	ctx, cancel := context.WithTimeout(context.Background(), <span class="number">1</span>*time.Second)</span><br><span class="line">	<span class="keyword">defer</span> cancel()</span><br><span class="line"></span><br><span class="line">	<span class="keyword">go</span> handle(ctx, <span class="number">500</span>*time.Millisecond)</span><br><span class="line">	<span class="keyword">select</span> &#123;</span><br><span class="line">	<span class="keyword">case</span> &lt;-ctx.Done():</span><br><span class="line">		fmt.Println(<span class="string">&quot;main&quot;</span>, ctx.Err())</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">handle</span><span class="params">(ctx context.Context, duration time.Duration)</span></span> &#123;</span><br><span class="line">	<span class="keyword">select</span> &#123;</span><br><span class="line">	<span class="keyword">case</span> &lt;-ctx.Done():</span><br><span class="line">		fmt.Println(<span class="string">&quot;handle&quot;</span>, ctx.Err())</span><br><span class="line">	<span class="keyword">case</span> &lt;-time.After(duration):</span><br><span class="line">		fmt.Println(<span class="string">&quot;process request with&quot;</span>, duration)</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<p>因为过期时间大于处理时间，所以我们有足够的时间处理该请求，运行上述代码会打印出下面的内容：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> go run context.go</span></span><br><span class="line">process request with 500ms</span><br><span class="line">main context deadline exceeded</span><br></pre></td></tr></table></figure></div>
<p>handle 函数没有进入超时的 select 分支，但是 main 函数的 select 却会等待 context.Context 超时并打印出 main context deadline exceeded。</p>
<p>如果我们将处理请求时间增加至 1500ms，整个程序都会因为Context的过期而被中止，：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> go run context.go</span></span><br><span class="line">main context deadline exceeded</span><br><span class="line">handle context deadline exceeded</span><br></pre></td></tr></table></figure></div>
<p>相信这两个例子能够帮助各位读者理解 context.Context 的使用方法和设计原理 — 多个 Goroutine 同时订阅 ctx.Done() 管道中的消息，一旦接收到取消信号就立刻停止当前正在执行的工作。</p>
<h3 id="默认context的使用"><a href="#默认context的使用" class="headerlink" title="默认context的使用"></a>默认context的使用</h3><p>context 包中最常用的方法还是 context.Background、context.TODO，这两个方法都会返回预先初始化好的私有变量 background 和 todo，它们会在同一个 Go 程序中被复用：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">var</span> (</span><br><span class="line">background = <span class="built_in">new</span>(emptyCtx)</span><br><span class="line">todo       = <span class="built_in">new</span>(emptyCtx)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Background</span><span class="params">()</span> <span class="title">Context</span></span> &#123;</span><br><span class="line">	<span class="keyword">return</span> background</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">TODO</span><span class="params">()</span> <span class="title">Context</span></span> &#123;</span><br><span class="line">	<span class="keyword">return</span> todo</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<p>这两个私有变量都是通过 new(emptyCtx) 语句初始化的，它们是指向私有结构体 context.emptyCtx 的指针，这是最简单、最常用的context类型</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> emptyCtx <span class="keyword">int</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(*emptyCtx)</span> <span class="title">Deadline</span><span class="params">()</span> <span class="params">(deadline time.Time, ok <span class="keyword">bool</span>)</span></span> &#123;</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(*emptyCtx)</span> <span class="title">Done</span><span class="params">()</span> &lt;-<span class="title">chan</span> <span class="title">struct</span></span>&#123;&#125; &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(*emptyCtx)</span> <span class="title">Err</span><span class="params">()</span> <span class="title">error</span></span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(*emptyCtx)</span> <span class="title">Value</span><span class="params">(key <span class="keyword">interface</span>&#123;&#125;)</span> <span class="title">interface</span></span>&#123;&#125; &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<p>从上述代码中，我们不难发现 context.emptyCtx 通过空方法实现了 context.Context 接口中的所有方法，它没有任何功能。<br><img src="/2022/06/16/uncatalog/cl4gopymv00009or79u472iwp/4.png" alt="img"></p>
<p>从源代码来看，context.Background 和 context.TODO 也只是互为别名，没有太大的差别，只是在使用和语义上稍有不同：</p>
<ul>
<li>context.Background 是context的默认值，所有其他的context都应该从它衍生出来；</li>
<li>context.TODO 应该仅在不确定应该使用哪种context时使用；</li>
</ul>
<p>在多数情况下，如果当前函数没有context作为入参，我们都会使用 context.Background 作为起始的context向下传递。</p>
<h3 id="取消信号"><a href="#取消信号" class="headerlink" title="取消信号"></a>取消信号</h3><p>context.WithCancel 函数能够从 context.Context 中衍生出一个新的子context并返回用于取消该context的函数。一旦我们执行返回的取消函数，当前context以及它的子context都会被取消，所有的 Goroutine 都会同步收到这一取消信号。<br><img src="/2022/06/16/uncatalog/cl4gopymv00009or79u472iwp/5.png" alt="img"></p>
<h4 id="Context-子树的取消"><a href="#Context-子树的取消" class="headerlink" title="Context 子树的取消"></a>Context 子树的取消</h4><p>我们直接从 context.WithCancel 函数的实现来看它到底做了什么：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">WithCancel</span><span class="params">(parent Context)</span> <span class="params">(ctx Context, cancel CancelFunc)</span></span> &#123;</span><br><span class="line">	c := newCancelCtx(parent)</span><br><span class="line">	propagateCancel(parent, &amp;c)</span><br><span class="line">	<span class="keyword">return</span> &amp;c, <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123; c.cancel(<span class="literal">true</span>, Canceled) &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<ul>
<li>context.newCancelCtx 将传入的context包装成私有结构体 context.cancelCtx； </li>
<li>context.propagateCancel 会构建父子context之间的关联，当父context被取消时，子context也会被取消：</li>
</ul>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">propagateCancel</span><span class="params">(parent Context, child canceler)</span></span> &#123;</span><br><span class="line">	done := parent.Done()</span><br><span class="line">	<span class="keyword">if</span> done == <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="comment">// 父context不会触发取消信号</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">select</span> &#123;</span><br><span class="line">	<span class="keyword">case</span> &lt;-done:</span><br><span class="line">		child.cancel(<span class="literal">false</span>, parent.Err()) <span class="comment">// 父context已经被取消</span></span><br><span class="line">		<span class="keyword">return</span></span><br><span class="line">	<span class="keyword">default</span>:</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span> p, ok := parentCancelCtx(parent); ok &#123;</span><br><span class="line">		p.mu.Lock()</span><br><span class="line">		<span class="keyword">if</span> p.err != <span class="literal">nil</span> &#123;</span><br><span class="line">			child.cancel(<span class="literal">false</span>, p.err)</span><br><span class="line">		&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">			p.children[child] = <span class="keyword">struct</span>&#123;&#125;&#123;&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		p.mu.Unlock()</span><br><span class="line">	&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">		<span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">			<span class="keyword">select</span> &#123;</span><br><span class="line">			<span class="keyword">case</span> &lt;-parent.Done():</span><br><span class="line">				child.cancel(<span class="literal">false</span>, parent.Err())</span><br><span class="line">			<span class="keyword">case</span> &lt;-child.Done():</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;()</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<p>上述函数总共与父context相关的三种不同的情况：</p>
<ul>
<li>当 parent.Done() == nil，也就是 parent 不会触发取消事件时，当前函数会直接返回；</li>
<li>当 child 的继承链包含可以取消的context时，会判断 parent 是否已经触发了取消信号； <ul>
<li>如果已经被取消，child 会立刻被取消；</li>
<li>如果没有被取消，child 会被加入 parent 的 children 列表中，等待 parent 释放取消信号；</li>
</ul>
</li>
<li>当父context是开发者自定义的类型、实现了 context.Context 接口并在 Done() 方法中返回了非空的管道时；<ul>
<li>运行一个新的 Goroutine 同时监听 parent.Done() 和 child.Done() 两个 Channel；</li>
<li>在 parent.Done() 关闭时调用 child.cancel 取消子context；</li>
</ul>
</li>
</ul>
<p>context.propagateCancel 的作用是在 parent 和 child 之间同步取消和结束的信号，保证在 parent 被取消时，child 也会收到对应的信号，不会出现状态不一致的情况。<br>context.cancelCtx 实现的几个接口方法也没有太多值得分析的地方，该结构体最重要的方法是 context.cancelCtx.cancel，该方法会关闭context中的 Channel 并向所有的子context同步取消信号：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *cancelCtx)</span> <span class="title">cancel</span><span class="params">(removeFromParent <span class="keyword">bool</span>, err error)</span></span> &#123;</span><br><span class="line">	c.mu.Lock()</span><br><span class="line">	<span class="keyword">if</span> c.err != <span class="literal">nil</span> &#123;</span><br><span class="line">		c.mu.Unlock()</span><br><span class="line">		<span class="keyword">return</span></span><br><span class="line">	&#125;</span><br><span class="line">	c.err = err</span><br><span class="line">	<span class="keyword">if</span> c.done == <span class="literal">nil</span> &#123;</span><br><span class="line">		c.done = closedchan</span><br><span class="line">	&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">		<span class="built_in">close</span>(c.done)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">for</span> child := <span class="keyword">range</span> c.children &#123;</span><br><span class="line">		child.cancel(<span class="literal">false</span>, err)</span><br><span class="line">	&#125;</span><br><span class="line">	c.children = <span class="literal">nil</span></span><br><span class="line">	c.mu.Unlock()</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span> removeFromParent &#123;</span><br><span class="line">		removeChild(c.Context, c)</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<p>除了 context.WithCancel 之外，context 包中的另外两个函数 context.WithDeadline 和 context.WithTimeout 也都能创建可以被取消的计时器context context.timerCtx：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">WithTimeout</span><span class="params">(parent Context, timeout time.Duration)</span> <span class="params">(Context, CancelFunc)</span></span> &#123;</span><br><span class="line">	<span class="keyword">return</span> WithDeadline(parent, time.Now().Add(timeout))</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">WithDeadline</span><span class="params">(parent Context, d time.Time)</span> <span class="params">(Context, CancelFunc)</span></span> &#123;</span><br><span class="line">	<span class="keyword">if</span> cur, ok := parent.Deadline(); ok &amp;&amp; cur.Before(d) &#123;</span><br><span class="line">		<span class="keyword">return</span> WithCancel(parent)</span><br><span class="line">	&#125;</span><br><span class="line">	c := &amp;timerCtx&#123;</span><br><span class="line">		cancelCtx: newCancelCtx(parent),</span><br><span class="line">		deadline:  d,</span><br><span class="line">	&#125;</span><br><span class="line">	propagateCancel(parent, c)</span><br><span class="line">	dur := time.Until(d)</span><br><span class="line">	<span class="keyword">if</span> dur &lt;= <span class="number">0</span> &#123;</span><br><span class="line">		c.cancel(<span class="literal">true</span>, DeadlineExceeded) <span class="comment">// 已经过了截止日期</span></span><br><span class="line">		<span class="keyword">return</span> c, <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123; c.cancel(<span class="literal">false</span>, Canceled) &#125;</span><br><span class="line">	&#125;</span><br><span class="line">	c.mu.Lock()</span><br><span class="line">	<span class="keyword">defer</span> c.mu.Unlock()</span><br><span class="line">	<span class="keyword">if</span> c.err == <span class="literal">nil</span> &#123;</span><br><span class="line">		c.timer = time.AfterFunc(dur, <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">			c.cancel(<span class="literal">true</span>, DeadlineExceeded)</span><br><span class="line">		&#125;)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> c, <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123; c.cancel(<span class="literal">true</span>, Canceled) &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<p>context.WithDeadline 在创建 context.timerCtx 的过程中判断了父context的截止日期与当前日期，并通过 time.AfterFunc 创建定时器，当时间超过了截止日期后会调用 context.timerCtx.cancel 同步取消信号。</p>
<p>context.timerCtx 内部不仅通过嵌入 context.cancelCtx 结构体继承了相关的变量和方法，还通过持有的定时器 timer 和截止时间 deadline 实现了定时取消的功能：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> timerCtx <span class="keyword">struct</span> &#123;</span><br><span class="line">	cancelCtx</span><br><span class="line">	timer *time.Timer <span class="comment">// Under cancelCtx.mu.</span></span><br><span class="line"></span><br><span class="line">	deadline time.Time</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *timerCtx)</span> <span class="title">Deadline</span><span class="params">()</span> <span class="params">(deadline time.Time, ok <span class="keyword">bool</span>)</span></span> &#123;</span><br><span class="line">	<span class="keyword">return</span> c.deadline, <span class="literal">true</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *timerCtx)</span> <span class="title">cancel</span><span class="params">(removeFromParent <span class="keyword">bool</span>, err error)</span></span> &#123;</span><br><span class="line">	c.cancelCtx.cancel(<span class="literal">false</span>, err)</span><br><span class="line">	<span class="keyword">if</span> removeFromParent &#123;</span><br><span class="line">		removeChild(c.cancelCtx.Context, c)</span><br><span class="line">	&#125;</span><br><span class="line">	c.mu.Lock()</span><br><span class="line">	<span class="keyword">if</span> c.timer != <span class="literal">nil</span> &#123;</span><br><span class="line">		c.timer.Stop()</span><br><span class="line">		c.timer = <span class="literal">nil</span></span><br><span class="line">	&#125;</span><br><span class="line">	c.mu.Unlock()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<p>值得注意的是，context.timerCtx.cancel 方法不仅调用了 context.cancelCtx.cancel，还会停止持有的定时器减少不必要的资源浪费。</p>
<h3 id="传值方法"><a href="#传值方法" class="headerlink" title="传值方法"></a>传值方法</h3><p>在最后我们需要了解如何使用context传值，context 包中的 context.WithValue 能从父context中创建一个子context，传值的子context使用 context.valueCtx 类型</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">WithValue</span><span class="params">(parent Context, key, val <span class="keyword">interface</span>&#123;&#125;)</span> <span class="title">Context</span></span> &#123;</span><br><span class="line">	<span class="keyword">if</span> key == <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="built_in">panic</span>(<span class="string">&quot;nil key&quot;</span>)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">if</span> !reflectlite.TypeOf(key).Comparable() &#123;</span><br><span class="line">		<span class="built_in">panic</span>(<span class="string">&quot;key is not comparable&quot;</span>)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> &amp;valueCtx&#123;parent, key, val&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<p>context.valueCtx 结构体会将除了 Value 之外的 Err、Deadline 等方法代理到父context中，它只会响应 context.valueCtx.Value 方法，该方法的实现也很简单：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> valueCtx <span class="keyword">struct</span> &#123;</span><br><span class="line">	Context</span><br><span class="line">	key, val <span class="keyword">interface</span>&#123;&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *valueCtx)</span> <span class="title">Value</span><span class="params">(key <span class="keyword">interface</span>&#123;&#125;)</span> <span class="title">interface</span></span>&#123;&#125; &#123;</span><br><span class="line">	<span class="keyword">if</span> c.key == key &#123;</span><br><span class="line">		<span class="keyword">return</span> c.val</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> c.Context.Value(key)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<p>如果 context.valueCtx 中存储的键值对与 context.valueCtx.Value 方法中传入的参数不匹配，就会从父context中查找该键对应的值直到某个父context中返回 nil 或者查找到对应的值。</p>
<h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>Go 语言中的 context.Context 的主要作用还是在多个 Goroutine 组成的树中同步取消信号以减少对资源的消耗和占用，虽然它也有传值的功能，但是这个功能我们还是很少用到。</p>
<p>在真正使用传值的功能时我们也应该非常谨慎，使用 context.Context 传递请求的所有参数一种非常差的设计，比较常见的使用场景是传递请求对应用户的认证令牌以及用于进行分布式追踪的请求 ID。</p>
<h3 id="开头问题的解答"><a href="#开头问题的解答" class="headerlink" title="开头问题的解答"></a>开头问题的解答</h3><p>先对比下以下两种方式：</p>
<h4 id="方式一：context-as-argument方式"><a href="#方式一：context-as-argument方式" class="headerlink" title="方式一：context-as-argument方式"></a>方式一：context-as-argument方式</h4><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Worker fetches and adds works to a remote work orchestration server.</span></span><br><span class="line"><span class="keyword">type</span> Worker <span class="keyword">struct</span> &#123; <span class="comment">/* … */</span> &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Work <span class="keyword">struct</span> &#123; <span class="comment">/* … */</span> &#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">New</span><span class="params">()</span> *<span class="title">Worker</span></span> &#123;</span><br><span class="line">  <span class="keyword">return</span> &amp;Worker&#123;&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(w *Worker)</span> <span class="title">Fetch</span><span class="params">(ctx context.Context)</span> <span class="params">(*Work, error)</span></span> &#123;</span><br><span class="line">  _ = ctx <span class="comment">// A per-call ctx is used for cancellation, deadlines, and metadata.</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(w *Worker)</span> <span class="title">Process</span><span class="params">(ctx context.Context, work *Work)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">  _ = ctx <span class="comment">// A per-call ctx is used for cancellation, deadlines, and metadata.</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<h4 id="方式二：-context-in-struct"><a href="#方式二：-context-in-struct" class="headerlink" title="方式二： context-in-struct"></a>方式二： context-in-struct</h4><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> Worker <span class="keyword">struct</span> &#123;</span><br><span class="line">  ctx context.Context</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">New</span><span class="params">(ctx context.Context)</span> *<span class="title">Worker</span></span> &#123;</span><br><span class="line">  <span class="keyword">return</span> &amp;Worker&#123;ctx: ctx&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(w *Worker)</span> <span class="title">Fetch</span><span class="params">()</span> <span class="params">(*Work, error)</span></span> &#123;</span><br><span class="line">  _ = w.ctx <span class="comment">// A shared w.ctx is used for cancellation, deadlines, and metadata.</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(w *Worker)</span> <span class="title">Process</span><span class="params">(work *Work)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">  _ = w.ctx <span class="comment">// A shared w.ctx is used for cancellation, deadlines, and metadata.</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>结论：</p>
<ul>
<li>方式一优点：<ul>
<li>方法直接接受一个context。通过这种传递即参数的设计，用户可以设置每个调用的deadlines、cancellation和metadata。</li>
<li>传递给每个方法的context.Context将被如何使用是很清楚的：不存在传递给一个方法的context.Context会被其他方法使用的情况。 </li>
<li>context的传递范围几乎和它必须被使用的操作范围一致，这大大增加了这个包中context的效用和清晰度。</li>
</ul>
</li>
<li>方式二缺点：<ul>
<li>当你将context存储在一个struct中时，调用者无法控制该context的生命周期。</li>
<li>调用者无法为下游<code>Fetch()</code>/<code>Process</code>设置deadlines、cancellation和metadata，无法对下游调用设置deadlines、cancellation控制。</li>
<li>调用者本身可能也存在context，这就会造成调用者的context和被调用者<code>Work</code>结构体内的context混淆。</li>
</ul>
</li>
</ul>
<p>但是问题又来了：</p>
<p>1，聪明的你肯定发现了，方式二<code>New</code>可以传一个context给Worker，这样调用Worker的两个方法的时候，就可以避免上面说的方式二的缺点。  </p>
<ul>
<li>这种实现方式，需要配合相关的文档说明，来告诉调用者怎么使用Worker。</li>
<li>调用者无法根据Worker的方法名称和方法参数来了解方法的作用，必须以来文档。</li>
<li>无法做到方法一优点的第二点和第三点。</li>
</ul>
<p>2，熟读go源码的你可能会发现，go标准库中存在方式二：context-in-struct的实现，比如下面的源码，这又是怎么回事呢？</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// A Request represents an HTTP request received by a server or to be sent by a client.</span></span><br><span class="line"><span class="comment">// ...</span></span><br><span class="line"><span class="keyword">type</span> Request <span class="keyword">struct</span> &#123;</span><br><span class="line">  ctx context.Context</span><br><span class="line"></span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// NewRequestWithContext returns a new Request given a method, URL, and optional</span></span><br><span class="line"><span class="comment">// body.</span></span><br><span class="line"><span class="comment">// [...]</span></span><br><span class="line"><span class="comment">// The given ctx is used for the lifetime of the Request.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">NewRequestWithContext</span><span class="params">(ctx context.Context, method, url <span class="keyword">string</span>, body io.Reader)</span> <span class="params">(*Request, error)</span></span> &#123;</span><br><span class="line">  <span class="comment">// Simplified for brevity of this article.</span></span><br><span class="line">  <span class="keyword">return</span> &amp;Request&#123;</span><br><span class="line">    ctx: ctx,</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Do sends an HTTP request and returns an HTTP response [...]</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *Client)</span> <span class="title">Do</span><span class="params">(req *Request)</span> <span class="params">(*Response, error)</span></span></span><br></pre></td></tr></table></figure></div>
<p>原因：context是在Go 1.7才引入的方案，当时有大量的API需要引入context，考虑到向前兼容，所以采用了方式二。</p>
<p>3，如果我的原有代码需要引入context，怎么在向前兼容的前提下，进行迭代呢？<br>函数复用！实例如下：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Call uses context.Background internally; to specify the context, use</span></span><br><span class="line"><span class="comment">// CallContext.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *Client)</span> <span class="title">Call</span><span class="params">()</span> <span class="title">error</span></span> &#123;</span><br><span class="line"><span class="keyword">return</span> c.CallContext(context.Background())</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *Client)</span> <span class="title">CallContext</span><span class="params">(ctx context.Context)</span> <span class="title">error</span></span> &#123;</span><br><span class="line"><span class="comment">// ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>]]></content>
      <tags>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title>面向对象设计六大原则</title>
    <url>/2022/06/17/uncatalog/cl4i43q7u00005sr70tpnfrfg/</url>
    <content><![CDATA[<hr>
<span id="more"></span>

<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>常言道实践是需要理论来指导的，而理论又是需要实践来检验和修正的，理论和实践就这样相互促进，最后将一个领域推向新的高度。从面向对象编程的出现到现在好像已经有半个世纪了（于1950s第一次出现在MIT），所以这六大原则是在无数先辈的理论与实践中产生的。 身为一名主要使用面向对象编程软件从业员（码农），这六大原则是必须要掌握的，它就是设计模式的理论，设计模式是它的实践。</p>
<h3 id="六大原则"><a href="#六大原则" class="headerlink" title="六大原则"></a>六大原则</h3><p>这六大原则应该成为你在日常开发中的理论指导，只要你或多或少的遵循这六大设计原则，那么写出的代码就不会太烂，慢慢的你会发现你竟然理解了那些吊炸天的设计模式意图及设计思路。</p>
<h4 id="1-单一职责（Single-Responsibility-Principle）"><a href="#1-单一职责（Single-Responsibility-Principle）" class="headerlink" title="1 单一职责（Single Responsibility Principle）"></a>1 单一职责（Single Responsibility Principle）</h4><p>这个原则顾名就可以思义，就是一个类应该只负责一个职责，术语叫：仅有一个引起其变化的原因。简单点说：一个类中应该是一组相关性很高的函数及数据的封装，个中含义请自行意会。看起来简单，但是做起来就难了，这可能是六大原则中最难以熟练掌握的一个原则了，它高度依赖程序员的自身素质及业务场景。</p>
<p>例如两个男码农能为是否应该将一个函数写进某个类里面吵一天，最后谁也没有说服谁，最后他两成了同志！</p>
<h4 id="2-开闭原则（Open-Close-Principle）"><a href="#2-开闭原则（Open-Close-Principle）" class="headerlink" title="2 开闭原则（Open Close Principle）"></a>2 开闭原则（Open Close Principle）</h4><p>它是面向对象最重要的设计原则，由Bertrand Meyer（勃兰特.梅耶）在1988年出版的《面向对象软件构造》。中提出的。</p>
<p>定义如下：</p>
<p>开闭原则(Open-Closed Principle, OCP)：一个软件实体应当对扩展开放，对修改关闭。即软件实体应尽量在不修改原有代码的情况下进行扩展。<br>提倡一个类一旦开发完成，后续增加新的功能就不应该通过修改这个类来完成，而是通过继承，增加新的类。 大家想必都听过软件需求不断变化的那个段子，在软件开发这个行当唯一不变的就是变化本身。那为什么应该对修改关闭呢，因为你一旦修改了某个类就有可能破坏系统原来的功能，就需要重新测试。其实我知道你们此刻在想什么，回忆一下自己的日常工作，有几个遵守了这个原则，都是需求来了就找到原来的类，进去改代码呗，^_^。看看有指导原则尚且如此，没有的话就更加乱套了。</p>
<p>那么是不是就一定不能修改原来的类的，当然不是了，我们都是成年人了，要清楚的认识到，这个世界不是非黑即白的。当我们发现原来的类已经烂到家了，当然在有条件的情况下及时重构，避免系统加速腐败。</p>
<h4 id="3-里氏替换原则（Liskov-Substitution-Principle）"><a href="#3-里氏替换原则（Liskov-Substitution-Principle）" class="headerlink" title="3 里氏替换原则（Liskov Substitution Principle）"></a>3 里氏替换原则（Liskov Substitution Principle）</h4><p>这个原则的的提出则可以是一位女性Barbara Liskov，下图为她2010年的照片，现在应该还健在吧，其实计算机这个行当的从业人员比较幸福，我们的祖师爷基本都健在，不像一些其他行业，都死了不知道多少年了，显得很神秘。</p>
<p>定义如下：</p>
<p>里氏代换原则(Liskov Substitution Principle, LSP)：所有引用基类（父类）的地方必须能透明地使用其子类的对象。<br>简单点说，一个软件系统中所有用到一个类的地方都替换成其子类，系统应该仍然可以正常工作。这个原则依赖面向对象的继承特性和多态特性，这个原则我们有意无意中使用的就比较多了。因为一个优秀的程序员一定面向抽象（接口）编程的，如果你不是，说明你还有很大的进步空间。</p>
<p>例如我们有如下的代码，一个图形的基类Shap,以及它的两个子类Rectangle ，Triangle,安装里式替换原则，所有使用Shape的地方都可以安全的替换成其子类。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="JAVASCRIPT"><figure class="iseeu highlight /javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">//基类</span></span><br><span class="line">public abstract <span class="class"><span class="keyword">class</span> <span class="title">Shape</span> </span>&#123;</span><br><span class="line">public abstract <span class="keyword">void</span> draw();</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//子类矩形</span></span><br><span class="line">public <span class="class"><span class="keyword">class</span> <span class="title">Rectangle</span> <span class="keyword">extends</span> <span class="title">Shape</span> </span>&#123;</span><br><span class="line">@Override</span><br><span class="line">public <span class="keyword">void</span> <span class="function"><span class="title">draw</span>(<span class="params"></span>)</span> &#123;</span><br><span class="line">System.out.println(<span class="string">&quot;绘制矩形&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//子类三角形</span></span><br><span class="line">public <span class="class"><span class="keyword">class</span> <span class="title">Triangle</span> <span class="keyword">extends</span> <span class="title">Shape</span> </span>&#123;</span><br><span class="line">@Override</span><br><span class="line">public <span class="keyword">void</span> <span class="function"><span class="title">draw</span>(<span class="params"></span>)</span> &#123;</span><br><span class="line">System.out.println(<span class="string">&quot;绘制三角形&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<p>写一个使用Shape类的函数</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="JAVASCRIPT"><figure class="iseeu highlight /javascript"><table><tr><td class="code"><pre><span class="line">public <span class="keyword">static</span> <span class="keyword">void</span> <span class="function"><span class="title">main</span>(<span class="params"><span class="built_in">String</span>[] args</span>)</span> &#123;</span><br><span class="line"><span class="comment">//使用Shape的子类Triangle 的实例来替换Shape的实例，程序工作正常</span></span><br><span class="line">drawShape(<span class="keyword">new</span> Triangle());</span><br><span class="line">&#125;</span><br><span class="line">private <span class="keyword">static</span> <span class="keyword">void</span> <span class="function"><span class="title">drawShape</span>(<span class="params">Shape shape</span>)</span>&#123;</span><br><span class="line">System.out.println(<span class="string">&quot;开始画图&quot;</span>);</span><br><span class="line">shape.draw();</span><br><span class="line">System.out.println(<span class="string">&quot;结束画图&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<p>输出结果：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">开始画图</span><br><span class="line">绘制三角形</span><br><span class="line">结束画图</span><br></pre></td></tr></table></figure></div>
<p>如上代码所示：本来drawShape()函数需要一个Shape的实例，而我们却传给他一个其子类的实例，但是它正常工作了。我们使用Shape的子类Triangle的实例来替换Shape的实例，程序工作正常。这个原则也非常重要而常用，面向抽象编程。</p>
<h4 id="4-依赖倒置原则（Dependence-Inversion-Principle）"><a href="#4-依赖倒置原则（Dependence-Inversion-Principle）" class="headerlink" title="4 依赖倒置原则（Dependence Inversion Principle）"></a>4 依赖倒置原则（Dependence Inversion Principle）</h4><p>这个原则的提倡者正是大名鼎鼎的 Robert C. Martin，人称Bob大叔</p>
<p>定义:</p>
<p>依赖倒转原则(Dependency Inversion Principle, DIP)：抽象不应该依赖于细节，细节应当依赖于抽象。换言之，要针对接口编程，而不是针对实现编程。</p>
<p>关键点：</p>
<ul>
<li> 高层模块不应该依赖低层模块，两者都应该依赖其抽象</li>
<li> 抽象不应该依赖细节</li>
<li> 细节应该依赖抽象</li>
</ul>
<p>抽象：java中的抽象类或者接口 （如上面代码中的Shape 抽象类） 细节：java中的具体实现类（如上面代码中的Rectangle 和Triangle 实体类） 高层模块：java中的调用类（例如上面代码中drawShape(Shape shape)函数的类） 低层模块：java中的实现类（细节）</p>
<p>依赖倒置又叫依赖倒转，关键在倒置上，啥叫倒置，那不倒置的时候是什么样的？如下面图所示</p>
<p>正常情况下：调用类（高层模块）应该依赖具体实现类（低层模块实现细节）</p>
<p>倒置后：高层模块与低层模块都依赖了实现类的接口（低层模块的细节抽象），底层模块的依赖箭头向上了，所以叫依赖倒置了。</p>
<p>例如菜鸟程序员（牛翠花）会这么写代码</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="JAVASCRIPT"><figure class="iseeu highlight /javascript"><table><tr><td class="code"><pre><span class="line">private <span class="keyword">static</span> <span class="keyword">void</span> drawRectangle (Rectangle rectangle)&#123;        </span><br><span class="line">rectangle.draw();</span><br><span class="line">&#125;</span><br><span class="line">private <span class="keyword">static</span> <span class="keyword">void</span> drawTriangle  (Triangle triangle)&#123;        </span><br><span class="line">triangle.draw();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<p>而老鸟（王二狗）则会</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="JAVASCRIPT"><figure class="iseeu highlight /javascript"><table><tr><td class="code"><pre><span class="line">private <span class="keyword">static</span> <span class="keyword">void</span> <span class="function"><span class="title">drawShape</span>(<span class="params">Shape shape</span>)</span>&#123;</span><br><span class="line">shape.draw();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<p>那么菜鸟的代码会有什么问题呢，假设现在产品经理觉得矩形不好看，让牛翠花将矩形换成五角形，那么牛翠花就要同时修改调用类和增加一个绘制类，而王二狗的代码只需要增加一个五角形的绘制类，这就遵循了开关闭原则</p>
<p>所以我们要对接口编程，举几个具体的例子：声明方法参数的类型，实例变量的类型，方法的返回值类型，类型强制转换等等场景。</p>
<p>牛翠花的代码直接依赖了实现细节，而王二狗的代码依赖的是实现细节的抽象（依赖倒置了）。刚入门时候我们都是牛翠花，但是几年后有的人变成了王二狗，有的人仍然是牛翠花。。。</p>
<p>与依赖倒置（DIP）相关的还有依赖注入(di- dependency injection)，控制翻转(Ioc—Inversion of Control)，记住他们不是同一个东西。</p>
<h4 id="5-接口隔离原则（Interface-Segregation-Principle）"><a href="#5-接口隔离原则（Interface-Segregation-Principle）" class="headerlink" title="5 接口隔离原则（Interface Segregation Principle）"></a>5 接口隔离原则（Interface Segregation Principle）</h4><p>接口隔离原则(Interface Segregation Principle, ISP)：使用多个专门的接口，而不使用单一的总接口，即客户端不应该依赖那些它不需要的接口。<br>其实这个原则是很容易理解的，就是让调用者依赖的接口尽可能的小。例如人类分男人和女人，男人和女人都要吃饭，但是只有女人每个月来大姨妈，那么如果你设计一个接口里面除了吃饭还有来大姨妈同时给男人和女人用就不合适了。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="JAVASCRIPT"><figure class="iseeu highlight /javascript"><table><tr><td class="code"><pre><span class="line">interface IHuman&#123;</span><br><span class="line"><span class="keyword">void</span> eat();</span><br><span class="line"><span class="keyword">void</span> sleep();</span><br><span class="line"><span class="keyword">void</span> laiDaYiMa();<span class="comment">//来大姨妈</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<p>这你让男人情何以堪，万一有个菜鸟程序员抽风了，直接给把来大姨妈的方法实现了，那后果就。。。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="JAVASCRIPT"><figure class="iseeu highlight /javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">//男人类不需要接口中的laiDaYiMa方法</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">man</span> <span class="title">implements</span> <span class="title">IHuman</span></span>&#123;</span><br><span class="line">@Override</span><br><span class="line">public <span class="keyword">void</span> <span class="function"><span class="title">eat</span>(<span class="params"></span>)</span> &#123;        </span><br><span class="line">&#125;</span><br><span class="line">@Override</span><br><span class="line">public <span class="keyword">void</span> <span class="function"><span class="title">laiDaYiMa</span>(<span class="params"></span>)</span> &#123;</span><br><span class="line"><span class="comment">//老子不来大姨妈，所以方法置空，啥也不干!</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">woman</span> <span class="title">implements</span> <span class="title">IHuman</span></span>&#123;</span><br><span class="line">@Override</span><br><span class="line">public <span class="keyword">void</span> <span class="function"><span class="title">eat</span>(<span class="params"></span>)</span> &#123;        </span><br><span class="line">&#125;</span><br><span class="line">@Override</span><br><span class="line">public <span class="keyword">void</span> <span class="function"><span class="title">laiDaYiMa</span>(<span class="params"></span>)</span> &#123;</span><br><span class="line">System.out.println(<span class="string">&quot;王二狗，给老娘倒一杯热水&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<p>上面的例子就违反了接口隔离原则，正确的做法是申明两个接口，使接口保持最小</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="JAVASCRIPT"><figure class="iseeu highlight /javascript"><table><tr><td class="code"><pre><span class="line">interface IHuman&#123;</span><br><span class="line"><span class="keyword">void</span> eat();</span><br><span class="line">&#125;</span><br><span class="line">interface ISpecialForWoman&#123;</span><br><span class="line"><span class="keyword">void</span> laiDaYiMa();<span class="comment">//来大姨妈</span></span><br><span class="line">&#125;</span><br><span class="line">男人只实现IHuman,女人实现IHuman 和ISpecialForWoman</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">man</span> <span class="title">implements</span> <span class="title">IHuman</span></span>&#123;</span><br><span class="line">@Override</span><br><span class="line">public <span class="keyword">void</span> <span class="function"><span class="title">eat</span>(<span class="params"></span>)</span> &#123;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">woman</span> <span class="title">implements</span> <span class="title">IHuman</span>,<span class="title">ISpecialForWoman</span></span>&#123;</span><br><span class="line">@Override</span><br><span class="line">public <span class="keyword">void</span> <span class="function"><span class="title">eat</span>(<span class="params"></span>)</span> &#123;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public <span class="keyword">void</span> <span class="function"><span class="title">laiDaYiMa</span>(<span class="params"></span>)</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;王二狗，给老娘倒一杯热水&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<h4 id="6-迪米特原则（Law-of-Demeter-又名Least-Knowledge-Principle）"><a href="#6-迪米特原则（Law-of-Demeter-又名Least-Knowledge-Principle）" class="headerlink" title="6 迪米特原则（Law of Demeter 又名Least Knowledge Principle）"></a>6 迪米特原则（Law of Demeter 又名Least Knowledge Principle）</h4><p>迪米特法则来自于1987年美国东北大学(Northeastern University)一个名为“Demeter”的研究项目，又称最少知识原则(LeastKnowledge Principle, LKP)，其定义如下：</p>
<p>迪米特法则(Law of Demeter, LoD)：一个软件实体应当尽可能少地与其他实体发生相互作用。<br>一个类应该对自己需要调用的类知道得最少，类的内部如何实现、如何复杂都与调用者或者依赖者没关系，调用者或者依赖者只需要知道他需要的方法即可，其他的我一概不关心。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>以上6大原则全部是以构建灵活可扩展可维护的软件系统为目的的，所以说它的重要性是高于设计模式的，也应该是程序员时刻印在脑子里的，设计模式也是它的具体实践而已。</p>
]]></content>
      <tags>
        <tag>设计模式</tag>
        <tag>架构设计</tag>
      </tags>
  </entry>
  <entry>
    <title>httprouter源码解析</title>
    <url>/2022/06/22/uncatalog/cl4pdun8r0000rsr7bninemtl/</url>
    <content><![CDATA[<hr>
<span id="more"></span>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><blockquote>
<p>gin框架采用了httprouter进行路由匹配，所以废话少说，这篇文章来帮你了解他的源码实现</p>
</blockquote>
<h3 id="树"><a href="#树" class="headerlink" title="树"></a>树</h3><p>httprouter的路由匹配功能是基于radix tree(前缀树/基数树)这种数据结构实现的：<br><img src="/2022/06/22/uncatalog/cl4pdun8r0000rsr7bninemtl/radix_tree.png" alt="img"><br>有读者可能会有疑问：为什么不按照RUL分隔符切割的来分割，每个segment作为一个节点，而是要用公共前缀来分割？针对这个疑问，了解树的开发者都知道，树的高度是影响查找效率的重要因素，高度越高，查找效率越低。两张图片来对比一下:<br><img src="/2022/06/22/uncatalog/cl4pdun8r0000rsr7bninemtl/1.png" alt="img"><br><img src="/2022/06/22/uncatalog/cl4pdun8r0000rsr7bninemtl/2.png" alt="img"></p>
<h3 id="源码"><a href="#源码" class="headerlink" title="源码"></a>源码</h3><p>demo</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">    <span class="string">&quot;fmt&quot;</span></span><br><span class="line">    <span class="string">&quot;net/http&quot;</span></span><br><span class="line">    <span class="string">&quot;log&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;github.com/julienschmidt/httprouter&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Index</span><span class="params">(w http.ResponseWriter, r *http.Request, _ httprouter.Params)</span></span> &#123;</span><br><span class="line">    fmt.Fprint(w, <span class="string">&quot;Welcome!\n&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Hello</span><span class="params">(w http.ResponseWriter, r *http.Request, ps httprouter.Params)</span></span> &#123;</span><br><span class="line">    fmt.Fprintf(w, <span class="string">&quot;hello, %s!\n&quot;</span>, ps.ByName(<span class="string">&quot;name&quot;</span>))</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    router := httprouter.New()</span><br><span class="line">    router.GET(<span class="string">&quot;/&quot;</span>, Index)</span><br><span class="line">    router.GET(<span class="string">&quot;/hello/:name&quot;</span>, Hello)</span><br><span class="line"></span><br><span class="line">    log.Fatal(http.ListenAndServe(<span class="string">&quot;:8080&quot;</span>, router))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<p>首先看到 httprouter.New()，因为它返回一个router实例：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">New</span><span class="params">()</span> *<span class="title">Router</span></span> &#123;</span><br><span class="line">	<span class="keyword">return</span> &amp;Router&#123;</span><br><span class="line">		RedirectTrailingSlash:  <span class="literal">true</span>,</span><br><span class="line">		RedirectFixedPath:      <span class="literal">true</span>,</span><br><span class="line">		HandleMethodNotAllowed: <span class="literal">true</span>,</span><br><span class="line">		HandleOPTIONS:          <span class="literal">true</span>,</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Router is a http.Handler which can be used to dispatch requests to different</span></span><br><span class="line"><span class="comment">// handler functions via configurable routes</span></span><br><span class="line"><span class="keyword">type</span> Router <span class="keyword">struct</span> &#123;</span><br><span class="line">	trees <span class="keyword">map</span>[<span class="keyword">string</span>]*node</span><br><span class="line"></span><br><span class="line">	paramsPool sync.Pool</span><br><span class="line">	maxParams  <span class="keyword">uint16</span></span><br><span class="line">	SaveMatchedRoutePath <span class="keyword">bool</span></span><br><span class="line">	RedirectTrailingSlash <span class="keyword">bool</span></span><br><span class="line">	RedirectFixedPath <span class="keyword">bool</span></span><br><span class="line">	HandleMethodNotAllowed <span class="keyword">bool</span></span><br><span class="line">	HandleOPTIONS <span class="keyword">bool</span></span><br><span class="line">	GlobalOPTIONS http.Handler</span><br><span class="line">	globalAllowed <span class="keyword">string</span></span><br><span class="line">	NotFound http.Handler</span><br><span class="line">	MethodNotAllowed http.Handler</span><br><span class="line">	PanicHandler <span class="function"><span class="keyword">func</span><span class="params">(http.ResponseWriter, *http.Request, <span class="keyword">interface</span>&#123;&#125;)</span></span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<p>它实现了 ServeHTTP 这个函数，因此符合 net/http.Handler 接口：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// ServeHTTP makes the router implement the http.Handler interface.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(r *Router)</span> <span class="title">ServeHTTP</span><span class="params">(w http.ResponseWriter, req *http.Request)</span></span> &#123;</span><br><span class="line">	<span class="keyword">if</span> r.PanicHandler != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">defer</span> r.recv(w, req)</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	path := req.URL.Path</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span> root := r.trees[req.Method]; root != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">if</span> handle, ps, tsr := root.getValue(path, r.getParams); handle != <span class="literal">nil</span> &#123;</span><br><span class="line">			<span class="keyword">if</span> ps != <span class="literal">nil</span> &#123;</span><br><span class="line">				handle(w, req, *ps)</span><br><span class="line">				r.putParams(ps)</span><br><span class="line">			&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">				handle(w, req, <span class="literal">nil</span>)</span><br><span class="line">			&#125;</span><br><span class="line">			<span class="keyword">return</span></span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<p>这就是处理请求的时候，查找路由树及handler的那部分，root.getValue就是查找路由树的具体函数，不过细节此处不表。</p>
<p>我们接下来看看注册路由的那部分：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// GET is a shortcut for router.Handle(http.MethodGet, path, handle)</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(r *Router)</span> <span class="title">GET</span><span class="params">(path <span class="keyword">string</span>, handle Handle)</span></span> &#123;</span><br><span class="line">	r.Handle(http.MethodGet, path, handle)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 跟进 r.Handle 函数之后发现调用了 addRoute 函数</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// addRoute adds a node with the given handle to the path.</span></span><br><span class="line"><span class="comment">// Not concurrency-safe!</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(n *node)</span> <span class="title">addRoute</span><span class="params">(path <span class="keyword">string</span>, handle Handle)</span></span> &#123;</span><br><span class="line">	fullPath := path</span><br><span class="line">	n.priority++</span><br><span class="line"></span><br><span class="line">	<span class="comment">// Empty tree</span></span><br><span class="line">	<span class="keyword">if</span> <span class="built_in">len</span>(n.path) == <span class="number">0</span> &amp;&amp; <span class="built_in">len</span>(n.indices) == <span class="number">0</span> &#123;</span><br><span class="line">		n.insertChild(path, fullPath, handle)</span><br><span class="line">		n.nType = root</span><br><span class="line">		<span class="keyword">return</span></span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">walk:</span><br><span class="line">	<span class="keyword">for</span> &#123;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>
<p>而 addRoute 函数就是实现radix tree这个数据结构的函数了，它会先找到共同的部分，然后考虑是否把路由切分为字节点，最后 把handler写上去(调用 insertChild 函数)。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> node <span class="keyword">struct</span> &#123;</span><br><span class="line">	path      <span class="keyword">string</span> <span class="comment">// URL</span></span><br><span class="line">	indices   <span class="keyword">string</span> <span class="comment">// 字节点的首字母拼成的string，顺序与 children 一致</span></span><br><span class="line">	wildChild <span class="keyword">bool</span> <span class="comment">// 是否是泛匹配</span></span><br><span class="line">	nType     nodeType <span class="comment">// 节点类型</span></span><br><span class="line">	priority  <span class="keyword">uint32</span> <span class="comment">// 优先级</span></span><br><span class="line">	children  []*node <span class="comment">// 子节点</span></span><br><span class="line">	handle    Handle <span class="comment">// 处理函数</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<p>node就是保存这些资料的radix tree的节点</p>
]]></content>
      <tags>
        <tag>手撸一个web框架</tag>
      </tags>
  </entry>
  <entry>
    <title>The Twelve-Factor App--I.Codebase</title>
    <url>/2022/06/24/uncatalog/cl4s23b37000010r7cl0h25hd/</url>
    <content><![CDATA[<hr>
<span id="more"></span>
<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>如今，软件通常会作为一种服务来交付，它们被称为网络应用程序，或软件即服务（SaaS）。12-Factor 为构建如下的 SaaS 应用提供了方法论：</p>
<ul>
<li>使用标准化流程自动配置，从而使新的开发者花费最少的学习成本加入这个项目。</li>
<li>和操作系统之间尽可能的划清界限，在各个系统中提供最大的可移植性。</li>
<li>适合部署在现代的云计算平台，从而在服务器和系统管理方面节省资源。</li>
<li>将开发环境和生产环境的差异降至最低，并使用持续交付实施敏捷开发。</li>
<li>可以在工具、架构和开发流程不发生明显变化的前提下实现扩展。<br>这套理论适用于任意语言和后端服务（数据库、消息队列、缓存等）开发的应用程序。</li>
</ul>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>这套方法论由Heroku的联合创始人Adam Wiggins发掘，应用到了数以百计的应用程序的开发和部署，并通过 Heroku 平台间接见证了数十万应用程序的开发，运作以及扩展的过程。</p>
<p><code>The Twelve-Factor App</code>系列文章，综合了Hero库关于 SaaS 应用几乎所有的经验和智慧，是开发此类应用的理想实践标准，并特别关注于应用程序如何保持良性成长，开发者之间如何进行有效的代码协作，以及如何 避免软件污染 。</p>
<blockquote>
<p>英文原文</p>
</blockquote>
<h2 id="I-Codebase"><a href="#I-Codebase" class="headerlink" title="I. Codebase"></a>I. Codebase</h2><blockquote>
<p>One codebase tracked in revision control, many deploys</p>
</blockquote>
<p>A twelve-factor app is always tracked in a version control system, such as Git, Mercurial, or Subversion. A copy of the revision tracking database is known as a code repository, often shortened to code repo or just repo.</p>
<p>A codebase is any single repo (in a centralized revision control system like Subversion), or any set of repos who share a root commit (in a decentralized revision control system like Git).</p>
<p>One codebase maps to many deploys</p>
<p>There is always a one-to-one correlation between the codebase and the app:</p>
<ul>
<li>If there are multiple codebases, it’s not an app – it’s a distributed system. Each component in a distributed system is an app, and each can individually comply with twelve-factor.</li>
<li>Multiple apps sharing the same code is a violation of twelve-factor. The solution here is to factor shared code into libraries which can be included through the dependency manager.<br><img src="/2022/06/24/uncatalog/cl4s23b37000010r7cl0h25hd/codebase-deploys.png" alt="imag"></li>
</ul>
<p>There is only one codebase per app, but there will be many deploys of the app. A deploy is a running instance of the app. This is typically a production site, and one or more staging sites. Additionally, every developer has a copy of the app running in their local development environment, each of which also qualifies as a deploy.</p>
<p>The codebase is the same across all deploys, although different versions may be active in each deploy. For example, a developer has some commits not yet deployed to staging; staging has some commits not yet deployed to production. But they all share the same codebase, thus making them identifiable as different deploys of the same app.  </p>
<blockquote>
<p>中文</p>
</blockquote>
<h3 id="I-基准代码"><a href="#I-基准代码" class="headerlink" title="I. 基准代码"></a>I. 基准代码</h3><blockquote>
<p>一份基准代码（Codebase），多份部署（deploy）</p>
</blockquote>
<p>12-Factor应用(译者注：应该是说一个使用本文概念来设计的应用，下同)通常会使用版本控制系统加以管理，如Git, Mercurial, Subversion。一份用来跟踪代码所有修订版本的数据库被称作 代码库（code repository, code repo, repo）。</p>
<p>在类似 SVN 这样的集中式版本控制系统中，基准代码 就是指控制系统中的这一份代码库；而在 Git 那样的分布式版本控制系统中，基准代码 则是指最上游的那份代码库。</p>
<p>一份代码库对应多份部署</p>
<p>基准代码和应用之间总是保持一一对应的关系：</p>
<ul>
<li>一旦有多个基准代码，就不能称为一个应用，而是一个分布式系统。分布式系统中的每一个组件都是一个应用，每一个应用可以分别使用 12-Factor 进行开发。</li>
<li>多个应用共享一份基准代码是有悖于 12-Factor 原则的。解决方案是将共享的代码拆分为独立的类库，然后使用 依赖管理 策略去加载它们。<br><img src="/2022/06/24/uncatalog/cl4s23b37000010r7cl0h25hd/codebase-deploys.png" alt="imag"></li>
</ul>
<p>尽管每个应用只对应一份基准代码，但可以同时存在多份部署。每份 部署 相当于运行了一个应用的实例。通常会有一个生产环境，一个或多个预发布环境。此外，每个开发人员都会在自己本地环境运行一个应用实例，这些都相当于一份部署。</p>
<p>所有部署的基准代码相同，但每份部署可以使用其不同的版本。比如，开发人员可能有一些提交还没有同步至预发布环境；预发布环境也有一些提交没有同步至生产环境。但它们都共享一份基准代码，我们就认为它们只是相同应用的不同部署而已</p>
]]></content>
      <tags>
        <tag>The Twelve-Factor App</tag>
      </tags>
  </entry>
  <entry>
    <title>The Twelve-Factor App--II.Dependencies</title>
    <url>/2022/06/24/uncatalog/cl4s5aedb0000yor75ersbj7b/</url>
    <content><![CDATA[<hr>
<span id="more"></span>
<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>如今，软件通常会作为一种服务来交付，它们被称为网络应用程序，或软件即服务（SaaS）。12-Factor 为构建如下的 SaaS 应用提供了方法论：</p>
<ul>
<li>使用标准化流程自动配置，从而使新的开发者花费最少的学习成本加入这个项目。</li>
<li>和操作系统之间尽可能的划清界限，在各个系统中提供最大的可移植性。</li>
<li>适合部署在现代的云计算平台，从而在服务器和系统管理方面节省资源。</li>
<li>将开发环境和生产环境的差异降至最低，并使用持续交付实施敏捷开发。</li>
<li>可以在工具、架构和开发流程不发生明显变化的前提下实现扩展。<br>这套理论适用于任意语言和后端服务（数据库、消息队列、缓存等）开发的应用程序。</li>
</ul>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>这套方法论由Heroku的联合创始人Adam Wiggins发掘，应用到了数以百计的应用程序的开发和部署，并通过 Heroku 平台间接见证了数十万应用程序的开发，运作以及扩展的过程。</p>
<p><code>The Twelve-Factor App</code>系列文章，综合了Hero库关于 SaaS 应用几乎所有的经验和智慧，是开发此类应用的理想实践标准，并特别关注于应用程序如何保持良性成长，开发者之间如何进行有效的代码协作，以及如何 避免软件污染 。</p>
<blockquote>
<p>英文原文</p>
</blockquote>
<h3 id="II-Dependencies"><a href="#II-Dependencies" class="headerlink" title="II. Dependencies"></a>II. Dependencies</h3><blockquote>
<p>Explicitly declare and isolate dependencies</p>
</blockquote>
<p>Most programming languages offer a packaging system for distributing support libraries, such as CPAN for Perl or Rubygems for Ruby. Libraries installed through a packaging system can be installed system-wide (known as “site packages”) or scoped into the directory containing the app (known as “vendoring” or “bundling”).</p>
<p>A twelve-factor app never relies on implicit existence of system-wide packages. It declares all dependencies, completely and exactly, via a dependency declaration manifest. Furthermore, it uses a dependency isolation tool during execution to ensure that no implicit dependencies “leak in” from the surrounding system. The full and explicit dependency specification is applied uniformly to both production and development.</p>
<p>For example, Bundler for Ruby offers the Gemfile manifest format for dependency declaration and bundle exec for dependency isolation. In Python there are two separate tools for these steps – Pip is used for declaration and Virtualenv for isolation. Even C has Autoconf for dependency declaration, and static linking can provide dependency isolation. No matter what the toolchain, dependency declaration and isolation must always be used together – only one or the other is not sufficient to satisfy twelve-factor.</p>
<p>One benefit of explicit dependency declaration is that it simplifies setup for developers new to the app. The new developer can check out the app’s codebase onto their development machine, requiring only the language runtime and dependency manager installed as prerequisites. They will be able to set up everything needed to run the app’s code with a deterministic build command. For example, the build command for Ruby/Bundler is bundle install, while for Clojure/Leiningen it is lein deps.</p>
<p>Twelve-factor apps also do not rely on the implicit existence of any system tools. Examples include shelling out to ImageMagick or curl. While these tools may exist on many or even most systems, there is no guarantee that they will exist on all systems where the app may run in the future, or whether the version found on a future system will be compatible with the app. If the app needs to shell out to a system tool, that tool should be vendored into the app.</p>
<blockquote>
<p>中文</p>
</blockquote>
<h3 id="II-依赖"><a href="#II-依赖" class="headerlink" title="II. 依赖"></a>II. 依赖</h3><blockquote>
<p>显式声明依赖关系（ dependency ）</p>
</blockquote>
<p>大多数编程语言都会提供一个打包系统，用来为各个类库提供打包服务，就像 Perl 的 CPAN 或是 Ruby 的 Rubygems 。通过打包系统安装的类库可以是系统级的（称之为 “site packages”），或仅供某个应用程序使用，部署在相应的目录中（称之为 “vendoring” 或 “bunding”）。</p>
<p>12-Factor规则下的应用程序不会隐式依赖系统级的类库。 它一定通过 依赖清单 ，确切地声明所有依赖项。此外，在运行过程中通过 依赖隔离 工具来确保程序不会调用系统中存在但清单中未声明的依赖项。这一做法会统一应用到生产和开发环境。</p>
<p>例如， Ruby 的 Bundler 使用 Gemfile 作为依赖项声明清单，使用 bundle exec 来进行依赖隔离。Python 中则可分别使用两种工具 – Pip 用作依赖声明， Virtualenv 用作依赖隔离。甚至 C 语言也有类似工具， Autoconf 用作依赖声明，静态链接库用作依赖隔离。无论用什么工具，依赖声明和依赖隔离必须一起使用，否则无法满足 12-Factor 规范。</p>
<p>显式声明依赖的优点之一是为新进开发者简化了环境配置流程。新进开发者可以检出应用程序的基准代码，安装编程语言环境和它对应的依赖管理工具，只需通过一个 构建命令 来安装所有的依赖项，即可开始工作。例如，Ruby/Bundler 下使用 bundle install，而 Clojure/Leiningen 则是 lein deps。</p>
<p>12-Factor 应用同样不会隐式依赖某些系统工具，如 ImageMagick 或是curl。即使这些工具存在于几乎所有系统，但终究无法保证所有未来的系统都能支持应用顺利运行，或是能够和应用兼容。如果应用必须使用到某些系统工具，那么这些工具应该被包含在应用之中。</p>
]]></content>
      <tags>
        <tag>The Twelve-Factor App</tag>
      </tags>
  </entry>
  <entry>
    <title>The Twelve-Factor App--III.Config</title>
    <url>/2022/06/24/uncatalog/cl4s5aede0001yor787lle01q/</url>
    <content><![CDATA[<hr>
<span id="more"></span>
<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>如今，软件通常会作为一种服务来交付，它们被称为网络应用程序，或软件即服务（SaaS）。12-Factor 为构建如下的 SaaS 应用提供了方法论：</p>
<ul>
<li>使用标准化流程自动配置，从而使新的开发者花费最少的学习成本加入这个项目。</li>
<li>和操作系统之间尽可能的划清界限，在各个系统中提供最大的可移植性。</li>
<li>适合部署在现代的云计算平台，从而在服务器和系统管理方面节省资源。</li>
<li>将开发环境和生产环境的差异降至最低，并使用持续交付实施敏捷开发。</li>
<li>可以在工具、架构和开发流程不发生明显变化的前提下实现扩展。<br>这套理论适用于任意语言和后端服务（数据库、消息队列、缓存等）开发的应用程序。</li>
</ul>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>这套方法论由Heroku的联合创始人Adam Wiggins发掘，应用到了数以百计的应用程序的开发和部署，并通过 Heroku 平台间接见证了数十万应用程序的开发，运作以及扩展的过程。</p>
<p><code>The Twelve-Factor App</code>系列文章，综合了Hero库关于 SaaS 应用几乎所有的经验和智慧，是开发此类应用的理想实践标准，并特别关注于应用程序如何保持良性成长，开发者之间如何进行有效的代码协作，以及如何 避免软件污染 。</p>
<blockquote>
<p>英文原文</p>
</blockquote>
<h3 id="III-Config"><a href="#III-Config" class="headerlink" title="III. Config"></a>III. Config</h3><blockquote>
<p>Store config in the environment</p>
</blockquote>
<p>An app’s config is everything that is likely to vary between deploys (staging, production, developer environments, etc). This includes:</p>
<ul>
<li>Resource handles to the database, Memcached, and other backing services</li>
<li>Credentials to external services such as Amazon S3 or Twitter</li>
<li>Per-deploy values such as the canonical hostname for the deploy<br>Apps sometimes store config as constants in the code. This is a violation of twelve-factor, which requires strict separation of config from code. Config varies substantially across deploys, code does not.</li>
</ul>
<p>A litmus test for whether an app has all config correctly factored out of the code is whether the codebase could be made open source at any moment, without compromising any credentials.</p>
<p>Note that this definition of “config” does not include internal application config, such as config/routes.rb in Rails, or how code modules are connected in Spring. This type of config does not vary between deploys, and so is best done in the code.</p>
<p>Another approach to config is the use of config files which are not checked into revision control, such as config/database.yml in Rails. This is a huge improvement over using constants which are checked into the code repo, but still has weaknesses: it’s easy to mistakenly check in a config file to the repo; there is a tendency for config files to be scattered about in different places and different formats, making it hard to see and manage all the config in one place. Further, these formats tend to be language- or framework-specific.</p>
<p>The twelve-factor app stores config in environment variables (often shortened to env vars or env). Env vars are easy to change between deploys without changing any code; unlike config files, there is little chance of them being checked into the code repo accidentally; and unlike custom config files, or other config mechanisms such as Java System Properties, they are a language- and OS-agnostic standard.</p>
<p>Another aspect of config management is grouping. Sometimes apps batch config into named groups (often called “environments”) named after specific deploys, such as the development, test, and production environments in Rails. This method does not scale cleanly: as more deploys of the app are created, new environment names are necessary, such as staging or qa. As the project grows further, developers may add their own special environments like joes-staging, resulting in a combinatorial explosion of config which makes managing deploys of the app very brittle.</p>
<p>In a twelve-factor app, env vars are granular controls, each fully orthogonal to other env vars. They are never grouped together as “environments”, but instead are independently managed for each deploy. This is a model that scales up smoothly as the app naturally expands into more deploys over its lifetime.</p>
<blockquote>
<p>中文</p>
</blockquote>
<h3 id="III-配置"><a href="#III-配置" class="headerlink" title="III. 配置"></a>III. 配置</h3><blockquote>
<p>在环境中存储配置</p>
</blockquote>
<p>通常，应用的 配置 在不同 部署 (预发布、生产环境、开发环境等等)间会有很大差异。这其中包括：</p>
<ul>
<li>数据库，Memcached，以及其他 后端服务 的配置</li>
<li>第三方服务的证书，如 Amazon S3、Twitter 等</li>
<li>每份部署特有的配置，如域名等</li>
</ul>
<p>有些应用在代码中使用常量保存配置，这与 12-Factor 所要求的代码和配置严格分离显然大相径庭。配置文件在各部署间存在大幅差异，代码却完全一致。</p>
<p>判断一个应用是否正确地将配置排除在代码之外，一个简单的方法是看该应用的基准代码是否可以立刻开源，而不用担心会暴露任何敏感的信息。</p>
<p>需要指出的是，这里定义的“配置”并不包括应用的内部配置，比如 Rails 的 config/routes.rb，或是使用 Spring 时 代码模块间的依赖注入关系 。这类配置在不同部署间不存在差异，所以应该写入代码。</p>
<p>另外一个解决方法是使用配置文件，但不把它们纳入版本控制系统，就像 Rails 的 config/database.yml 。这相对于在代码中使用常量已经是长足进步，但仍然有缺点：总是会不小心将配置文件签入了代码库；配置文件的可能会分散在不同的目录，并有着不同的格式，这让找出一个地方来统一管理所有配置变的不太现实。更糟的是，这些格式通常是语言或框架特定的。</p>
<p>12-Factor推荐将应用的配置存储于 环境变量 中（ env vars, env ）。环境变量可以非常方便地在不同的部署间做修改，却不动一行代码；与配置文件不同，不小心把它们签入代码库的概率微乎其微；与一些传统的解决配置问题的机制（比如 Java 的属性配置文件）相比，环境变量与语言和系统无关。</p>
<p>配置管理的另一个方面是分组。有时应用会将配置按照特定部署进行分组（或叫做“环境”），例如Rails中的 development,test, 和 production 环境。这种方法无法轻易扩展：更多部署意味着更多新的环境，例如 staging 或 qa 。 随着项目的不断深入，开发人员可能还会添加他们自己的环境，比如 joes-staging ，这将导致各种配置组合的激增，从而给管理部署增加了很多不确定因素。</p>
<p>12-Factor 应用中，环境变量的粒度要足够小，且相对独立。它们永远也不会组合成一个所谓的“环境”，而是独立存在于每个部署之中。当应用程序不断扩展，需要更多种类的部署时，这种配置管理方式能够做到平滑过渡。</p>
]]></content>
      <tags>
        <tag>The Twelve-Factor App</tag>
      </tags>
  </entry>
  <entry>
    <title>The Twelve-Factor App--IV.Backing_services</title>
    <url>/2022/06/24/uncatalog/cl4s5aedf0003yor755fd317a/</url>
    <content><![CDATA[<hr>
<span id="more"></span>
<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>如今，软件通常会作为一种服务来交付，它们被称为网络应用程序，或软件即服务（SaaS）。12-Factor 为构建如下的 SaaS 应用提供了方法论：</p>
<ul>
<li>使用标准化流程自动配置，从而使新的开发者花费最少的学习成本加入这个项目。</li>
<li>和操作系统之间尽可能的划清界限，在各个系统中提供最大的可移植性。</li>
<li>适合部署在现代的云计算平台，从而在服务器和系统管理方面节省资源。</li>
<li>将开发环境和生产环境的差异降至最低，并使用持续交付实施敏捷开发。</li>
<li>可以在工具、架构和开发流程不发生明显变化的前提下实现扩展。<br>这套理论适用于任意语言和后端服务（数据库、消息队列、缓存等）开发的应用程序。</li>
</ul>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>这套方法论由Heroku的联合创始人Adam Wiggins发掘，应用到了数以百计的应用程序的开发和部署，并通过 Heroku 平台间接见证了数十万应用程序的开发，运作以及扩展的过程。</p>
<p><code>The Twelve-Factor App</code>系列文章，综合了Hero库关于 SaaS 应用几乎所有的经验和智慧，是开发此类应用的理想实践标准，并特别关注于应用程序如何保持良性成长，开发者之间如何进行有效的代码协作，以及如何 避免软件污染 。</p>
<blockquote>
<p>英文原文</p>
</blockquote>
<h3 id="IV-Backing-services"><a href="#IV-Backing-services" class="headerlink" title="IV. Backing services"></a>IV. Backing services</h3><blockquote>
<p>Treat backing services as attached resources</p>
</blockquote>
<p>A backing service is any service the app consumes over the network as part of its normal operation. Examples include datastores (such as MySQL or CouchDB), messaging/queueing systems (such as RabbitMQ or Beanstalkd), SMTP services for outbound email (such as Postfix), and caching systems (such as Memcached).</p>
<p>Backing services like the database are traditionally managed by the same systems administrators who deploy the app’s runtime. In addition to these locally-managed services, the app may also have services provided and managed by third parties. Examples include SMTP services (such as Postmark), metrics-gathering services (such as New Relic or Loggly), binary asset services (such as Amazon S3), and even API-accessible consumer services (such as Twitter, Google Maps, or Last.fm).</p>
<p>The code for a twelve-factor app makes no distinction between local and third party services. To the app, both are attached resources, accessed via a URL or other locator/credentials stored in the config. A deploy of the twelve-factor app should be able to swap out a local MySQL database with one managed by a third party (such as Amazon RDS) without any changes to the app’s code. Likewise, a local SMTP server could be swapped with a third-party SMTP service (such as Postmark) without code changes. In both cases, only the resource handle in the config needs to change.</p>
<p>Each distinct backing service is a resource. For example, a MySQL database is a resource; two MySQL databases (used for sharding at the application layer) qualify as two distinct resources. The twelve-factor app treats these databases as attached resources, which indicates their loose coupling to the deploy they are attached to.<br><img src="/2022/06/24/uncatalog/cl4s5aedf0003yor755fd317a/attached-resources.png" alt="image"><br>Resources can be attached to and detached from deploys at will. For example, if the app’s database is misbehaving due to a hardware issue, the app’s administrator might spin up a new database server restored from a recent backup. The current production database could be detached, and the new database attached – all without any code changes.</p>
<blockquote>
<p>中文</p>
</blockquote>
<h3 id="IV-后端服务"><a href="#IV-后端服务" class="headerlink" title="IV. 后端服务"></a>IV. 后端服务</h3><blockquote>
<p>把后端服务(backing services)当作附加资源</p>
</blockquote>
<p>后端服务是指程序运行所需要的通过网络调用的各种服务，如数据库（MySQL，CouchDB），消息/队列系统（RabbitMQ，Beanstalkd），SMTP 邮件发送服务（Postfix），以及缓存系统（Memcached）。</p>
<p>类似数据库的后端服务，通常由部署应用程序的系统管理员一起管理。除了本地服务之外，应用程序有可能使用了第三方发布和管理的服务。示例包括 SMTP（例如 Postmark），数据收集服务（例如 New Relic 或 Loggly），数据存储服务（如 Amazon S3），以及使用 API 访问的服务（例如 Twitter, Google Maps, Last.fm）。</p>
<p>12-Factor 应用不会区别对待本地或第三方服务。 对应用程序而言，两种都是附加资源，通过一个 url 或是其他存储在 配置 中的服务定位/服务证书来获取数据。12-Factor 应用的任意 部署 ，都应该可以在不进行任何代码改动的情况下，将本地 MySQL 数据库换成第三方服务（例如 Amazon RDS）。类似的，本地 SMTP 服务应该也可以和第三方 SMTP 服务（例如 Postmark ）互换。上述 2 个例子中，仅需修改配置中的资源地址。</p>
<p>每个不同的后端服务是一份 资源 。例如，一个 MySQL 数据库是一个资源，两个 MySQL 数据库（用来数据分区）就被当作是 2 个不同的资源。12-Factor 应用将这些数据库都视作 附加资源 ，这些资源和它们附属的部署保持松耦合。<br><img src="/2022/06/24/uncatalog/cl4s5aedf0003yor755fd317a/attached-resources.png" alt="image"><br>部署可以按需加载或卸载资源。例如，如果应用的数据库服务由于硬件问题出现异常，管理员可以从最近的备份中恢复一个数据库，卸载当前的数据库，然后加载新的数据库 – 整个过程都不需要修改代码。</p>
]]></content>
      <tags>
        <tag>The Twelve-Factor App</tag>
      </tags>
  </entry>
  <entry>
    <title>The Twelve-Factor App--IX.Disposability</title>
    <url>/2022/06/24/uncatalog/cl4s5aedi0005yor703iffxzw/</url>
    <content><![CDATA[<hr>
<span id="more"></span>
<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>如今，软件通常会作为一种服务来交付，它们被称为网络应用程序，或软件即服务（SaaS）。12-Factor 为构建如下的 SaaS 应用提供了方法论：</p>
<ul>
<li>使用标准化流程自动配置，从而使新的开发者花费最少的学习成本加入这个项目。</li>
<li>和操作系统之间尽可能的划清界限，在各个系统中提供最大的可移植性。</li>
<li>适合部署在现代的云计算平台，从而在服务器和系统管理方面节省资源。</li>
<li>将开发环境和生产环境的差异降至最低，并使用持续交付实施敏捷开发。</li>
<li>可以在工具、架构和开发流程不发生明显变化的前提下实现扩展。<br>这套理论适用于任意语言和后端服务（数据库、消息队列、缓存等）开发的应用程序。</li>
</ul>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>这套方法论由Heroku的联合创始人Adam Wiggins发掘，应用到了数以百计的应用程序的开发和部署，并通过 Heroku 平台间接见证了数十万应用程序的开发，运作以及扩展的过程。</p>
<p><code>The Twelve-Factor App</code>系列文章，综合了Hero库关于 SaaS 应用几乎所有的经验和智慧，是开发此类应用的理想实践标准，并特别关注于应用程序如何保持良性成长，开发者之间如何进行有效的代码协作，以及如何 避免软件污染 。</p>
<blockquote>
<p>英文原文</p>
</blockquote>
<h3 id="IX-Disposability"><a href="#IX-Disposability" class="headerlink" title="IX. Disposability"></a>IX. Disposability</h3><blockquote>
<p>Maximize robustness with fast startup and graceful shutdown</p>
</blockquote>
<p>The twelve-factor app’s processes are disposable, meaning they can be started or stopped at a moment’s notice. This facilitates fast elastic scaling, rapid deployment of code or config changes, and robustness of production deploys.</p>
<p>Processes should strive to minimize startup time. Ideally, a process takes a few seconds from the time the launch command is executed until the process is up and ready to receive requests or jobs. Short startup time provides more agility for the release process and scaling up; and it aids robustness, because the process manager can more easily move processes to new physical machines when warranted.</p>
<p>Processes shut down gracefully when they receive a SIGTERM signal from the process manager. For a web process, graceful shutdown is achieved by ceasing to listen on the service port (thereby refusing any new requests), allowing any current requests to finish, and then exiting. Implicit in this model is that HTTP requests are short (no more than a few seconds), or in the case of long polling, the client should seamlessly attempt to reconnect when the connection is lost.</p>
<p>For a worker process, graceful shutdown is achieved by returning the current job to the work queue. For example, on RabbitMQ the worker can send a NACK; on Beanstalkd, the job is returned to the queue automatically whenever a worker disconnects. Lock-based systems such as Delayed Job need to be sure to release their lock on the job record. Implicit in this model is that all jobs are reentrant, which typically is achieved by wrapping the results in a transaction, or making the operation idempotent.</p>
<p>Processes should also be robust against sudden death, in the case of a failure in the underlying hardware. While this is a much less common occurrence than a graceful shutdown with SIGTERM, it can still happen. A recommended approach is use of a robust queueing backend, such as Beanstalkd, that returns jobs to the queue when clients disconnect or time out. Either way, a twelve-factor app is architected to handle unexpected, non-graceful terminations. Crash-only design takes this concept to its logical conclusion.</p>
<blockquote>
<p>中文</p>
</blockquote>
<h3 id="IX-易处理"><a href="#IX-易处理" class="headerlink" title="IX. 易处理"></a>IX. 易处理</h3><blockquote>
<p>快速启动和优雅终止可最大化健壮性</p>
</blockquote>
<p>12-Factor 应用的 进程 是 易处理（disposable）的，意思是说它们可以瞬间开启或停止。 这有利于快速、弹性的伸缩应用，迅速部署变化的 代码 或 配置 ，稳健的部署应用。</p>
<p>进程应当追求 最小启动时间 。 理想状态下，进程从敲下命令到真正启动并等待请求的时间应该只需很短的时间。更少的启动时间提供了更敏捷的 发布 以及扩展过程，此外还增加了健壮性，因为进程管理器可以在授权情形下容易的将进程搬到新的物理机器上。</p>
<p>进程 一旦接收 终止信号（SIGTERM） 就会优雅的终止 。就网络进程而言，优雅终止是指停止监听服务的端口，即拒绝所有新的请求，并继续执行当前已接收的请求，然后退出。此类型的进程所隐含的要求是HTTP请求大多都很短(不会超过几秒钟)，而在长时间轮询中，客户端在丢失连接后应该马上尝试重连。</p>
<p>对于 worker 进程来说，优雅终止是指将当前任务退回队列。例如，RabbitMQ 中，worker 可以发送一个NACK信号。 Beanstalkd 中，任务终止并退回队列会在worker断开时自动触发。有锁机制的系统诸如 Delayed Job 则需要确定释放了系统资源。此类型的进程所隐含的要求是，任务都应该 可重复执行 ， 这主要由将结果包装进事务或是使重复操作 幂等 来实现。</p>
<p>进程还应当在面对突然死亡时保持健壮，例如底层硬件故障。虽然这种情况比起优雅终止来说少之又少，但终究有可能发生。一种推荐的方式是使用一个健壮的后端队列，例如 Beanstalkd ，它可以在客户端断开或超时后自动退回任务。无论如何，12-Factor 应用都应该可以设计能够应对意外的、不优雅的终结。Crash-only design 将这种概念转化为 合乎逻辑的理论。</p>
]]></content>
      <tags>
        <tag>The Twelve-Factor App</tag>
      </tags>
  </entry>
  <entry>
    <title>The Twelve-Factor App--V.Build,release,run</title>
    <url>/2022/06/24/uncatalog/cl4s5aedk0007yor7fl055pq7/</url>
    <content><![CDATA[<hr>
<span id="more"></span>
<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>如今，软件通常会作为一种服务来交付，它们被称为网络应用程序，或软件即服务（SaaS）。12-Factor 为构建如下的 SaaS 应用提供了方法论：</p>
<ul>
<li>使用标准化流程自动配置，从而使新的开发者花费最少的学习成本加入这个项目。</li>
<li>和操作系统之间尽可能的划清界限，在各个系统中提供最大的可移植性。</li>
<li>适合部署在现代的云计算平台，从而在服务器和系统管理方面节省资源。</li>
<li>将开发环境和生产环境的差异降至最低，并使用持续交付实施敏捷开发。</li>
<li>可以在工具、架构和开发流程不发生明显变化的前提下实现扩展。<br>这套理论适用于任意语言和后端服务（数据库、消息队列、缓存等）开发的应用程序。</li>
</ul>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>这套方法论由Heroku的联合创始人Adam Wiggins发掘，应用到了数以百计的应用程序的开发和部署，并通过 Heroku 平台间接见证了数十万应用程序的开发，运作以及扩展的过程。</p>
<p><code>The Twelve-Factor App</code>系列文章，综合了Hero库关于 SaaS 应用几乎所有的经验和智慧，是开发此类应用的理想实践标准，并特别关注于应用程序如何保持良性成长，开发者之间如何进行有效的代码协作，以及如何 避免软件污染 。</p>
<blockquote>
<p>英文原文</p>
</blockquote>
<h3 id="V-Build-release-run"><a href="#V-Build-release-run" class="headerlink" title="V. Build, release, run"></a>V. Build, release, run</h3><blockquote>
<p>Strictly separate build and run stages</p>
</blockquote>
<p>A codebase is transformed into a (non-development) deploy through three stages:</p>
<ul>
<li>The build stage is a transform which converts a code repo into an executable bundle known as a build. Using a version of the code at a commit specified by the deployment process, the build stage fetches vendors dependencies and compiles binaries and assets.</li>
<li>The release stage takes the build produced by the build stage and combines it with the deploy’s current config. The resulting release contains both the build and the config and is ready for immediate execution in the execution environment.</li>
<li>The run stage (also known as “runtime”) runs the app in the execution environment, by launching some set of the app’s processes against a selected release.<br>Code becomes a build, which is combined with config to create a release.<br><img src="/2022/06/24/uncatalog/cl4s5aedk0007yor7fl055pq7/release.png" alt="im"></li>
</ul>
<p>The twelve-factor app uses strict separation between the build, release, and run stages. For example, it is impossible to make changes to the code at runtime, since there is no way to propagate those changes back to the build stage.</p>
<p>Deployment tools typically offer release management tools, most notably the ability to roll back to a previous release. For example, the Capistrano deployment tool stores releases in a subdirectory named releases, where the current release is a symlink to the current release directory. Its rollback command makes it easy to quickly roll back to a previous release.</p>
<p>Every release should always have a unique release ID, such as a timestamp of the release (such as 2011-04-06-20:32:17) or an incrementing number (such as v100). Releases are an append-only ledger and a release cannot be mutated once it is created. Any change must create a new release.</p>
<p>Builds are initiated by the app’s developers whenever new code is deployed. Runtime execution, by contrast, can happen automatically in cases such as a server reboot, or a crashed process being restarted by the process manager. Therefore, the run stage should be kept to as few moving parts as possible, since problems that prevent an app from running can cause it to break in the middle of the night when no developers are on hand. The build stage can be more complex, since errors are always in the foreground for a developer who is driving the deploy.</p>
<blockquote>
<p>中文</p>
</blockquote>
<h3 id="V-构建，发布，运行"><a href="#V-构建，发布，运行" class="headerlink" title="V. 构建，发布，运行"></a>V. 构建，发布，运行</h3><blockquote>
<p>严格分离构建和运行</p>
</blockquote>
<p>基准代码 转化为一份部署(非开发环境)需要以下三个阶段：</p>
<ul>
<li>构建阶段 是指将代码仓库转化为可执行包的过程。构建时会使用指定版本的代码，获取和打包 依赖项，编译成二进制文件和资源文件。</li>
<li>发布阶段 会将构建的结果和当前部署所需 配置 相结合，并能够立刻在运行环境中投入使用。</li>
<li>运行阶段 （或者说“运行时”）是指针对选定的发布版本，在执行环境中启动一系列应用程序 进程。<br>代码被构建，然后和配置结合成为发布版本<br><img src="/2022/06/24/uncatalog/cl4s5aedk0007yor7fl055pq7/release.png" alt="im"></li>
</ul>
<p>12-factor 应用严格区分构建，发布，运行这三个步骤。 举例来说，直接修改处于运行状态的代码是非常不可取的做法，因为这些修改很难再同步回构建步骤。</p>
<p>部署工具通常都提供了发布管理工具，最引人注目的功能是退回至较旧的发布版本。比如， Capistrano 将所有发布版本都存储在一个叫 releases 的子目录中，当前的在线版本只需映射至对应的目录即可。该工具的 rollback 命令可以很容易地实现回退版本的功能。</p>
<p>每一个发布版本必须对应一个唯一的发布 ID，例如可以使用发布时的时间戳（2011-04-06-20:32:17），亦或是一个增长的数字（v100）。发布的版本就像一本只能追加的账本，一旦发布就不可修改，任何的变动都应该产生一个新的发布版本。</p>
<p>新的代码在部署之前，需要开发人员触发构建操作。但是，运行阶段不一定需要人为触发，而是可以自动进行。如服务器重启，或是进程管理器重启了一个崩溃的进程。因此，运行阶段应该保持尽可能少的模块，这样假设半夜发生系统故障而开发人员又捉襟见肘也不会引起太大问题。构建阶段是可以相对复杂一些的，因为错误信息能够立刻展示在开发人员面前，从而得到妥善处理。</p>
]]></content>
      <tags>
        <tag>The Twelve-Factor App</tag>
      </tags>
  </entry>
  <entry>
    <title>The Twelve-Factor App--VI.Processes</title>
    <url>/2022/06/24/uncatalog/cl4s5aedm0009yor77lq164nz/</url>
    <content><![CDATA[<hr>
<span id="more"></span>
<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>如今，软件通常会作为一种服务来交付，它们被称为网络应用程序，或软件即服务（SaaS）。12-Factor 为构建如下的 SaaS 应用提供了方法论：</p>
<ul>
<li>使用标准化流程自动配置，从而使新的开发者花费最少的学习成本加入这个项目。</li>
<li>和操作系统之间尽可能的划清界限，在各个系统中提供最大的可移植性。</li>
<li>适合部署在现代的云计算平台，从而在服务器和系统管理方面节省资源。</li>
<li>将开发环境和生产环境的差异降至最低，并使用持续交付实施敏捷开发。</li>
<li>可以在工具、架构和开发流程不发生明显变化的前提下实现扩展。<br>这套理论适用于任意语言和后端服务（数据库、消息队列、缓存等）开发的应用程序。</li>
</ul>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>这套方法论由Heroku的联合创始人Adam Wiggins发掘，应用到了数以百计的应用程序的开发和部署，并通过 Heroku 平台间接见证了数十万应用程序的开发，运作以及扩展的过程。</p>
<p><code>The Twelve-Factor App</code>系列文章，综合了Hero库关于 SaaS 应用几乎所有的经验和智慧，是开发此类应用的理想实践标准，并特别关注于应用程序如何保持良性成长，开发者之间如何进行有效的代码协作，以及如何 避免软件污染 。</p>
<blockquote>
<p>英文原文</p>
</blockquote>
<h3 id="VI-Processes"><a href="#VI-Processes" class="headerlink" title="VI. Processes"></a>VI. Processes</h3><blockquote>
<p>Execute the app as one or more stateless processes</p>
</blockquote>
<p>The app is executed in the execution environment as one or more processes.</p>
<p>In the simplest case, the code is a stand-alone script, the execution environment is a developer’s local laptop with an installed language runtime, and the process is launched via the command line (for example, python my_script.py). On the other end of the spectrum, a production deploy of a sophisticated app may use many process types, instantiated into zero or more running processes.</p>
<p>Twelve-factor processes are stateless and share-nothing. Any data that needs to persist must be stored in a stateful backing service, typically a database.</p>
<p>The memory space or filesystem of the process can be used as a brief, single-transaction cache. For example, downloading a large file, operating on it, and storing the results of the operation in the database. The twelve-factor app never assumes that anything cached in memory or on disk will be available on a future request or job – with many processes of each type running, chances are high that a future request will be served by a different process. Even when running only one process, a restart (triggered by code deploy, config change, or the execution environment relocating the process to a different physical location) will usually wipe out all local (e.g., memory and filesystem) state.</p>
<p>Asset packagers like django-assetpackager use the filesystem as a cache for compiled assets. A twelve-factor app prefers to do this compiling during the build stage. Asset packagers such as Jammit and the Rails asset pipeline can be configured to package assets during the build stage.</p>
<p>Some web systems rely on “sticky sessions” – that is, caching user session data in memory of the app’s process and expecting future requests from the same visitor to be routed to the same process. Sticky sessions are a violation of twelve-factor and should never be used or relied upon. Session state data is a good candidate for a datastore that offers time-expiration, such as Memcached or Redis.</p>
<blockquote>
<p>中文</p>
</blockquote>
<h3 id="VI-进程"><a href="#VI-进程" class="headerlink" title="VI. 进程"></a>VI. 进程</h3><blockquote>
<p>以一个或多个无状态进程运行应用</p>
</blockquote>
<p>运行环境中，应用程序通常是以一个和多个 进程 运行的。</p>
<p>最简单的场景中，代码是一个独立的脚本，运行环境是开发人员自己的笔记本电脑，进程由一条命令行（例如python my_script.py）。另外一个极端情况是，复杂的应用可能会使用很多 进程类型 ，也就是零个或多个进程实例。</p>
<p>12-Factor 应用的进程必须无状态且 无共享 。 任何需要持久化的数据都要存储在 后端服务 内，比如数据库。</p>
<p>内存区域或磁盘空间可以作为进程在做某种事务型操作时的缓存，例如下载一个很大的文件，对其操作并将结果写入数据库的过程。12-Factor应用根本不用考虑这些缓存的内容是不是可以保留给之后的请求来使用，这是因为应用启动了多种类型的进程，将来的请求多半会由其他进程来服务。即使在只有一个进程的情形下，先前保存的数据（内存或文件系统中）也会因为重启（如代码部署、配置更改、或运行环境将进程调度至另一个物理区域执行）而丢失。</p>
<p>源文件打包工具（Jammit, django-compressor） 使用文件系统来缓存编译过的源文件。12-Factor 应用更倾向于在 构建步骤 做此动作——正如 Rails资源管道 ，而不是在运行阶段。</p>
<p>一些互联网系统依赖于 “粘性 session”， 这是指将用户 session 中的数据缓存至某进程的内存中，并将同一用户的后续请求路由到同一个进程。粘性 session 是 12-Factor 极力反对的。Session 中的数据应该保存在诸如 Memcached 或 Redis 这样的带有过期时间的缓存中。</p>
]]></content>
      <tags>
        <tag>The Twelve-Factor App</tag>
      </tags>
  </entry>
  <entry>
    <title>The Twelve-Factor App--VII.Port_binding</title>
    <url>/2022/06/24/uncatalog/cl4s5aedo000byor78qwog8wr/</url>
    <content><![CDATA[<hr>
<span id="more"></span>
<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>如今，软件通常会作为一种服务来交付，它们被称为网络应用程序，或软件即服务（SaaS）。12-Factor 为构建如下的 SaaS 应用提供了方法论：</p>
<ul>
<li>使用标准化流程自动配置，从而使新的开发者花费最少的学习成本加入这个项目。</li>
<li>和操作系统之间尽可能的划清界限，在各个系统中提供最大的可移植性。</li>
<li>适合部署在现代的云计算平台，从而在服务器和系统管理方面节省资源。</li>
<li>将开发环境和生产环境的差异降至最低，并使用持续交付实施敏捷开发。</li>
<li>可以在工具、架构和开发流程不发生明显变化的前提下实现扩展。<br>这套理论适用于任意语言和后端服务（数据库、消息队列、缓存等）开发的应用程序。</li>
</ul>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>这套方法论由Heroku的联合创始人Adam Wiggins发掘，应用到了数以百计的应用程序的开发和部署，并通过 Heroku 平台间接见证了数十万应用程序的开发，运作以及扩展的过程。</p>
<p><code>The Twelve-Factor App</code>系列文章，综合了Hero库关于 SaaS 应用几乎所有的经验和智慧，是开发此类应用的理想实践标准，并特别关注于应用程序如何保持良性成长，开发者之间如何进行有效的代码协作，以及如何 避免软件污染 。</p>
<blockquote>
<p>英文原文</p>
</blockquote>
<h3 id="VII-Port-binding"><a href="#VII-Port-binding" class="headerlink" title="VII. Port binding"></a>VII. Port binding</h3><blockquote>
<p>Export services via port binding</p>
</blockquote>
<p>Web apps are sometimes executed inside a webserver container. For example, PHP apps might run as a module inside Apache HTTPD, or Java apps might run inside Tomcat.</p>
<p>The twelve-factor app is completely self-contained and does not rely on runtime injection of a webserver into the execution environment to create a web-facing service. The web app exports HTTP as a service by binding to a port, and listening to requests coming in on that port.</p>
<p>In a local development environment, the developer visits a service URL like <a href="http://localhost:5000/">http://localhost:5000/</a> to access the service exported by their app. In deployment, a routing layer handles routing requests from a public-facing hostname to the port-bound web processes.</p>
<p>This is typically implemented by using dependency declaration to add a webserver library to the app, such as Tornado for Python, Thin for Ruby, or Jetty for Java and other JVM-based languages. This happens entirely in user space, that is, within the app’s code. The contract with the execution environment is binding to a port to serve requests.</p>
<p>HTTP is not the only service that can be exported by port binding. Nearly any kind of server software can be run via a process binding to a port and awaiting incoming requests. Examples include ejabberd (speaking XMPP), and Redis (speaking the Redis protocol).</p>
<p>Note also that the port-binding approach means that one app can become the backing service for another app, by providing the URL to the backing app as a resource handle in the config for the consuming app.</p>
<blockquote>
<p>中文</p>
</blockquote>
<h3 id="VII-端口绑定"><a href="#VII-端口绑定" class="headerlink" title="VII. 端口绑定"></a>VII. 端口绑定</h3><blockquote>
<p>通过端口绑定(Port binding)来提供服务</p>
</blockquote>
<p>互联网应用有时会运行于服务器的容器之中。例如 PHP 经常作为 Apache HTTPD 的一个模块来运行，正如 Java 运行于 Tomcat 。</p>
<p>12-Factor 应用完全自我加载 而不依赖于任何网络服务器就可以创建一个面向网络的服务。互联网应用 通过端口绑定来提供服务 ，并监听发送至该端口的请求。</p>
<p>本地环境中，开发人员通过类似 <a href="http://localhost:5000/">http://localhost:5000/</a> 的地址来访问服务。在线上环境中，请求统一发送至公共域名而后路由至绑定了端口的网络进程。</p>
<p>通常的实现思路是，将网络服务器类库通过 依赖声明 载入应用。例如，Python 的 Tornado, Ruby 的Thin , Java 以及其他基于 JVM 语言的 Jetty。完全由 用户端 ，确切的说应该是应用的代码，发起请求。和运行环境约定好绑定的端口即可处理这些请求。</p>
<p>HTTP 并不是唯一一个可以由端口绑定提供的服务。其实几乎所有服务器软件都可以通过进程绑定端口来等待请求。例如，使用 XMPP 的 ejabberd ， 以及使用 Redis 协议 的 Redis 。</p>
<p>还要指出的是，端口绑定这种方式也意味着一个应用可以成为另外一个应用的 后端服务 ，调用方将服务方提供的相应 URL 当作资源存入 配置 以备将来调用。</p>
]]></content>
      <tags>
        <tag>The Twelve-Factor App</tag>
      </tags>
  </entry>
  <entry>
    <title>The Twelve-Factor App--VIII.Concurrency</title>
    <url>/2022/06/24/uncatalog/cl4s5aedq000dyor70ynbgtrg/</url>
    <content><![CDATA[<hr>
<span id="more"></span>
<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>如今，软件通常会作为一种服务来交付，它们被称为网络应用程序，或软件即服务（SaaS）。12-Factor 为构建如下的 SaaS 应用提供了方法论：</p>
<ul>
<li>使用标准化流程自动配置，从而使新的开发者花费最少的学习成本加入这个项目。</li>
<li>和操作系统之间尽可能的划清界限，在各个系统中提供最大的可移植性。</li>
<li>适合部署在现代的云计算平台，从而在服务器和系统管理方面节省资源。</li>
<li>将开发环境和生产环境的差异降至最低，并使用持续交付实施敏捷开发。</li>
<li>可以在工具、架构和开发流程不发生明显变化的前提下实现扩展。<br>这套理论适用于任意语言和后端服务（数据库、消息队列、缓存等）开发的应用程序。</li>
</ul>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>这套方法论由Heroku的联合创始人Adam Wiggins发掘，应用到了数以百计的应用程序的开发和部署，并通过 Heroku 平台间接见证了数十万应用程序的开发，运作以及扩展的过程。</p>
<p><code>The Twelve-Factor App</code>系列文章，综合了Hero库关于 SaaS 应用几乎所有的经验和智慧，是开发此类应用的理想实践标准，并特别关注于应用程序如何保持良性成长，开发者之间如何进行有效的代码协作，以及如何 避免软件污染 。</p>
<blockquote>
<p>英文原文</p>
</blockquote>
<h3 id="VIII-Concurrency"><a href="#VIII-Concurrency" class="headerlink" title="VIII. Concurrency"></a>VIII. Concurrency</h3><blockquote>
<p>Scale out via the process model</p>
</blockquote>
<p>Any computer program, once run, is represented by one or more processes. Web apps have taken a variety of process-execution forms. For example, PHP processes run as child processes of Apache, started on demand as needed by request volume. Java processes take the opposite approach, with the JVM providing one massive uberprocess that reserves a large block of system resources (CPU and memory) on startup, with concurrency managed internally via threads. In both cases, the running process(es) are only minimally visible to the developers of the app.</p>
<p>Scale is expressed as running processes, workload diversity is expressed as process types.</p>
<p>In the twelve-factor app, processes are a first class citizen. Processes in the twelve-factor app take strong cues from the unix process model for running service daemons. Using this model, the developer can architect their app to handle diverse workloads by assigning each type of work to a process type. For example, HTTP requests may be handled by a web process, and long-running background tasks handled by a worker process.</p>
<p>This does not exclude individual processes from handling their own internal multiplexing, via threads inside the runtime VM, or the async/evented model found in tools such as EventMachine, Twisted, or Node.js. But an individual VM can only grow so large (vertical scale), so the application must also be able to span multiple processes running on multiple physical machines.<br><img src="/2022/06/24/uncatalog/cl4s5aedq000dyor70ynbgtrg/process-types.png" alt="img"><br>The process model truly shines when it comes time to scale out. The share-nothing, horizontally partitionable nature of twelve-factor app processes means that adding more concurrency is a simple and reliable operation. The array of process types and number of processes of each type is known as the process formation.</p>
<p>Twelve-factor app processes should never daemonize or write PID files. Instead, rely on the operating system’s process manager (such as systemd, a distributed process manager on a cloud platform, or a tool like Foreman in development) to manage output streams, respond to crashed processes, and handle user-initiated restarts and shutdowns.</p>
<blockquote>
<p>中文</p>
</blockquote>
<h3 id="VIII-并发"><a href="#VIII-并发" class="headerlink" title="VIII. 并发"></a>VIII. 并发</h3><blockquote>
<p>通过进程模型进行扩展</p>
</blockquote>
<p>任何计算机程序，一旦启动，就会生成一个或多个进程。互联网应用采用多种进程运行方式。例如，PHP 进程作为 Apache 的子进程存在，随请求按需启动。Java 进程则采取了相反的方式，在程序启动之初 JVM 就提供了一个超级进程储备了大量的系统资源(CPU 和内存)，并通过多线程实现内部的并发管理。上述 2 个例子中，进程是开发人员可以操作的最小单位。</p>
<p>扩展表现为运行中的进程，工作多样性表现为进程类型。</p>
<p>在 12-factor 应用中，进程是一等公民。12-Factor 应用的进程主要借鉴于 unix 守护进程模型 。开发人员可以运用这个模型去设计应用架构，将不同的工作分配给不同的 进程类型 。例如，HTTP 请求可以交给 web 进程来处理，而常驻的后台工作则交由 worker 进程负责。</p>
<p>这并不包括个别较为特殊的进程，例如通过虚拟机的线程处理并发的内部运算，或是使用诸如 EventMachine, Twisted, Node.js 的异步/事件触发模型。但一台独立的虚拟机的扩展有瓶颈（垂直扩展），所以应用程序必须可以在多台物理机器间跨进程工作。<br><img src="/2022/06/24/uncatalog/cl4s5aedq000dyor70ynbgtrg/process-types.png" alt="img"><br>上述进程模型会在系统急需扩展时大放异彩。 12-Factor 应用的进程所具备的无共享，水平分区的特性 意味着添加并发会变得简单而稳妥。这些进程的类型以及每个类型中进程的数量就被称作 进程构成 。</p>
<p>12-Factor 应用的进程 不需要守护进程 或是写入 PID 文件。相反的，应该借助操作系统的进程管理器(例如 systemd ，分布式的进程管理云平台，或是类似 Foreman 的工具)，来管理 输出流 ，响应崩溃的进程，以及处理用户触发的重启和关闭超级进程的请</p>
]]></content>
      <tags>
        <tag>The Twelve-Factor App</tag>
      </tags>
  </entry>
  <entry>
    <title>The Twelve-Factor App--X.Dev/prod_parity</title>
    <url>/2022/06/24/uncatalog/cl4s5aedr000fyor726t7b7ya/</url>
    <content><![CDATA[<hr>
<span id="more"></span>
<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>如今，软件通常会作为一种服务来交付，它们被称为网络应用程序，或软件即服务（SaaS）。12-Factor 为构建如下的 SaaS 应用提供了方法论：</p>
<ul>
<li>使用标准化流程自动配置，从而使新的开发者花费最少的学习成本加入这个项目。</li>
<li>和操作系统之间尽可能的划清界限，在各个系统中提供最大的可移植性。</li>
<li>适合部署在现代的云计算平台，从而在服务器和系统管理方面节省资源。</li>
<li>将开发环境和生产环境的差异降至最低，并使用持续交付实施敏捷开发。</li>
<li>可以在工具、架构和开发流程不发生明显变化的前提下实现扩展。<br>这套理论适用于任意语言和后端服务（数据库、消息队列、缓存等）开发的应用程序。</li>
</ul>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>这套方法论由Heroku的联合创始人Adam Wiggins发掘，应用到了数以百计的应用程序的开发和部署，并通过 Heroku 平台间接见证了数十万应用程序的开发，运作以及扩展的过程。</p>
<p><code>The Twelve-Factor App</code>系列文章，综合了Hero库关于 SaaS 应用几乎所有的经验和智慧，是开发此类应用的理想实践标准，并特别关注于应用程序如何保持良性成长，开发者之间如何进行有效的代码协作，以及如何 避免软件污染 。</p>
<blockquote>
<p>英文原文</p>
</blockquote>
<h3 id="IX-X-Dev-prod-parity"><a href="#IX-X-Dev-prod-parity" class="headerlink" title="IX. X. Dev/prod parity"></a>IX. X. Dev/prod parity</h3><blockquote>
<p>Keep development, staging, and production as similar as possible</p>
</blockquote>
<p>Historically, there have been substantial gaps between development (a developer making live edits to a local deploy of the app) and production (a running deploy of the app accessed by end users). These gaps manifest in three areas:</p>
<ul>
<li>The time gap: A developer may work on code that takes days, weeks, or even months to go into production.</li>
<li>The personnel gap: Developers write code, ops engineers deploy it.</li>
<li>The tools gap: Developers may be using a stack like Nginx, SQLite, and OS X, while the production deploy uses Apache, MySQL, and Linux.</li>
</ul>
<p>The twelve-factor app is designed for continuous deployment by keeping the gap between development and production small. Looking at the three gaps described above:</p>
<ul>
<li>Make the time gap small: a developer may write code and have it deployed hours or even just minutes later.</li>
<li>Make the personnel gap small: developers who wrote code are closely involved in deploying it and watching its behavior in production.</li>
<li>Make the tools gap small: keep development and production as similar as possible.</li>
</ul>
<p>Summarizing the above into a table:</p>
<table>
<thead>
<tr>
<th></th>
<th>Traditional app</th>
<th>Twelve-factor app</th>
</tr>
</thead>
<tbody><tr>
<td>Time between deploys</td>
<td>Weeks</td>
<td>Hours</td>
</tr>
<tr>
<td>Code authors vs code deployers</td>
<td>Different people</td>
<td>Same people</td>
</tr>
<tr>
<td>Dev vs production environments</td>
<td>Divergent</td>
<td>As similar as possible</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
</tbody></table>
<p>Backing services, such as the app’s database, queueing system, or cache, is one area where dev/prod parity is important. Many languages offer libraries which simplify access to the backing service, including adapters to different types of services. Some examples are in the table below.</p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Language</th>
<th>Library</th>
<th>Adapters</th>
</tr>
</thead>
<tbody><tr>
<td>Database</td>
<td>Ruby/Rails</td>
<td>ActiveRecord</td>
<td>MySQL, PostgreSQL, SQLite</td>
</tr>
<tr>
<td>Queue</td>
<td>Python/Django</td>
<td>Celery</td>
<td>RabbitMQ, Beanstalkd, Redis</td>
</tr>
<tr>
<td>Cache</td>
<td>Ruby/Rails</td>
<td>ActiveSupport::Cache</td>
<td>Memory, filesystem, Memcached</td>
</tr>
</tbody></table>
<p>Developers sometimes find great appeal in using a lightweight backing service in their local environments, while a more serious and robust backing service will be used in production. For example, using SQLite locally and PostgreSQL in production; or local process memory for caching in development and Memcached in production.</p>
<p>The twelve-factor developer resists the urge to use different backing services between development and production, even when adapters theoretically abstract away any differences in backing services. Differences between backing services mean that tiny incompatibilities crop up, causing code that worked and passed tests in development or staging to fail in production. These types of errors create friction that disincentivizes continuous deployment. The cost of this friction and the subsequent dampening of continuous deployment is extremely high when considered in aggregate over the lifetime of an application.</p>
<p>Lightweight local services are less compelling than they once were. Modern backing services such as Memcached, PostgreSQL, and RabbitMQ are not difficult to install and run thanks to modern packaging systems, such as Homebrew and apt-get. Alternatively, declarative provisioning tools such as Chef and Puppet combined with light-weight virtual environments such as Docker and Vagrant allow developers to run local environments which closely approximate production environments. The cost of installing and using these systems is low compared to the benefit of dev/prod parity and continuous deployment.</p>
<p>Adapters to different backing services are still useful, because they make porting to new backing services relatively painless. But all deploys of the app (developer environments, staging, production) should be using the same type and version of each of the backing services.</p>
<blockquote>
<p>中文</p>
</blockquote>
<h3 id="X-开发环境与线上环境等价"><a href="#X-开发环境与线上环境等价" class="headerlink" title="X. 开发环境与线上环境等价"></a>X. 开发环境与线上环境等价</h3><blockquote>
<p>尽可能的保持开发，预发布，线上环境相同</p>
</blockquote>
<p>从以往经验来看，开发环境（即开发人员的本地 部署）和线上环境（外部用户访问的真实部署）之间存在着很多差异。这些差异表现在以下三个方面：</p>
<ul>
<li>时间差异： 开发人员正在编写的代码可能需要几天，几周，甚至几个月才会上线。</li>
<li>人员差异： 开发人员编写代码，运维人员部署代码。</li>
<li>工具差异： 开发人员或许使用 Nginx，SQLite，OS X，而线上环境使用 Apache，MySQL 以及 Linux。</li>
</ul>
<p>12-Factor 应用想要做到 持续部署 就必须缩小本地与线上差异。 再回头看上面所描述的三个差异:</p>
<ul>
<li>缩小时间差异：开发人员可以几小时，甚至几分钟就部署代码。</li>
<li>缩小人员差异：开发人员不只要编写代码，更应该密切参与部署过程以及代码在线上的表现。</li>
<li>缩小工具差异：尽量保证开发环境以及线上环境的一致性。</li>
</ul>
<p>将上述总结变为一个表格如下：</p>
<table>
<thead>
<tr>
<th></th>
<th>传统应用</th>
<th>12-Factor 应用</th>
</tr>
</thead>
<tbody><tr>
<td>每次部署间隔</td>
<td>数周</td>
<td>几小时</td>
</tr>
<tr>
<td>开发人员 vs 运维人员</td>
<td>不同的人</td>
<td>相同的人</td>
</tr>
<tr>
<td>开发环境 vs 线上环境</td>
<td>不同</td>
<td>尽量接近</td>
</tr>
</tbody></table>
<p>后端服务 是保持开发与线上等价的重要部分，例如数据库，队列系统，以及缓存。许多语言都提供了简化获取后端服务的类库，例如不同类型服务的 适配器 。下列表格提供了一些例子。</p>
<table>
<thead>
<tr>
<th>类型</th>
<th>语言</th>
<th>类库</th>
<th>适配器</th>
</tr>
</thead>
<tbody><tr>
<td>数据库</td>
<td>Ruby/Rails</td>
<td>ActiveRecord</td>
<td>MySQL, PostgreSQL, SQLite</td>
</tr>
<tr>
<td>队列</td>
<td>Python/Django</td>
<td>Celery</td>
<td>RabbitMQ, Beanstalkd, Redis</td>
</tr>
<tr>
<td>缓存</td>
<td>Ruby/Rails</td>
<td>ActiveSupport::Cache</td>
<td>Memory, filesystem, Memcached</td>
</tr>
</tbody></table>
<p>开发人员有时会觉得在本地环境中使用轻量的后端服务具有很强的吸引力，而那些更重量级的健壮的后端服务应该使用在生产环境。例如，本地使用 SQLite 线上使用 PostgreSQL；又如本地缓存在进程内存中而线上存入 Memcached。</p>
<p>12-Factor 应用的开发人员应该反对在不同环境间使用不同的后端服务 ，即使适配器已经可以几乎消除使用上的差异。这是因为，不同的后端服务意味着会突然出现的不兼容，从而导致测试、预发布都正常的代码在线上出现问题。这些错误会给持续部署带来阻力。从应用程序的生命周期来看，消除这种阻力需要花费很大的代价。</p>
<p>与此同时，轻量的本地服务也不像以前那样引人注目。借助于Homebrew，apt-get等现代的打包系统，诸如Memcached、PostgreSQL、RabbitMQ 等后端服务的安装与运行也并不复杂。此外，使用类似 Chef 和 Puppet 的声明式配置工具，结合像 Vagrant 这样轻量的虚拟环境就可以使得开发人员的本地环境与线上环境无限接近。与同步环境和持续部署所带来的益处相比，安装这些系统显然是值得的。</p>
<p>不同后端服务的适配器仍然是有用的，因为它们可以使移植后端服务变得简单。但应用的所有部署，这其中包括开发、预发布以及线上环境，都应该使用同一个后端服务的相同版本。</p>
]]></content>
      <tags>
        <tag>The Twelve-Factor App</tag>
      </tags>
  </entry>
  <entry>
    <title>The Twelve-Factor App--XI.Logs</title>
    <url>/2022/06/24/uncatalog/cl4s5aedu000hyor72kq5660y/</url>
    <content><![CDATA[<hr>
<span id="more"></span>
<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>如今，软件通常会作为一种服务来交付，它们被称为网络应用程序，或软件即服务（SaaS）。12-Factor 为构建如下的 SaaS 应用提供了方法论：</p>
<ul>
<li>使用标准化流程自动配置，从而使新的开发者花费最少的学习成本加入这个项目。</li>
<li>和操作系统之间尽可能的划清界限，在各个系统中提供最大的可移植性。</li>
<li>适合部署在现代的云计算平台，从而在服务器和系统管理方面节省资源。</li>
<li>将开发环境和生产环境的差异降至最低，并使用持续交付实施敏捷开发。</li>
<li>可以在工具、架构和开发流程不发生明显变化的前提下实现扩展。<br>这套理论适用于任意语言和后端服务（数据库、消息队列、缓存等）开发的应用程序。</li>
</ul>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>这套方法论由Heroku的联合创始人Adam Wiggins发掘，应用到了数以百计的应用程序的开发和部署，并通过 Heroku 平台间接见证了数十万应用程序的开发，运作以及扩展的过程。</p>
<p><code>The Twelve-Factor App</code>系列文章，综合了Hero库关于 SaaS 应用几乎所有的经验和智慧，是开发此类应用的理想实践标准，并特别关注于应用程序如何保持良性成长，开发者之间如何进行有效的代码协作，以及如何 避免软件污染 。</p>
<blockquote>
<p>英文原文</p>
</blockquote>
<h3 id="XI-Logs"><a href="#XI-Logs" class="headerlink" title="XI. Logs"></a>XI. Logs</h3><blockquote>
<p>Treat logs as event streams</p>
</blockquote>
<p>Logs provide visibility into the behavior of a running app. In server-based environments they are commonly written to a file on disk (a “logfile”); but this is only an output format.</p>
<p>Logs are the stream of aggregated, time-ordered events collected from the output streams of all running processes and backing services. Logs in their raw form are typically a text format with one event per line (though backtraces from exceptions may span multiple lines). Logs have no fixed beginning or end, but flow continuously as long as the app is operating.</p>
<p>A twelve-factor app never concerns itself with routing or storage of its output stream. It should not attempt to write to or manage logfiles. Instead, each running process writes its event stream, unbuffered, to stdout. During local development, the developer will view this stream in the foreground of their terminal to observe the app’s behavior.</p>
<p>In staging or production deploys, each process’ stream will be captured by the execution environment, collated together with all other streams from the app, and routed to one or more final destinations for viewing and long-term archival. These archival destinations are not visible to or configurable by the app, and instead are completely managed by the execution environment. Open-source log routers (such as Logplex and Fluentd) are available for this purpose.</p>
<p>The event stream for an app can be routed to a file, or watched via realtime tail in a terminal. Most significantly, the stream can be sent to a log indexing and analysis system such as Splunk, or a general-purpose data warehousing system such as Hadoop/Hive. These systems allow for great power and flexibility for introspecting an app’s behavior over time, including:</p>
<ul>
<li>Finding specific events in the past.</li>
<li>Large-scale graphing of trends (such as requests per minute).</li>
<li>Active alerting according to user-defined heuristics (such as an alert when the quantity of errors per minute exceeds a certain threshold).</li>
</ul>
<blockquote>
<p>中文</p>
</blockquote>
<h3 id="XI-日志"><a href="#XI-日志" class="headerlink" title="XI. 日志"></a>XI. 日志</h3><blockquote>
<p>把日志当作事件流</p>
</blockquote>
<p>日志 使得应用程序运行的动作变得透明。在基于服务器的环境中，日志通常被写在硬盘的一个文件里，但这只是一种输出格式。</p>
<p>日志应该是 事件流 的汇总，将所有运行中进程和后端服务的输出流按照时间顺序收集起来。尽管在回溯问题时可能需要看很多行，日志最原始的格式确实是一个事件一行。日志没有确定开始和结束，但随着应用在运行会持续的增加。</p>
<p>12-factor应用本身从不考虑存储自己的输出流。 不应该试图去写或者管理日志文件。相反，每一个运行的进程都会直接的标准输出（stdout）事件流。开发环境中，开发人员可以通过这些数据流，实时在终端看到应用的活动。</p>
<p>在预发布或线上部署中，每个进程的输出流由运行环境截获，并将其他输出流整理在一起，然后一并发送给一个或多个最终的处理程序，用于查看或是长期存档。这些存档路径对于应用来说不可见也不可配置，而是完全交给程序的运行环境管理。类似 Logplex 和 Fluentd 的开源工具可以达到这个目的。</p>
<p>这些事件流可以输出至文件，或者在终端实时观察。最重要的，输出流可以发送到 Splunk 这样的日志索引及分析系统，或 Hadoop/Hive 这样的通用数据存储系统。这些系统为查看应用的历史活动提供了强大而灵活的功能，包括：</p>
<ul>
<li>找出过去一段时间特殊的事件。</li>
<li>图形化一个大规模的趋势，比如每分钟的请求量。</li>
<li>根据用户定义的条件实时触发警报，比如每分钟的报错超过某个警戒线。</li>
</ul>
]]></content>
      <tags>
        <tag>The Twelve-Factor App</tag>
      </tags>
  </entry>
  <entry>
    <title>The Twelve-Factor App--XII.Admin_processes</title>
    <url>/2022/06/24/uncatalog/cl4s5aedw000jyor73nwic37r/</url>
    <content><![CDATA[<hr>
<span id="more"></span>
<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>如今，软件通常会作为一种服务来交付，它们被称为网络应用程序，或软件即服务（SaaS）。12-Factor 为构建如下的 SaaS 应用提供了方法论：</p>
<ul>
<li>使用标准化流程自动配置，从而使新的开发者花费最少的学习成本加入这个项目。</li>
<li>和操作系统之间尽可能的划清界限，在各个系统中提供最大的可移植性。</li>
<li>适合部署在现代的云计算平台，从而在服务器和系统管理方面节省资源。</li>
<li>将开发环境和生产环境的差异降至最低，并使用持续交付实施敏捷开发。</li>
<li>可以在工具、架构和开发流程不发生明显变化的前提下实现扩展。<br>这套理论适用于任意语言和后端服务（数据库、消息队列、缓存等）开发的应用程序。</li>
</ul>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>这套方法论由Heroku的联合创始人Adam Wiggins发掘，应用到了数以百计的应用程序的开发和部署，并通过 Heroku 平台间接见证了数十万应用程序的开发，运作以及扩展的过程。</p>
<p><code>The Twelve-Factor App</code>系列文章，综合了Hero库关于 SaaS 应用几乎所有的经验和智慧，是开发此类应用的理想实践标准，并特别关注于应用程序如何保持良性成长，开发者之间如何进行有效的代码协作，以及如何 避免软件污染 。</p>
<blockquote>
<p>英文原文</p>
</blockquote>
<h3 id="XII-Admin-processes"><a href="#XII-Admin-processes" class="headerlink" title="XII. Admin processes"></a>XII. Admin processes</h3><blockquote>
<p>Run admin/management tasks as one-off processes</p>
</blockquote>
<p>The process formation is the array of processes that are used to do the app’s regular business (such as handling web requests) as it runs. Separately, developers will often wish to do one-off administrative or maintenance tasks for the app, such as:</p>
<ul>
<li>Running database migrations (e.g. manage.py migrate in Django, rake db:migrate in Rails).</li>
<li>Running a console (also known as a REPL shell) to run arbitrary code or inspect the app’s models against the live database. Most languages provide a REPL by running the interpreter without any arguments (e.g. python or perl) or in some cases have a separate command (e.g. irb for Ruby, rails console for Rails).</li>
<li>Running one-time scripts committed into the app’s repo (e.g. php scripts/fix_bad_records.php).</li>
</ul>
<p>One-off admin processes should be run in an identical environment as the regular long-running processes of the app. They run against a release, using the same codebase and config as any process run against that release. Admin code must ship with application code to avoid synchronization issues.</p>
<p>The same dependency isolation techniques should be used on all process types. For example, if the Ruby web process uses the command bundle exec thin start, then a database migration should use bundle exec rake db:migrate. Likewise, a Python program using Virtualenv should use the vendored bin/python for running both the Tornado webserver and any manage.py admin processes.</p>
<p>Twelve-factor strongly favors languages which provide a REPL shell out of the box, and which make it easy to run one-off scripts. In a local deploy, developers invoke one-off admin processes by a direct shell command inside the app’s checkout directory. In a production deploy, developers can use ssh or other remote command execution mechanism provided by that deploy’s execution environment to run such a process.</p>
<blockquote>
<p>中文</p>
</blockquote>
<h3 id="XII-管理进程"><a href="#XII-管理进程" class="headerlink" title="XII. 管理进程"></a>XII. 管理进程</h3><blockquote>
<p>后台管理任务当作一次性进程运行</p>
</blockquote>
<p>进程构成（process formation）是指用来处理应用的常规业务（比如处理 web 请求）的一组进程。与此不同，开发人员经常希望执行一些管理或维护应用的一次性任务，例如：</p>
<ul>
<li>运行数据移植（Django 中的 manage.py migrate, Rails 中的 rake db:migrate）。</li>
<li>运行一个控制台（也被称为 REPL shell），来执行一些代码或是针对线上数据库做一些检查。大多数语言都通过解释器提供了一个 REPL 工具（python 或 perl） ，或是其他命令（Ruby 使用 irb, Rails 使用 rails console）。</li>
<li>运行一些提交到代码仓库的一次性脚本。</li>
</ul>
<p>一次性管理进程应该和正常的 常驻进程 使用同样的环境。这些管理进程和任何其他的进程一样使用相同的 代码 和 配置 ，基于某个 发布版本 运行。后台管理代码应该随其他应用程序代码一起发布，从而避免同步问题。</p>
<p>所有进程类型应该使用同样的 依赖隔离 技术。例如，如果Ruby的web进程使用了命令 bundle exec thin start ，那么数据库移植应使用 bundle exec rake db:migrate 。同样的，如果一个 Python 程序使用了 Virtualenv，则需要在运行 Tornado Web 服务器和任何 manage.py 管理进程时引入 bin/python 。</p>
<p>12-factor 尤其青睐那些提供了 REPL shell 的语言，因为那会让运行一次性脚本变得简单。在本地部署中，开发人员直接在命令行使用 shell 命令调用一次性管理进程。在线上部署中，开发人员依旧可以使用ssh或是运行环境提供的其他机制来运行这样的进程。</p>
]]></content>
      <tags>
        <tag>The Twelve-Factor App</tag>
      </tags>
  </entry>
  <entry>
    <title>Go编程模式之--函数式选项模式</title>
    <url>/2022/07/01/uncatalog/cl53og7mv0000xwr74g9n8mtt/</url>
    <content><![CDATA[<hr>
<span id="more"></span>
<p>Go编程模式之–函数式选项模式</p>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>在阅读grpc和gorm源码的时候，发现了一个比较有意思的设计：</p>
<blockquote>
<p>grpc: ServerOption</p>
</blockquote>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// A ServerOption sets options such as credentials, codec and keepalive parameters, etc.</span></span><br><span class="line"><span class="keyword">type</span> ServerOption <span class="keyword">interface</span> &#123;</span><br><span class="line">apply(*serverOptions)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// NewServer creates a gRPC server which has no service registered and has not</span></span><br><span class="line"><span class="comment">// started to accept requests yet.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">NewServer</span><span class="params">(opt ...ServerOption)</span> *<span class="title">Server</span></span> &#123;</span><br><span class="line">	opts := defaultServerOptions</span><br><span class="line">	<span class="keyword">for</span> _, o := <span class="keyword">range</span> opt &#123;</span><br><span class="line">		o.apply(&amp;opts)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 省略 ...</span></span><br><span class="line">	s := &amp;Server&#123;&#125;</span><br><span class="line">	<span class="keyword">return</span> s</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<blockquote>
<p>gorm: Option</p>
</blockquote>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Option gorm option interface</span></span><br><span class="line"><span class="keyword">type</span> Option <span class="keyword">interface</span> &#123;</span><br><span class="line">Apply(*Config) error</span><br><span class="line">AfterInitialize(*DB) error</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Open initialize db session based on dialector</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Open</span><span class="params">(dialector Dialector, opts ...Option)</span> <span class="params">(db *DB, err error)</span></span> &#123;</span><br><span class="line">        config := &amp;Config&#123;&#125;</span><br><span class="line">        <span class="comment">// 省略...</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> _, opt := <span class="keyword">range</span> opts &#123;</span><br><span class="line">        <span class="keyword">if</span> opt != <span class="literal">nil</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> applyErr := opt.Apply(config); applyErr != <span class="literal">nil</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">nil</span>, applyErr</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 省略...</span></span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<p>设计上的共同点还是很明显的，接下来将从实践出发，剖析一下这种设计的精妙之处。</p>
<h2 id="函数式选项模式"><a href="#函数式选项模式" class="headerlink" title="函数式选项模式"></a>函数式选项模式</h2><p>Go 语言没有构造函数，一般通过定义 New 函数来充当构造函数。然而，如果结构有较多字段，要初始化这些字段，有很多种方式，但有一种方式认为是最好的，这就是函数式选项模式（Functional Options Pattern）。</p>
<p>函数式选项模式是一种在 Go 中构造结构体的模式，它通过设计一组非常有表现力和灵活的 API 来帮助配置和初始化结构体。</p>
<p>在 Uber 的 Go 语言规范中提到了该模式：</p>
<blockquote>
<p>Functional options 是一种模式，在该模式中，你可以声明一个不透明的 Option 类型，该类型在某些内部结构中记录信息。你接受这些可变数量的选项，并根据内部结构上的选项记录的完整信息进行操作。将此模式用于构造函数和其他公共 API 中的可选参数，你预计这些参数需要扩展，尤其是在这些函数上已经有三个或更多参数的情况下。</p>
</blockquote>
<h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h3><p>为了更好的理解该模式，我们通过一个例子来讲解。</p>
<p>定义一个 Server 结构体：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Server <span class="keyword">struct</span>&#123;</span><br><span class="line">  host <span class="keyword">string</span></span><br><span class="line">  port <span class="keyword">int</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">New</span><span class="params">(host <span class="keyword">string</span>, port <span class="keyword">int</span>)</span> *<span class="title">Server</span></span> &#123;</span><br><span class="line">  <span class="keyword">return</span> &amp;Server&#123;host, port&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s *Server)</span> <span class="title">Start</span><span class="params">()</span> <span class="title">error</span></span> &#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<p>如何使用呢？</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">  <span class="string">&quot;log&quot;</span></span><br><span class="line">  <span class="string">&quot;server&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">  svr := New(<span class="string">&quot;localhost&quot;</span>, <span class="number">1234</span>)</span><br><span class="line">  <span class="keyword">if</span> err := svr.Start(); err != <span class="literal">nil</span> &#123;</span><br><span class="line">    log.Fatal(err)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<p>但如果要扩展 Server 的配置选项，如何做？通常有三种做法：</p>
<ul>
<li>为每个不同的配置选项声明一个新的构造函数</li>
<li>定义一个新的 Config 结构体来保存配置信息</li>
<li>使用 Functional Option Pattern</li>
</ul>
<h4 id="做法-1：为每个不同的配置选项声明一个新的构造函数"><a href="#做法-1：为每个不同的配置选项声明一个新的构造函数" class="headerlink" title="做法 1：为每个不同的配置选项声明一个新的构造函数"></a>做法 1：为每个不同的配置选项声明一个新的构造函数</h4><p>这种做法是为不同选项定义专有的构造函数。假如上面的 Server 增加了两个字段：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> Server <span class="keyword">struct</span>&#123;</span><br><span class="line">  host <span class="keyword">string</span></span><br><span class="line">  port <span class="keyword">int</span></span><br><span class="line">  timeout time.Duration</span><br><span class="line">  maxConn <span class="keyword">int</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<p>一般来说，host 和 port 是必须的字段，而 timeout 和 maxConn 是可选的，所以，可以保留原来的构造函数，而这两个字段给默认值：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">New</span><span class="params">(host <span class="keyword">string</span>, port <span class="keyword">int</span>)</span> *<span class="title">Server</span></span> &#123;</span><br><span class="line">  <span class="keyword">return</span> &amp;Server&#123;host, port, time.Minute, <span class="number">100</span>&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<p>然后针对 timeout 和 maxConn 额外提供两个构造函数：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">NewWithTimeout</span><span class="params">(host <span class="keyword">string</span>, port <span class="keyword">int</span>, timeout time.Duration)</span> *<span class="title">Server</span></span> &#123;</span><br><span class="line">  <span class="keyword">return</span> &amp;Server&#123;host, port, timeout&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">NewWithTimeoutAndMaxConn</span><span class="params">(host <span class="keyword">string</span>, port <span class="keyword">int</span>, timeout time.Duration, maxConn <span class="keyword">int</span>)</span> *<span class="title">Server</span></span> &#123;</span><br><span class="line">  <span class="keyword">return</span> &amp;Server&#123;host, port, timeout, maxConn&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<p>这种方式配置较少且不太会变化的情况，否则每次你需要为新配置创建新的构造函数。在 Go 语言标准库中，有这种方式的应用。比如 net 包中的 Dial 和 DialTimeout：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Dial</span><span class="params">(network, address <span class="keyword">string</span>)</span> <span class="params">(Conn, error)</span></span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">DialTimeout</span><span class="params">(network, address <span class="keyword">string</span>, timeout time.Duration)</span> <span class="params">(Conn, error)</span></span></span><br></pre></td></tr></table></figure></div>
<h4 id="做法-2：使用专门的配置结构体"><a href="#做法-2：使用专门的配置结构体" class="headerlink" title="做法 2：使用专门的配置结构体"></a>做法 2：使用专门的配置结构体</h4><p>这种方式也是很常见的，特别是当配置选项很多时。通常可以创建一个 Config 结构体，其中包含 Server 的所有配置选项。这种做法，即使将来增加更多配置选项，也可以轻松的完成扩展，不会破坏 Server 的 API。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> Server <span class="keyword">struct</span>&#123;</span><br><span class="line">  cfg Config</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Config <span class="keyword">struct</span> &#123;</span><br><span class="line">  Host <span class="keyword">string</span></span><br><span class="line">  Port <span class="keyword">int</span></span><br><span class="line">  Timeout time.Duration</span><br><span class="line">  MaxConn <span class="keyword">int</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">New</span><span class="params">(cfg Config)</span> *<span class="title">Server</span></span> &#123;</span><br><span class="line">  <span class="keyword">return</span> &amp;Server&#123;cfg&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<p>在使用时，需要先构造 Config 实例，对这个实例，又回到了前面 Server 的问题上，因为增加或删除选项，需要对 Config 有较大的修改。如果将 Config 中的字段改为私有，可能需要定义 Config 的构造函数。</p>
<h4 id="做法-3：使用-Functional-Option-Pattern"><a href="#做法-3：使用-Functional-Option-Pattern" class="headerlink" title="做法 3：使用 Functional Option Pattern"></a>做法 3：使用 Functional Option Pattern</h4><p>一个更好的解决方案是使用 Functional Option Pattern。</p>
<p>在这个模式中，我们定义一个 Option 函数类型：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> Option <span class="function"><span class="keyword">func</span><span class="params">(*Server)</span></span></span><br></pre></td></tr></table></figure></div>
<p>Option 类型是一个函数类型，它接收一个参数：*Server。然后，Server 的构造函数接收一个 Option 类型的不定参数：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">New</span><span class="params">(options ...Option)</span> *<span class="title">Server</span></span> &#123;</span><br><span class="line">  svr := &amp;Server&#123;&#125;</span><br><span class="line">  <span class="keyword">for</span> _, f := <span class="keyword">range</span> options &#123;</span><br><span class="line">    f(svr)</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> svr</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<p>那选项如何起作用？需要定义一系列相关返回 Option 的函数：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">WithHost</span><span class="params">(host <span class="keyword">string</span>)</span> <span class="title">Option</span></span> &#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="function"><span class="keyword">func</span><span class="params">(s *Server)</span></span> &#123;</span><br><span class="line">    s.host = host</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">WithPort</span><span class="params">(port <span class="keyword">int</span>)</span> <span class="title">Option</span></span> &#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="function"><span class="keyword">func</span><span class="params">(s *Server)</span></span> &#123;</span><br><span class="line">    s.port = port</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">WithTimeout</span><span class="params">(timeout time.Duration)</span> <span class="title">Option</span></span> &#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="function"><span class="keyword">func</span><span class="params">(s *Server)</span></span> &#123;</span><br><span class="line">    s.timeout = timeout</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">WithMaxConn</span><span class="params">(maxConn <span class="keyword">int</span>)</span> <span class="title">Option</span></span> &#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="function"><span class="keyword">func</span><span class="params">(s *Server)</span></span> &#123;</span><br><span class="line">    s.maxConn = maxConn</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<p>针对这种模式，客户端类似这么使用：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">  <span class="string">&quot;log&quot;</span></span><br><span class="line">  </span><br><span class="line">  <span class="string">&quot;server&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">  svr := New(</span><br><span class="line">    WithHost(<span class="string">&quot;localhost&quot;</span>),</span><br><span class="line">    WithPort(<span class="number">8080</span>),</span><br><span class="line">    WithTimeout(time.Minute),</span><br><span class="line">    WithMaxConn(<span class="number">120</span>),</span><br><span class="line">  )</span><br><span class="line">  <span class="keyword">if</span> err := svr.Start(); err != <span class="literal">nil</span> &#123;</span><br><span class="line">    log.Fatal(err)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<p>将来增加选项，只需要增加对应的 WithXXX 函数即可。</p>
<p>这种模式，在第三方库中使用挺多，比如 github.com/gocolly/colly：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> Collector &#123;</span><br><span class="line">  <span class="comment">// 省略...</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">NewCollector</span><span class="params">(options ...CollectorOption)</span> *<span class="title">Collector</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 定义了一系列 CollectorOpiton</span></span><br><span class="line"><span class="keyword">type</span> CollectorOption&#123;</span><br><span class="line">  <span class="comment">// 省略...</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">AllowURLRevisit</span><span class="params">()</span> <span class="title">CollectorOption</span></span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">AllowedDomains</span><span class="params">(domains ...<span class="keyword">string</span>)</span> <span class="title">CollectorOption</span></span></span><br><span class="line">...</span><br></pre></td></tr></table></figure></div>
<p>不过 Uber 的 Go 语言编程规范中提到该模式时，建议定义一个 Option 接口，而不是 Option 函数类型。该 Option 接口有一个未导出的方法，然后通过一个未导出的 options 结构来记录各选项。</p>
<p>Uber 的这个例子能看懂吗？</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> options <span class="keyword">struct</span> &#123;</span><br><span class="line">  cache  <span class="keyword">bool</span></span><br><span class="line">  logger *zap.Logger</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Option <span class="keyword">interface</span> &#123;</span><br><span class="line">  apply(*options)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> cacheOption <span class="keyword">bool</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c cacheOption)</span> <span class="title">apply</span><span class="params">(opts *options)</span></span> &#123;</span><br><span class="line">  opts.cache = <span class="keyword">bool</span>(c)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">WithCache</span><span class="params">(c <span class="keyword">bool</span>)</span> <span class="title">Option</span></span> &#123;</span><br><span class="line">  <span class="keyword">return</span> cacheOption(c)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> loggerOption <span class="keyword">struct</span> &#123;</span><br><span class="line">  Log *zap.Logger</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(l loggerOption)</span> <span class="title">apply</span><span class="params">(opts *options)</span></span> &#123;</span><br><span class="line">  opts.logger = l.Log</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">WithLogger</span><span class="params">(log *zap.Logger)</span> <span class="title">Option</span></span> &#123;</span><br><span class="line">  <span class="keyword">return</span> loggerOption&#123;Log: log&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Open creates a connection.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Open</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">  addr <span class="keyword">string</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">  opts ...Option,</span></span></span><br><span class="line"><span class="function"><span class="params">)</span> <span class="params">(*Connection, error)</span></span> &#123;</span><br><span class="line">  options := options&#123;</span><br><span class="line">    cache:  defaultCache,</span><br><span class="line">    logger: zap.NewNop(),</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> _, o := <span class="keyword">range</span> opts &#123;</span><br><span class="line">    o.apply(&amp;options)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<h2 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h2><p>在实际项目中，当你要处理的选项比较多，或者处理不同来源的选项（来自文件、来自环境变量等）时，可以考虑试试函数式选项模式。</p>
<p>注意，在实际工作中，我们不应该教条的应用上面的模式，就像 Uber 中的例子，Open 函数并非只接受一个 Option 不定参数，因为 addr 参数是必须的。因此，函数式选项模式更多应该应用在那些配置较多，且有可选参数的情况。</p>
]]></content>
      <tags>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title>架构设计那些事儿--缓存那些事儿(一)，缓存的前世今生</title>
    <url>/2022/07/04/uncatalog/cl56he3gx000050r72rv69xlr/</url>
    <content><![CDATA[<hr>
<span id="more"></span>
<blockquote>
<p>目前各种类型的缓存都活跃在成千上万的应用服务中，还没有一种缓存方案可以解决一切的业务场景或数据类型，我们需要根据自身的特殊场景和背景，选择最适合的缓存方案。缓存的使用是程序员、架构师的必备技能，好的程序员能根据数据类型、业务场景来准确判断使用何种类型的缓存，如何使用这种缓存，以最小的成本最快的效率达到最优的目的。 </p>
</blockquote>
<p>《架构设计那些事儿–缓存那些事儿》系列共分六章：</p>
<ul>
<li><a href="https://bugkillerpro.github.io/2022/07/04/uncatalog/cl56he3gx000050r72rv69xlr/">架构设计那些事儿–缓存那些事儿(一)，缓存的前世今生</a></li>
<li><a href="https://bugkillerpro.github.io/2022/07/04/uncatalog/cl58235qb0001ikr7dxwr0zu2/">架构设计那些事儿–缓存那些事儿(二)，缓存设计模式</a></li>
<li><a href="https://bugkillerpro.github.io/2022/07/04/uncatalog/cl58235q80000ikr72lnvg3qt/">架构设计那些事儿–缓存那些事儿(三)，缓存性能和一致性的最佳实践</a></li>
<li><a href="https://bugkillerpro.github.io/2022/07/12/uncatalog/cl5hl5x3l00000wr734tl8oua/">架构设计那些事儿–缓存那些事儿(四)，缓存穿透、 缓存雪崩 和 缓存击穿</a></li>
<li><a href="https://bugkillerpro.github.io/2022/07/12/uncatalog/cl5hm81oo00000wr786z6dmjl/">架构设计那些事儿–缓存那些事儿(五)，布隆过滤器详解</a></li>
<li><a href>架构设计那些事儿–缓存那些事儿(六)，redis</a></li>
</ul>
<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>一般而言，现在互联网应用（网站或App）的整体流程，可以概括如图1所示，用户请求从界面（浏览器或App界面）到网络转发、应用服务再到存储（数据库或文件系统），然后返回到界面呈现内容。随着互联网的普及，内容信息越来越复杂，用户数和访问量越来越大，我们的应用需要支撑更多的并发量，同时我们的应用服务器和数据库服务器所做的计算也越来越多。但是往往我们的应用服务器资源是有限的，且技术变革是缓慢的，数据库每秒能接受的请求次数也是有限的（或者文件的读写也是有限的），如何能够有效利用有限的资源来提供尽可能大的吞吐量？一个有效的办法就是引入缓存，打破标准流程，每个环节中请求可以从缓存中直接获取目标数据并返回，从而减少计算量，有效提升响应速度，让有限的资源服务更多的用户。如图1所示，缓存的使用可以出现在1～4的各个环节中，每个环节的缓存方案与使用各有特点。<br>如下图所示，缓存的使用可以出现在1～4的各个环节中，每个环节的缓存方案与使用各有特点。<br><img src="/2022/07/04/uncatalog/cl56he3gx000050r72rv69xlr/v2-9838f98ea50f9f143b2d56eed6dac717_b.png" alt="ima"></p>
<h2 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a>缓存</h2><h3 id="1-缓存特征"><a href="#1-缓存特征" class="headerlink" title="1.缓存特征"></a>1.缓存特征</h3><p>缓存也是一个数据模型对象，那么必然有它的一些特征：</p>
<h4 id="1-1-命中率"><a href="#1-1-命中率" class="headerlink" title="1.1 命中率"></a>1.1 命中率</h4><p>命中率=返回正确结果数/请求缓存次数，命中率问题是缓存中的一个非常重要的问题，它是衡量缓存有效性的重要指标。命中率越高，表明缓存的使用率越高。</p>
<h4 id="1-2-最大元素（或最大空间）"><a href="#1-2-最大元素（或最大空间）" class="headerlink" title="1.2 最大元素（或最大空间）"></a>1.2 最大元素（或最大空间）</h4><p>缓存中可以存放的最大元素的数量，一旦缓存中元素数量超过这个值（或者缓存数据所占空间超过其最大支持空间），那么将会触发缓存启动清空策略根据不同的场景合理的设置最大元素值往往可以一定程度上提高缓存的命中率，从而更有效的时候缓存。</p>
<h4 id="1-3-清空策略"><a href="#1-3-清空策略" class="headerlink" title="1.3 清空策略"></a>1.3 清空策略</h4><p>如上描述，缓存的存储空间有限制，当缓存空间被用满时，如何保证在稳定服务的同时有效提升命中率？这就由缓存清空策略来处理，设计适合自身数据特征的清空策略能有效提升命中率。常见的一般策略有：</p>
<ul>
<li>FIFO(first in first out) 先进先出策略，最先进入缓存的数据在缓存空间不够的情况下（超出最大元素限制）会被优先被清除掉，以腾出新的空间接受新的数据。策略算法主要比较缓存元素的创建时间。在数据实效性要求场景下可选择该类策略，优先保障最新数据可用。 </li>
<li>LFU(less frequently used)最少使用策略，无论是否过期，根据元素的被使用次数判断，清除使用次数较少的元素释放空间。策略算法主要比较元素的hitCount（命中次数）。在保证高频数据有效性场景下，可选择这类策略。</li>
<li>LRU(least recently used)最近最少使用策略，无论是否过期，根据元素最后一次被使用的时间戳，清除最远使用时间戳的元素释放空间。策略算法主要比较元素最近一次被get使用时间。在热点数据场景下较适用，优先保证热点数据的有效性。</li>
</ul>
<p>除此之外，还有一些简单策略比如：</p>
<ul>
<li>根据过期时间判断，清理过期时间最长的元素；</li>
<li>根据过期时间判断，清理最近要过期的元素；</li>
<li>随机清理；</li>
<li>根据关键字（或元素内容）长短清理等。</li>
</ul>
<h4 id="1-4-缓存介质"><a href="#1-4-缓存介质" class="headerlink" title="1.4 缓存介质"></a>1.4 缓存介质</h4><p>虽然从硬件介质上来看，无非就是内存和硬盘两种，但从技术上，可以分成内存、硬盘文件、数据库。</p>
<ul>
<li>内存：将缓存存储于内存中是最快的选择，无需额外的I/O开销，但是内存的缺点是没有持久化落地物理磁盘，一旦应用异常break down而重新启动，数据很难或者无法复原。</li>
<li>硬盘：一般来说，很多缓存框架会结合使用内存和硬盘，在内存分配空间满了或是在异常的情况下，可以被动或主动的将内存空间数据持久化到硬盘中，达到释放空间或备份数据的目的。</li>
<li>数据库：前面有提到，增加缓存的策略的目的之一就是为了减少数据库的I/O压力。现在使用数据库做缓存介质是不是又回到了老问题上了？其实，数据库也有很多种类型，像那些不支持SQL，只是简单的key-value存储结构的特殊数据库（如BerkeleyDB和Redis），响应速度和吞吐量都远远高于我们常用的关系型数据库等。</li>
</ul>
<h4 id="1-5-缓存分类和应用场景"><a href="#1-5-缓存分类和应用场景" class="headerlink" title="1.5 缓存分类和应用场景"></a>1.5 缓存分类和应用场景</h4><p>缓存有各类特征，而且有不同介质的区别，那么实际工程中我们怎么去对缓存分类呢？在目前的应用服务框架中，比较常见的，时根据缓存与应用的耦合度，分为local cache（本地缓存）和remote cache（分布式缓存）：</p>
<ul>
<li>本地缓存：指的是在应用中的缓存组件，其最大的优点是应用和cache是在同一个进程内部，请求缓存非常快速，没有过多的网络开销等，在单应用不需要集群支持或者集群情况下各节点无需互相通知的场景下使用本地缓存较合适；同时，它的缺点也是应为缓存跟应用程序耦合，多个应用程序无法直接的共享缓存，各应用或集群的各节点都需要维护自己的单独缓存，对内存是一种浪费。</li>
<li>分布式缓存：指的是与应用分离的缓存组件或服务，其最大的优点是自身就是一个独立的应用，与本地应用隔离，多个应用可直接的共享缓存。</li>
</ul>
<h5 id="1-5-1-本地缓存"><a href="#1-5-1-本地缓存" class="headerlink" title="1.5.1 本地缓存"></a>1.5.1 本地缓存</h5><p>编程直接实现缓存<br>个别场景下，我们只需要简单的缓存数据的功能，而无需关注更多存取、清空策略等深入的特性时，直接编程实现缓存则是最便捷和高效的。<br>a. 成员变量或局部变量实现</p>
<p>简单代码示例如下：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="JAVASCRIPT"><figure class="iseeu highlight /javascript"><table><tr><td class="code"><pre><span class="line">public <span class="keyword">void</span> <span class="function"><span class="title">UseLocalCache</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">     <span class="comment">//一个本地的缓存变量</span></span><br><span class="line">     <span class="built_in">Map</span>&lt;<span class="built_in">String</span>, <span class="built_in">Object</span>&gt; localCacheStoreMap = <span class="keyword">new</span> HashMap&lt;<span class="built_in">String</span>, <span class="built_in">Object</span>&gt;();</span><br><span class="line">    </span><br><span class="line">     List&lt;<span class="built_in">Object</span>&gt; infosList = <span class="built_in">this</span>.getInfoList();</span><br><span class="line">    <span class="keyword">for</span>(<span class="built_in">Object</span> item:infosList)&#123;</span><br><span class="line">        <span class="keyword">if</span>(localCacheStoreMap.containsKey(item))&#123; <span class="comment">//缓存命中 使用缓存数据</span></span><br><span class="line">            <span class="comment">// todo</span></span><br><span class="line">        &#125; <span class="keyword">else</span> &#123; <span class="comment">// 缓存未命中  IO获取数据，结果存入缓存</span></span><br><span class="line">            <span class="built_in">Object</span> valueObject = <span class="built_in">this</span>.getInfoFromDB();</span><br><span class="line">            localCacheStoreMap.put(valueObject.toString(), valueObject);</span><br><span class="line">            </span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//示例</span></span><br><span class="line">private List&lt;<span class="built_in">Object</span>&gt; <span class="function"><span class="title">getInfoList</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line"><span class="keyword">return</span> <span class="keyword">new</span> ArrayList&lt;<span class="built_in">Object</span>&gt;();</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//示例数据库IO获取</span></span><br><span class="line">private <span class="built_in">Object</span> <span class="function"><span class="title">getInfoFromDB</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> <span class="built_in">Object</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<p>以局部变量map结构缓存部分业务数据，减少频繁的重复数据库I/O操作。缺点仅限于类的自身作用域内，类间无法共享缓存。<br>b. 静态变量实现</p>
<p>最常用的单例实现静态资源缓存，代码示例如下：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="JAVASCRIPT"><figure class="iseeu highlight /javascript"><table><tr><td class="code"><pre><span class="line">public <span class="class"><span class="keyword">class</span> <span class="title">CityUtils</span> </span>&#123;</span><br><span class="line">      private <span class="keyword">static</span> final HttpClient httpClient = ServerHolder.createClientWithPool(); </span><br><span class="line">      private <span class="keyword">static</span> <span class="built_in">Map</span>&lt;Integer, <span class="built_in">String</span>&gt; cityIdNameMap = <span class="keyword">new</span> HashMap&lt;Integer, <span class="built_in">String</span>&gt;();</span><br><span class="line">      private <span class="keyword">static</span> <span class="built_in">Map</span>&lt;Integer, <span class="built_in">String</span>&gt; districtIdNameMap = <span class="keyword">new</span> HashMap&lt;Integer, <span class="built_in">String</span>&gt;();</span><br><span class="line"></span><br><span class="line">  <span class="keyword">static</span> &#123;</span><br><span class="line">    HttpGet get = <span class="keyword">new</span> HttpGet(<span class="string">&quot;http://gis-in.sankuai.com/api/location/city/all&quot;</span>);</span><br><span class="line">    BaseAuthorizationUtils.generateAuthAndDateHeader(get,</span><br><span class="line">            BaseAuthorizationUtils.CLIENT_TO_REQUEST_MDC,</span><br><span class="line">            BaseAuthorizationUtils.SECRET_TO_REQUEST_MDC);</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="built_in">String</span> resultStr = httpClient.execute(get, <span class="keyword">new</span> BasicResponseHandler());</span><br><span class="line">        JSONObject resultJo = <span class="keyword">new</span> JSONObject(resultStr);</span><br><span class="line">        JSONArray dataJa = resultJo.getJSONArray(<span class="string">&quot;data&quot;</span>);</span><br><span class="line">        <span class="keyword">for</span> (int i = <span class="number">0</span>; i &lt; dataJa.length(); i++) &#123;</span><br><span class="line">            JSONObject itemJo = dataJa.getJSONObject(i);</span><br><span class="line">            cityIdNameMap.put(itemJo.getInt(<span class="string">&quot;id&quot;</span>), itemJo.getString(<span class="string">&quot;name&quot;</span>));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(<span class="string">&quot;Init City List Error!&quot;</span>, e);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">    <span class="keyword">static</span> &#123;</span><br><span class="line">    HttpGet get = <span class="keyword">new</span> HttpGet(<span class="string">&quot;http://gis-in.sankuai.com/api/location/district/all&quot;</span>);</span><br><span class="line">    BaseAuthorizationUtils.generateAuthAndDateHeader(get,</span><br><span class="line">            BaseAuthorizationUtils.CLIENT_TO_REQUEST_MDC,</span><br><span class="line">            BaseAuthorizationUtils.SECRET_TO_REQUEST_MDC);</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="built_in">String</span> resultStr = httpClient.execute(get, <span class="keyword">new</span> BasicResponseHandler());</span><br><span class="line">        JSONObject resultJo = <span class="keyword">new</span> JSONObject(resultStr);</span><br><span class="line">        JSONArray dataJa = resultJo.getJSONArray(<span class="string">&quot;data&quot;</span>);</span><br><span class="line">        <span class="keyword">for</span> (int i = <span class="number">0</span>; i &lt; dataJa.length(); i++) &#123;</span><br><span class="line">            JSONObject itemJo = dataJa.getJSONObject(i);</span><br><span class="line">            districtIdNameMap.put(itemJo.getInt(<span class="string">&quot;id&quot;</span>), itemJo.getString(<span class="string">&quot;name&quot;</span>));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(<span class="string">&quot;Init District List Error!&quot;</span>, e);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">    public <span class="keyword">static</span> <span class="built_in">String</span> <span class="function"><span class="title">getCityName</span>(<span class="params">int cityId</span>)</span> &#123;</span><br><span class="line">      <span class="built_in">String</span> name = cityIdNameMap.get(cityId);</span><br><span class="line">      <span class="keyword">if</span> (name == <span class="literal">null</span>) &#123;</span><br><span class="line">        name = <span class="string">&quot;未知&quot;</span>;</span><br><span class="line">      &#125;</span><br><span class="line">       <span class="keyword">return</span> name;</span><br><span class="line">     &#125;</span><br><span class="line"></span><br><span class="line">    public <span class="keyword">static</span> <span class="built_in">String</span> <span class="function"><span class="title">getDistrictName</span>(<span class="params">int districtId</span>)</span> &#123;</span><br><span class="line">      <span class="built_in">String</span> name = districtIdNameMap.get(districtId);</span><br><span class="line">       <span class="keyword">if</span> (name == <span class="literal">null</span>) &#123;</span><br><span class="line">         name = <span class="string">&quot;未知&quot;</span>;</span><br><span class="line">        &#125;</span><br><span class="line">       <span class="keyword">return</span> name;</span><br><span class="line">     &#125;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure></div>
<p>O2O业务中常用的城市基础基本信息判断，通过静态变量一次获取缓存内存中，减少频繁的I/O读取，静态变量实现类间可共享，进程内可共享，缓存的实时性稍差。</p>
<p>为了解决本地缓存数据的实时性问题，目前大量使用的是结合ZooKeeper的自动发现机制，实时变更本地静态变量缓存：</p>
<p>美团内部的基础配置组件MtConfig，采用的就是类似原理，使用静态变量缓存，结合ZooKeeper的统一管理，做到自动动态更新缓存，如下图所示：<br><img src="/2022/07/04/uncatalog/cl56he3gx000050r72rv69xlr/ef639c8f.png" alt="im"></p>
<blockquote>
<p>这类缓存实现，优点是能直接在heap区内读写，最快也最方便；缺点同样是受heap区域影响，缓存的数据量非常有限，同时缓存时间受GC影响。主要满足单机场景下的小数据量缓存需求，同时对缓存数据的变更无需太敏感感知，如上一般配置管理、基础静态数据等场景。</p>
</blockquote>
<h5 id="1-5-1-1-Ehcache"><a href="#1-5-1-1-Ehcache" class="headerlink" title="1.5.1.1 Ehcache"></a>1.5.1.1 Ehcache</h5><p>Ehcache是现在最流行的纯Java开源缓存框架，配置简单、结构清晰、功能强大，是一个非常轻量级的缓存实现，我们常用的Hibernate里面就集成了相关缓存功能。<br><img src="/2022/07/04/uncatalog/cl56he3gx000050r72rv69xlr/b810d158.png" alt="img"></p>
<p>整体上看，Ehcache的使用还是相对简单便捷的，提供了完整的各类API接口。需要注意的是，虽然Ehcache支持磁盘的持久化，但是由于存在两级缓存介质，在一级内存中的缓存，如果没有主动的刷入磁盘持久化的话，在应用异常down机等情形下，依然会出现缓存数据丢失，为此可以根据需要将缓存刷到磁盘，将缓存条目刷到磁盘的操作可以通过cache.flush()方法来执行，需要注意的是，对于对象的磁盘写入，前提是要将对象进行序列化</p>
<h5 id="1-5-1-2-Guava-Cache"><a href="#1-5-1-2-Guava-Cache" class="headerlink" title="1.5.1.2 Guava Cache"></a>1.5.1.2 Guava Cache</h5><p>Guava Cache是Google开源的Java重用工具集库Guava里的一款缓存工具，其主要实现的缓存功能有：</p>
<ul>
<li>自动将entry节点加载进缓存结构中；</li>
<li>当缓存的数据超过设置的最大值时，使用LRU算法移除；</li>
<li>具备根据entry节点上次被访问或者写入时间计算它的过期机制；</li>
<li>缓存的key被封装在WeakReference引用内；</li>
<li>缓存的Value被封装在WeakReference或SoftReference引用内；</li>
<li>统计缓存使用过程中命中率、异常率、未命中率等统计数据。<br>Guava Cache的架构设计灵感来源于ConcurrentHashMap，我们前面也提到过，简单场景下可以自行编码通过hashmap来做少量数据的缓存，但是，如果结果可能随时间改变或者是希望存储的数据空间可控的话，自己实现这种数据结构还是有必要的。</li>
</ul>
<p>Guava Cache继承了ConcurrentHashMap的思路，使用多个segments方式的细粒度锁，在保证线程安全的同时，支持高并发场景需求。Cache类似于Map，它是存储键值对的集合，不同的是它还需要处理evict、expire、dynamic load等算法逻辑，需要一些额外信息来实现这些操作。对此，根据面向对象思想，需要做方法与数据的关联封装。如图5所示cache的内存数据模型，可以看到，使用ReferenceEntry接口来封装一个键值对，而用ValueReference来封装Value值，之所以用Reference命令，是因为Cache要支持WeakReference Key和SoftReference、WeakReference value。<br>总体来看，Guava Cache基于ConcurrentHashMap的优秀设计借鉴，在高并发场景支持和线程安全上都有相应的改进策略，使用Reference引用命令，提升高并发下的数据……访问速度并保持了GC的可回收，有效节省空间；同时，write链和access链的设计，能更灵活、高效的实现多种类型的缓存清理策略，包括基于容量的清理、基于时间的清理、基于引用的清理等；编程式的build生成器管理，让使用者有更多的自由度，能够根据不同场景设置合适的模式</p>
<h5 id="1-5-2-分布式缓存"><a href="#1-5-2-分布式缓存" class="headerlink" title="1.5.2 分布式缓存"></a>1.5.2 分布式缓存</h5><h5 id="1-5-2-1-memcached缓存"><a href="#1-5-2-1-memcached缓存" class="headerlink" title="1.5.2.1 memcached缓存"></a>1.5.2.1 memcached缓存</h5><p>memcached是应用较广的开源分布式缓存产品之一，它本身其实不提供分布式解决方案。在服务端，memcached集群环境实际就是一个个memcached服务器的堆积，环境搭建较为简单；cache的分布式主要是在客户端实现，通过客户端的路由处理来达到分布式解决方案的目的。客户端做路由的原理非常简单，应用服务器在每次存取某key的value时，通过某种算法把key映射到某台memcached服务器nodeA上，因此这个key所有操作都在nodeA上，结构图如下图所示<br><img src="/2022/07/04/uncatalog/cl56he3gx000050r72rv69xlr/2c71fc19.png" alt="im"><br>memcached客户端路由图<br><img src="/2022/07/04/uncatalog/cl56he3gx000050r72rv69xlr/9a76052b.png" alt="img"><br>memcached一致性hash示例图<br>memcached客户端采用一致性hash算法作为路由策略，如图7，相对于一般hash（如简单取模）的算法，一致性hash算法除了计算key的hash值外，还会计算每个server对应的hash值，然后将这些hash值映射到一个有限的值域上（比如0~2^32）。通过寻找hash值大于hash(key)的最小server作为存储该key数据的目标server。如果找不到，则直接把具有最小hash值的server作为目标server。同时，一定程度上，解决了扩容问题，增加或删除单个节点，对于整个集群来说，不会有大的影响。最近版本，增加了虚拟节点的设计，进一步提升了可用性。<br>memcached是一个高效的分布式内存cache，了解memcached的内存管理机制，才能更好的掌握memcached，让我们可以针对我们数据特点进行调优，让其更好的为我所用。我们知道memcached仅支持基础的key-value键值对类型数据存储。在memcached内存结构中有两个非常重要的概念：slab和chunk。如图下图所示:<br><img src="/2022/07/04/uncatalog/cl56he3gx000050r72rv69xlr/8552dd28.png" alt="img"><br>slab是一个内存块，它是memcached一次申请内存的最小单位。在启动memcached的时候一般会使用参数-m指定其可用内存，但是并不是在启动的那一刻所有的内存就全部分配出去了，只有在需要的时候才会去申请，而且每次申请一定是一个slab。Slab的大小固定为1M（1048576 Byte），一个slab由若干个大小相等的chunk组成。每个chunk中都保存了一个item结构体、一对key和value。</p>
<p>虽然在同一个slab中chunk的大小相等的，但是在不同的slab中chunk的大小并不一定相等，在memcached中按照chunk的大小不同，可以把slab分为很多种类（class），默认情况下memcached把slab分为40类（class1～class40），在class 1中，chunk的大小为80字节，由于一个slab的大小是固定的1048576字节（1M），因此在class1中最多可以有13107个chunk（也就是这个slab能存最多13107个小于80字节的key-value数据）。</p>
<p>memcached内存管理采取预分配、分组管理的方式，分组管理就是我们上面提到的slab class，按照chunk的大小slab被分为很多种类。内存预分配过程是怎样的呢？向memcached添加一个item时候，memcached首先会根据item的大小，来选择最合适的slab class：例如item的大小为190字节，默认情况下class 4的chunk大小为160字节显然不合适，class 5的chunk大小为200字节，大于190字节，因此该item将放在class 5中（显然这里会有10字节的浪费是不可避免的），计算好所要放入的chunk之后，memcached会去检查该类大小的chunk还有没有空闲的，如果没有，将会申请1M（1个slab）的空间并划分为该种类chunk。例如我们第一次向memcached中放入一个190字节的item时，memcached会产生一个slab class 2（也叫一个page），并会用去一个chunk，剩余5241个chunk供下次有适合大小item时使用，当我们用完这所有的5242个chunk之后，下次再有一个在160～200字节之间的item添加进来时，memcached会再次产生一个class 5的slab（这样就存在了2个pages）。</p>
<p>总结来看，memcached内存管理需要注意的几个方面：</p>
<ul>
<li>chunk是在page里面划分的，而page固定为1m，所以chunk最大不能超过1m。</li>
<li>chunk实际占用内存要加48B，因为chunk数据结构本身需要占用48B。</li>
<li>如果用户数据大于1m，则memcached会将其切割，放到多个chunk内。</li>
<li>已分配出去的page不能回收。</li>
</ul>
<p>对于key-value信息，最好不要超过1m的大小；同时信息长度最好相对是比较均衡稳定的，这样能够保障最大限度的使用内存；同时，memcached采用的LRU清理策略，合理甚至过期时间，提高命中率。<br>无特殊场景下，key-value能满足需求的前提下，使用memcached分布式集群是较好的选择，搭建与操作使用都比较简单；分布式集群在单点故障时，只影响小部分数据异常，目前还可以通过Magent缓存代理模式，做单点备份，提升高可用；整个缓存都是基于内存的，因此响应时间是很快，不需要额外的序列化、反序列化的程序，但同时由于基于内存，数据没有持久化，集群故障重启数据无法恢复。高版本的memcached已经支持CAS模式的原子操作，可以低成本的解决并发控制问题。</p>
<h5 id="1-5-2-2-Redis缓存"><a href="#1-5-2-2-Redis缓存" class="headerlink" title="1.5.2.2 Redis缓存"></a>1.5.2.2 Redis缓存</h5><p>Redis是一个远程内存数据库（非关系型数据库），性能强劲，具有复制特性以及解决问题而生的独一无二的数据模型。它可以存储键值对与5种不同类型的值之间的映射，可以将存储在内存的键值对数据持久化到硬盘，可以使用复制特性来扩展读性能，还可以使用客户端分片来扩展写性能。<br><img src="/2022/07/04/uncatalog/cl56he3gx000050r72rv69xlr/58db8aae.png" alt="img"><br>上图，Redis内部使用一个redisObject对象来标识所有的key和value数据，redisObject最主要的信息如图所示：type代表一个value对象具体是何种数据类型，encoding是不同数据类型在Redis内部的存储方式，比如——type=string代表value存储的是一个普通字符串，那么对应的encoding可以是raw或是int，如果是int则代表世界Redis内部是按数值类型存储和表示这个字符串。</p>
<p>上图左边的raw列为对象的编码方式：字符串可以被编码为raw（一般字符串）或Rint（为了节约内存，Redis会将字符串表示的64位有符号整数编码为整数来进行储存）；列表可以被编码为ziplist或linkedlist，ziplist是为节约大小较小的列表空间而作的特殊表示；集合可以被编码为intset或者hashtable，intset是只储存数字的小集合的特殊表示；hash表可以编码为zipmap或者hashtable，zipmap是小hash表的特殊表示；有序集合可以被编码为ziplist或者skiplist格式，ziplist用于表示小的有序集合，而skiplist则用于表示任何大小的有序集合。</p>
<p>从网络I/O模型上看，Redis使用单线程的I/O复用模型，自己封装了一个简单的AeEvent事件处理框架，主要实现了epoll、kqueue和select。对于单纯只有I/O操作来说，单线程可以将速度优势发挥到最大，但是Redis也提供了一些简单的计算功能，比如排序、聚合等，对于这些操作，单线程模型实际会严重影响整体吞吐量，CPU计算过程中，整个I/O调度都是被阻塞住的，在这些特殊场景的使用中，需要额外的考虑。相较于memcached的预分配内存管理，Redis使用现场申请内存的方式来存储数据，并且很少使用free-list等方式来优化内存分配，会在一定程度上存在内存碎片。Redis跟据存储命令参数，会把带过期时间的数据单独存放在一起，并把它们称为临时数据，非临时数据是永远不会被剔除的，即便物理内存不够，导致swap也不会剔除任何非临时数据（但会尝试剔除部分临时数据）。</p>
<p>我们描述Redis为内存数据库，作为缓存服务，大量使用内存间的数据快速读写，支持高并发大吞吐；而作为数据库，则是指Redis对缓存的持久化支持。Redis由于支持了非常丰富的内存数据库结构类型，如何把这些复杂的内存组织方式持久化到磁盘上？Redis的持久化与传统数据库的方式差异较大，Redis一共支持四种持久化方式，主要使用的两种：</p>
<ul>
<li>1.定时快照方式(snapshot)：该持久化方式实际是在Redis内部一个定时器事件，每隔固定时间去检查当前数据发生的改变次数与时间是否满足配置的持久化触发的条件，如果满足则通过操作系统fork调用来创建出一个子进程，这个子进程默认会与父进程共享相同的地址空间，这时就可以通过子进程来遍历整个内存来进行存储操作，而主进程则仍然可以提供服务，当有写入时由操作系统按照内存页（page）为单位来进行copy-on-write保证父子进程之间不会互相影响。它的缺点是快照只是代表一段时间内的内存映像，所以系统重启会丢失上次快照与重启之间所有的数据。 </li>
<li>2.基于语句追加文件的方式(aof)：aof方式实际类似MySQl的基于语句的binlog方式，即每条会使Redis内存数据发生改变的命令都会追加到一个log文件中，也就是说这个log文件就是Redis的持久化数据。</li>
</ul>
<p>aof的方式的主要缺点是追加log文件可能导致体积过大，当系统重启恢复数据时如果是aof的方式则加载数据会非常慢，几十G的数据可能需要几小时才能加载完，当然这个耗时并不是因为磁盘文件读取速度慢，而是由于读取的所有命令都要在内存中执行一遍。另外由于每条命令都要写log，所以使用aof的方式，Redis的读写性能也会有所下降。<br>Redis的持久化使用了Buffer I/O，所谓Buffer I/O是指Redis对持久化文件的写入和读取操作都会使用物理内存的Page Cache，而大多数数据库系统会使用Direct I/O来绕过这层Page Cache并自行维护一个数据的Cache。而当Redis的持久化文件过大（尤其是快照文件），并对其进行读写时，磁盘文件中的数据都会被加载到物理内存中作为操作系统对该文件的一层Cache，而这层Cache的数据与Redis内存中管理的数据实际是重复存储的。虽然内核在物理内存紧张时会做Page Cache的剔除工作，但内核很可能认为某块Page Cache更重要，而让你的进程开始Swap，这时你的系统就会开始出现不稳定或者崩溃了，因此在持久化配置后，针对内存使用需要实时监控观察。</p>
<p>与memcached客户端支持分布式方案不同，Redis更倾向于在服务端构建分布式存储,如下图<br><img src="/2022/07/04/uncatalog/cl56he3gx000050r72rv69xlr/0941f7e1.png" alt="img"><br><img src="/2022/07/04/uncatalog/cl56he3gx000050r72rv69xlr/ce564c30.png" alt="img"><br>Redis Cluster是一个实现了分布式且允许单点故障的Redis高级版本，它没有中心节点，具有线性可伸缩的功能。如上图，其中节点与节点之间通过二进制协议进行通信，节点与客户端之间通过ascii协议进行通信。在数据的放置策略上，Redis Cluster将整个key的数值域分成4096个hash槽，每个节点上可以存储一个或多个hash槽，也就是说当前Redis Cluster支持的最大节点数就是4096。Redis Cluster使用的分布式算法也很简单：crc16( key ) % HASH_SLOTS_NUMBER。</p>
<p>个人总结了以下多种Web应用场景，在这些场景下可以充分的利用Redis的特性，大大提高效率。</p>
<ul>
<li>在主页中显示最新的项目列表：Redis使用的是常驻内存的缓存，速度非常快。LPUSH用来插入一个内容ID，作为关键字存储在列表头部。LTRIM用来限制列表中的项目数最多为5000。如果用户需要的检索的数据量超越这个缓存容量，这时才需要把请求发送到数据库。</li>
<li>删除和过滤：如果一篇文章被删除，可以使用LREM从缓存中彻底清除掉。</li>
<li>排行榜及相关问题：排行榜（leader board）按照得分进行排序。ZADD命令可以直接实现这个功能，而ZREVRANGE命令可以用来按照得分来获取前100名的用户，ZRANK可以用来获取用户排名，非常直接而且操作容易。</li>
<li>按照用户投票和时间排序：排行榜，得分会随着时间变化。LPUSH和LTRIM命令结合运用，把文章添加到一个列表中。一项后台任务用来获取列表，并重新计算列表的排序，ZADD命令用来按照新的顺序填充生成列表。列表可以实现非常快速的检索，即使是负载很重的站点。</li>
<li>过期项目处理：使用Unix时间作为关键字，用来保持列表能够按时间排序。对current_time和time_to_live进行检索，完成查找过期项目的艰巨任务。另一项后台任务使用ZRANGE…WITHSCORES进行查询，删除过期的条目。</li>
<li>计数：进行各种数据统计的用途是非常广泛的，比如想知道什么时候封锁一个IP地址。INCRBY命令让这些变得很容易，通过原子递增保持计数；GETSET用来重置计数器；过期属性用来确认一个关键字什么时候应该删除。</li>
<li>特定时间内的特定项目：这是特定访问者的问题，可以通过给每次页面浏览使用SADD命令来解决。SADD不会将已经存在的成员添加到一个集合。</li>
<li>Pub/Sub：在更新中保持用户对数据的映射是系统中的一个普遍任务。Redis的pub/sub功能使用了SUBSCRIBE、UNSUBSCRIBE和PUBLISH命令，让这个变得更加容易。</li>
<li>队列：在当前的编程中队列随处可见。除了push和pop类型的命令之外，Redis还有阻塞队列的命令，能够让一个程序在执行时被另一个程序添加到队列。</li>
</ul>
]]></content>
      <tags>
        <tag>架构设计那些事儿</tag>
      </tags>
  </entry>
  <entry>
    <title>架构设计那些事儿--缓存那些事儿(三)，缓存性能和一致性的最佳实践</title>
    <url>/2022/07/04/uncatalog/cl58235q80000ikr72lnvg3qt/</url>
    <content><![CDATA[<hr>
<span id="more"></span>
<blockquote>
<p>目前各种类型的缓存都活跃在成千上万的应用服务中，还没有一种缓存方案可以解决一切的业务场景或数据类型，我们需要根据自身的特殊场景和背景，选择最适合的缓存方案。缓存的使用是程序员、架构师的必备技能，好的程序员能根据数据类型、业务场景来准确判断使用何种类型的缓存，如何使用这种缓存，以最小的成本最快的效率达到最优的目的。</p>
</blockquote>
<p>《架构设计那些事儿–缓存那些事儿》系列共分六章：</p>
<ul>
<li><a href="https://bugkillerpro.github.io/2022/07/04/uncatalog/cl56he3gx000050r72rv69xlr/">架构设计那些事儿–缓存那些事儿(一)，缓存的前世今生</a></li>
<li><a href="https://bugkillerpro.github.io/2022/07/04/uncatalog/cl58235qb0001ikr7dxwr0zu2/">架构设计那些事儿–缓存那些事儿(二)，缓存设计模式</a></li>
<li><a href="https://bugkillerpro.github.io/2022/07/04/uncatalog/cl58235q80000ikr72lnvg3qt/">架构设计那些事儿–缓存那些事儿(三)，缓存性能和一致性的最佳实践</a></li>
<li><a href="https://bugkillerpro.github.io/2022/07/12/uncatalog/cl5hl5x3l00000wr734tl8oua/">架构设计那些事儿–缓存那些事儿(四)，缓存穿透、 缓存雪崩 和 缓存击穿</a></li>
<li><a href="https://bugkillerpro.github.io/2022/07/12/uncatalog/cl5hm81oo00000wr786z6dmjl/">架构设计那些事儿–缓存那些事儿(五)，布隆过滤器详解</a></li>
<li><a href>架构设计那些事儿–缓存那些事儿(六)，redis</a></li>
</ul>
<p>当系统决定引入缓存方案的时候，缓存和数据库的一致性，便会成为一个无法回避的问题。<br>很多人对这个问题，有很多疑惑：</p>
<ul>
<li>到底是更新缓存还是删缓存？</li>
<li>到底选择先更新数据库，再删除缓存，还是先删除缓存，再更新数据库？</li>
<li>为什么要引入消息队列保证一致性？</li>
<li>延迟双删会有什么问题？到底要不要用？</li>
<li>…</li>
</ul>
<p>接下来将从根源上详细解决这些疑惑<br><img src="/2022/07/04/uncatalog/cl58235q80000ikr72lnvg3qt/640.png" alt="img"></p>
<h2 id="引入缓存提高性能"><a href="#引入缓存提高性能" class="headerlink" title="引入缓存提高性能"></a>引入缓存提高性能</h2><p>我们从最简单的场景开始讲起。</p>
<p>如果你的业务处于起步阶段，流量非常小，那无论是读请求还是写请求，直接操作数据库即可，这时你的架构模型是这样的：<br><img src="/2022/07/04/uncatalog/cl58235q80000ikr72lnvg3qt/640.jpg" alt="img"><br>但随着业务量的增长，你的项目请求量越来越大，这时如果每次都从数据库中读数据，那肯定会有性能问题。</p>
<p>这个阶段通常的做法是，引入「缓存」来提高读性能，架构模型就变成了这样：<br><img src="/2022/07/04/uncatalog/cl58235q80000ikr72lnvg3qt/6401.jpg" alt="img"><br>当下优秀的缓存中间件，当属 Redis 莫属，它不仅性能非常高，还提供了很多友好的数据类型，可以很好地满足我们的业务需求。</p>
<p>但引入缓存之后，你就会面临一个问题：之前数据只存在数据库中，现在要放到缓存中读取，具体要怎么存呢？</p>
<p>最简单直接的方案是「全量数据刷到缓存中」：</p>
<ul>
<li>数据库的数据，全量刷入缓存（不设置失效时间）</li>
<li>写请求只更新数据库，不更新缓存</li>
<li>启动一个定时任务，定时把数据库的数据，更新到缓存中</li>
</ul>
<p><img src="/2022/07/04/uncatalog/cl58235q80000ikr72lnvg3qt/6402.jpg" alt="img"></p>
<p>这个方案的优点是，所有读请求都可以直接「命中」缓存，不需要再查数据库，性能非常高。</p>
<p>但缺点也很明显，有 2 个问题：</p>
<ul>
<li>缓存利用率低：不经常访问的数据，还一直留在缓存中</li>
<li>数据不一致：因为是「定时」刷新缓存，缓存和数据库存在不一致（取决于定时任务的执行频率）</li>
</ul>
<p>所以，这种方案一般更适合业务「体量小」，且对数据一致性要求不高的业务场景。</p>
<p>那如果我们的业务体量很大，怎么解决这 2 个问题呢？</p>
<h2 id="缓存利用率和一致性问题"><a href="#缓存利用率和一致性问题" class="headerlink" title="缓存利用率和一致性问题"></a>缓存利用率和一致性问题</h2><p>先来看第一个问题，如何提高缓存利用率？</p>
<p>想要缓存利用率「最大化」，我们很容易想到的方案是，缓存中只保留最近访问的「热数据」。但具体要怎么做呢？</p>
<p>我们可以这样优化：</p>
<ul>
<li>写请求依旧只写数据库</li>
<li>读请求先读缓存，如果缓存不存在，则从数据库读取，并重建缓存</li>
<li>同时，写入缓存中的数据，都设置失效时间</li>
</ul>
<p><img src="/2022/07/04/uncatalog/cl58235q80000ikr72lnvg3qt/6403.jpg" alt="img"></p>
<p>这样一来，缓存中不经常访问的数据，随着时间的推移，都会逐渐「过期」淘汰掉，最终缓存中保留的，都是经常被访问的「热数据」，缓存利用率得以最大化。</p>
<p>再来看数据一致性问题。</p>
<p>要想保证缓存和数据库「实时」一致，那就不能再用定时任务刷新缓存了。</p>
<p>所以，当数据发生更新时，我们不仅要操作数据库，还要一并操作缓存。具体操作就是，修改一条数据时，不仅要更新数据库，也要连带缓存一起更新。</p>
<p>但数据库和缓存都更新，又存在先后问题，那对应的方案就有 2 个：</p>
<ul>
<li>先更新缓存，后更新数据库</li>
<li>先更新数据库，后更新缓存<br>哪个方案更好呢？</li>
</ul>
<p>先不考虑并发问题，正常情况下，无论谁先谁后，都可以让两者保持一致，但现在我们需要重点考虑「异常」情况。</p>
<p>因为操作分为两步，那么就很有可能存在「第一步成功、第二步失败」的情况发生。</p>
<p>这 2 种方案我们一个个来分析。</p>
<h3 id="1-先更新缓存，后更新数据库"><a href="#1-先更新缓存，后更新数据库" class="headerlink" title="1) 先更新缓存，后更新数据库"></a>1) 先更新缓存，后更新数据库</h3><p>如果缓存更新成功了，但数据库更新失败，那么此时缓存中是最新值，但数据库中是「旧值」。</p>
<p>虽然此时读请求可以命中缓存，拿到正确的值，但是，一旦缓存「失效」，就会从数据库中读取到「旧值」，重建缓存也是这个旧值。</p>
<p>这时用户会发现自己之前修改的数据又「变回去」了，对业务造成影响。</p>
<h3 id="2-先更新数据库，后更新缓存"><a href="#2-先更新数据库，后更新缓存" class="headerlink" title="2) 先更新数据库，后更新缓存"></a>2) 先更新数据库，后更新缓存</h3><p>如果数据库更新成功了，但缓存更新失败，那么此时数据库中是最新值，缓存中是「旧值」。</p>
<p>之后的读请求读到的都是旧数据，只有当缓存「失效」后，才能从数据库中得到正确的值。</p>
<p>这时用户会发现，自己刚刚修改了数据，但却看不到变更，一段时间过后，数据才变更过来，对业务也会有影响。</p>
<p>可见，无论谁先谁后，但凡后者发生异常，就会对业务造成影响。那怎么解决这个问题呢？</p>
<p>别急，后面我会详细给出对应的解决方案。</p>
<p>我们继续分析，除了操作失败问题，还有什么场景会影响数据一致性？</p>
<p>这里我们还需要重点关注：并发问题。</p>
<h2 id="并发引发的一致性问题"><a href="#并发引发的一致性问题" class="headerlink" title="并发引发的一致性问题"></a>并发引发的一致性问题</h2><p>假设我们采用「先更新数据库，再更新缓存」的方案，并且两步都可以「成功执行」的前提下，如果存在并发，情况会是怎样的呢？</p>
<p>有线程 A 和线程 B 两个线程，需要更新「同一条」数据，会发生这样的场景：</p>
<ol>
<li>线程 A 更新数据库（X = 1）</li>
<li>线程 B 更新数据库（X = 2）</li>
<li>线程 B 更新缓存（X = 2）</li>
<li>线程 A 更新缓存（X = 1）<br>最终 X 的值在缓存中是 1，在数据库中是 2，发生不一致。</li>
</ol>
<p>也就是说，A 虽然先于 B 发生，但 B 操作数据库和缓存的时间，却要比 A 的时间短，执行时序发生「错乱」，最终这条数据结果是不符合预期的。</p>
<blockquote>
<p>同样地，采用「先更新缓存，再更新数据库」的方案，也会有类似问题，这里不再详述。</p>
</blockquote>
<p>除此之外，我们从「缓存利用率」的角度来评估这个方案，也是不太推荐的。</p>
<p>这是因为每次数据发生变更，都「无脑」更新缓存，但是缓存中的数据不一定会被「马上读取」，这就会导致缓存中可能存放了很多不常访问的数据，浪费缓存资源。</p>
<p>而且很多情况下，写到缓存中的值，并不是与数据库中的值一一对应的，很有可能是先查询数据库，再经过一系列「计算」得出一个值，才把这个值才写到缓存中。</p>
<p>由此可见，这种「更新数据库 + 更新缓存」的方案，不仅缓存利用率不高，还会造成机器性能的浪费。</p>
<p>所以此时我们需要考虑另外一种方案：删除缓存。</p>
<h2 id="删除缓存可以保证一致性吗？"><a href="#删除缓存可以保证一致性吗？" class="headerlink" title="删除缓存可以保证一致性吗？"></a>删除缓存可以保证一致性吗？</h2><p>删除缓存对应的方案也有 2 种：</p>
<ol>
<li>先删除缓存，后更新数据库</li>
<li>先更新数据库，后删除缓存<br>经过前面的分析我们已经得知，但凡「第二步」操作失败，都会导致数据不一致。</li>
</ol>
<p>这里我不再详述具体场景，你可以按照前面的思路推演一下，就可以看到依旧存在数据不一致的情况。</p>
<p>这里我们重点来看「并发」问题</p>
<h3 id="1-先删除缓存，后更新数据库"><a href="#1-先删除缓存，后更新数据库" class="headerlink" title="1) 先删除缓存，后更新数据库"></a>1) 先删除缓存，后更新数据库</h3><p>如果有 2 个线程要并发「读写」数据，可能会发生以下场景：</p>
<ol>
<li>线程 A 要更新 X = 2（原值 X = 1）</li>
<li>线程 A 先删除缓存</li>
<li>线程 B 读缓存，发现不存在，从数据库中读取到旧值（X = 1）</li>
<li>线程 A 将新值写入数据库（X = 2）</li>
<li>线程 B 将旧值写入缓存（X = 1）<br>最终 X 的值在缓存中是 1（旧值），在数据库中是 2（新值），发生不一致。</li>
</ol>
<p>可见，先删除缓存，后更新数据库，当发生「读+写」并发时，还是存在数据不一致的情况。</p>
<h3 id="2-先更新数据库，后删除缓存"><a href="#2-先更新数据库，后删除缓存" class="headerlink" title="2) 先更新数据库，后删除缓存"></a>2) 先更新数据库，后删除缓存</h3><p>依旧是 2 个线程并发「读写」数据：</p>
<ol>
<li>缓存中 X 不存在（数据库 X = 1）</li>
<li>线程 A 读取数据库，得到旧值（X = 1）</li>
<li>线程 B 更新数据库（X = 2)</li>
<li>线程 B 删除缓存</li>
<li>线程 A 将旧值写入缓存（X = 1）<br>最终 X 的值在缓存中是 1（旧值），在数据库中是 2（新值），也发生不一致。</li>
</ol>
<p>这种情况「理论」来说是可能发生的，但实际真的有可能发生吗？</p>
<p>其实概率「很低」，这是因为它必须满足 3 个条件：</p>
<ol>
<li>缓存刚好已失效</li>
<li>读请求 + 写请求并发</li>
<li>更新数据库 + 删除缓存的时间（步骤 3-4），要比读数据库 + 写缓存时间短（步骤 2 和 5）<br>仔细想一下，条件 3 发生的概率其实是非常低的。</li>
</ol>
<p>因为写数据库一般会先「加锁」，所以写数据库，通常是要比读数据库的时间更长的。</p>
<p>这么来看，「先更新数据库 + 再删除缓存」的方案，是可以保证数据一致性的。</p>
<p>所以，我们应该采用这种方案，来操作数据库和缓存。</p>
<p>好，解决了并发问题，我们继续来看前面遗留的，第二步执行「失败」导致数据不一致的问题。</p>
<h2 id="如何保证两步都执行成功？"><a href="#如何保证两步都执行成功？" class="headerlink" title="如何保证两步都执行成功？"></a>如何保证两步都执行成功？</h2><p>前面我们分析到，无论是更新缓存还是删除缓存，只要第二步发生失败，那么就会导致数据库和缓存不一致。</p>
<p>保证第二步成功执行，就是解决问题的关键。</p>
<p>想一下，程序在执行过程中发生异常，最简单的解决办法是什么？</p>
<p>答案是：重试。</p>
<p>是的，其实这里我们也可以这样做。</p>
<p>无论是先操作缓存，还是先操作数据库，但凡后者执行失败了，我们就可以发起重试，尽可能地去做「补偿」。</p>
<p>那这是不是意味着，只要执行失败，我们「无脑重试」就可以了呢？</p>
<p>答案是否定的。现实情况往往没有想的这么简单，失败后立即重试的问题在于：</p>
<ul>
<li>立即重试很大概率「还会失败」</li>
<li>「重试次数」设置多少才合理？</li>
<li>重试会一直「占用」这个线程资源，无法服务其它客户端请求<br>看到了么，虽然我们想通过重试的方式解决问题，但这种「同步」重试的方案依旧不严谨。</li>
</ul>
<p>那更好的方案应该怎么做？</p>
<p>答案是：异步重试。什么是异步重试？</p>
<p>其实就是把重试请求写到「消息队列」中，然后由专门的消费者来重试，直到成功。</p>
<p>或者更直接的做法，为了避免第二步执行失败，我们可以把操作缓存这一步，直接放到消息队列中，由消费者来操作缓存。</p>
<p>到这里你可能会问，写消息队列也有可能会失败啊？而且，引入消息队列，这又增加了更多的维护成本，这样做值得吗？<br>这个问题很好，但我们思考这样一个问题：如果在执行失败的线程中一直重试，还没等执行成功，此时如果项目「重启」了，那这次重试请求也就「丢失」了，那这条数据就一直不一致了。</p>
<p>所以，这里我们必须把重试或第二步操作放到另一个「服务」中，这个服务用「消息队列」最为合适。这是因为消息队列的特性，正好符合我们的需求：</p>
<ul>
<li><p>消息队列保证可靠性：写到队列中的消息，成功消费之前不会丢失（重启项目也不担心）</p>
</li>
<li><p>消息队列保证消息成功投递：下游从队列拉取消息，成功消费后才会删除消息，否则还会继续投递消息给消费者（符合我们重试的场景）<br>至于写队列失败和消息队列的维护成本问题：</p>
</li>
<li><p>写队列失败：操作缓存和写消息队列，「同时失败」的概率其实是很小的</p>
</li>
<li><p>维护成本：我们项目中一般都会用到消息队列，维护成本并没有新增很多<br>所以，引入消息队列来解决这个问题，是比较合适的。这时架构模型就变成了这样：</p>
</li>
</ul>
<p><img src="/2022/07/04/uncatalog/cl58235q80000ikr72lnvg3qt/6404.jpg" alt="img"></p>
<p>那如果你确实不想在应用中去写消息队列，是否有更简单的方案，同时又可以保证一致性呢？</p>
<p>方案还是有的，这就是近几年比较流行的解决方案：订阅数据库变更日志，再操作缓存。</p>
<p>具体来讲就是，我们的业务应用在修改数据时，「只需」修改数据库，无需操作缓存。</p>
<p>那什么时候操作缓存呢？这就和数据库的「变更日志」有关了。</p>
<p>拿 MySQL 举例，当一条数据发生修改时，MySQL 就会产生一条变更日志（Binlog），我们可以订阅这个日志，拿到具体操作的数据，然后再根据这条数据，去删除对应的缓存。</p>
<p><img src="/2022/07/04/uncatalog/cl58235q80000ikr72lnvg3qt/6405.jpg" alt="img"></p>
<p>订阅变更日志，目前也有了比较成熟的开源中间件，例如阿里的 canal，使用这种方案的优点在于：</p>
<ul>
<li>无需考虑写消息队列失败情况：只要写 MySQL 成功，Binlog 肯定会有</li>
<li>自动投递到下游队列：canal 自动把数据库变更日志「投递」给下游的消息队列<br>当然，与此同时，我们需要投入精力去维护 canal 的高可用和稳定性。</li>
</ul>
<blockquote>
<p>如果你有留意观察很多数据库的特性，就会发现其实很多数据库都逐渐开始提供「订阅变更日志」的功能了，相信不远的将来，我们就不用通过中间件来拉取日志，自己写程序就可以订阅变更日志了，这样可以进一步简化流程。</p>
</blockquote>
<p>至此，我们可以得出结论，想要保证数据库和缓存一致性，推荐采用「先更新数据库，再删除缓存」方案，并配合「消息队列」或「订阅变更日志」的方式来做。</p>
<h2 id="主从库延迟和延迟双删问题"><a href="#主从库延迟和延迟双删问题" class="headerlink" title="主从库延迟和延迟双删问题"></a>主从库延迟和延迟双删问题</h2><p>到这里，还有 2 个问题，是我们没有重点分析过的。</p>
<p>第一个问题，还记得前面讲到的「先删除缓存，再更新数据库」方案，导致不一致的场景么？</p>
<p>这里我再把例子拿过来让你复习一下：</p>
<p>2 个线程要并发「读写」数据，可能会发生以下场景：</p>
<ol>
<li>线程 A 要更新 X = 2（原值 X = 1）</li>
<li>线程 A 先删除缓存</li>
<li>线程 B 读缓存，发现不存在，从数据库中读取到旧值（X = 1）</li>
<li>线程 A 将新值写入数据库（X = 2）</li>
<li>线程 B 将旧值写入缓存（X = 1）<br>最终 X 的值在缓存中是 1（旧值），在数据库中是 2（新值），发生不一致。</li>
</ol>
<p>第二个问题：是关于「读写分离 + 主从复制延迟」情况下，缓存和数据库一致性的问题。</p>
<p>在「先更新数据库，再删除缓存」方案下，「读写分离 + 主从库延迟」其实也会导致不一致：</p>
<ol>
<li>线程 A 更新主库 X = 2（原值 X = 1）</li>
<li>线程 A 删除缓存</li>
<li>线程 B 查询缓存，没有命中，查询「从库」得到旧值（从库 X = 1）</li>
<li>从库「同步」完成（主从库 X = 2）</li>
<li>线程 B 将「旧值」写入缓存（X = 1）<br>最终 X 的值在缓存中是 1（旧值），在主从库中是 2（新值），也发生不一致。</li>
</ol>
<p>看到了么？这 2 个问题的核心在于：缓存都被回种了「旧值」。</p>
<p>那怎么解决这类问题呢？</p>
<p>最有效的办法就是，把缓存删掉。</p>
<p>但是，不能立即删，而是需要「延迟删」，这就是业界给出的方案：缓存延迟双删策略。</p>
<p>按照延时双删策略，这 2 个问题的解决方案是这样的：</p>
<p>解决第一个问题：在线程 A 删除缓存、更新完数据库之后，先「休眠一会」，再「删除」一次缓存。</p>
<p>解决第二个问题：线程 A 可以生成一条「延时消息」，写到消息队列中，消费者延时「删除」缓存。</p>
<p>这两个方案的目的，都是为了把缓存清掉，这样一来，下次就可以从数据库读取到最新值，写入缓存。</p>
<p>但问题来了，这个「延迟删除」缓存，延迟时间到底设置要多久呢？</p>
<ul>
<li>问题1：延迟时间要大于「主从复制」的延迟时间</li>
<li>问题2：延迟时间要大于线程 B 读取数据库 + 写入缓存的时间<br>但是，这个时间在分布式和高并发场景下，其实是很难评估的。</li>
</ul>
<p>很多时候，我们都是凭借经验大致估算这个延迟时间，例如延迟 1-5s，只能尽可能地降低不一致的概率。</p>
<p>所以你看，采用这种方案，也只是尽可能保证一致性而已，极端情况下，还是有可能发生不一致。</p>
<p>所以实际使用中，我还是建议你采用「先更新数据库，再删除缓存」的方案，同时，要尽可能地保证「主从复制」不要有太大延迟，降低出问题的概率。</p>
<h2 id="可以做到强一致吗？"><a href="#可以做到强一致吗？" class="headerlink" title="可以做到强一致吗？"></a>可以做到强一致吗？</h2><p>看到这里你可能会想，这些方案还是不够完美，我就想让缓存和数据库「强一致」，到底能不能做到呢？</p>
<p>其实很难。</p>
<p>要想做到强一致，最常见的方案是 2PC、3PC、Paxos、Raft 这类一致性协议，但它们的性能往往比较差，而且这些方案也比较复杂，还要考虑各种容错问题。</p>
<p>相反，这时我们换个角度思考一下，我们引入缓存的目的是什么？</p>
<p>没错，性能。</p>
<p>一旦我们决定使用缓存，那必然要面临一致性问题。性能和一致性就像天平的两端，无法做到都满足要求。</p>
<p>而且，就拿我们前面讲到的方案来说，当操作数据库和缓存完成之前，只要有其它请求可以进来，都有可能查到「中间状态」的数据。</p>
<p>所以如果非要追求强一致，那必须要求所有更新操作完成之前期间，不能有「任何请求」进来。</p>
<p>虽然我们可以通过加「分布锁」的方式来实现，但我们要付出的代价，很可能会超过引入缓存带来的性能提升。</p>
<p>所以，既然决定使用缓存，就必须容忍「一致性」问题，我们只能尽可能地去降低问题出现的概率。</p>
<p>同时我们也要知道，缓存都是有「失效时间」的，就算在这期间存在短期不一致，我们依旧有失效时间来兜底，这样也能达到最终一致。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>好了，总结一下这篇文章的重点。</p>
<p>1、想要提高应用的性能，可以引入「缓存」来解决</p>
<p>2、引入缓存后，需要考虑缓存和数据库一致性问题，可选的方案有：「更新数据库 + 更新缓存」、「更新数据库 + 删除缓存」</p>
<p>3、更新数据库 + 更新缓存方案，在「并发」场景下无法保证缓存和数据一致性，且存在「缓存资源浪费」和「机器性能浪费」的情况发生</p>
<p>4、在更新数据库 + 删除缓存的方案中，「先删除缓存，再更新数据库」在「并发」场景下依旧有数据不一致问题，解决方案是「延迟双删」，但这个延迟时间很难评估，所以推荐用「先更新数据库，再删除缓存」的方案</p>
<p>5、在「先更新数据库，再删除缓存」方案下，为了保证两步都成功执行，需配合「消息队列」或「订阅变更日志」的方案来做，本质是通过「重试」的方式保证数据一致性</p>
<p>6、在「先更新数据库，再删除缓存」方案下，「读写分离 + 主从库延迟」也会导致缓存和数据库不一致，缓解此问题的方案是「延迟双删」，凭借经验发送「延迟消息」到队列中，延迟删除缓存，同时也要控制主从库延迟，尽可能降低不一致发生的概率</p>
<h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>本以为这个老生常谈的话题，写起来很好写，没想到在写的过程中，还是挖到了很多之前没有深度思考过的细节。</p>
<p>在这里我也分享 4 点心得给你：</p>
<p>1、性能和一致性不能同时满足，为了性能考虑，通常会采用「最终一致性」的方案</p>
<p>2、掌握缓存和数据库一致性问题，核心问题有 3 点：缓存利用率、并发、缓存 + 数据库一起成功问题</p>
<p>3、失败场景下要保证一致性，常见手段就是「重试」，同步重试会影响吞吐量，所以通常会采用异步重试的方案</p>
<p>4、订阅变更日志的思想，本质是把权威数据源（例如 MySQL）当做 leader 主本，让其它异质系统（例如 Redis / Elasticsearch）成为它的 follower 副本，通过同步变更日志的方式，保证 leader 和 follower 之间保持一致</p>
<p>很多一致性问题，都会采用这些方案来解决，希望我的这些心得对你有所启发。</p>
]]></content>
      <tags>
        <tag>架构设计那些事儿</tag>
      </tags>
  </entry>
  <entry>
    <title>架构设计那些事儿--缓存那些事儿(二)，缓存设计模式()</title>
    <url>/2022/07/04/uncatalog/cl58235qb0001ikr7dxwr0zu2/</url>
    <content><![CDATA[<hr>
<span id="more"></span>
<blockquote>
<p>目前各种类型的缓存都活跃在成千上万的应用服务中，还没有一种缓存方案可以解决一切的业务场景或数据类型，我们需要根据自身的特殊场景和背景，选择最适合的缓存方案。缓存的使用是程序员、架构师的必备技能，好的程序员能根据数据类型、业务场景来准确判断使用何种类型的缓存，如何使用这种缓存，以最小的成本最快的效率达到最优的目的。</p>
</blockquote>
<p>《架构设计那些事儿–缓存那些事儿》系列共分六章：</p>
<ul>
<li><a href="https://bugkillerpro.github.io/2022/07/04/uncatalog/cl56he3gx000050r72rv69xlr/">架构设计那些事儿–缓存那些事儿(一)，缓存的前世今生</a></li>
<li><a href="https://bugkillerpro.github.io/2022/07/04/uncatalog/cl58235qb0001ikr7dxwr0zu2/">架构设计那些事儿–缓存那些事儿(二)，缓存设计模式</a></li>
<li><a href="https://bugkillerpro.github.io/2022/07/04/uncatalog/cl58235q80000ikr72lnvg3qt/">架构设计那些事儿–缓存那些事儿(三)，缓存性能和一致性的最佳实践</a></li>
<li><a href="https://bugkillerpro.github.io/2022/07/12/uncatalog/cl5hl5x3l00000wr734tl8oua/">架构设计那些事儿–缓存那些事儿(四)，缓存穿透、 缓存雪崩 和 缓存击穿</a></li>
<li><a href="https://bugkillerpro.github.io/2022/07/12/uncatalog/cl5hm81oo00000wr786z6dmjl/">架构设计那些事儿–缓存那些事儿(五)，布隆过滤器详解</a></li>
<li><a href>架构设计那些事儿–缓存那些事儿(六)，redis</a></li>
</ul>
<h2 id="缓存设计的几种常见模式"><a href="#缓存设计的几种常见模式" class="headerlink" title="缓存设计的几种常见模式"></a>缓存设计的几种常见模式</h2><h3 id="1，Cache-Aside"><a href="#1，Cache-Aside" class="headerlink" title="1，Cache-Aside"></a>1，Cache-Aside</h3><ul>
<li>读操作：应用先去查询缓存，命中则返回；没命中应用则会去数据库读取数据，写入缓存后返回。</li>
<li>写操作：应用先更新数据库再删除缓存，然后返回。<br>可以看到，这种模式下，缓存只有写入与删除而没有修改操作。<br>适用场景：读多写少。<br>存在的问题：多线程下易出现数据不一致的问题。</li>
</ul>
<h3 id="2，Read-Write-Through"><a href="#2，Read-Write-Through" class="headerlink" title="2，Read/Write-Through"></a>2，Read/Write-Through</h3><p>核心思想：应用需要操作数据时只与缓存组件进行交互；缓存里的数据不会过期。</p>
<ul>
<li>Read-Through，应用查询缓存是否存在，存在则返回；不存在则由缓存组件去数据库加载数据。</li>
<li>Write-Through，先查询要写入的数据在缓存是否存在，存在则先更新缓存然后再更新数据库最后返回；如果要写入的数据在缓存不存在，有两对应策略：一种是先将数据写入缓存，然后由缓存组件将数据同步更新到数据库；另一种策略是不写缓存直接将数据写入数据库。<br>适用场景：读多写少。<br>存在的问题：<br>因为应用操作数据时只与缓存组件交互，相对于Cache-Aside而言数据不一致的概率要低一些。<br>因为此模式下缓存没有过期时间，所以缓存的使用量会非常大。</li>
</ul>
<h3 id="3，Write-Back"><a href="#3，Write-Back" class="headerlink" title="3，Write-Back"></a>3，Write-Back</h3><p>Write-Back也称Write-Behind，这种模式是承接Write-Through的，在对数据进行数据持久化存储回写时一般采用异步回写，也可以间隔一定时间后批量回写<br><img src="/2022/07/04/uncatalog/cl58235qb0001ikr7dxwr0zu2/20200806194359875.png" alt="img"><br>适用场景：读少写多<br>存在的问题：异步或间隔一定时间的批量回写会导致数据延迟或数据丢失的情形出现。</p>
<p>这里只是介绍了常见的缓存模式里的一些基本情况，所讨论的缓存模式都存各自的问题，需要我们根据自己的业务场景来选用适合自己的模式。当然数据丢失、热点数据、缓存穿透、缓存预热等这些问题是在使用缓存时都必须考虑的。另外数据模型也是需要注意的，在Cache-Aside下缓存里的数据模型可以与数据库数据模型不一致，而Read/Write-Through模式下二者的数据模型一般是需要相同的。</p>
]]></content>
      <tags>
        <tag>架构设计那些事儿</tag>
      </tags>
  </entry>
  <entry>
    <title>架构设计那些事儿--缓存那些事儿(四)，缓存穿透、 缓存雪崩 和 缓存击穿</title>
    <url>/2022/07/12/uncatalog/cl5hl5x3l00000wr734tl8oua/</url>
    <content><![CDATA[<hr>
<span id="more"></span>
<blockquote>
<p>目前各种类型的缓存都活跃在成千上万的应用服务中，还没有一种缓存方案可以解决一切的业务场景或数据类型，我们需要根据自身的特殊场景和背景，选择最适合的缓存方案。缓存的使用是程序员、架构师的必备技能，好的程序员能根据数据类型、业务场景来准确判断使用何种类型的缓存，如何使用这种缓存，以最小的成本最快的效率达到最优的目的。</p>
</blockquote>
<p>《架构设计那些事儿–缓存那些事儿》系列共分六章：</p>
<ul>
<li><a href="https://bugkillerpro.github.io/2022/07/04/uncatalog/cl56he3gx000050r72rv69xlr/">架构设计那些事儿–缓存那些事儿(一)，缓存的前世今生</a></li>
<li><a href="https://bugkillerpro.github.io/2022/07/04/uncatalog/cl58235qb0001ikr7dxwr0zu2/">架构设计那些事儿–缓存那些事儿(二)，缓存设计模式</a></li>
<li><a href="https://bugkillerpro.github.io/2022/07/04/uncatalog/cl58235q80000ikr72lnvg3qt/">架构设计那些事儿–缓存那些事儿(三)，缓存性能和一致性的最佳实践</a></li>
<li><a href="https://bugkillerpro.github.io/2022/07/12/uncatalog/cl5hl5x3l00000wr734tl8oua/">架构设计那些事儿–缓存那些事儿(四)，缓存穿透、 缓存雪崩 和 缓存击穿</a></li>
<li><a href="https://bugkillerpro.github.io/2022/07/12/uncatalog/cl5hm81oo00000wr786z6dmjl/">架构设计那些事儿–缓存那些事儿(五)，布隆过滤器详解</a></li>
<li><a href>架构设计那些事儿–缓存那些事儿(六)，redis</a></li>
</ul>
<h2 id="缓存穿透、-缓存雪崩-和-缓存击穿"><a href="#缓存穿透、-缓存雪崩-和-缓存击穿" class="headerlink" title="缓存穿透、 缓存雪崩 和 缓存击穿"></a>缓存穿透、 缓存雪崩 和 缓存击穿</h2><blockquote>
<p>在生产环境中，会因为很多的原因造成访问请求绕过了缓存，都需要访问数据库持久层，虽然对Redsi缓存服务器不会造成影响，但是数据库的负载就会增大，使缓存的作用降低</p>
</blockquote>
<h3 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h3><p>缓存穿透是指查询一个根本不存在的数据，缓存层和持久层都不会命中。在日常工作中出于容错的考虑，如果从持久层查不到数据则不写入缓存层，缓存穿透将导致不存在的数据每次请求都要到持久层去查询，失去了缓存保护后端持久的意义</p>
<p>缓存穿透示意图：<br><img src="/2022/07/12/uncatalog/cl5hl5x3l00000wr734tl8oua/1.png" alt="img"><br>缓存穿透问题可能会使后端存储负载加大，由于很多后端持久层不具备高并发性，甚至可能造成后端存储宕机。通常可以在程序中统计总调用数、缓存层命中数、如果同一个Key的缓存命中率很低，可能就是出现了缓存穿透问题。<br>造成缓存穿透的基本原因有两个:</p>
<ul>
<li>第一，自身业务代码或者数据出现问题（例如：set 和 get 的key不一致） </li>
<li>第二，一些恶意攻击、爬虫等造成大量空命中（爬取线上商城商品数据，超大循环递增商品的ID）</li>
</ul>
<h4 id="解决方案："><a href="#解决方案：" class="headerlink" title="解决方案："></a>解决方案：</h4><ol>
<li><p>缓存空对象</p>
<pre><code>缓存空对象：是指在持久层没有命中的情况下，对key进行set （key,null）

缓存空对象会有两个问题：第一，value为null 不代表不占用内存空间，空值做了缓存，意味着缓存层中存了更多的键，需要更多的内存空间，比较有效的方法是针对这类数据设置一个较短的过期时间，让其自动剔除。第二，缓存层和存储层的数据会有一段时间窗口的不一致，可能会对业务有一定影响。例如过期时间设置为5分钟，如果此时存储层添加了这个数据，那此段时间就会出现缓存层和存储层数据的不一致，此时可以利用消息系统或者其他方式清除掉缓存层中的空对象
</code></pre>
</li>
<li><p>布隆过滤器拦截(详见<a href="https://hexo.io/">布隆过滤器</a>)</p>
<pre><code> 在访问缓存层和存储层之前，将存在的key用布隆过滤器提前保存起来，做第一层拦截，当收到一个对key请求时先用布隆过滤器验证是key否存在，如果存在在进入缓存层、存储层。可以使用bitmap做布隆过滤器。这种方法适用于数据命中不高、数据相对固定、实时性低的应用场景，代码维护较为复杂，但是缓存空间占用少。

 布隆过滤器实际上是一个很长的二进制向量和一系列随机映射函数。布隆过滤器可以用于检索一个元素是否在一个集合中。它的优点是空间效率和查询时间都远远超过一般的算法，缺点是有一定的误识别率和删除困难。
</code></pre>
</li>
</ol>
<p>方案对比:<br><img src="/2022/07/12/uncatalog/cl5hl5x3l00000wr734tl8oua/2.png" alt="img"></p>
<h3 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h3><p>由于缓存层承载着大量请求，有效地保护了存储层，但是如果缓存层由于某些原因不可用（宕机）或者大量缓存由于超时时间相同在同一时间段失效（大批key失效/热点数据失效），大量请求直接到达存储层，存储层压力过大导致系统雪崩。</p>
<h4 id="解决方案：-1"><a href="#解决方案：-1" class="headerlink" title="解决方案："></a>解决方案：</h4><ul>
<li>可以把缓存层设计成高可用的，即使个别节点、个别机器、甚至是机房宕掉，依然可以提供服务。利用sentinel或cluster实现。</li>
<li>采用多级缓存，本地进程作为一级缓存，redis作为二级缓存，不同级别的缓存设置的超时时间不同，即使某级缓存过期了，也有其他级别缓存兜底</li>
<li>缓存的过期时间用随机值，尽量让不同的key的过期时间不同（例如：定时任务新建大批量key，设置的过期时间相同）</li>
</ul>
<h3 id="缓存击穿"><a href="#缓存击穿" class="headerlink" title="缓存击穿"></a>缓存击穿</h3><p>系统中存在以下两个问题时需要引起注意：</p>
<p>当前key是一个热点key（例如一个秒杀活动），并发量非常大。<br>重建缓存不能在短时间完成，可能是一个复杂计算，例如复杂的SQL、多次IO、多个依赖等。<br>在缓存失效的瞬间，有大量线程来重建缓存，造成后端负载加大，甚至可能会让应用崩溃。</p>
<h4 id="解决方案：-2"><a href="#解决方案：-2" class="headerlink" title="解决方案："></a>解决方案：</h4><ol>
<li><p>分布式互斥锁</p>
<p>只允许一个线程重建缓存，其他线程等待重建缓存的线程执行完，重新从缓存获取数据即可。set(key,value,timeout)</p>
</li>
</ol>
<p><img src="/2022/07/12/uncatalog/cl5hl5x3l00000wr734tl8oua/3.png" alt="img"></p>
<ol start="2">
<li>永不过期</li>
</ol>
<ul>
<li>从缓存层面来看，确实没有设置过期时间，所以不会出现热点key过期后产生的问题，也就是“物理”不过期。</li>
<li>从功能层面来看，为每个value设置一个逻辑过期时间，当发现超过逻辑过期时间后，会使用单独的线程去更新缓</li>
</ul>
<p><img src="/2022/07/12/uncatalog/cl5hl5x3l00000wr734tl8oua/4.png" alt="img"><br>两种方案对比：</p>
<p>分布式互斥锁：这种方案思路比较简单，但是存在一定的隐患，如果在查询数据库 + 和 重建缓存（key失效后进行了大量的计算）时间过长，也可能会存在死锁和线程池阻塞的风险，高并发情景下吞吐量会大大降低！但是这种方法能够较好地降低后端存储负载，并在一致性上做得比较好。</p>
<p>“永远不过期”：这种方案由于没有设置真正的过期时间，实际上已经不存在热点key产生的一系列危害，但是会存在数据不一致的情况，同时代码复杂度会增大。</p>
]]></content>
      <tags>
        <tag>架构设计那些事儿</tag>
      </tags>
  </entry>
  <entry>
    <title>架构设计那些事儿--缓存那些事儿(五)，布隆过滤器详解</title>
    <url>/2022/07/12/uncatalog/cl5hm81oo00000wr786z6dmjl/</url>
    <content><![CDATA[<hr>
<span id="more"></span>
<blockquote>
<p>目前各种类型的缓存都活跃在成千上万的应用服务中，还没有一种缓存方案可以解决一切的业务场景或数据类型，我们需要根据自身的特殊场景和背景，选择最适合的缓存方案。缓存的使用是程序员、架构师的必备技能，好的程序员能根据数据类型、业务场景来准确判断使用何种类型的缓存，如何使用这种缓存，以最小的成本最快的效率达到最优的目的。</p>
</blockquote>
<p>《架构设计那些事儿–缓存那些事儿》系列共分六章：</p>
<ul>
<li><a href="https://bugkillerpro.github.io/2022/07/04/uncatalog/cl56he3gx000050r72rv69xlr/">架构设计那些事儿–缓存那些事儿(一)，缓存的前世今生</a></li>
<li><a href="https://bugkillerpro.github.io/2022/07/04/uncatalog/cl58235qb0001ikr7dxwr0zu2/">架构设计那些事儿–缓存那些事儿(二)，缓存设计模式</a></li>
<li><a href="https://bugkillerpro.github.io/2022/07/04/uncatalog/cl58235q80000ikr72lnvg3qt/">架构设计那些事儿–缓存那些事儿(三)，缓存性能和一致性的最佳实践</a></li>
<li><a href="https://bugkillerpro.github.io/2022/07/12/uncatalog/cl5hl5x3l00000wr734tl8oua/">架构设计那些事儿–缓存那些事儿(四)，缓存穿透、 缓存雪崩 和 缓存击穿</a></li>
<li><a href="https://bugkillerpro.github.io/2022/07/12/uncatalog/cl5hm81oo00000wr786z6dmjl/">架构设计那些事儿–缓存那些事儿(五)，布隆过滤器详解</a></li>
<li><a href>架构设计那些事儿–缓存那些事儿(六)，redis</a></li>
</ul>
<h2 id="布隆过滤器"><a href="#布隆过滤器" class="headerlink" title="布隆过滤器"></a>布隆过滤器</h2><p>本质上布隆过滤器(Bloom Filter)是一种数据结构，比较巧妙的概率型数据结构（probabilistic data structure），特点是高效地插入和查询，可以用来告诉你 某样东西一定不存在或者可能存在。</p>
<p>相比于传统的 List、Set、Map 等数据结构，它更高效、占用空间更少，但是缺点是其返回的结果是概率性的，而不是确切的。</p>
<p>可以一句话总结：</p>
<ul>
<li>如果Bloom Filter告诉你某个数据不存在，那么它一定不存在。</li>
<li>如果Bloom Filter告诉你某个数据存在，那么它不一定存在。</li>
</ul>
<p>然后你可能要问了，他都不一定存在了，那它有什么用。它虽然不保证100%存在，但是这个误判率却是可以控制的，一般根据场景你可以设置一个可以接受的错误率，比如 0.0001(万分之一)，0.00001(十万分之一)。在很多场景下，这个概率是可以接受的。在这些场景下，它就有用武之地了。</p>
<p>而它的优点非常明显，就是极少的空间占用，一般比正常存所有数据可以节省90%左右以上的内存。</p>
<p>如果有人对具体的误判率怎么用数学公式推算出来的算法感兴趣。下面的详解部分会给出推导的链接。</p>
<h2 id="实际场景"><a href="#实际场景" class="headerlink" title="实际场景"></a>实际场景</h2><p>根据实际场景来让大家了解一下在什么场景下需要布隆过滤器，它又解决了什么问题。</p>
<p>我们有一个需求，是判断任意的两个userid有没有聊过天。即(useridA, useridB)是否聊过天，来决定前端场景是否展示对方的username。我们最初的设计是放在Redis里面，存放的格式是：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="TEXT"><figure class="iseeu highlight /text"><table><tr><td class="code"><pre><span class="line">Redis String</span><br><span class="line">Key: &#123;prefix&#125;&#123;useridA&#125;,&#123;useridB&#125;</span><br><span class="line">Value: &quot;1&quot;</span><br></pre></td></tr></table></figure></div>
<p>我们的Userid是int32的递增值，现在已经有10位整数。（eg: 1212341234）。所以这个key至少有22字节。</p>
<p>但是最终统计出来，我们的userid聊天的唯一Key：(useridA, useridB) 有4 Billion(40亿)的数据。</p>
<p>也就是我们至少需要存40亿的数据到Redis。</p>
<h3 id="内存预估"><a href="#内存预估" class="headerlink" title="内存预估"></a>内存预估</h3><p>Redis使用SDS的数据结构来储存字符串。格式简化后如下图所示：</p>
<p><img src="/2022/07/12/uncatalog/cl5hm81oo00000wr786z6dmjl/1.png" alt="img"></p>
<ul>
<li>Key占用储存空间：Key(22)+SDS(9)=31;</li>
<li>Value占用储存空间：Value(1)+SDS(9)+redisObject(16)=26;</li>
</ul>
<p>总内存占用：(31+26) * 4 billion = 228G。</p>
<p>我们预估未来还有10倍的增长空间，那就是2.28T。</p>
<p>当然这只是粗略的估计，Redis有更加复杂详细的规则来优化内存占用。<br>我自己尝试过插入一百万的数据到Redis，实际内存占用跟我的计算公式差不多。<br>所以这个内存占用是非常夸张的，我们需要用技术方案来优化这个内存占用。</p>
<p>这个时候我们就需要解决内存的占用过多的问题，布隆过滤器(Bloom Filter)闪耀登场。</p>
<h2 id="布隆过滤器详解"><a href="#布隆过滤器详解" class="headerlink" title="布隆过滤器详解"></a>布隆过滤器详解</h2><p>布隆过滤器实际上是一个很长的二进制向量和一系列随机映射函数，二进制大家应该都清楚，存储的数据不是0就是1，默认是0。</p>
<p>主要用于判断一个元素是否在一个集合中，0代表不存在某个数据，1代表存在某个数据。布隆过滤器使用k个hash函数，每个哈希函数映射到Bit位的某一位，这样当k个位都为1的时候，我们认为这个元素存在。如图所示：<br><img src="/2022/07/12/uncatalog/cl5hm81oo00000wr786z6dmjl/2.png" alt="img"></p>
<h3 id="使用流程"><a href="#使用流程" class="headerlink" title="使用流程"></a>使用流程</h3><h4 id="1，Set流程"><a href="#1，Set流程" class="headerlink" title="1，Set流程"></a>1，Set流程</h4><p>1.设置K个hash函数. (f1, f2, f3, … fk).<br>2.对数据 (eg: golang) 进行hash，得到k个值. (2,6,11, …)<br>3.在Bit Array指定的位置设置为1.</p>
<h4 id="2，Check流程"><a href="#2，Check流程" class="headerlink" title="2，Check流程"></a>2，Check流程</h4><p>1.使用K个hash函数得到K个值。<br>2.在Bit Array上各个位置查看对应的值是否为1.<br>3.任何一个值为0，则此元素不存在。<br>4.所有的值都为0，则我们认为此元素存在。</p>
<h3 id="布隆过滤器计算器"><a href="#布隆过滤器计算器" class="headerlink" title="布隆过滤器计算器"></a>布隆过滤器计算器</h3><p>我们首先定义以下布隆过滤器的相关变量。</p>
<ul>
<li>n: 总的数据量的数量大小。</li>
<li>p: 误判率的大小 (0.01 means 1%)</li>
<li>k: hash函数的数量</li>
<li>m: 需要的Bit数组的Bits空间量。</li>
</ul>
<p>我们可以把 n,p 作为输入，就可以得到 k, m 作为输出。也可以使用 n,p,k 作为输入，可以得到 m 作为输出。</p>
<p>这里是在线布隆过滤器计算器 (布隆过滤器计算器)[<a href="https://hur.st/bloomfilter/">https://hur.st/bloomfilter/</a> ]</p>
<p>下图是我计算出来的值。<br><img src="/2022/07/12/uncatalog/cl5hm81oo00000wr786z6dmjl/3.png" alt="img"><br>可以对比最初的设计方案，4 Billion的数据， 0.001的错误率。只需要7GB的内存。7/228=3%， 差不多节省了97的内存空间。</p>
<h4 id="误判率"><a href="#误判率" class="headerlink" title="误判率"></a>误判率</h4><p>你可能会好奇，误判率是什么。因为我们使用的是hash映射。不同的数据经过不同的hash函数是有几率映射到同一个位置的。例如：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="TEXT"><figure class="iseeu highlight /text"><table><tr><td class="code"><pre><span class="line">f1(golang)=2, f2(golang)=6, f3(golang)=11</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">f1(python)=6</span><br><span class="line">f2(java)=11</span><br><span class="line">f3(cpp)=2</span><br></pre></td></tr></table></figure></div>

<p>当我们把 python, jave, cpp 插入到Bit Array后，位置(2,6,11)的值都为1。<br>这个时候我们检查 golang 是否存在，由于这几个位置的值都为1， 所以系统会告诉我们 golang 存在。<br>实际上我们并没有插入 golang， 这就产生了误判。</p>
<p>所以我们回到最初的定义：<br>本质上布隆过滤器是一种数据结构，比较巧妙的概率型数据结构（probabilistic data structure），特点是高效地插入和查询，可以用来告诉你 某样东西一定不存在或者可能存在。</p>
<ul>
<li>如果布隆过滤器告诉你个数据不存在，那么它一定不存在。</li>
<li>如果布隆过滤器告诉你某个数据存在，那么它可能存在。（也可能不存在，误判）</li>
</ul>
<h2 id="布隆过滤器实现"><a href="#布隆过滤器实现" class="headerlink" title="布隆过滤器实现"></a>布隆过滤器实现</h2><h3 id="1-Redis内实现"><a href="#1-Redis内实现" class="headerlink" title="1,Redis内实现"></a>1,Redis内实现</h3><p>Redis在4.0版本推出了 module 的形式，可以将 module 作为插件额外实现Redis的一些功能。官网推荐了一个 RedisBloom[2] 作为 Redis 布隆过滤器的 Module。它主要使用的命令包含两个命令:</p>
<ul>
<li>1.bff.add key value //添加某个value</li>
<li>2.bff.exists key value //判断某个value是否存在。<h4 id="1-1-RedisBloom-安装"><a href="#1-1-RedisBloom-安装" class="headerlink" title="1.1 RedisBloom 安装"></a>1.1 RedisBloom 安装</h4>Redis不是默认就有，需要安装module才可以使用其命令。未安装之前提示：<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">127.0.0.1:6379&gt; bf.add bloom_key bloom_value</span><br><span class="line">(error) ERR unknown command `bf.add`, with args beginning with: `bloom_key`, `bloom_value`,</span><br></pre></td></tr></table></figure></div>
可以使用docker安装，也可以使用源码安装：这里只展示一下docker安装并测试简单指令，有需要源码安装的可以网上查看教程。</li>
</ul>
<p>1.拉镜像<br>2.docker运行redisbloom<br>3.进入docker<br>4.执行redis-cli</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">docker pull redislabs/rebloom:latest</span><br><span class="line">docker run -p 6379:6379 --name redis-redisbloom redislabs/rebloom:latest</span><br><span class="line">docker exec -it redis-redisbloom bash</span><br><span class="line"><span class="meta">#</span><span class="bash"> redis-cli</span></span><br><span class="line">127.0.0.1:6379&gt; bf.add bloom_key bloom_value</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; bf.exists bloom_key bloom_value</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; bf.exists bloom_key bloom_other</span><br><span class="line">(integer) 0</span><br></pre></td></tr></table></figure></div>
<p>Redis的Bloom Filter内部使用Redis的Bitmap来实现。<br>Bitmap基于最小的单位bit进行存储，所以非常省空间。<br>redis中bit映射被限制在512MB之内。<br>有兴趣可以看一下Redis的官方文档。<a href="https://redislabs.com/redis-best-practices/bloom-filter-pattern/">Redis BloomFilter</a></p>
<h4 id="1-2-go操作RedisBloom"><a href="#1-2-go操作RedisBloom" class="headerlink" title="1.2 go操作RedisBloom"></a>1.2 go操作RedisBloom</h4><p> 详见<a href="https://redis.uptrace.dev/guide/bloom-cuckoo-count-min-top-k.html#bloom-and-cuckoo">Go Redis</a> 、<br> <a href="https://github.com/go-redis/redis/tree/master/example/redis-bloom">github</a></p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="GO"><figure class="iseeu highlight /go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">bloomFilter</span><span class="params">(ctx context.Context, rdb *redis.Client)</span></span> &#123;</span><br><span class="line">	inserted, err := rdb.Do(ctx, <span class="string">&quot;BF.ADD&quot;</span>, <span class="string">&quot;bf_key&quot;</span>, <span class="string">&quot;item0&quot;</span>).Bool()</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="built_in">panic</span>(err)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">if</span> inserted &#123;</span><br><span class="line">		fmt.Println(<span class="string">&quot;item0 was inserted&quot;</span>)</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">for</span> _, item := <span class="keyword">range</span> []<span class="keyword">string</span>&#123;<span class="string">&quot;item0&quot;</span>, <span class="string">&quot;item1&quot;</span>&#125; &#123;</span><br><span class="line">		exists, err := rdb.Do(ctx, <span class="string">&quot;BF.EXISTS&quot;</span>, <span class="string">&quot;bf_key&quot;</span>, item).Bool()</span><br><span class="line">		<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">			<span class="built_in">panic</span>(err)</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">if</span> exists &#123;</span><br><span class="line">			fmt.Printf(<span class="string">&quot;%s does exist\n&quot;</span>, item)</span><br><span class="line">		&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">			fmt.Printf(<span class="string">&quot;%s does not exist\n&quot;</span>, item)</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h3 id="2-go编码实现布隆过滤器"><a href="#2-go编码实现布隆过滤器" class="headerlink" title="2,go编码实现布隆过滤器"></a>2,go编码实现布隆过滤器</h3><p>由于Redis的Bloom Filter并非Redis原生自带的功能，需要安装module才能使用，很多时候生产环境使用的云服务并不一定完美支持，所以需要一个自己实现的布隆过滤器，在这里就不重复造轮子了，详见开箱即用的<a href="https://github.com/bits-and-blooms/bloom">bloom</a>，非常方便。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><ul>
<li>布隆过滤器告诉我们一个元素是否在一个集合里</li>
<li>布隆过滤器非常省内存空间<h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3></li>
<li>不支持删除 因为布隆过滤器是通过多个哈希函数把数据映射到多个bit中，那么不同的value可能映射到其中相同的bit中，所以如果删除某一个value，会影响所有其他映射到同样的bit中的value。</li>
<li>误判率 由于是hash映射，所以多个value可能映射到同样的bit位中，可以通过增大hash的数量来减少误判率，但是无法完全避免。</li>
<li>如果总的元素数量大于最初预估的总元素数量，误判率就会升高，需要重新扩容并初始化布隆过滤器。</li>
</ul>
]]></content>
      <tags>
        <tag>架构设计那些事儿</tag>
      </tags>
  </entry>
  <entry>
    <title>架构设计那些事儿--缓存那些事儿(六)，redis</title>
    <url>/2022/07/12/uncatalog/cl5hsfpv60000m4r706d63234/</url>
    <content><![CDATA[<hr>
<span id="more"></span>
<blockquote>
<p>目前各种类型的缓存都活跃在成千上万的应用服务中，还没有一种缓存方案可以解决一切的业务场景或数据类型，我们需要根据自身的特殊场景和背景，选择最适合的缓存方案。缓存的使用是程序员、架构师的必备技能，好的程序员能根据数据类型、业务场景来准确判断使用何种类型的缓存，如何使用这种缓存，以最小的成本最快的效率达到最优的目的。</p>
</blockquote>
<p>《架构设计那些事儿–缓存那些事儿》系列共分六章：</p>
<ul>
<li><a href="https://bugkillerpro.github.io/2022/07/04/uncatalog/cl56he3gx000050r72rv69xlr/">架构设计那些事儿–缓存那些事儿(一)，缓存的前世今生</a></li>
<li><a href="https://bugkillerpro.github.io/2022/07/04/uncatalog/cl58235qb0001ikr7dxwr0zu2/">架构设计那些事儿–缓存那些事儿(二)，缓存设计模式</a></li>
<li><a href="https://bugkillerpro.github.io/2022/07/04/uncatalog/cl58235q80000ikr72lnvg3qt/">架构设计那些事儿–缓存那些事儿(三)，缓存性能和一致性的最佳实践</a></li>
<li><a href="https://bugkillerpro.github.io/2022/07/12/uncatalog/cl5hl5x3l00000wr734tl8oua/">架构设计那些事儿–缓存那些事儿(四)，缓存穿透、 缓存雪崩 和 缓存击穿</a></li>
<li><a href="https://bugkillerpro.github.io/2022/07/12/uncatalog/cl5hm81oo00000wr786z6dmjl/">架构设计那些事儿–缓存那些事儿(五)，布隆过滤器详解</a></li>
<li><a href>架构设计那些事儿–缓存那些事儿(六)，redis</a></li>
</ul>
<h2 id="First-of-all"><a href="#First-of-all" class="headerlink" title="First of all"></a>First of all</h2><p> 当我们想要全面无误的了解一个工具的时候，强烈建议直接去读官方文档，redis也不例外</p>
<ul>
<li><a href="https://redis.io/">reids官方文档</a></li>
<li><a href="https://redis.uptrace.dev/">go redis</a></li>
</ul>
<h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ul>
<li><p><a href="#Redis%E4%BB%8B%E7%BB%8D">跳到 Redis 介绍</a></p>
<ul>
<li><a href="#Redis%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F">Redis 是什么？</a></li>
<li><a href="#Redis%E7%89%B9%E6%80%A7">Redis 特性</a></li>
<li><a href="#Redis%E5%85%B8%E5%9E%8B%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF">Redis 典型使用场景</a></li>
<li><a href="#Redis%E9%AB%98%E5%B9%B6%E5%8F%91%E5%8E%9F%E7%90%86">Redis 高并发原理</a></li>
<li><a href="#Redis%E5%AE%89%E8%A3%85%E3%80%81%E5%90%AF%E5%8A%A8">Redis 安装、启动</a></li>
<li>[redis conf 配置文件](#redis conf配置文件)</li>
</ul>
</li>
<li><p><a href="#Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8">Redis 数据结构与命令使用</a></p>
<ul>
<li><a href="#%E9%80%9A%E7%94%A8%E5%85%A8%E5%B1%80%E5%91%BD%E4%BB%A4">通用全局命令</a></li>
<li><a href="#%E5%B8%B8%E7%94%A8%E5%85%A8%E5%B1%80%E5%91%BD%E4%BB%A4">常用全局命令</a></li>
<li><a href="#%E5%AD%97%E7%AC%A6%E4%B8%B2%E4%BD%BF%E7%94%A8">字符串使用</a></li>
<li><a href="#%E5%93%88%E5%B8%8Chash">哈希 hash</a></li>
<li><a href="#%E5%88%97%E8%A1%A8%EF%BC%88lists%EF%BC%89">列表（lists）</a></li>
<li><a href="#set%E9%9B%86%E5%90%88%E5%92%8Czset%E6%9C%89%E5%BA%8F%E9%9B%86%E5%90%88">set 集合和 zset 有序集合</a></li>
</ul>
</li>
<li><p><a href="#%E5%B0%8F%E5%8A%9F%E8%83%BD%E5%A4%A7%E7%94%A8%E5%A4%84">小功能大用处</a></p>
<ul>
<li><a href="#%E6%85%A2%E6%9F%A5%E8%AF%A2%E5%88%86%E6%9E%90">慢查询分析</a></li>
<li><a href="#Pipeline%EF%BC%88%E6%B5%81%E6%B0%B4%E7%BA%BF%EF%BC%89%E6%9C%BA%E5%88%B6">Pipeline（流水线）机制</a></li>
<li><a href="#%E4%BA%8B%E5%8A%A1%E4%B8%8ELua">事务与 Lua</a></li>
<li><a href="#Bitmaps">Bitmaps</a></li>
<li><a href="#HyperLogLog">HyperLogLog</a></li>
<li><a href="#%E5%8F%91%E5%B8%83%E8%AE%A2%E9%98%85">发布订阅</a></li>
<li><a href="#GEO">GEO</a></li>
</ul>
</li>
<li><p><a href="#Redis%E5%AE%A2%E6%88%B7%E7%AB%AF">Redis 客户端</a></p>
</li>
<li><p><a href="#%E6%8C%81%E4%B9%85%E5%8C%96%E3%80%81%E4%B8%BB%E4%BB%8E%E5%90%8C%E6%AD%A5%E4%B8%8E%E7%BC%93%E5%AD%98%E8%AE%BE%E8%AE%A1">持久化、主从同步与缓存设计</a></p>
<ul>
<li><a href="#%E6%8C%81%E4%B9%85%E5%8C%96">持久化</a></li>
<li><a href="#%E4%B8%BB%E4%BB%8E%E5%90%8C%E6%AD%A5">主从同步</a></li>
<li><a href="#%E7%BC%93%E5%AD%98">缓存</a></li>
</ul>
</li>
<li><p><a href="#%E7%9F%A5%E8%AF%86%E6%8B%93%E5%B1%95">知识拓展</a></p>
<ul>
<li><a href="#%E7%BC%93%E5%AD%98%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E5%90%8C%E6%AD%A5%E7%AD%96%E7%95%A5">缓存与数据库同步策略</a></li>
<li><a href="#%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81">分布式锁</a></li>
<li><a href="#%E5%85%B3%E4%BA%8E%E9%9B%86%E7%BE%A4">关于集群</a></li>
</ul>
</li>
</ul>
<p id="Redis介绍"></p>   

<h2 id="Redis-介绍"><a href="#Redis-介绍" class="headerlink" title="Redis 介绍"></a>Redis 介绍</h2><p id="Redis是什么？"></p>  

<h3 id="Redis-是什么？"><a href="#Redis-是什么？" class="headerlink" title="Redis 是什么？"></a>Redis 是什么？</h3><ul>
<li>Redis 是一个开源（BSD 许可）的，内存中的数据结构存储系统，它可以用作数据库、缓存和消息中间件；</li>
<li>Redis 支持多种类型的数据结构，如 字符串（strings），散列（hashes）， 列表（lists）， 集合（sets）， 有序集合（sorted sets） ，范围查询， bitmaps， hyperloglogs 和 地理空间（geospatial） 索引半径查询；</li>
<li>Redis 内置了复制（replication），LUA 脚本（Lua scripting），LRU 驱动事件（LRU eviction），事务（transactions）和不同级别的 磁盘持久化（persistence）；</li>
<li>Redis 通过 哨兵（Sentinel） 和自动分区（Cluster）提供高可用性（high availability）。</li>
</ul>
<p id="Redis特性？"></p>  

<h3 id="Redis-特性"><a href="#Redis-特性" class="headerlink" title="Redis 特性"></a>Redis 特性</h3><p>速度快</p>
<ul>
<li>单节点读110000次/s，写81000次/s</li>
<li>数据存放内存中</li>
<li>用 C 语言实现，离操作系统更近</li>
<li>单线程架构，6.0 开始支持多线程（CPU、IO 读写负荷）<br>持久化</li>
<li>数据的更新将异步地保存到硬盘（RDB 和 AOF）<br>多种数据结构 - 不仅仅支持简单的 key-value 类型数据，还支持：字符串、hash、列表、集合、有序集合，</li>
</ul>
<p>支持多种编程语言</p>
<p>功能丰富</p>
<ul>
<li>HyperLogLog、GEO、发布订阅、Lua脚本、事务、Pipeline、Bitmaps，key 过期</li>
</ul>
<p>简单稳定</p>
<ul>
<li>源码少、单线程模型</li>
</ul>
<p>主从复制</p>
<p>Redis 支持数据的备份（master-slave）与集群（分片存储），以及拥有哨兵监控机制。</p>
<p>Redis 的所有操作都是原子性的，同时 Redis 还支持对几个操作合并后的原子性执行。</p>
<p id="Redis典型使用场景"></p>  

<h3 id="Redis-典型使用场景"><a href="#Redis-典型使用场景" class="headerlink" title="Redis 典型使用场景"></a>Redis 典型使用场景</h3><p>缓存<br><img src="/2022/07/12/uncatalog/cl5hsfpv60000m4r706d63234/1.png" alt="img"><br>计数器<br><img src="/2022/07/12/uncatalog/cl5hsfpv60000m4r706d63234/2.png" alt="img"><br>消息队列<br><img src="/2022/07/12/uncatalog/cl5hsfpv60000m4r706d63234/3.png" alt="img"><br>排行榜<br><img src="/2022/07/12/uncatalog/cl5hsfpv60000m4r706d63234/4.png" alt="img"><br>社交网络:<br><img src="/2022/07/12/uncatalog/cl5hsfpv60000m4r706d63234/5.png" alt="img"></p>
<h3 id="Redis-高并发原理"><a href="#Redis-高并发原理" class="headerlink" title="Redis 高并发原理"></a>Redis 高并发原理</h3><ul>
<li>Redis 是纯内存数据库，一般都是简单的存取操作，线程占用的时间很多，时间的花费主要集中在 IO 上，所以读取速度快</li>
<li>Redis 使用的是IO 多路复用，使用了单线程来轮询描述符，将数据库的开、关、读、写都转换成了事件，减少了线程切换时上下文的切换和竞争。</li>
<li>Redis 采用了单线程的模型，保证了每个操作的原子性，也减少了线程的上下文切换和竞争。</li>
<li>Redis 存储结构多样化，不同的数据结构对数据存储进行了优化，如压缩表，对短数据进行压缩存储，再如，跳表，使用有序的数据结构加快读取的速度。</li>
<li>Redis 采用自己实现的事件分离器，效率比较高，内部采用非阻塞的执行方式，吞吐能力比较大。</li>
</ul>
<p>(Redis性能很快的原因<br>1）基于内存操作，Redis的所有数据都存在内存中，因此所有的运算都是内存级别的，所以他的性能比较高。<br>2）数据结构简单：Redis的数据结构都是专门设计的，而这些简单的数据结构的查找和操作的时间大部分复杂度都是O（1），因此性能比较强，可以参考我之前写过的这篇文章。深入理解redis——redis经典五种数据类型及底层实现<br>3）多路复用和非阻塞I/O，Redis使用I/O多路复用来监听多个socket链接客户端，这样就可以使用一个线程链接来处理多个请求，减少线程切换带来的开销，同时也避免了I/O阻塞操作。<br>4）主线程为单线程，避免上下文切换，因为是单线程模型，因此避免了不必要的上下文切换和多线程竞争（比如锁），这就省去了多线程切换带来的时间和性能上的消耗，而且单线程不会导致死锁问题的发生。)</p>
<h3 id="redis-安装"><a href="#redis-安装" class="headerlink" title="redis 安装"></a>redis 安装</h3><p><a href="https://www.cnblogs.com/hunanzp/p/12304622.html">参考链接</a></p>
<h2 id="Redis-数据结构与命令使用"><a href="#Redis-数据结构与命令使用" class="headerlink" title="Redis 数据结构与命令使用"></a>Redis 数据结构与命令使用</h2><p>Redis 的数据结构有：string(字符串)、hash(哈希)、list(列表)、set(集合)、zset(有序集 合)。但这些只是 Redis 对外的数据结构，实际上每种数据结构都有自己底层的内部编码实现，而且是多种实现， 这样 Redis 会在合适的场景选择合适的内部编码。<br><img src="/2022/07/12/uncatalog/cl5hsfpv60000m4r706d63234/640.jpg" alt="img"><br>可以看到每种数据结构都有两种以上的内部编码实现，例如 list 数据结 构包含了 linkedlist 和 ziplist 两种内部编码。同时，有些内部编码，例如 ziplist， 可以作为多种外部数据结构的内部实现，可以通过 object encoding 命令查询内部编码。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">object encoding xxx  # xxx 为键名</span><br></pre></td></tr></table></figure></div>
<p>Redis 所有的数据结构都是以唯一的 key 字符串作为名称，然后通过这个唯一 key 值来获取相应的 value 数据。不同类型的数据结 构的差异就在于 value 的结构不一样。</p>
<h3 id="通用全局命令"><a href="#通用全局命令" class="headerlink" title="通用全局命令"></a>通用全局命令</h3><h4 id="常用全局命令"><a href="#常用全局命令" class="headerlink" title="常用全局命令"></a>常用全局命令</h4><ul>
<li>keys：查看所有键</li>
<li>dbsize：键总数</li>
<li>exists key：检查键是否存在</li>
<li>del key [key …]：删除键</li>
<li>expire key seconds：键过期</li>
<li>ttl key: 通过 ttl 命令观察键键的剩余过期时间</li>
<li>type key：键的数据结构类型<br><img src="/2022/07/12/uncatalog/cl5hsfpv60000m4r706d63234/6401.jpg" alt="img"><br><img src="/2022/07/12/uncatalog/cl5hsfpv60000m4r706d63234/6402.jpg" alt="img"><br>根据上面的命令解释，大家应该比较容易看懂截图里面的所有命令含义，这里就不过多解释了。</li>
</ul>
<h3 id="字符串使用"><a href="#字符串使用" class="headerlink" title="字符串使用"></a>字符串使用</h3><p>字符串 string 是 Redis 最简单的数据结构。Redis 的字符串是动态字符串，是可以修改的字符串，内部结构实现上类似于 Java 的 ArrayList，采用预分配冗余空间的方式来减少内存的频繁分配。</p>
<p>字符串结构使用非常广泛，一个常见的用途就是缓存用户信息。我们将用户信息结构体 使用 JSON 序列化成字符串，然后将序列化后的字符串塞进 Redis 来缓存。同样，取用户 信息会经过一次反序列化的过程。</p>
<h4 id="常用字符串命令"><a href="#常用字符串命令" class="headerlink" title="常用字符串命令"></a>常用字符串命令</h4><ul>
<li><p>set key value [ex seconds][px milliseconds] [nx|xx]: 设置值，返回 ok 表示成功</p>
<ul>
<li>ex seconds:为键设置秒级过期时间。</li>
<li>px milliseconds:为键设置毫秒级过期时间。</li>
<li>nx:键必须不存在，才可以设置成功，用于添加。可单独用 setnx 命令替代</li>
<li>xx:与 nx 相反，键必须存在，才可以设置成功，用于更新。可单独用 setxx 命令替代</li>
</ul>
</li>
<li><p>get key：获取值</p>
</li>
<li><p>mset key value [key value …]：批量设置值，批量操作命令可以有效提高业务处理效率</p>
</li>
<li><p>mget key [key …]：批量获取值，批量操作命令可以有效提高业务处理效率</p>
</li>
<li><p>incr key：计数，返回结果分 3 种情况：</p>
<ul>
<li>值不是整数，返回错误。</li>
<li>值是整数，返回自增后的结果。</li>
<li>键不存在，按照值为 0 自增，返回结果为 1。</li>
</ul>
</li>
<li><p>decr(自减)、incrby(自增指定数字)、 decrby(自减指定数字)</p>
<p><img src="/2022/07/12/uncatalog/cl5hsfpv60000m4r706d63234/6403.jpg" alt="img"><br><img src="/2022/07/12/uncatalog/cl5hsfpv60000m4r706d63234/6404.jpg" alt="img"></p>
</li>
</ul>
<p>根据上面的命令解释，大家应该比较容易看懂截图里面的所有命令含义，这里就不过多解释了。</p>
<h3 id="字符串使用场景"><a href="#字符串使用场景" class="headerlink" title="字符串使用场景"></a>字符串使用场景</h3><ul>
<li>缓存数据，提高查询性能。比如存储登录用户信息、电商中存储商品信息</li>
<li>可以做计数器（想知道什么时候封锁一个 IP 地址(访问超过几次)）,短信限流</li>
<li>共享 Session，例如：一个分布式 Web 服务将用户的 Session 信息(例如用户登录信息)保存在各自服务器中，这样会造成一个问题，出于负载均衡的考虑，分布式服务会将用户的访问均衡到不同服务器上，用户刷新一次访问可 能会发现需要重新登录，为了解决这个问题，可以使用 Redis 将用户的 Session 进行集中管理，在这种模式下只要保证 Redis 是高可用和扩展性的，每次用户 更新或者查询登录信息都直接从 Redis 中集中获取，如图：</li>
</ul>
<p><img src="/2022/07/12/uncatalog/cl5hsfpv60000m4r706d63234/6405.jpg" alt="img"><br><img src="/2022/07/12/uncatalog/cl5hsfpv60000m4r706d63234/6406.jpg" alt="img"></p>
<h3 id="哈希-hash"><a href="#哈希-hash" class="headerlink" title="哈希 hash"></a>哈希 hash</h3><p>哈希相当于 Java 中的 HashMap，以及 Js 中的 Map，内部是无序字典。实现原理跟 HashMap 一致。一个哈希表有多个节点，每个节点保存一个键值对。</p>
<p>与 Java 中的 HashMap 不同的是，rehash 的方式不一样，因为 Java 的 HashMap 在字典很大时，rehash 是个耗时的操作，需要一次性全部 rehash。</p>
<p>Redis 为了高性能，不能堵塞服务，所以采用了渐进式 rehash 策略。</p>
<p>渐进式 rehash 会在 rehash 的同时，保留新旧两个 hash 结构，查询时会同时查询两个 hash 结构，然后在后续的定时任务中以及 hash 操作指令中，循序渐进地将旧 hash 的内容一点点迁移到新的 hash 结构中。当搬迁完成了，就会使用新的 hash 结构取而代之。</p>
<p>当 hash 移除了最后一个元素之后，该数据结构自动被删除，内存被回收。</p>
<h4 id="常用哈希命令"><a href="#常用哈希命令" class="headerlink" title="常用哈希命令"></a>常用哈希命令</h4><ul>
<li>hset key field value：设置值</li>
<li>hget key field：获取值</li>
<li>hdel key field [field …]：删除 field</li>
<li>hlen key：计算 field 个数</li>
<li>hmset key field value [field value …]：批量设置 field-value</li>
<li>hmget key field [field …]：批量获取 field-value</li>
<li>hexists key field：判断 field 是否存在</li>
<li>hkeys key：获取所有 field</li>
<li>hvals key：获取所有 value</li>
<li>hgetall key：获取所有的 field-value</li>
<li>incrbyfloat 和 hincrbyfloat:就像 incrby 和 incrbyfloat 命令一样，但是它们的作 用域是 filed</li>
</ul>
<p><img src="/2022/07/12/uncatalog/cl5hsfpv60000m4r706d63234/6407.jpg" alt="img"><br><img src="/2022/07/12/uncatalog/cl5hsfpv60000m4r706d63234/6408.jpg" alt="img"><br>根据上面的命令解释，大家应该比较容易看懂截图里面的所有命令含义，这里同样不过多解释了</p>
<h4 id="哈希使用场景"><a href="#哈希使用场景" class="headerlink" title="哈希使用场景"></a>哈希使用场景</h4><ul>
<li>Hash 也可以同于对象存储，比如存储用户信息，与字符串不一样的是，字符串是需要将对象进行序列化（比如 json 序列化）之后才能保存，而 Hash 则可以讲用户对象的每个字段单独存储，这样就能节省序列化和反序列的时间。如下：<br><img src="/2022/07/12/uncatalog/cl5hsfpv60000m4r706d63234/640.gif" alt="img"></li>
<li>此外还可以保存用户的购买记录，比如 key 为用户 id，field 为商品 i d，value 为商品数量。同样还可以用于购物车数据的存储，比如 key 为用户 id，field 为商品 id，value 为购买数量等等:<br><img src="/2022/07/12/uncatalog/cl5hsfpv60000m4r706d63234/6409.jpg" alt="img"></li>
</ul>
<h3 id="列表（lists）"><a href="#列表（lists）" class="headerlink" title="列表（lists）"></a>列表（lists）</h3><p>Redis 中的 lists 相当于 Java 中的 LinkedList，实现原理是一个双向链表（其底层是一个快速列表），即可以支持反向查找和遍历，更方便操作。插入和删除操作非常快，时间复杂度为 O(1)，但是索引定位很慢，时间复杂度为 O(n)。<br><img src="/2022/07/12/uncatalog/cl5hsfpv60000m4r706d63234/6401.gif" alt="img"></p>
<h4 id="常用列表命令"><a href="#常用列表命令" class="headerlink" title="常用列表命令"></a>常用列表命令</h4><ul>
<li><p>rpush key value [value …]：从右边插入元素</p>
</li>
<li><p>lpush key value [value …]：从左边插入元素</p>
</li>
<li><p>linsert key before|after pivot value：向某个元素前或者后插入元素</p>
</li>
<li><p>lrange key start end：获取指定范围内的元素列表，lrange key 0 -1可以从左到右获取列表的所有元素</p>
</li>
<li><p>lindex key index：获取列表指定索引下标的元素</p>
</li>
<li><p>llen key：获取列表长度</p>
</li>
<li><p>lpop key：从列表左侧弹出元素</p>
</li>
<li><p>rpop key：从列表右侧弹出</p>
</li>
<li><p>lrem key count value：删除指定元素，lrem 命令会从列表中找到等于 value 的元素进行删除，根据 count 的不同 分为三种情况:</p>
<ul>
<li>count&gt;0，从左到右，删除最多 count 个元素。 </li>
<li>count&lt;0，从右到左，删除最多 count 绝对值个元素。</li>
<li>count=0，删除所有。</li>
</ul>
</li>
<li><p>ltrim key start end：按照索引范围修剪列表</p>
</li>
<li><p>lset key index newValue：修改指定索引下标的元素</p>
</li>
<li><p>blpop key [key …] timeout 和 brpop key [key …] timeout：阻塞式弹出<br><img src="/2022/07/12/uncatalog/cl5hsfpv60000m4r706d63234/64010.jpg" alt="img"><br><img src="/2022/07/12/uncatalog/cl5hsfpv60000m4r706d63234/64011.jpg" alt="img"><br><img src="/2022/07/12/uncatalog/cl5hsfpv60000m4r706d63234/64012.jpg" alt="img"><br><img src="/2022/07/12/uncatalog/cl5hsfpv60000m4r706d63234/64013.jpg" alt="img"><br><img src="/2022/07/12/uncatalog/cl5hsfpv60000m4r706d63234/64014.jpg" alt="img"></p>
</li>
</ul>
<p>根据上面的命令解释，大家应该比较容易看懂截图里面的所有命令含义，这里同样不过多解释了</p>
<h4 id="列表使用场景"><a href="#列表使用场景" class="headerlink" title="列表使用场景"></a>列表使用场景</h4><ul>
<li>热销榜，文章列表</li>
<li>实现工作队列（利用 lists 的 push 操作，将任务存在 lists 中，然后工作线程再用 pop 操作将任务取出进行执行 ），例如消息队列</li>
<li>最新列表，比如最新评论</li>
</ul>
<h4 id="使用参考："><a href="#使用参考：" class="headerlink" title="使用参考："></a>使用参考：</h4><ul>
<li>lpush+lpop=Stack(栈)</li>
<li>lpush+rpop=Queue(队列)</li>
<li>lpsh+ltrim=Capped Collection(有限集合)</li>
<li>lpush+brpop=Message Queue(消息队列)</li>
</ul>
<h3 id="set-集合和-zset-有序集合"><a href="#set-集合和-zset-有序集合" class="headerlink" title="set 集合和 zset 有序集合"></a>set 集合和 zset 有序集合</h3><p>Redis 的集合相当于 Java 语言里面的 HashSet 和 JS 里面的 Set，它内部的键值对是无序的唯一的。Set 集合中最后一个 value 被移除后，数据结构自动删除，内存被回收。</p>
<p>zset 可能是 Redis 提供的最为特色的数据结构，它也是在面试中面试官最爱问的数据结构。它类似于 Java 的 SortedSet 和 HashMap 的结合体，一方面它是一个 set，保证了内部 value 的唯一性，另一方面它可以给每个 value 赋予一个 score，代表这个 value 的排序权重。它的内部实现用的是一种叫着「跳跃列表」(后面会简单介绍)的数据结构。</p>
<h4 id="常用集合命令"><a href="#常用集合命令" class="headerlink" title="常用集合命令"></a>常用集合命令</h4><ul>
<li>sadd key element [element …]：添加元素，返回结果为添加成功的元素个数</li>
<li>srem key element [element …]：删除元素，返回结果为成功删除元素个数</li>
<li>smembers key：获取所有元素</li>
<li>sismember key element：判断元素是否在集合中，如果给定元素 element 在集合内返回 1，反之返回 0</li>
<li>scard key：计算元素个数，scard 的时间复杂度为 O(1)，它不会遍历集合所有元素</li>
<li>spop key：从集合随机弹出元素，从 3.2 版本开始，spop 也支持[count]参数。</li>
<li>srandmember key [count]：随机从集合返回指定个数元素，[count]是可选参数，如果不写默认为 1</li>
<li>sinter key [key …]：求多个集合的交集</li>
<li>suinon key [key …]：求多个集合的并集</li>
<li>sdiff key [key …]：求多个集合的差集</li>
</ul>
<p><img src="/2022/07/12/uncatalog/cl5hsfpv60000m4r706d63234/64015.jpg" alt="img"></p>
<h4 id="常用有序集合命令"><a href="#常用有序集合命令" class="headerlink" title="常用有序集合命令"></a>常用有序集合命令</h4><ul>
<li><p>zadd key score member [score member …]：添加成员，返回结果代表成功添加成员的个数。Redis3.2 为 zadd 命令添加了 nx、xx、ch、incr 四个选项:</p>
<ul>
<li>nx:member 必须不存在，才可以设置成功，用于添加</li>
<li>xx:member 必须存在，才可以设置成功，用于更新</li>
<li>ch:返回此次操作后，有序集合元素和分数发生变化的个数</li>
<li>incr:对 score 做增加，相当于后面介绍的 zincrby</li>
</ul>
</li>
<li><p>zcard key：计算成员个数</p>
</li>
<li><p>zscore key member：计算某个成员的分数</p>
</li>
<li><p>zrank key member 和 zrevrank key member：计算成员的排名，zrank 是从分数从低到高返回排名，zrevrank 反之</p>
</li>
<li><p>zrem key member [member …]：删除成员</p>
</li>
<li><p>zincrby key increment member：增加成员的分数</p>
</li>
<li><p>zrange key start end [withscores] 和 zrevrange key start end [withscores]：返回指定排名范围的成员，zrange 是从低到高返回，zrevrange 反之。</p>
</li>
<li><p>zrangebyscore key min max [withscores][limit offset count] 和 zrevrangebyscore key max min [withscores][limit offset count] 返回指定分数范围的成员，其中 zrangebyscore 按照分数从低到高返回，zrevrangebyscore 反之</p>
</li>
<li><p>zcount key min max：返回指定分数范围成员个数</p>
</li>
<li><p>zremrangebyrank key start end：删除指定排名内的升序元素</p>
</li>
<li><p>zremrangebyscore key min max：删除指定分数范围的成员</p>
</li>
<li><p>zinterstore 和 zunionstore 命令求集合的交集和并集，可用参数比较多，可用到再查文档</p>
</li>
</ul>
<p>有序集合相比集合提供了排序字段，但是也产生了代价，zadd 的时间 复杂度为 O(log(n))，sadd 的时间复杂度为 O(1)。</p>
<p><img src="/2022/07/12/uncatalog/cl5hsfpv60000m4r706d63234/64016.jpg" alt="img"></p>
<h4 id="集合和有序集合使用场景"><a href="#集合和有序集合使用场景" class="headerlink" title="集合和有序集合使用场景"></a>集合和有序集合使用场景</h4><ul>
<li>给用户添加标签</li>
<li>给标签添加用户</li>
<li>根据某个权重进行排序的队列的场景，比如游戏积分排行榜，设置优先级的任务列表，学生成绩表等</li>
</ul>
<p><img src="/2022/07/12/uncatalog/cl5hsfpv60000m4r706d63234/6402.gif" alt="img"></p>
<h4 id="关于跳跃列表"><a href="#关于跳跃列表" class="headerlink" title="关于跳跃列表"></a>关于跳跃列表</h4><p>跳跃列表就是一种层级制，最下面一层所有的元素都会串起来。然后每隔几个元素挑选出一个代表来，再将这几个代表使用另外一级指针串起来。然后在这些代表里再挑出二级代表，再串起来。最终就形成了金字塔结构，如图：<br><img src="/2022/07/12/uncatalog/cl5hsfpv60000m4r706d63234/64017.jpg" alt="img"><br><a href="https://www.jianshu.com/p/09c3b0835ba6">跳表参考</a></p>
<h4 id="列表、集合和有序集合异同"><a href="#列表、集合和有序集合异同" class="headerlink" title="列表、集合和有序集合异同"></a>列表、集合和有序集合异同</h4><p><img src="/2022/07/12/uncatalog/cl5hsfpv60000m4r706d63234/64018.jpg" alt="img"></p>
<h2 id="小功能大用处"><a href="#小功能大用处" class="headerlink" title="小功能大用处"></a>小功能大用处</h2><h3 id="慢查询分析"><a href="#慢查询分析" class="headerlink" title="慢查询分析"></a>慢查询分析</h3><p>许多存储系统（例如 MySQL）提供慢查询日志帮助开发和运维人员定位系统存在的慢操作。</p>
<p>所谓慢查询日志就是系统在命令执行前后计算每条命令的执行时间，当超过预设阈值，就将这条命令的相关信息（例如：发生时间，耗时，命令的详细信息）记录下来，Redis 也提供了类似的功能。这里可以顺带了解一下 Redis 客户端执行一条命令的过程，分为如下 4 个部分：</p>
<p><img src="/2022/07/12/uncatalog/cl5hsfpv60000m4r706d63234/64019.jpg" alt="img"></p>
<p>对于慢查询功能，需要明确 3 件事：</p>
<p>1、预设阈值怎么设置？</p>
<p>在 redis 配置文件中修改配置 ‘slowlog-log-slower-than’ 的值，单位是微妙（1 秒 = 1000 毫秒 = 1000000 微秒），默认是 10000 微秒，如果把 slowlog-log-slower-than 设置为 0，将会记录所有命令到日志中。如果把 slowlog-log-slower-than 设置小于 0，将会不记录任何命令到日志中。</p>
<p>2、慢查询记录存放在哪？</p>
<p>在 redis 配置文件中修改配置 ‘slowlog-max-len’ 的值。slowlog-max-len 的作用是指定慢查询日志最多存储的条数。实际上，Redis 使用了一个列表存放慢查询日志，slowlog-max-len 就是这个列表的最大长度。当一个新的命令满足满足慢查询条件时，被插入这个列表中。当慢查询日志列表已经达到最大长度时，最早插入的那条命令将被从列表中移出。比如，slowlog-max-len 被设置为 10，当有第 11 条命令插入时，在列表中的第 1 条命令先被移出，然后再把第 11 条命令放入列表。</p>
<p>记录慢查询指 Redis 会对长命令进行截断，不会大量占用大量内存。在实际的生产环境中，为了减缓慢查询被移出的可能和更方便地定位慢查询，建议将慢查询日志的长度调整的大一些。比如可以设置为 1000 以上。</p>
<p>除了去配置文件中修改，也可以通过 config set 命令动态修改配置</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash"> config <span class="built_in">set</span> slowlog-log-slower-than 1000</span></span><br><span class="line">OK</span><br><span class="line"><span class="meta">&gt;</span><span class="bash"> config <span class="built_in">set</span> slowlog-max-len 1200</span></span><br><span class="line">OK</span><br><span class="line"><span class="meta">&gt;</span><span class="bash"> config rewrite</span></span><br><span class="line">OK</span><br></pre></td></tr></table></figure></div>

<p>3、如何获取慢查询日志？</p>
<p>可以使用 slowlog get 命令获取慢查询日志，在 slowlog get 后面还可以加一个数字，用于指定获取慢查询日志的条数，比如，获取 2 条慢查询日志：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash"> slowlog get 3</span></span><br><span class="line">1) 1) (integer) 6107</span><br><span class="line">   2) (integer) 1616398930</span><br><span class="line">   3) (integer) 3109</span><br><span class="line">   4) 1) &quot;config&quot;</span><br><span class="line">      2) &quot;rewrite&quot;</span><br><span class="line">2) 1) (integer) 6106</span><br><span class="line">   2) (integer) 1613701788</span><br><span class="line">   3) (integer) 36004</span><br><span class="line">   4) 1) &quot;flushall&quot;</span><br></pre></td></tr></table></figure></div>

<p>可以看出每一条慢查询日志都有 4 个属性组成：</p>
<p> 1,唯一标识 ID<br> 2,命令执行的时间戳<br> 3,命令执行时长<br> 4,执行的命名和参数<br>此外，可以通过 slowlog len 命令获取慢查询日志的长度；通过 slowlog reset 命令清理慢查询日志。</p>
<h3 id="Pipeline（流水线）机制"><a href="#Pipeline（流水线）机制" class="headerlink" title="Pipeline（流水线）机制"></a>Pipeline（流水线）机制</h3><p>Redis 提供了批量操作命令（例如 mget、mset 等），有效地节约 RTT。但大部分命令是不支持批量操作的，例如要执行 n 次 hgetall 命令，并没有 mhgetall 命令存在，需要消耗 n 次 RTT。</p>
<p>Redis 的客户端和服务端可能部署在不同的机器上。例如客户端在北京，Redis 服务端在上海，两地直线距离约为 1300 公里，那么 1 次 RTT 时间 = 1300×2/(300000×2/3) = 13 毫秒（光在真空中 传输速度为每秒 30 万公里，这里假设光纤为光速的 2/3），那么客户端在 1 秒 内大约只能执行 80 次左右的命令，这个和 Redis 的高并发高吞吐特性背道而驰。</p>
<p>Pipeline（流水线）机制能改善上面这类问题，它能将一组 Redis 命令进 行组装，通过一次 RTT 传输给 Redis，再将这组 Redis 命令的执行结果按顺序返回给客户端。</p>
<p>不使用 Pipeline 的命令执行流程：</p>
<p><img src="/2022/07/12/uncatalog/cl5hsfpv60000m4r706d63234/64020.jpg" alt="img"><br>使用 Pipeline 的命令执行流程：<br><img src="/2022/07/12/uncatalog/cl5hsfpv60000m4r706d63234/64021.jpg" alt="img"><br>Redis 的流水线是一种通信协议，没有办法通过客户端演示给大家，这里以 Jedis 为例，通过 Java API 或者使用 Spring 操作它（代码来源于互联网）：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="JAVASCRIPT"><figure class="iseeu highlight /javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 测试Redis流水线</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author <span class="variable">liu</span></span></span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">publicclass TestPipelined &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 使用Java API测试流水线的性能</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    @SuppressWarnings(&#123; <span class="string">&quot;unused&quot;</span>, <span class="string">&quot;resource&quot;</span> &#125;)</span><br><span class="line">    @Test</span><br><span class="line">    public <span class="keyword">void</span> <span class="function"><span class="title">testPipelinedByJavaAPI</span>(<span class="params"></span>)</span> &#123;</span><br><span class="line">        JedisPoolConfig jedisPoolConfig = <span class="keyword">new</span> JedisPoolConfig();</span><br><span class="line">        jedisPoolConfig.setMaxIdle(<span class="number">20</span>);</span><br><span class="line">        jedisPoolConfig.setMaxTotal(<span class="number">10</span>);</span><br><span class="line">        jedisPoolConfig.setMaxWaitMillis(<span class="number">20000</span>);</span><br><span class="line"></span><br><span class="line">        JedisPool jedisPool = <span class="keyword">new</span> JedisPool(jedisPoolConfig,<span class="string">&quot;localhost&quot;</span>,<span class="number">6379</span>);</span><br><span class="line">        Jedis jedis = jedisPool.getResource();</span><br><span class="line">        long start = System.currentTimeMillis();</span><br><span class="line">        <span class="comment">// 开启流水线</span></span><br><span class="line">        Pipeline pipeline = jedis.pipelined();</span><br><span class="line">        <span class="comment">// 测试10w条数据读写</span></span><br><span class="line">        <span class="keyword">for</span>(int i = <span class="number">0</span>; i &lt; <span class="number">100000</span>; i++) &#123;</span><br><span class="line">            int j = i + <span class="number">1</span>;</span><br><span class="line">            pipeline.set(<span class="string">&quot;key&quot;</span> + j, <span class="string">&quot;value&quot;</span> + j);</span><br><span class="line">            pipeline.get(<span class="string">&quot;key&quot;</span> + j);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 只执行同步但不返回结果</span></span><br><span class="line">        <span class="comment">//pipeline.sync();</span></span><br><span class="line">        <span class="comment">// 以list的形式返回执行过的命令的结果</span></span><br><span class="line">        List&lt;<span class="built_in">Object</span>&gt; result = pipeline.syncAndReturnAll();</span><br><span class="line">        long end = System.currentTimeMillis();</span><br><span class="line">        <span class="comment">// 计算耗时</span></span><br><span class="line">        System.out.println(<span class="string">&quot;耗时&quot;</span> + (end - start) + <span class="string">&quot;毫秒&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 使用RedisTemplate测试流水线</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    @SuppressWarnings(&#123; <span class="string">&quot;resource&quot;</span>, <span class="string">&quot;rawtypes&quot;</span>, <span class="string">&quot;unchecked&quot;</span>, <span class="string">&quot;unused&quot;</span> &#125;)</span><br><span class="line">    @Test</span><br><span class="line">    public <span class="keyword">void</span> <span class="function"><span class="title">testPipelineBySpring</span>(<span class="params"></span>)</span> &#123;</span><br><span class="line">        ApplicationContext applicationContext = <span class="keyword">new</span> ClassPathXmlApplicationContext(<span class="string">&quot;spring.xml&quot;</span>);</span><br><span class="line">        RedisTemplate rt = (RedisTemplate)applicationContext.getBean(<span class="string">&quot;redisTemplate&quot;</span>);</span><br><span class="line">        SessionCallback callback = (SessionCallback)(RedisOperations ops)-&gt;&#123;</span><br><span class="line">            <span class="keyword">for</span>(int i = <span class="number">0</span>; i &lt; <span class="number">100000</span>; i++) &#123;</span><br><span class="line">                int j = i + <span class="number">1</span>;</span><br><span class="line">                ops.boundValueOps(<span class="string">&quot;key&quot;</span> + j).set(<span class="string">&quot;value&quot;</span> + j);</span><br><span class="line">                ops.boundValueOps(<span class="string">&quot;key&quot;</span> + j).get();</span><br><span class="line">            &#125;</span><br><span class="line">            returnnull;</span><br><span class="line">        &#125;;</span><br><span class="line">        long start = System.currentTimeMillis();</span><br><span class="line">        <span class="comment">// 执行Redis的流水线命令</span></span><br><span class="line">        List result = rt.executePipelined(callback);</span><br><span class="line">        long end = System.currentTimeMillis();</span><br><span class="line">        System.out.println(end - start);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<p>网上写的测试结果为：使用 Java API 耗时在 550ms 到 700ms 之间，也就是不到 1s 就完成了 10 万次读写，使用 Spring 耗时在 1100ms 到 1300ms 之间。这个与之前一条一条命令使用，1s 内就发送几十几百条（客户端和服务端距离导致）命令的差距不是一般的大了。</p>
<p>注意，这里只是为了测试性能而已，当你要执行很多的命令并返回结果的时候，需要考虑 List 对象的大小，因为它会“吃掉”服务器上许多的内存空间，严重时会导致内存不足，引发 JVM 溢出异常，所以在工作环境中，是需要读者自己去评估的，可以考虑使用迭代的方式去处理。</p>
<h3 id="事务与-Lua"><a href="#事务与-Lua" class="headerlink" title="事务与 Lua"></a>事务与 Lua</h3><h4 id="multi-和-exec-命令"><a href="#multi-和-exec-命令" class="headerlink" title="multi 和 exec 命令"></a>multi 和 exec 命令</h4><p>很多情况下我们需要一次执行不止一个命令，而且需要其同时成功或者失败。为了保证多条命令组合的原子性，Redis 提供了简单的事务功能以及集成 Lua 脚本来解决这个问题。</p>
<p>Redis 提供了简单的事务功能，将一组需要一起执行的命令放到 multi 和 exec 两个命令之间。Multi 命令代表事务开始，exec 命令代表事务结束，它们之间的命令是原子顺序执行的。使用案例：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">127.0.0.1:6379&gt; multi</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; SET msg &quot;hello chrootliu&quot;</span><br><span class="line">QUEUED</span><br><span class="line">127.0.0.1:6379&gt; GET msg</span><br><span class="line">QUEUED</span><br><span class="line">127.0.0.1:6379&gt; EXEC</span><br><span class="line">1) OK</span><br><span class="line">1) hello chrootliu</span><br></pre></td></tr></table></figure></div>

<p>Redis 提供了简单的事务，之所以说它简单，主要是因为它不支持事务中的回滚特性，同时无法实现命令之间的逻辑关系计算，主要有以下几点：</p>
<p> 1,不够满足原子性。一个事务执行过程中，其他事务或 client 是可以对相应的 key 进行修改的（并发情况下，例如电商常见的超卖问题），想要避免这样的并发性问题就需要使用 WATCH 命令，但是通常来说，必须经过仔细考虑才能决定究竟需要对哪些 key 进行 WATCH 加锁。然而，额外的 WATCH 会增加事务失败的可能，而缺少必要的 WATCH 又会让我们的程序产生竞争条件。<br> 2,后执行的命令无法依赖先执行命令的结果。由于事务中的所有命令都是互相独立的，在遇到 exec 命令之前并没有真正的执行，所以我们无法在事务中的命令中使用前面命令的查询结果。我们唯一可以做的就是通过 watch 保证在我们进行修改时，如果其它事务刚好进行了修改，则我们的修改停止，然后应用层做相应的处理。<br> 3,事务中的每条命令都会与 Redis 服务器进行网络交互。Redis 事务开启之后，每执行一个操作返回的都是 queued，这里就涉及到客户端与服务器端的多次交互，明明是需要一次批量执行的 n 条命令，还需要通过多次网络交互，显然非常浪费（这个就是为什么会有 pipeline 的原因，减少 RTT 的时间）。</p>
<h4 id="Redis-事务缺陷的解决-–-Lua"><a href="#Redis-事务缺陷的解决-–-Lua" class="headerlink" title="Redis 事务缺陷的解决 – Lua"></a>Redis 事务缺陷的解决 – Lua</h4><p>Lua 是一个小巧的脚本语言，用标准 C 编写，几乎在所有操作系统和平台上都可以编译运行。一个完整的 Lua 解释器不过 200k，在目前所有脚本引擎中，Lua 的速度是最快的，这一切都决定了 Lua 是作为嵌入式脚本的最佳选择。</p>
<p>Redis 2.6 版本之后内嵌了一个 Lua 解释器，可以用于一些简单的事务与逻辑运算，也可帮助开发者定制自己的 Redis 命令（例如：一次性的执行复杂的操作，和带有逻辑判断的操作），在这之前，必须修改源码。</p>
<p>在 Redis 中执行 Lua 脚本有两种方法：eval 和 evalsha，这里以 eval 做为案例介绍：<br>eval 语法：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">eval script numkeys key [key ...] arg [arg ...]</span><br></pre></td></tr></table></figure></div>
<p>其中：</p>
<ul>
<li>script 一段 Lua 脚本或 Lua 脚本文件所在路径及文件名</li>
<li>numkeys Lua 脚本对应参数数量</li>
<li>key [key …] Lua 中通过全局变量 KEYS 数组存储的传入参数</li>
<li>arg [arg …] Lua 中通过全局变量 ARGV 数组存储的传入附加参数</li>
</ul>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">EVAL &quot;return &#123;KEYS[1],KEYS[2],ARGV[1],ARGV[2]&#125;&quot; 2 key1 key2 first second</span><br><span class="line">1) &quot;key1&quot;</span><br><span class="line">2) &quot;key2&quot;</span><br><span class="line">3) &quot;first&quot;</span><br><span class="line">4) &quot;second&quot;</span><br></pre></td></tr></table></figure></div>

<p>Lua 执行流程图:<br><img src="/2022/07/12/uncatalog/cl5hsfpv60000m4r706d63234/64022.jpg" alt="img"></p>
<h4 id="SCRIPT-LOAD-与-EVALSHA-命令"><a href="#SCRIPT-LOAD-与-EVALSHA-命令" class="headerlink" title="SCRIPT LOAD 与 EVALSHA 命令"></a>SCRIPT LOAD 与 EVALSHA 命令</h4><p>对于不立即执行的 Lua 脚本，或需要重用的 Lua 脚本，可以通过 SCRIPT LOAD 提前载入 Lua 脚本，这个命令会立即返回对应的 SHA1 校验码</p>
<p>当需要执行函数时，通过 EVALSHA 调用 SCRIPT LOAD 返回的 SHA1 即可</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">SCRIPT LOAD &quot;return &#123;KEYS[1],KEYS[2],ARGV[1],ARGV[2]&#125;&quot;</span><br><span class="line">&quot;232fd51614574cf0867b83d384a5e898cfd24e5a&quot;</span><br><span class="line"></span><br><span class="line">EVALSHA &quot;232fd51614574cf0867b83d384a5e898cfd24e5a&quot; 2 key1 key2 first second</span><br><span class="line">1) &quot;key1&quot;</span><br><span class="line">2) &quot;key2&quot;</span><br><span class="line">3) &quot;first&quot;</span><br><span class="line">4) &quot;second&quot;</span><br></pre></td></tr></table></figure></div>
<h4 id="通过-Lua-脚本执行-Redis-命令"><a href="#通过-Lua-脚本执行-Redis-命令" class="headerlink" title="通过 Lua 脚本执行 Redis 命令"></a>通过 Lua 脚本执行 Redis 命令</h4><p>在 Lua 脚本中，只要使用 redis.call() 或 redis.pcall() 传入 Redis 命令就可以直接执行：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">eval &quot;return redis.call(&#x27;set&#x27;,KEYS[1],&#x27;bar&#x27;)&quot; 1 foo     --等同于在服务端执行 set foo bar</span><br></pre></td></tr></table></figure></div>
<p>案例，使用 Lua 脚本实现访问频率限制：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">--</span><br><span class="line">-- KEYS[1] 要限制的ip</span><br><span class="line">-- ARGV[1] 限制的访问次数</span><br><span class="line">-- ARGV[2] 限制的时间</span><br><span class="line">--</span><br><span class="line"></span><br><span class="line">local key = &quot;rate.limit:&quot; .. KEYS[1]</span><br><span class="line">local limit = tonumber(ARGV[1])</span><br><span class="line">local expire_time = ARGV[2]</span><br><span class="line"></span><br><span class="line">local is_exists = redis.call(&quot;EXISTS&quot;, key)</span><br><span class="line">if is_exists == 1then</span><br><span class="line">    if redis.call(&quot;INCR&quot;, key) &gt; limit then</span><br><span class="line">        return0</span><br><span class="line">    else</span><br><span class="line">        return1</span><br><span class="line">    end</span><br><span class="line">else</span><br><span class="line">    redis.call(&quot;SET&quot;, key, 1)</span><br><span class="line">    redis.call(&quot;EXPIRE&quot;, key, expire_time)</span><br><span class="line">    return1</span><br><span class="line">end</span><br></pre></td></tr></table></figure></div>

<p>使用方法，通过：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">eval(file_get_contents(storage_path(&quot;limit.lua&quot;)), 3, &quot;127.0.0.1&quot;, &quot;3&quot;, &quot;100&quot;);</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>
<p>redis 的事务与 Lua，就先介绍到这里了，更多的用法大家请查看 Lua 官方文档</p>
<h3 id="Bitmaps"><a href="#Bitmaps" class="headerlink" title="Bitmaps"></a>Bitmaps</h3><p>许多开发语言都提供了操作位的功能，合理地使用位能够有效地提高内存使用率和开发效率。Redis 提供了 Bitmaps 这个“数据结构”可以实现对位的操作。把数据结构加上引号主要因为：</p>
<ul>
<li>Bitmaps 本身不是一种数据结构，实际上它就是字符串，但是它可以对字符串的位进行操作。</li>
<li>Bitmaps 单独提供了一套命令，所以在 Redis 中使用 Bitmaps 和使用字符串的方法不太相同。可以把 Bitmaps 想象成一个以位为单位的数组，数组的每个单元只能存储 0 和 1，数组的下标在 Bitmaps 中叫做偏移量。<br>在我们平时开发过程中，会有一些 bool 型数据需要存取，比如用户一年的签到记录， 签了是 1，没签是 0，要记录 365 天。如果使用普通的 key/value，每个用户要记录 365 个，当用户上亿的时候，需要的存储空间是惊人的。为了解决这个问题，Redis 提供了位图数据结构，这样每天的签到记录只占据一个位， 365 天就是 365 个位，46 个字节 (一个稍长一点的字符串) 就可以完全容纳下，这就大大节约了存储空间。</li>
</ul>
<p>语法：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">setbit key offset value  # 设置或者清空 key 的 value(字符串)在 offset 处的 bit 值</span><br><span class="line">getbit key offset  # 返回 key 对应的 string 在 offset 处的 bit 值</span><br><span class="line">bitcount key [start end] # start end 范围内被设置为1的数量，不传递 start end 默认全范围</span><br></pre></td></tr></table></figure></div>
<p>使用案例，统计用户登录（活跃）情况</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">127.0.0.1:6379&gt; setbit userLogin:2021-04-10 66666 1 #userId=66666的用户登录，这是今天登录的第一个用户。</span><br><span class="line">(integer) 0</span><br><span class="line">127.0.0.1:6379&gt; setbit userLogin:2021-04-10 999999 1 #userId=999999的用户登录，这是今天第二个登录、的用户。</span><br><span class="line">(integer) 0</span><br><span class="line">127.0.0.1:6379&gt; setbit userLogin:2021-04-10 3333 1</span><br><span class="line">(integer) 0</span><br><span class="line">127.0.0.1:6379&gt; setbit userLogin:2021-04-10 8888 1</span><br><span class="line">(integer) 0</span><br><span class="line">127.0.0.1:6379&gt; setbit userLogin:2021-04-10 100000 1</span><br><span class="line">(integer) 0</span><br><span class="line"></span><br><span class="line">127.0.0.1:6379&gt; getbit userLogin:2021-04-10 66666</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; getbit userLogin:2021-04-10 55555</span><br><span class="line">(integer)</span><br><span class="line"></span><br><span class="line">127.0.0.1:6379&gt; bitcount userLogin:2021-04-10</span><br><span class="line">(integer) 5</span><br></pre></td></tr></table></figure></div>

<p>由于 bit 数组的每个位置只能存储 0 或者 1 这两个状态；所以对于实际生活中，处理两个状态的业务场景就可以考虑使用 bitmaps。如用户登录/未登录，签到/未签到，关注/未关注，打卡/未打卡等。同时 bitmap 还通过了相关的统计方法进行快速统计。</p>
<h3 id="HyperLogLog"><a href="#HyperLogLog" class="headerlink" title="HyperLogLog"></a>HyperLogLog</h3><p>HyperLogLog 并不是一种新的数据结构（实际类型为字符串类型），而 是一种基数算法，通过 HyperLogLog 可以利用极小的内存空间完成独立总数的统计，数据集可以是 IP、Email、ID 等。</p>
<p>HyperLogLog 提供了 3 个命令：pfadd、pfcount、pfmerge。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 用于向 HyperLogLog 添加元素</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 如果 HyperLogLog 估计的近似基数在 PFADD 命令执行之后出现了变化， 那么命令返回 1 ， 否则返回 0</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 如果命令执行时给定的键不存在， 那么程序将先创建一个空的 HyperLogLog 结构， 然后再执行命令</span></span><br><span class="line">pfadd key value1 [value2 value3]</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> PFCOUNT 命令会给出 HyperLogLog 包含的近似基数</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 在计算出基数后， PFCOUNT 会将值存储在 HyperLogLog 中进行缓存，知道下次 PFADD 执行成功前，就都不需要再次进行基数的计算。</span></span><br><span class="line">pfcount key</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> PFMERGE 将多个 HyperLogLog 合并为一个 HyperLogLog ， 合并后的 HyperLogLog 的基数接近于所有输入 HyperLogLog 的并集基数。</span></span><br><span class="line">pfmerge destkey key1 key2 [...keyn]</span><br><span class="line">127.0.0.1:6379&gt; pfadd totaluv user1</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; pfcount totaluv</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; pfadd totaluv user2</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; pfcount totaluv</span><br><span class="line">(integer) 2</span><br><span class="line">127.0.0.1:6379&gt; pfadd totaluv user3</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; pfcount totaluv</span><br><span class="line">(integer) 3</span><br><span class="line">127.0.0.1:6379&gt; pfadd totaluv user4</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; pfcount totaluv</span><br><span class="line">(integer) 4</span><br><span class="line">127.0.0.1:6379&gt; pfadd totaluv user5</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; pfcount totaluv</span><br><span class="line">(integer) 5</span><br><span class="line">127.0.0.1:6379&gt; pfadd totaluv user6 user7 user8 user9 user10</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; pfcount totaluv</span><br><span class="line">(integer) 10</span><br></pre></td></tr></table></figure></div>

<p>HyperLogLog 内存占用量非常小，但是存在错误率，开发者在进行数据 229 结构选型时只需要确认如下两条即可：</p>
<p> 1,只为了计算独立总数，不需要获取单条数据。<br> 2,可以容忍一定误差率，毕竟 HyperLogLog 在内存的占用量上有很大的优势。</p>
<p>例如：如果你负责开发维护一个大型的网站，有一天老板找产品经理要网站每个网页每天的 UV 数据，然后让你来开发这个统计模块，你会如何实现?</p>
<p>如果统计 PV 那非常好办，给每个网页一个独立的 Redis 计数器就可以了，这个计数器 的 key 后缀加上当天的日期。这样来一个请求，incrby 一次，最终就可以统计出所有的 PV 数据。</p>
<p>但是 UV 不一样，它要去重，同一个用户一天之内的多次访问请求只能计数一次。这就 要求每一个网页请求都需要带上用户的 ID，无论是登录用户还是未登录用户都需要一个唯一 ID 来标识。</p>
<p>你也许已经想到了一个简单的方案，那就是为每一个页面一个独立的 set 集合来存储所 有当天访问过此页面的用户 ID。当一个请求过来时，我们使用 sadd 将用户 ID 塞进去就可 以了。通过 scard 可以取出这个集合的大小，这个数字就是这个页面的 UV 数据。没错，这是一个非常简单的方案。</p>
<p>但是，如果你的页面访问量非常大，比如一个爆款页面几千万的 UV，你需要一个很大 的 set 集合来统计，这就非常浪费空间。如果这样的页面很多，那所需要的存储空间是惊人 的。为这样一个去重功能就耗费这样多的存储空间，值得么?其实老板需要的数据又不需要 太精确，105w 和 106w 这两个数字对于老板们来说并没有多大区别，So，有没有更好的解 决方案呢?</p>
<p>Redis 提供了 HyperLogLog 数据结构就是用来解决 这种统计问题的。HyperLogLog 提供不精确的去重计数方案，虽然不精确但是也不是非常不精确，标准误差是 0.81%，这样的精确度已经可以满足上面的 UV 统计需求了。</p>
<p>对于上面的场景，同学们可能有疑问，我或许同样可以使用 HashMap、BitMap 和 HyperLogLog 来解决。对于这三种解决方案，这边做下对比：</p>
<ul>
<li>HashMap：算法简单，统计精度高，对于少量数据建议使用，但是对于大量的数据会占用很大内存空间；</li>
<li>BitMap：位图算法，具体内容可以参考我的这篇文章，统计精度高，虽然内存占用要比 HashMap 少，但是对于大量数据还是会占用较大内存；</li>
<li>HyperLogLog：存在一定误差，占用内存少，稳定占用 12k 左右内存，可以统计 2^64 个元素，对于上面举例的应用场景，建议使用。</li>
</ul>
<h3 id="发布订阅"><a href="#发布订阅" class="headerlink" title="发布订阅"></a>发布订阅</h3><p>Redis 提供了基于“发布/订阅”模式的消息机制，此种模式下，消息发布者和订阅者不进行直接通信，发布者客户端向指定的频道（channel）发布消 息，订阅该频道的每个客户端都可以收到该消息：</p>
<p><img src="/2022/07/12/uncatalog/cl5hsfpv60000m4r706d63234/64022.jpg" alt="img"></p>
<p>主要对应的 Redis 命令为:</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">subscribe channel [channel ...] # 订阅一个或多个频道</span><br><span class="line">unsubscribe channel # 退订指定频道</span><br><span class="line">publish channel message # 发送消息</span><br><span class="line">psubscribe pattern # 订阅指定模式</span><br><span class="line">punsubscribe pattern # 退订指定模式</span><br></pre></td></tr></table></figure></div>
<p>使用案例：</p>
<p>打开一个 Redis 客户端，如向 TestChanne 说一声 hello:</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">127.0.0.1:6379&gt; publish TestChanne hello</span><br><span class="line">(integer) 1 # 返回的是接收这条消息的订阅者数量</span><br></pre></td></tr></table></figure></div>
<p>这样消息就发出去了。发出去的消息不会被持久化，也就是有客户端订阅 TestChanne 后只能接收到后续发布到该频道的消息，之前的就接收不到了。</p>
<p>打开另一 Redis 个客户端，这里假设发送消息之前就打开并且订阅了 TestChanne 频道：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">127.0.0.1:6379&gt; subscribe TestChanne # 执行上面命令客户端会进入订阅状态</span><br><span class="line">Reading messages... (press Ctrl-C to quit)</span><br><span class="line">1) &quot;subscribe&quot; // 消息类型</span><br><span class="line">2) &quot;TestChanne&quot; // 频道</span><br><span class="line">3) &quot;hello&quot; // 消息内容</span><br></pre></td></tr></table></figure></div>

<p>我们可以利用 Redis 发布订阅功能，实现的简单 MQ 功能，实现上下游的解耦。不过需要注意了，由于 Redis 发布的消息不会被持久化，这就会导致新订阅的客户端将不会收到历史消息。所以，如果当前的业务场景不能容忍这些缺点，那还是用专业 MQ 吧。</p>
<h3 id="GEO"><a href="#GEO" class="headerlink" title="GEO"></a>GEO</h3><p>Redis3.2 版本提供了 GEO（地理信息定位）功能，支持存储地理位置信 息用来实现诸如附近位置、摇一摇这类依赖于地理位置信息的功能，对于需 要实现这些功能的开发者来说是一大福音。GEO 功能是 Redis 的另一位作者 Matt Stancliff 借鉴 NoSQL 数据库 Ardb 实现的，Ardb 的作者来自中国，它提供了优秀的 GEO 功能。</p>
<p>Redis GEO 相关的命令如下：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 添加一个空间元素,longitude、latitude、member分别是该地理位置的经度、纬度、成员</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 这里的成员就是指代具体的业务数据，比如说用户的ID等</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 需要注意的是Redis的纬度有效范围不是[-90,90]而是[-85,85]</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 如果在添加一个空间元素时，这个元素中的menber已经存在key中，那么GEOADD命令会返回0,相当于更新了这个menber的位置信息</span></span><br><span class="line">GEOADD key longitude latitude member [longitude latitude member]</span><br><span class="line"><span class="meta">#</span><span class="bash"> 用于添加城市的坐标信息</span></span><br><span class="line">geoadd cities:locations 117.12 39.08 tianjin 114.29 38.02 shijiazhuang 118.01 39.38 tangshan 115.29 38.51 baoding</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 获取地理位置信息</span></span><br><span class="line">geopos key member [member ...]</span><br><span class="line"><span class="meta">#</span><span class="bash"> 获取天津的坐标</span></span><br><span class="line">geopos cities:locations tianjin</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 获取两个坐标之间的距离</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> unit代表单位，有4个单位值</span></span><br><span class="line">  - m (meter) 代表米</span><br><span class="line">  - km （kilometer）代表千米</span><br><span class="line">  - mi （miles）代表英里</span><br><span class="line">  - ft （ft）代表尺</span><br><span class="line">geodist key member1 member2 [unit]</span><br><span class="line"><span class="meta">#</span><span class="bash"> 获取天津和保定之间的距离</span></span><br><span class="line">GEODIST cities:locations tianjin baoding km</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 获取指定位置范围内的地理信息位置集合，此命令可以用于实现附近的人的功能</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> georadius和georadiusbymember两个命令的作用是一样的，都是以一个地理位置为中心算出指定半径内的其他地理信息位置，不同的是georadius命令的中心位置给出了具体的经纬度，georadiusbymember只需给出成员即可。其中radiusm|km|ft|mi是必需参数，指定了半径（带单位），这两个命令有很多可选参数，参数含义如下：</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> - withcoord：返回结果中包含经纬度。</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> - withdist：返回结果中包含离中心节点位置的距离。</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> - withhash：返回结果中包含geohash，有关geohash后面介绍。</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> - COUNT count：指定返回结果的数量。</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> - asc|desc：返回结果按照离中心节点的距离做升序或者降序。</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> - store key：将返回结果的地理位置信息保存到指定键。</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> - storedist key：将返回结果离中心节点的距离保存到指定键。</span></span><br><span class="line">georadius key longitude latitude radiusm|km|ft|mi [withcoord] [withdist] [withhash] [COUNT count] [asc|desc] [store key] [storedist key]</span><br><span class="line"></span><br><span class="line">georadiusbymember key member radiusm|km|ft|mi [withcoord] [withdist] [withhash] [COUNT count] [asc|desc] [store key] [storedist key]</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 获取geo <span class="built_in">hash</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Redis使用geohash将二维经纬度转换为一维字符串，geohash有如下特点：</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> - GEO的数据类型为zset，Redis将所有地理位置信息的geohash存放在zset中。</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> - 字符串越长，表示的位置更精确，表3-8给出了字符串长度对应的精度，例如geohash长度为9时，精度在2米左右。长度和精度的对应关系，请参考：https://easyreadfs.nosdn.127.net/9F42_CKRFsfc8SUALbHKog==/8796093023252281390</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> - 两个字符串越相似，它们之间的距离越近，Redis利用字符串前缀匹配算法实现相关的命令。</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> - geohash编码和经纬度是可以相互转换的。</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> - Redis正是使用有序集合并结合geohash的特性实现了GEO的若干命令。</span></span><br><span class="line">geohash key member [member ...]</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 删除操作，GEO没有提供删除成员的命令，但是因为GEO的底层实现是zset，所以可以借用zrem命令实现对地理位置信息的删除。</span></span><br><span class="line">zrem key member</span><br></pre></td></tr></table></figure></div>

<p>使用案例，例如咋部门是做直播的，那直播业务一般会有一个“附近的直播”功能，这里就可以考虑用 Redis 的 GEO 技术来完成这个功能。</p>
<p>数据操作主要有两个：一是主播开播的时候写入主播 Id 的经纬度，二是主播关播的时候删除主播 Id 元素。这样就维护了一个具有位置信息的在线主播集合提供给线上检索。</p>
<p>大家具体使用的时候，可以去了解一下 Redis GEO 原理，主要用到了空间索引的算法 GEOHASH 的相关知识，针对索引我们日常所见都是一维的字符，那么如何对三维空间里面的坐标点建立索引呢，直接点就是三维变二维，二维变一维。这里就不再详细阐述了。</p>
<h3 id="Redis-客户端"><a href="#Redis-客户端" class="headerlink" title="Redis 客户端"></a>Redis 客户端</h3><p>主流编程语言都有对应的常用 Redis 客户端，例如：</p>
<p>go -&gt; go redis<br>java -&gt; Jedis<br>python -&gt; redis-py<br>node -&gt; ioredis<br>具体使用语法，大家可以根据自己的需要查找对应的官方文档：</p>
<p>Jedis 文档：<a href="https://github.com/redis/jedis">https://github.com/redis/jedis</a></p>
<p>redis-py 文档：<a href="https://github.com/redis/redis-py">https://github.com/redis/redis-py</a></p>
<p>ioredis 文档：<a href="https://github.com/luin/ioredis">https://github.com/luin/ioredis</a><br>go redis 文档：<a href="https://redis.uptrace.dev/">https://redis.uptrace.dev/</a></p>
<h2 id="持久化、主从同步与缓存设计"><a href="#持久化、主从同步与缓存设计" class="headerlink" title="持久化、主从同步与缓存设计"></a>持久化、主从同步与缓存设计</h2><h3 id="持久化"><a href="#持久化" class="headerlink" title="持久化"></a>持久化</h3><p>Redis 支持 RDB 和 AOF 两种持久化机制，持久化功能有效地避免因进程 退出造成的数据丢失问题，当下次重启时利用之前持久化的文件即可实现数据恢复。</p>
<ul>
<li>RDB 是一次全量备份，AOF 日志是连续的增量备份， RDB 是内存数据的二进制序列化形式，在存储上非常紧凑，而 AOF 日志记录的是内存数据修改的指令记录文本。</li>
<li>AOF 以独立日志的方式记录每次写命令， 重启时再重新执行 AOF 文件中的命令达到恢复数据的目的。AOF 的主要作用 是解决了数据持久化的实时性，目前已经是 Redis 持久化的主流方式。</li>
</ul>
<p>AOF 日志在长期的运行过程中会变的无比庞大，数据库重启时需要加载 AOF 日志进行指令重放，这个时间就会无比漫长。所以需要定期进行 AOF 重写，给 AOF 日志进行瘦身。</p>
<h4 id="RDB"><a href="#RDB" class="headerlink" title="RDB"></a>RDB</h4><p>我们知道 Redis 是单线程程序，这个线程要同时负责多个客户端套接字的并发读写操作和内存数据结构的逻辑读写。</p>
<p>在服务线上请求的同时，Redis 还需要进行内存 RDB，内存 RDB 要求 Redis 必须进行文件 IO 操作，可文件 IO 操作是不能使用多路复用 API。这意味着单线程同时在服务线上的请求还要进行文件 IO 操作，文件 IO 操作会严重拖垮服务器请求的性能。还有个重要的问题是为了不阻塞线上的业务，就需要边持久化边响应客户端请求。持久化的同时，内存数据结构还在改变，比如一个大型的 hash 字典正在持久化，结果一个请求过来把它给删掉了，还没持久化完呢，这可怎么办?</p>
<p>那该怎么办呢? Redis 使用操作系统的多进程 COW(Copy On Write) 机制来实现 RDB 持久化，以下为 RDB 备份流程：<br><img src="/2022/07/12/uncatalog/cl5hsfpv60000m4r706d63234/64024.jpg" alt="img"><br>1，执行 bgsave 命令，Redis 父进程判断当前是否存在正在执行的子进 程，如 RDB/AOF 子进程，如果存在 bgsave 命令直接返回。<br>2，父进程执行 fork 操作创建子进程，fork 操作过程中父进程会阻塞，通 过 info stats 命令查看 latest_fork_usec 选项，可以获取最近一个 fork 操作的耗 时，单位为微秒。<br>3，父进程 fork 完成后，bgsave 命令返回 “Background saving started” 信息 并不再阻塞父进程，可以继续响应其他命令。<br>4，子进程创建 RDB 文件，根据父进程内存生成临时快照文件，完成后 对原有文件进行原子替换。执行 lastsave 命令可以获取最后一次生成 RDB 的 时间，对应 info 统计的 rdb_last_save_time 选项。<br>5，进程发送信号给父进程表示完成，父进程更新统计信息，具体见 info Persistence 下的 rdb_* 相关选项</p>
<h4 id="AOF"><a href="#AOF" class="headerlink" title="AOF"></a>AOF</h4><p>AOF 日志存储的是 Redis 服务器的顺序指令序列，AOF 日志只记录对内存进行修改的 指令记录。</p>
<p>假设 AOF 日志记录了自 Redis 实例创建以来所有的修改性指令序列，那么就可以通过 对一个空的 Redis 实例顺序执行所有的指令，也就是「重放」，来恢复 Redis 当前实例的内 存数据结构的状态。</p>
<p>Redis 会在收到客户端修改指令后，先进行参数校验，如果没问题，就立即将该指令文本存储到 AOF 日志中，也就是先存到磁盘，然后再执行指令。这样即使遇到突发宕机，已经存储到 AOF 日志的指令进行重放一下就可以恢复到宕机前的状态。通过 appendfsync 参数可以控制实时/秒级持久化 。</p>
<p>AOF 流程:</p>
<p><img src="/2022/07/12/uncatalog/cl5hsfpv60000m4r706d63234/64025.jpg" alt="img"></p>
<p> 1，所有的写入命令会追加到 aof_buf(缓冲区)中。<br> 2，AOF 缓冲区根据对应的策略向硬盘做同步操作。<br> 3，随着 AOF 文件越来越大，需要定期对 AOF 文件进行重写，达到压缩的目的。<br> 4，当 Redis 服务器重启时，可以加载 AOF 文件进行数据恢复。</p>
<p>Redis 在长期运行的过程中，AOF 的日志会越变越长。如果实例宕机重启，重放整个 AOF 日志会非常耗时，导致长时间 Redis 无法对外提供服务。所以需要对 AOF 日志瘦身。</p>
<p>Redis 提供了 bgrewriteaof 指令用于对 AOF 日志进行瘦身。其原理就是开辟一个子进程对内存进行遍历转换成一系列 Redis 的操作指令，序列化到一个新的 AOF 日志文件中。序列化完毕后再将操作期间发生的增量 AOF 日志追加到这个新的 AOF 日志文件中，追加完毕后就立即替代旧的 AOF 日志文件了，瘦身工作就完成了。</p>
<p>AOF 瘦身重写流程：</p>
<p><img src="/2022/07/12/uncatalog/cl5hsfpv60000m4r706d63234/64026.jpg" alt="img"></p>
<p>AOF 重写可以通过 auto-aof-rewrite-min-siz e 和 auto-aof-rewrite- percentage 参数控制自动触发，也可以使用 bgrewriteaof 命令手动触发。</p>
<p>子进程执行期间使用 copy-on-write 机制与父进程共享内存，避免内 存消耗翻倍。AOF 重写期间还需要维护重写缓冲区，保存新的写入命令避免 数据丢失。</p>
<p>单机下部署多个实例时，为了防止出现多个子进程执行重写操作， 建议做隔离控制，避免 CPU 和 IO 资源竞争。</p>
<h4 id="Redis-4-0-混合持久化"><a href="#Redis-4-0-混合持久化" class="headerlink" title="Redis 4.0 混合持久化"></a>Redis 4.0 混合持久化</h4><p>重启 Redis 时，我们很少使用 RDB 来恢复内存状态，因为会丢失大量数据。我们通常 使用 AOF 日志重放，但是重放 AOF 日志性能相对 rdb 来说要慢很多，这样在 Redis 实 例很大的情况下，启动需要花费很长的时间。</p>
<p>Redis 4.0 为了解决这个问题，带来了一个新的持久化选项——混合持久化。将 RDB 文 件的内容和增量的 AOF 日志文件存在一起。这里的 AOF 日志不再是全量的日志，而是自 持久化开始到持久化结束的这段时间发生的增量 AOF 日志，通常这部分 AOF 日志很小。</p>
<p>于是在 Redis 重启的时候，可以先加载 RDB 的内容，然后再重放增量 AOF 日志就可 以完全替代之前的 AOF 全量文件重放，重启效率因此大幅得到提升。<br><img src="/2022/07/12/uncatalog/cl5hsfpv60000m4r706d63234/64027.jpg" alt="img"></p>
<h2 id="主从同步—简单了解"><a href="#主从同步—简单了解" class="headerlink" title="主从同步—简单了解"></a>主从同步—简单了解</h2><p>很多企业都没有使用到 Redis 的集群，但是至少都做了主从。有了主从，当 master 挂 掉的时候，运维让从库过来接管，服务就可以继续，否则 master 需要经过数据恢复和重启的过程，这就可能会拖很长的时间，影响线上业务的持续服务。</p>
<p>Redis 通过主从同步功能实现主节点的多个副本。从节点可灵活地通过 slaveof 命令建立或断开同步流程。同步复制分为：全量复制和部分增量复制主从节点之间维护心跳和偏移量检查机制，保证主从节点通信正常和数据一致。</p>
<p>Redis 为了保证高性能复制过程是异步的，写命令处理完后直接返回给客户端，不等待从节点复制完成。因此从节点数据集会有延迟情况。即当使用从节点用于读写分离时会存在数据延迟、过期数据、从节点可用性等问题，需要根据自身业务提前作出规避。</p>
<p>注意：在运维过程中，主节点存在多个从节点或者一台机器上部署大量主节点的情况下，会有复制风暴的风险。</p>
<h3 id="Redis-Sentinel-哨兵"><a href="#Redis-Sentinel-哨兵" class="headerlink" title="Redis Sentinel(哨兵)"></a>Redis Sentinel(哨兵)</h3><p>主从复制是 Redis 分布式的基础，Redis 的高可用离开了主从复制将无从进行。后面的我们会讲到 Redis 的集群模式，集群模式都依赖于本节所讲的主从复制。</p>
<p>不过复制功能也不是必须的，如果你将 Redis 只用来做缓存，也就无需要从库做备份，挂掉了重新启动一下就行。但是只要你使用了 Redis 的持久化 功能，就必须认真对待主从复制，它是系统数据安全的基础保障。</p>
<p>举例：如果主节点凌晨 3 点突发宕机怎么办?就坐等运维从床上爬起来，然后手工进行从主切换，再通知所有的程 序把地址统统改一遍重新上线么?毫无疑问，这样的人工运维效率太低，事故发生时估计得 至少 1 个小时才能缓过来。</p>
<p>Sentinel 负责持续监控主从节点的健康，当主节点挂掉时，自动选择一个最优的从节点切换为主节点。客户端来连接集群时，会首先连接 sentinel，通过 sentinel 来查询主节点的地址， 然后再去连接主节点进行数据交互。当主节点发生故障时，客户端会重新向 sentinel 要地址，sentinel 会将最新的主节点地址告诉客户端。如此应用程序将无需重启即可自动完成节点切换。如图</p>
<p><img src="/2022/07/12/uncatalog/cl5hsfpv60000m4r706d63234/64028.jpg" alt="img"><br><img src="/2022/07/12/uncatalog/cl5hsfpv60000m4r706d63234/64029.jpg" alt="img"></p>
<h3 id="消息丢失"><a href="#消息丢失" class="headerlink" title="消息丢失"></a>消息丢失</h3><p>Redis 主从采用异步复制，意味着当主节点挂掉时，从节点可能没有收到全部的同步消息，这部分未同步的消息就丢失了。如果主从延迟特别大，那么丢失的数据就可能会特别 多。Sentinel 无法保证消息完全不丢失，但是也尽可能保证消息少丢失。它有两个选项可以 限制主从延迟过大：</p>
<ul>
<li>min-slaves-to-write 1</li>
<li>min-slaves-max-lag 10<br>第一个参数表示主节点必须至少有一个从节点在进行正常复制，否则就停止对外写服务，丧失可用性。</li>
</ul>
<p>何为正常复制，何为异常复制?这个就是由第二个参数控制的，它的单位是秒，表示如果 10s 没有收到从节点的反馈，就意味着从节点同步不正常，要么网络断开了，要么一直没有给反馈。</p>
<h3 id="Redis-最终一致"><a href="#Redis-最终一致" class="headerlink" title="Redis 最终一致"></a>Redis 最终一致</h3><p>Redis 的主从数据是异步同步的，所以分布式的 Redis 系统并不满足「一致性」要求。当客户端在 Redis 的主节点修改了数据后，立即返回，即使在主从网络断开的情况下，主节 点依旧可以正常对外提供修改服务，所以 Redis 满足「可用性」。</p>
<p>Redis 保证「最终一致性」，从节点会努力追赶主节点，最终从节点的状态会和主节点 的状态将保持一致。如果网络断开了，主从节点的数据将会出现大量不一致，一旦网络恢 复，从节点会采用多种策略努力追赶上落后的数据，继续尽力保持和主节点一致。</p>
<h2 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a>缓存</h2><p>缓存的收益与成本<br>收益：</p>
<ul>
<li>加速读写：CPU L1/L2/L3 Cache、浏览器缓存等。因为缓存通常都是全内存的（例如 Redis、Memcache），而 存储层通常读写性能不够强悍（例如 MySQL），通过缓存的使用可以有效 地加速读写，优化用户体验。</li>
<li>降低后端负载：帮助后端减少访问量和复杂计算，在很大程度降低了后端的负载。成本：</li>
<li>数据不一致：缓存层和数据层有时间窗口不一致，和更新策略有关。</li>
<li>代码维护成本：加入缓存后，需要同时处理缓存层和存储层的逻辑， 增大了开发者维护代码的成本。</li>
<li>运维成本：以 Redis Cluster 为例，加入后无形中增加了运维成本。使用场景：</li>
<li>降低后端负载：对高消耗的 SQL：join 结果集/分组统计结果缓存。</li>
<li>加速请求响应：利用 Redis/Memcache 优化 IO 响应时间。</li>
<li>大量写合并为批量写：比如计数器先 Redis 累加再批量写入 DB。<br>缓存更新策略—算法剔除</li>
<li>LRU：Least Recently Used，最近最少使用。</li>
<li>LFU：Least Frequently Used，最不经常使用。</li>
<li>FIFO：First In First Out，先进先出。<br>使用场景：剔除算法通常用于缓存使用量超过了预设的最大值时候，如何对现有的数据进行剔除。例如 Redis 使用 maxmemory-policy 这个配置作为内存最大值后对于数据的剔除策略。</li>
</ul>
<p>一致性：要清理哪些数据是由具体算法决定，开发人员只能决定使用哪种算法，所以数据的一致性是最差的。</p>
<p>维护成本：算法不需要开发人员自己来实现，通常只需要配置最大 maxmemory 和对应的策略即可。</p>
<h4 id="缓存更新策略—超时剔除"><a href="#缓存更新策略—超时剔除" class="headerlink" title="缓存更新策略—超时剔除"></a>缓存更新策略—超时剔除</h4><p>使用场景：超时剔除通过给缓存数据设置过期时间，让其在过期时间后自动删除，例如 Redis 提供的 expire 命令。如果业务可以容忍一段时间内，缓存层数据和存储层数据不一致，那么可以为其设置过期时间。在数据过期后，再从真实数据源获取数据，重新放到缓存并设置过期时间。</p>
<p>一致性：一段时间窗口内（取决于过期时间长短）存在一致性问题，即缓存数据和真实数据源的数据不一致。</p>
<p>维护成本：维护成本不是很高，只需设置 expire 过期时间即可，当然前提是应用方允许这段时间可能发生的数据不一致。</p>
<h4 id="缓存更新策略—主动更新"><a href="#缓存更新策略—主动更新" class="headerlink" title="缓存更新策略—主动更新"></a>缓存更新策略—主动更新</h4><p>使用场景：应用方对于数据的一致性要求高，需要在真实数据更新后， 立即更新缓存数据。例如可以利用消息系统或者其他方式通知缓存更新。</p>
<p>一致性：一致性最高，但如果主动更新发生了问题，那么这条数据很可能很长时间不会更新，所以建议结合超时剔除一起使用效果会更好。</p>
<p>维护成本：维护成本会比较高，开发者需要自己来完成更新，并保证更新操作的正确性。</p>
<h4 id="缓存更新策略—总结"><a href="#缓存更新策略—总结" class="headerlink" title="缓存更新策略—总结"></a>缓存更新策略—总结</h4><p><img src="/2022/07/12/uncatalog/cl5hsfpv60000m4r706d63234/64030.jpg" alt="img"></p>
<p>低一致性业务：建议配置最大内存和淘汰策略的方式使用。</p>
<p>高一致性业务：可以结合使用超时剔除和主动更新，这样即使主动更新出了问题，也能保证数据过期时间后删除脏数据。</p>
<h4 id="缓存可能会遇到的问题"><a href="#缓存可能会遇到的问题" class="headerlink" title="缓存可能会遇到的问题"></a>缓存可能会遇到的问题</h4><p>缓存穿透：指查询一个一定不存在的数据，由于缓存是不命中时被动写的，并且出于容错考虑，如果从存储层查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到存储层去查询，失去了缓存的意义。在流量大时，可能 DB 就挂掉了，要是有人利用不存在的 key 频繁攻击我们的应用，这就是漏洞。解决方法：</p>
<ul>
<li>布隆过滤器，将所有可能存在的数据哈希到一个足够大的 bitmap 中，一个一定不存在的数据会被 这个 bitmap 拦截掉，从而避免了对底层存储系统的查询压力。</li>
<li>另外也有一个更为简单粗暴的方法（我们采用的就是这种），如果一个查询返回的数据为空（不管是数 据不存在，还是系统故障），我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。<br>缓存雪崩：指在我们设置缓存时采用了相同的过期时间，导致缓存在某一时刻同时失效，请求全部转发到 DB，DB 瞬时压力过重雪崩。解决方法：我们可以在原有的失效时间基础上增加一个随机值，比如 1-5 分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。</li>
</ul>
<p>缓存击穿：对于一些设置了过期时间的 key，如果这些 key 可能会在某些时间点被超高并发地访问，是一种非常“热点”的数据。这个时候，需要考虑一个问题：缓存被“击穿”的问题，这个和缓存雪崩的区别在于这里针对某一 key 缓存，前者则是很多 key。缓存在某个时间点过期的时候，恰好在这个时间点对这个 Key 有大量的并发请求过来，这些请求发现缓存过期一般都会从后端 DB 加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端 DB 压垮。解决方法：互斥锁、永远不过期设置、资源保护等等。</p>
<p>缓存无底洞问题：Facebook 的工作人员反应 2010 年已达到 3000 个 memcached 节点，储存数千 G 的缓存。他们发现一个问题– memcached 的连接效率下降了，于是添加 memcached 节点，添加完之后，并没有好转。称为“无底洞”现象。原因：客户端一次批量操作会涉及多次网络操作，也就意味着批量操作会随着实例的增多，耗时会不断增大。服务端网络连接次数变多，对实例的性能也有一定影响。即：更多的机器不代表更多的性能，所谓“无底洞”就是说投入越多不一定产出越多。解决方案有：串行 mget、串行 IO、并行 IO、Hash tag 实现等，更多请看：缓存无底洞问题（<a href="http://ifeve.com/redis-multiget-hole/%EF%BC%89">http://ifeve.com/redis-multiget-hole/）</a></p>
<h2 id="知识拓展"><a href="#知识拓展" class="headerlink" title="知识拓展"></a>知识拓展</h2><h3 id="缓存与数据库同步策略（如何保证缓存-Redis-与数据库-MySQL-的一致性？）"><a href="#缓存与数据库同步策略（如何保证缓存-Redis-与数据库-MySQL-的一致性？）" class="headerlink" title="缓存与数据库同步策略（如何保证缓存(Redis)与数据库(MySQL)的一致性？）"></a>缓存与数据库同步策略（如何保证缓存(Redis)与数据库(MySQL)的一致性？）</h3><p>对于热点数据（经常被查询，但不经常被修改的数据），我们一般会将其放入 Redis 缓存中，以增加查询效率，但需要保证从 Redis 中读取的数据与数据库中存储的数据最终是一致的，这就是经典的缓存与数据库同步问题。</p>
<p>那么，如何保证缓存(Redis)与数据库(MySQL)的一致性呢？根据缓存是删除还是更新，以及操作顺序大概是可以分为下面四种情况：</p>
<ul>
<li>先更新数据库，再更新缓存 </li>
<li>先更新缓存，再更新数据库</li>
<li>先删除缓存，再更新数据库</li>
<li>先更新数据库，再删除缓存<br>删除缓存对比更新缓存</li>
<li>删除缓存: 数据只会写入数据库，不会写入缓存，只会删除缓存</li>
<li>更新缓存: 数据不但写入数据库，还会写入缓存<br>删除缓存</li>
<li>优点：操作简单，无论更新操作是否复杂，直接删除，并且能防止更新出现的线程安全问题</li>
<li>缺点：删除后，下一次查询无法在 cache 中查到，会有一次 Cache Miss，这时需要重新读取数据库，高并发下可能会出现上面说的缓存问题</li>
</ul>
<p>更新缓存</p>
<ul>
<li><p>优点：命中率高，直接更新缓存，不会有 Cache Miss 的情况</p>
</li>
<li><p>缺点：更新缓存消耗较大，尤其在复杂的操作流程中<br>那到底是选择更新缓存还是删除缓存呢，主要取决于更新缓存的复杂度</p>
</li>
<li><p>更新缓存的代价很小，此时我们应该更倾向于更新缓存，以保证更高的缓存命中率</p>
</li>
<li><p>更新缓存的代价很大，此时我们应该更倾向于删除缓存<br>例如：只是简单的更新一下用户积分，只操作一个字段，那就可以采用更新缓存，还有类似秒杀下商品库存数量这种并发下查询频繁的数据，也可以使用更新缓存，不过也要注意线程安全的问题，防止产生脏数据。但是当更新操作的逻辑较复杂时，需要涉及到其它数据，如用户购买商品付款时，需要考虑打折、优惠券、红包等多种因素，这样需要缓存与数据库进行多次交互，将打折等信息传入缓存，再与缓存中的其它值进行计算才能得到最终结果，此时更新缓存的消耗要大于直接淘汰缓存。</p>
</li>
</ul>
<p>所以还是要根据业务场景来进行选择，不过大部分场景下删除缓存操作简单，并且带来的副作用只是增加了一次 Cache Miss，建议作为通用的处理方式。</p>
<h3 id="先更新数据库，再更新缓存"><a href="#先更新数据库，再更新缓存" class="headerlink" title="先更新数据库，再更新缓存"></a>先更新数据库，再更新缓存</h3><p>这种方式就适合更新缓存的代价很小的数据，例如上面说的用户积分，库存数量这类数据，同样还是要注意线程安全的问题。</p>
<h4 id="线程安全角度"><a href="#线程安全角度" class="headerlink" title="线程安全角度"></a>线程安全角度</h4><p>同时有请求 A 和请求 B 进行更新操作，那么会出现</p>
<p> 1，线程 A 更新了数据库<br> 2，线程 B 更新了数据库<br> 3，线程 B 更新了缓存<br> 4，线程 A 更新了缓存<br>这就出现请求 A 更新缓存应该比请求 B 更新缓存早才对，但是因为网络等原因，B 却比 A 更早更新了缓存，这就导致了脏数据。</p>
<h4 id="业务场景角度"><a href="#业务场景角度" class="headerlink" title="业务场景角度"></a>业务场景角度</h4><p>有如下两种不适合场景：</p>
<p> 1，如果你是一个写数据库场景比较多，而读数据场景比较少的业务需求，采用这种方案就会导致，数据压根还没读到，缓存就被频繁的更新，浪费性能<br> 2，如果你写入数据库的值，并不是直接写入缓存的，而是要经过一系列复杂的计算再写入缓存。那么，每次写入数据库后，都再次计算写入缓存的值，无疑是也浪费性能的</p>
<h3 id="先更新缓存，再更新数据库"><a href="#先更新缓存，再更新数据库" class="headerlink" title="先更新缓存，再更新数据库"></a>先更新缓存，再更新数据库</h3><p>这种情况应该是和第一种情况一样会存在线程安全问题的，但是这种情况是有人使用过的，根据书籍《淘宝技术这十年》里，多隆把商品详情页放入缓存，采取的正是先更新缓存，再将缓存中的数据异步更新到数据库这种方式，有兴趣了解的可以查看这篇博客: <a href="https://www.cnblogs.com/rjzheng/p/9240611.html">https://www.cnblogs.com/rjzheng/p/9240611.html</a></p>
<p>还有现在互联网常见的点赞功能，也可以采用这种方式，有兴趣了解的可以查看这篇文章: <a href="https://juejin.im/post/5bdc257e6fb9a049ba410098">https://juejin.im/post/5bdc257e6fb9a049ba410098</a></p>
<h3 id="先删除缓存，再更新数据库"><a href="#先删除缓存，再更新数据库" class="headerlink" title="先删除缓存，再更新数据库"></a>先删除缓存，再更新数据库</h3><p>简单的想一下，好像这种方式不错，就算是第一步删除缓存成功，第二步写数据库失败，则只会引发一次 Cache Miss，对数据没有影响，其实仔细一想并发下也很容易导致了脏数据，例如</p>
<p> 1，请求 A 进行写操作，删除缓存<br> 2，请求 B 查询发现缓存不存在<br> 3，请求 B 去数据库查询得到旧值<br> 4，请求 B 将旧值写入缓存<br> 5，请求 A 将新值写入数据库<br>那怎么解决呢，先看第四种情况（先更新数据库，再删除缓存），后面再统一说第三种和第四种的解决方案。</p>
<h3 id="先更新数据库，再删除缓存"><a href="#先更新数据库，再删除缓存" class="headerlink" title="先更新数据库，再删除缓存"></a>先更新数据库，再删除缓存</h3><p>先说一下，国外有人提出了一个缓存更新套路，名为 Cache-Aside Pattern：<a href="https://docs.microsoft.com/en-us/azure/architecture/patterns/cache-aside">https://docs.microsoft.com/en-us/azure/architecture/patterns/cache-aside</a></p>
<ul>
<li>失效：应用程序先从 cache 取数据，没有得到，则从数据库中取数据，成功后，放到缓存中</li>
<li>命中：应用程序从 cache 中取数据，渠道后返回</li>
<li>更新：先把数据存到数据库中，成功后再让缓存失效<br>更新操作就是先更新数据库，再删除缓存；读取操作先从缓存取数据，没有，则从数据库中取数据，成功后，放到缓存中；这是标准的设计方案，包括 Facebook 的论文 Scaling Memcache at Facebook：chrome-extension://ikhdkkncnoglghljlkmcimlnlhkeamad/pdf-viewer/web/viewer.html? file=https%3A%2F%2F<a href="http://www.usenix.org%2Fsystem%2Ffiles%2Fconference%2Fnsdi13%2Fnsdi13-final170_update.pdf">www.usenix.org%2Fsystem%2Ffiles%2Fconference%2Fnsdi13%2Fnsdi13-final170_update.pdf</a> 也使用了这个策略。</li>
</ul>
<p>为什么他们都用这种方式呢，这种情况不存在并发问题么?</p>
<p>答案是也存在，但是出现概率比第三种低，例如：</p>
<p> 1，请求缓存刚好失效<br> 2，请求 A 查询数据库，得一个旧值<br> 3，请求 B 将新值写入数据库<br> 4，请求 B 删除缓存<br> 5，请求 A 将查到的旧值写入缓存<br>这样就出现脏数据了，然而，实际上出现的概率可能非常低，因为这个条件需要发生在读缓存时缓存失效，而且并发着有一个写操作。而实际上数据库的写操作会比读操作慢得多，而且还要锁表，而读操作必需在写操作前进入数据库操作，而又要晚于写操作删除缓存，所有的这些条件都具备的概率基本并不大，但是还是会有出现的概率。</p>
<p>并且假如第一步写数据库成功，第二步删除缓存失败，这样也导致脏数据，请看解决方案。</p>
<h3 id="方案三四脏数据解决方案"><a href="#方案三四脏数据解决方案" class="headerlink" title="方案三四脏数据解决方案"></a>方案三四脏数据解决方案</h3><p>那怎么解决呢，可以采用延时双删策略(缓存双淘汰法)，可以将前面所造成的缓存脏数据，再次删除：</p>
<p> 1，先删除(淘汰)缓存<br> 2，再写数据库（这两步和原来一样）<br> 3，休眠 1 秒，再次删除(淘汰)缓存<br>或者是：</p>
<p> 1，先写数据库<br> 2，再删除(淘汰)缓存（这两步和原来一样）<br> 3，休眠 1 秒，再次删除(淘汰)缓存<br>这个 1 秒应该看你的业务场景，应该自行评估自己的项目的读数据业务逻辑的耗时，然后写数据的休眠时间则在读数据业务逻辑的耗时基础上，加几百毫秒即可，这么做确保读请求结束，写请求可以删除读请求造成的缓存脏数据。</p>
<p>如果你用了 MySql 的读写分离架构怎么办？，例如：</p>
<p> 1，请求 A 进行写操作，删除缓存<br> 2，请求 A 将数据写入数据库了，(或者是先更新数据库，后删除缓存)<br> 3，请求 B 查询缓存发现，缓存没有值<br> 4，请求 B 去从库查询，这时，还没有完成主从同步，因此查询到的是旧值<br> 5，请求 B 将旧值写入缓存<br> 6，数据库完成主从同步，从库变为新值<br>这种情景，就是数据不一致的原因，还是采用延时双删策略(缓存双淘汰法)，只是，休眠时间修改为在主从同步的延时时间基础上，加几百毫秒<br> 并且为了性能更快，可以把第二次删除缓存可以做成异步的，这样不会阻塞请求了，如果再严谨点，防止第二次删除缓存失败，这个异步删除缓存可以加上重试机制，失败一直重试，直到成功。</p>
<p>这里给出两种重试机制参考</p>
<h4 id="方案一"><a href="#方案一" class="headerlink" title="方案一"></a>方案一</h4><p> 1，更新数据库数据<br> 2，缓存因为种种问题删除失败<br> 3，将需要删除的 key 发送至消息队列<br> 4，自己消费消息，获得需要删除的 key<br> 5，继续重试删除操作，直到成功</p>
<p><img src="/2022/07/12/uncatalog/cl5hsfpv60000m4r706d63234/64031.jpg" alt="img"><br>然而，该方案有一个缺点，对业务线代码造成大量的侵入，于是有了方案二，启动一个订阅程序去订阅数据库的 Binlog，获得需要操作的数据。在应用程序中，另起一段程序，获得这个订阅程序传来的信息，进行删除缓存操作</p>
<h4 id="方案二："><a href="#方案二：" class="headerlink" title="方案二："></a>方案二：</h4><p> 1,更新数据库数据<br> 2,数据库会将操作信息写入 binlog 日志当中<br> 3,订阅程序提取出所需要的数据以及 key<br> 4,另起一段非业务代码，获得该信息<br> 5,尝试删除缓存操作，发现删除失败<br> 6,将这些信息发送至消息队列<br> 7,重新从消息队列中获得该数据，重试操作</p>
<p><img src="/2022/07/12/uncatalog/cl5hsfpv60000m4r706d63234/64032.jpg" alt="img"></p>
<p>上述的订阅 Binlog 程序在 MySql 中有现成的中间件叫 Canal，可以完成订阅 Binlog 日志的功能，另外，重试机制，这里采用的是消息队列的方式。如果对一致性要求不是很高，直接在程序中另起一个线程，每隔一段时间去重试即可，这些大家可以灵活自由发挥，只是提供一个思路。</p>
<p>总结： 大部分应该使用的都是第三种或第四种方式，如果都是采用延时双删策略(缓存双淘汰法)，可能区别不会很大，不过第四种方式出现脏数据概率是更小点，更多的话还是要结合自身业务场景使用，灵活变通。</p>
<h2 id="分布式锁"><a href="#分布式锁" class="headerlink" title="分布式锁"></a>分布式锁</h2><p>例如一个操作要修改用户的状态，修改状态需要先读出用户的状态，在内存里进行修 改，改完了再存回去。如果这样的操作同时进行了，就会出现并发问题，因为读取和保存状 态这两个操作不是原子的。（Wiki 解释：所谓原子操作是指不会被线程调度机制打断的操作；这种操作一旦开始，就一直运行到结束，中间不会有任何 context switch 线程切换。）如图：</p>
<p><img src="/2022/07/12/uncatalog/cl5hsfpv60000m4r706d63234/64033.jpg" alt="img"><br>这个时候就要使用到分布式锁来限制程序的并发执行。</p>
<p>分布式锁本质上要实现的目标就是在 Redis 里面占一个“茅坑”，当别的进程也要来占 时，发现已经有人蹲在那里了，就只好放弃或者稍后再试。占坑一般是使用 setnx(set if not exists) 指令，只允许被一个客户端占坑。先来先占， 用 完了，再调用 del 指令释放茅坑。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">setnx lock:codehole true</span><br><span class="line">OK</span><br><span class="line"> ... do something critical ...</span><br><span class="line">del lock:codehole</span><br><span class="line">(integer) 1</span><br></pre></td></tr></table></figure></div>
<p>但是有个问题，如果逻辑执行到中间出现异常了，可能会导致 del 指令没有被调用，这样 就会陷入死锁，锁永远得不到释放。于是我们在拿到锁之后，再给锁加上一个过期时间，比如 5s，这样即使中间出现异常也 可以保证 5 秒之后锁会自动释放。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">setnx lock:codehole true</span><br><span class="line">OK</span><br><span class="line"><span class="meta">&gt;</span><span class="bash"> expire lock:codehole 5 ...</span></span><br><span class="line">do something critical ...</span><br><span class="line"><span class="meta">&gt;</span><span class="bash"> del lock:codehole</span></span><br><span class="line"> (integer) 1</span><br></pre></td></tr></table></figure></div>
<p>如果在 setnx 和 expire 之间服务器进程突然挂掉了，可能是因为机器掉电或者是被人为杀掉的，就会导致 expire 得不到执行，也会造成死锁。</p>
<p>这种问题的根源就在于 setnx 和 expire 是两条指令而不是原子指令。如果这两条指令可 以一起执行就不会出现问题。也许你会想到用 Redis 事务来解决。但是这里不行，因为 expire 是依赖于 setnx 的执行结果的，如果 setnx 没抢到锁，expire 是不应该执行的。事务里没有 if else 分支逻辑，事务的特点是一口气执行，要么全部执行要么一个都不执行。</p>
<p>Redis 2.8 版本中作者加入了 set 指令的扩展参数，使得 setnx 和 expire 指令可以一起执行：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">set lock:codehole trueex 5 nx</span><br><span class="line">OK</span><br><span class="line">... do something critical ...</span><br><span class="line">del lock:codehole</span><br></pre></td></tr></table></figure></div>
<p>上面这个指令就是 setnx 和 expire 组合在一起的原子指令，它就是分布式锁的奥义所在。</p>
<h3 id="分布式锁存在的问题"><a href="#分布式锁存在的问题" class="headerlink" title="分布式锁存在的问题"></a>分布式锁存在的问题</h3><p>超时问题：如果在加锁和释放锁之间的逻辑执行的太长，以至于超出了锁的超时限制，就会出现问题。因为这时候锁过期了，第二个线程重新持有了这把锁，但是紧接着第一个线程执行完了业务逻辑，就把锁给释放了，第三个线程就会在第二个线程逻辑执行完之间拿到了锁。</p>
<p>单节点的分布式锁问题：在单 Matste 的主从 Matster-Slave Redis 系统中，正常情况下 Client 向 Master 获取锁之后同步给 Slave，如果 Client 获取锁成功之后 Master 节点挂掉，并且未将该锁同步到 Slave，之后在 Sentinel 的帮助下 Slave 升级为 Master 但是并没有之前未同步的锁的信息，此时如果有新的 Client 要在新 Master 获取锁，那么将可能出现两个 Client 持有同一把锁的问题，来看个图来想下这个过程：</p>
<p><img src="/2022/07/12/uncatalog/cl5hsfpv60000m4r706d63234/64034.jpg" alt="img"><br>所以，为了保证自己的锁只能自己释放需要增加唯一性的校验，综上基于单 Redis 节点的获取锁和释放锁的简单过程如下:</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">// 获取锁 unique_value作为唯一性的校验</span><br><span class="line">SET resource_name unique_value NX PX 30000</span><br><span class="line"></span><br><span class="line">// 释放锁 比较unique_value是否相等 避免误释放</span><br><span class="line">if redis.call(&quot;get&quot;,KEYS[1]) == ARGV[1] then</span><br><span class="line">    return redis.call(&quot;del&quot;,KEYS[1])</span><br><span class="line">else</span><br><span class="line">    return 0</span><br><span class="line">end</span><br></pre></td></tr></table></figure></div>
<h3 id="关于分布式锁的-Redlock-算法"><a href="#关于分布式锁的-Redlock-算法" class="headerlink" title="关于分布式锁的 Redlock 算法"></a>关于分布式锁的 Redlock 算法</h3><p>Redis 性能好并且实现方便，但是单节点的分布式锁在故障迁移时产生安全问题，Redlock 算法是 Redis 的作者 Antirez 提出的集群模式分布式锁，基于 N 个完全独立的 Redis 节点实现分布式锁的高可用。</p>
<p>在 Redis 的分布式环境中，我们假设有 N 个完全互相独立的 Redis 节点，在 N 个 Redis 实例上使用与在 Redis 单实例下相同方法获取锁和释放锁。</p>
<p>现在假设有 5 个 Redis 主节点(大于 3 的奇数个)，这样基本保证他们不会同时都宕掉，获取锁和释放锁的过程中，客户端会执行以下操作:</p>
<p> 1,获取当前 Unix 时间，以毫秒为单位<br> 2,依次尝试从 5 个实例，使用相同的 key 和具有唯一性的 value 获取锁 当向 Redis 请求获取锁时，客户端应该设置一个网络连接和响应超时时间，这个超时时间应该小于锁的失效时间，这样可以避免客户端死等<br> 3,客户端使用当前时间减去开始获取锁时间就得到获取锁使用的时间。当且仅当从半数以上的 Redis 节点取到锁，并且使用的时间小于锁失效时间时，锁才算获取成功<br> 4,如果取到了锁，key 的真正有效时间等于有效时间减去获取锁所使用的时间，这个很重要<br> 5,如果因为某些原因，获取锁失败（没有在半数以上实例取到锁或者取锁时间已经超过了有效时间），客户端应该在所有的 Redis 实例上进行解锁，无论 Redis 实例是否加锁成功，因为可能服务端响应消息丢失了但是实际成功了，毕竟多释放一次也不会有问题</p>
<h2 id="关于集群"><a href="#关于集群" class="headerlink" title="关于集群"></a>关于集群</h2><p>在大数据高并发场景下，单个 Redis 实例往往会显得捉襟见肘。首先体现在内存上，单个 Redis 的内存不宜过大，内存太大会导致 rdb 文件过大，进一步导致主从同步时全量同步时间过长，在实例重启恢复时也会消耗很长的数据加载时间，特别是在云环境下，单个实例内存往往都是受限的。其次体现在 CPU 的利用率上，单个 Redis 实例只能利用单个核心，这单个核心要完成海量数据的存取和管理工作压力会非常大。所以孕育而生了 Redis 集群，集群方案主要有以下几种：</p>
<ul>
<li><p>Sentinel：Sentinel（哨兵）模式，基于主从复制模式，只是引入了哨兵来监控与自动处理故障</p>
</li>
<li><p>Codis：Codis 是 Redis 集群方案之一，令我们感到骄傲的是，它是中国人开发并开源的，来自前豌豆荚中间件团队。</p>
</li>
<li><p>Cluster：Redis Cluster 是 Redis 的亲儿子，它是 Redis 作者自己提供的 Redis 集群化方案。</p>
</li>
</ul>
<p>感谢阅读，部分图片来源于互联网，暂未备注来源～</p>
]]></content>
      <tags>
        <tag>架构设计那些事儿</tag>
      </tags>
  </entry>
  <entry>
    <title>架构设计那些事儿--CAP和BASE理论</title>
    <url>/2022/07/14/uncatalog/cl5kwnmjs0000f8r7dj6j1eib/</url>
    <content><![CDATA[<hr>
<span id="more"></span>
<blockquote>
<p>分布式系统（distributed system）正变得越来越重要，大型网站几乎都是分布式的。分布式系统的最大难点，就是各个节点的状态如何同步。CAP 定理是这方面的基本定理，也是理解分布式系统的起点。</p>
</blockquote>
<p>本文介绍该定理。它其实很好懂，而且是显而易见的。下面的内容主要参考了 Michael Whittaker 的<a href="https://mwhittaker.github.io/blog/an_illustrated_proof_of_the_cap_theorem/">文章</a>。</p>
<h2 id="一、分布式系统的三个指标"><a href="#一、分布式系统的三个指标" class="headerlink" title="一、分布式系统的三个指标"></a>一、分布式系统的三个指标</h2><p><img src="/2022/07/14/uncatalog/cl5kwnmjs0000f8r7dj6j1eib/bg2018071607.jpg" alt="img"><br>1998年，加州大学的计算机科学家 Eric Brewer 提出，分布式系统有三个指标。</p>
<ul>
<li>Consistency</li>
<li>Availability</li>
<li>Partition tolerance<br>它们的第一个字母分别是 C、A、P。</li>
</ul>
<p>Eric Brewer 说，这三个指标不可能同时做到。这个结论就叫做 CAP 定理</p>
<h2 id="二、Partition-tolerance"><a href="#二、Partition-tolerance" class="headerlink" title="二、Partition tolerance"></a>二、Partition tolerance</h2><p>先看 Partition tolerance，中文叫做”分区容错”。</p>
<p>大多数分布式系统都分布在多个子网络。每个子网络就叫做一个区（partition）。分区容错的意思是，区间通信可能失败。比如，一台服务器放在中国，另一台服务器放在美国，这就是两个区，它们之间可能无法通信。<br><img src="/2022/07/14/uncatalog/cl5kwnmjs0000f8r7dj6j1eib/bg2018071601.png" alt="img"><br>上图中，G1 和 G2 是两台跨区的服务器。G1 向 G2 发送一条消息，G2 可能无法收到。系统设计的时候，必须考虑到这种情况。</p>
<p>一般来说，分区容错无法避免，因此可以认为 CAP 的 P 总是成立。CAP 定理告诉我们，剩下的 C 和 A 无法同时做到。</p>
<h2 id="三、Consistency"><a href="#三、Consistency" class="headerlink" title="三、Consistency"></a>三、Consistency</h2><p>Consistency 中文叫做”一致性”。意思是，写操作之后的读操作，必须返回该值。举例来说，某条记录是 v0，用户向 G1 发起一个写操作，将其改为 v1。<br><img src="/2022/07/14/uncatalog/cl5kwnmjs0000f8r7dj6j1eib/bg2018071602.png" alt="img"><br>接下来，用户的读操作就会得到 v1。这就叫一致性。<br><img src="/2022/07/14/uncatalog/cl5kwnmjs0000f8r7dj6j1eib/bg2018071603.png" alt="img"><br>问题是，用户有可能向 G2 发起读操作，由于 G2 的值没有发生变化，因此返回的是 v0。G1 和 G2 读操作的结果不一致，这就不满足一致性了。<br><img src="/2022/07/14/uncatalog/cl5kwnmjs0000f8r7dj6j1eib/bg2018071604.png" alt="img"><br>为了让 G2 也能变为 v1，就要在 G1 写操作的时候，让 G1 向 G2 发送一条消息，要求 G2 也改成 v1。<br><img src="/2022/07/14/uncatalog/cl5kwnmjs0000f8r7dj6j1eib/bg2018071605.png" alt="img"><br>这样的话，用户向 G2 发起读操作，也能得到 v1。<br><img src="/2022/07/14/uncatalog/cl5kwnmjs0000f8r7dj6j1eib/bg2018071606.png" alt="img"></p>
<h2 id="四、Availability"><a href="#四、Availability" class="headerlink" title="四、Availability"></a>四、Availability</h2><p>Availability 中文叫做”可用性”，意思是只要收到用户的请求，服务器就必须给出回应。</p>
<p>用户可以选择向 G1 或 G2 发起读操作。不管是哪台服务器，只要收到请求，就必须告诉用户，到底是 v0 还是 v1，否则就不满足可用性。</p>
<h2 id="五、Consistency-和-Availability-的矛盾"><a href="#五、Consistency-和-Availability-的矛盾" class="headerlink" title="五、Consistency 和 Availability 的矛盾"></a>五、Consistency 和 Availability 的矛盾</h2><p>一致性和可用性，为什么不可能同时成立？答案很简单，因为可能通信失败（即出现分区容错）。</p>
<p>如果保证 G2 的一致性，那么 G1 必须在写操作时，锁定 G2 的读操作和写操作。只有数据同步后，才能重新开放读写。锁定期间，G2 不能读写，没有可用性不。</p>
<p>如果保证 G2 的可用性，那么势必不能锁定 G2，所以一致性不成立。</p>
<p>综上所述，G2 无法同时做到一致性和可用性。系统设计时只能选择一个目标。如果追求一致性，那么无法保证所有节点的可用性；如果追求所有节点的可用性，那就没法做到一致性。</p>
<h2 id="CAP权衡"><a href="#CAP权衡" class="headerlink" title="CAP权衡"></a>CAP权衡</h2><p>通过CAP理论及前面的证明，我们知道无法同时满足一致性、可用性和分区容错性这三个特性，那要舍弃哪个呢？</p>
<p>我们分三种情况来阐述一下。</p>
<h3 id="CA-without-P"><a href="#CA-without-P" class="headerlink" title="CA without P"></a>CA without P</h3><p>这种情况在分布式系统中几乎是不存在的。首先在分布式环境下，网络分区是一个自然的事实。因为分区是必然的，所以如果舍弃P，意味着要舍弃分布式系统。那也就没有必要再讨论CAP理论了。这也是为什么在前面的CAP证明中，我们以系统满足P为前提论述了无法同时满足C和A。</p>
<p>比如我们熟知的关系型数据库，如My Sql和Oracle就是保证了可用性和数据一致性，但是他并不是个分布式系统。一旦关系型数据库要考虑主备同步、集群部署等就必须要把P也考虑进来。</p>
<p>其实，在CAP理论中。C，A，P三者并不是平等的，CAP之父在《Spanner，真时，CAP理论》一文中写到：</p>
<p>如果说Spanner真有什么特别之处，那就是谷歌的广域网。Google通过建立私有网络以及强大的网络工程能力来保证P，在多年运营改进的基础上，在生产环境中可以最大程度的减少分区发生，从而实现高可用性。</p>
<p>从Google的经验中可以得到的结论是，无法通过降低CA来提升P。要想提升系统的分区容错性，需要通过提升基础设施的稳定性来保障。</p>
<p>所以，对于一个分布式系统来说。P是一个基本要求，CAP三者中，只能在CA两者之间做权衡，并且要想尽办法提升P。</p>
<h3 id="CP-without-A"><a href="#CP-without-A" class="headerlink" title="CP without A"></a>CP without A</h3><p>如果一个分布式系统不要求强的可用性，即容许系统停机或者长时间无响应的话，就可以在CAP三者中保障CP而舍弃A。</p>
<p>一个保证了CP而一个舍弃了A的分布式系统，一旦发生网络故障或者消息丢失等情况，就要牺牲用户的体验，等待所有数据全部一致了之后再让用户访问系统。</p>
<p>设计成CP的系统其实也不少，其中最典型的就是很多分布式数据库，他们都是设计成CP的。在发生极端情况时，优先保证数据的强一致性，代价就是舍弃系统的可用性。如Redis、HBase等，还有分布式系统中常用的Zookeeper也是在CAP三者之中选择优先保证CP的。</p>
<p>无论是像Redis、HBase这种分布式存储系统，还是像Zookeeper这种分布式协调组件。数据的一致性是他们最最基本的要求。一个连数据一致性都保证不了的分布式存储要他有何用？</p>
<p>在我的Zookeeper介绍（二）——Zookeeper概述一文中其实介绍过zk关于CAP的思考，这里再简单回顾一下：</p>
<p>ZooKeeper是个CP（一致性+分区容错性）的，即任何时刻对ZooKeeper的访问请求能得到一致的数据结果，同时系统对网络分割具备容错性。但是它不能保证每次服务请求的可用性，也就是在极端环境下，ZooKeeper可能会丢弃一些请求，消费者程序需要重新请求才能获得结果。ZooKeeper是分布式协调服务，它的职责是保证数据在其管辖下的所有服务之间保持同步、一致。所以就不难理解为什么ZooKeeper被设计成CP而不是AP特性的了。</p>
<h3 id="AP-wihtout-C"><a href="#AP-wihtout-C" class="headerlink" title="AP wihtout C"></a>AP wihtout C</h3><p>要高可用并允许分区，则需放弃一致性。一旦网络问题发生，节点之间可能会失去联系。为了保证高可用，需要在用户访问时可以马上得到返回，则每个节点只能用本地数据提供服务，而这样会导致全局数据的不一致性。</p>
<p>这种舍弃强一致性而保证系统的分区容错性和可用性的场景和案例非常多。前面我们介绍可用性的时候说到过，很多系统在可用性方面会做很多事情来保证系统的全年可用性可以达到N个9，所以，对于很多业务系统来说，比如淘宝的购物，12306的买票。都是在可用性和一致性之间舍弃了一致性而选择可用性。</p>
<p>你在12306买票的时候肯定遇到过这种场景，当你购买的时候提示你是有票的（但是可能实际已经没票了），你也正常的去输入验证码，下单了。但是过了一会系统提示你下单失败，余票不足。这其实就是先在可用性方面保证系统可以正常的服务，然后在数据的一致性方面做了些牺牲，会影响一些用户体验，但是也不至于造成用户流程的严重阻塞。</p>
<p>但是，我们说很多网站牺牲了一致性，选择了可用性，这其实也不准确的。就比如上面的买票的例子，其实舍弃的只是强一致性。退而求其次保证了最终一致性。也就是说，虽然下单的瞬间，关于车票的库存可能存在数据不一致的情况，但是过了一段时间，还是要保证最终一致性的。</p>
<p>对于多数大型互联网应用的场景，主机众多、部署分散，而且现在的集群规模越来越大，所以节点故障、网络故障是常态，而且要保证服务可用性达到N个9，即保证P和A，舍弃C（退而求其次保证最终一致性）。虽然某些地方会影响客户体验，但没达到造成用户流程的严重程度。</p>
<h3 id="适合的才是最好的"><a href="#适合的才是最好的" class="headerlink" title="适合的才是最好的"></a>适合的才是最好的</h3><p>上面介绍了如何CAP中权衡及取舍以及典型的案例。孰优孰略，没有定论，只能根据场景定夺，适合的才是最好的。</p>
<p>对于涉及到钱财这样不能有一丝让步的场景，C必须保证。网络发生故障宁可停止服务，这是保证CP，舍弃A。比如前几年支付宝光缆被挖断的事件，在网络出现故障的时候，支付宝就在可用性和数据一致性之间选择了数据一致性，用户感受到的是支付宝系统长时间宕机，但是其实背后是无数的工程师在恢复数据，保证数数据的一致性。</p>
<p>对于其他场景，比较普遍的做法是选择可用性和分区容错性，舍弃强一致性，退而求其次使用最终一致性来保证数据的安全。这其实是分布式领域的另外一个理论——BASE理论。</p>
<h2 id="Base理论"><a href="#Base理论" class="headerlink" title="Base理论"></a>Base理论</h2><p>Base理论是Basically Available（基本可用）、Soft state（软状态）、Eventually consistent（最终一致性）的缩写；它基于CAP定理逐步演化来的，它是CAP中一致性和可用性权衡的结果，其核心思想是即使系统无法达到强一致性，可以根据应用自身的业务特点，采用适当的方式来使系统达到最终一致性。</p>
<h3 id="基本可用（Basically-Available）"><a href="#基本可用（Basically-Available）" class="headerlink" title="基本可用（Basically Available）"></a>基本可用（Basically Available）</h3><p>基本可用是指当分布式系统发生故障的时候，允许损失部分可用性。常见的有以下几种情况：</p>
<ul>
<li>响应时间上的损失：正常情况下，一个在线搜索引擎需要再0.5秒之内返回给用户响应的查询结果，但由于出现故障，查询结果的响应时间增加到了1~2秒。</li>
<li>功能上的损失：通常的做法是降级服务，如对于展示一些有序元素的页面，但部分组件出现故障时，这个时候可不展示有序元素，降级为无序元素列表。</li>
</ul>
<h3 id="软状态"><a href="#软状态" class="headerlink" title="软状态"></a>软状态</h3><p>软状态是指允许系统中的数据存在中间状态，并认为该中间状态的存在不影响系统的整体可用性，即允许系统不同节点的数据副本之间进行数据同步的过程中存在延时。</p>
<h3 id="最终一致性"><a href="#最终一致性" class="headerlink" title="最终一致性"></a>最终一致性</h3><p>最终一致性强调的是系统所有的数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态。因此，最终一致性的本质是需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>CAP 是分布式系统设计理论，BASE 是 CAP 理论中 AP 方案的延伸，ACID 是数据库事务完整性的理论。</p>
<p>CAP理论严格来讲不是三选二，而是CP、AP二选一，因为通常P（分区容错性）是必须得到保证的。</p>
<p>BASE理论面向的是大型高可用、可扩展的分布式系统。与传统ACID特性相反，不是强一致性模型，BASE提出通过牺牲强一致性来获得可用性，并允许数据一段时间内的不一致，但是最终需要达到一致状态。</p>
]]></content>
      <tags>
        <tag>架构设计那些事儿</tag>
      </tags>
  </entry>
  <entry>
    <title>架构设计那些事儿--登录认证那些事儿(一)，OAuth 2.0</title>
    <url>/2022/07/18/uncatalog/cl5qed6p700001cr78iu9hcbm/</url>
    <content><![CDATA[<hr>
<span id="more"></span>
<blockquote>
<p>OAuth 2.0 是目前最流行的授权机制，用来授权第三方应用，获取用户数据。 这个标准比较抽象，使用了很多术语，初学者不容易理解。其实说起来并不复杂，下面我就通过一个简单的类比，帮助大家轻松理解，OAuth 2.0 到底是什么。</p>
</blockquote>
<h2 id="一、快递员问题"><a href="#一、快递员问题" class="headerlink" title="一、快递员问题"></a>一、快递员问题</h2><p>我住在一个大型的居民小区。</p>
<p><img src="/2022/07/18/uncatalog/cl5qed6p700001cr78iu9hcbm/bg2019040401.jpg" alt="img"><br>小区有门禁系统。<br><img src="/2022/07/18/uncatalog/cl5qed6p700001cr78iu9hcbm/bg2019040402.jpg" alt="IMG"><br>进入的时候需要输入密码。</p>
<p><img src="/2022/07/18/uncatalog/cl5qed6p700001cr78iu9hcbm/bg2019040403.jpg" alt="img"><br>我经常网购和外卖，每天都有快递员来送货。我必须找到一个办法，让快递员通过门禁系统，进入小区。</p>
<p><img src="/2022/07/18/uncatalog/cl5qed6p700001cr78iu9hcbm/bg2019040404.jpg" alt="img"><br>如果我把自己的密码，告诉快递员，他就拥有了与我同样的权限，这样好像不太合适。万一我想取消他进入小区的权力，也很麻烦，我自己的密码也得跟着改了，还得通知其他的快递员。</p>
<p>有没有一种办法，让快递员能够自由进入小区，又不必知道小区居民的密码，而且他的唯一权限就是送货，其他需要密码的场合，他都没有权限？</p>
<h2 id="二、授权机制的设计"><a href="#二、授权机制的设计" class="headerlink" title="二、授权机制的设计"></a>二、授权机制的设计</h2><p>于是，我设计了一套授权机制。</p>
<p>第一步，门禁系统的密码输入器下面，增加一个按钮，叫做”获取授权”。快递员需要首先按这个按钮，去申请授权。</p>
<p>第二步，他按下按钮以后，屋主（也就是我）的手机就会跳出对话框：有人正在要求授权。系统还会显示该快递员的姓名、工号和所属的快递公司。</p>
<p>我确认请求属实，就点击按钮，告诉门禁系统，我同意给予他进入小区的授权。</p>
<p>第三步，门禁系统得到我的确认以后，向快递员显示一个进入小区的令牌（access token）。令牌就是类似密码的一串数字，只在短期内（比如七天）有效。</p>
<p>第四步，快递员向门禁系统输入令牌，进入小区。</p>
<p>有人可能会问，为什么不是远程为快递员开门，而要为他单独生成一个令牌？这是因为快递员可能每天都会来送货，第二天他还可以复用这个令牌。另外，有的小区有多重门禁，快递员可以使用同一个令牌通过它们。</p>
<h2 id="三、互联网场景"><a href="#三、互联网场景" class="headerlink" title="三、互联网场景"></a>三、互联网场景</h2><p>我们把上面的例子搬到互联网，就是 OAuth 的设计了。</p>
<p>首先，居民小区就是储存用户数据的网络服务。比如，微信储存了我的好友信息，获取这些信息，就必须经过微信的”门禁系统”。</p>
<p>其次，快递员（或者说快递公司）就是第三方应用，想要穿过门禁系统，进入小区。</p>
<p>最后，我就是用户本人，同意授权第三方应用进入小区，获取我的数据。</p>
<p>简单说，OAuth 就是一种授权机制。数据的所有者告诉系统，同意授权第三方应用进入系统，获取这些数据。系统从而产生一个短期的进入令牌（token），用来代替密码，供第三方应用使用。</p>
<h2 id="四、令牌与密码"><a href="#四、令牌与密码" class="headerlink" title="四、令牌与密码"></a>四、令牌与密码</h2><p>令牌（token）与密码（password）的作用是一样的，都可以进入系统，但是有三点差异。</p>
<p>（1）令牌是短期的，到期会自动失效，用户自己无法修改。密码一般长期有效，用户不修改，就不会发生变化。</p>
<p>（2）令牌可以被数据所有者撤销，会立即失效。以上例而言，屋主可以随时取消快递员的令牌。密码一般不允许被他人撤销。</p>
<p>（3）令牌有权限范围（scope），比如只能进小区的二号门。对于网络服务来说，只读令牌就比读写令牌更安全。密码一般是完整权限。</p>
<p>上面这些设计，保证了令牌既可以让第三方应用获得权限，同时又随时可控，不会危及系统安全。这就是 OAuth 2.0 的优点。</p>
<p>注意，只要知道了令牌，就能进入系统。系统一般不会再次确认身份，所以令牌必须保密，泄漏令牌与泄漏密码的后果是一样的。 这也是为什么令牌的有效期，一般都设置得很短的原因。</p>
<p>OAuth 2.0 对于如何颁发令牌的细节，规定得非常详细。具体来说，一共分成四种授权类型（authorization grant），即四种颁发令牌的方式，适用于不同的互联网场景。</p>
<h2 id="RFC-6749"><a href="#RFC-6749" class="headerlink" title="RFC 6749"></a>RFC 6749</h2><p>OAuth 2.0 的标准是 RFC 6749 文件。该文件先解释了 OAuth 是什么。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="TEXT"><figure class="iseeu highlight /text"><table><tr><td class="code"><pre><span class="line">OAuth 引入了一个授权层，用来分离两种不同的角色：客户端和资源所有者。......资源所有者同意以后，资源服务器可以向客户端颁发令牌。客户端通过令牌，去请求数据。</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>
<p>这段话的意思就是，OAuth 的核心就是向第三方应用颁发令牌。然后，RFC 6749 接着写道：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="TEXT"><figure class="iseeu highlight /text"><table><tr><td class="code"><pre><span class="line">（由于互联网有多种场景，）本标准定义了获得令牌的四种授权方式（authorization grant ）。</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>
<p>也就是说，OAuth 2.0 规定了四种获得令牌的流程。你可以选择最适合自己的那一种，向第三方应用颁发令牌。下面就是这四种授权方式。</p>
<ul>
<li>授权码（authorization-code） </li>
<li>隐藏式（implicit）</li>
<li>密码式（password）</li>
<li>客户端凭证（client credentials）</li>
</ul>
<p>注意，不管哪一种授权方式，第三方应用申请令牌之前，都必须先到系统备案，说明自己的身份，然后会拿到两个身份识别码：客户端 ID（client ID）和客户端密钥（client secret）。这是为了防止令牌被滥用，没有备案过的第三方应用，是不会拿到令牌的。</p>
<h2 id="第一种授权方式：授权码"><a href="#第一种授权方式：授权码" class="headerlink" title="第一种授权方式：授权码"></a>第一种授权方式：授权码</h2><p>授权码（authorization code）方式，指的是第三方应用先申请一个授权码，然后再用该码获取令牌。</p>
<p>这种方式是最常用的流程，安全性也最高，它适用于那些有后端的 Web 应用。授权码通过前端传送，令牌则是储存在后端，而且所有与资源服务器的通信都在后端完成。这样的前后端分离，可以避免令牌泄漏。</p>
<p>第一步，A 网站提供一个链接，用户点击后就会跳转到 B 网站，授权用户数据给 A 网站使用。下面就是 A 网站跳转 B 网站的一个示意链接。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="TEXT"><figure class="iseeu highlight /text"><table><tr><td class="code"><pre><span class="line">https://b.com/oauth/authorize?</span><br><span class="line">  response_type=code&amp;</span><br><span class="line">  client_id=CLIENT_ID&amp;</span><br><span class="line">  redirect_uri=CALLBACK_URL&amp;</span><br><span class="line">  scope=read</span><br></pre></td></tr></table></figure></div>
<p>上面 URL 中，response_type参数表示要求返回授权码（code），client_id参数让 B 知道是谁在请求，redirect_uri参数是 B 接受或拒绝请求后的跳转网址，scope参数表示要求的授权范围（这里是只读）。</p>
<p><img src="/2022/07/18/uncatalog/cl5qed6p700001cr78iu9hcbm/bg2019040902.jpg" alt="img"></p>
<p>第二步，用户跳转后，B 网站会要求用户登录，然后询问是否同意给予 A 网站授权。用户表示同意，这时 B 网站就会跳回redirect_uri参数指定的网址。跳转时，会传回一个授权码，就像下面这样。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="TEXT"><figure class="iseeu highlight /text"><table><tr><td class="code"><pre><span class="line">https://a.com/callback?code=AUTHORIZATION_CODE</span><br></pre></td></tr></table></figure></div>
<p>上面 URL 中，code参数就是授权码。</p>
<p><img src="/2022/07/18/uncatalog/cl5qed6p700001cr78iu9hcbm/bg2019040907.jpg" alt="img"><br>第三步，A 网站拿到授权码以后，就可以在后端，向 B 网站请求令牌。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="TEXT"><figure class="iseeu highlight /text"><table><tr><td class="code"><pre><span class="line">https://b.com/oauth/token?</span><br><span class="line"> client_id=CLIENT_ID&amp;</span><br><span class="line"> client_secret=CLIENT_SECRET&amp;</span><br><span class="line"> grant_type=authorization_code&amp;</span><br><span class="line"> code=AUTHORIZATION_CODE&amp;</span><br><span class="line"> redirect_uri=CALLBACK_URL</span><br></pre></td></tr></table></figure></div>
<p>上面 URL 中，client_id参数和client_secret参数用来让 B 确认 A 的身份（client_secret参数是保密的，因此只能在后端发请求），grant_type参数的值是AUTHORIZATION_CODE，表示采用的授权方式是授权码，code参数是上一步拿到的授权码，redirect_uri参数是令牌颁发后的回调网址。</p>
<p><img src="/2022/07/18/uncatalog/cl5qed6p700001cr78iu9hcbm/bg2019040904.jpg" alt="img"><br>第四步，B 网站收到请求以后，就会颁发令牌。具体做法是向redirect_uri指定的网址，发送一段 JSON 数据。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="JSON"><figure class="iseeu highlight /json"><table><tr><td class="code"><pre><span class="line">&#123;    </span><br><span class="line">  <span class="attr">&quot;access_token&quot;</span>:<span class="string">&quot;ACCESS_TOKEN&quot;</span>,</span><br><span class="line">  <span class="attr">&quot;token_type&quot;</span>:<span class="string">&quot;bearer&quot;</span>,</span><br><span class="line">  <span class="attr">&quot;expires_in&quot;</span>:<span class="number">2592000</span>,</span><br><span class="line">  <span class="attr">&quot;refresh_token&quot;</span>:<span class="string">&quot;REFRESH_TOKEN&quot;</span>,</span><br><span class="line">  <span class="attr">&quot;scope&quot;</span>:<span class="string">&quot;read&quot;</span>,</span><br><span class="line">  <span class="attr">&quot;uid&quot;</span>:<span class="number">100101</span>,</span><br><span class="line">  <span class="attr">&quot;info&quot;</span>:&#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<p>上面 JSON 数据中，access_token字段就是令牌，A 网站在后端拿到了。<br><img src="/2022/07/18/uncatalog/cl5qed6p700001cr78iu9hcbm/bg2019040905.jpg" alt="img"></p>
<h2 id="第二种方式：隐藏式"><a href="#第二种方式：隐藏式" class="headerlink" title="第二种方式：隐藏式"></a>第二种方式：隐藏式</h2><p>有些 Web 应用是纯前端应用，没有后端。这时就不能用上面的方式了，必须将令牌储存在前端。RFC 6749 就规定了第二种方式，允许直接向前端颁发令牌。这种方式没有授权码这个中间步骤，所以称为（授权码）”隐藏式”（implicit）。</p>
<p>第一步，A 网站提供一个链接，要求用户跳转到 B 网站，授权用户数据给 A 网站使用。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="TEXT"><figure class="iseeu highlight /text"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">https://b.com/oauth/authorize?</span><br><span class="line">  response_type=token&amp;</span><br><span class="line">  client_id=CLIENT_ID&amp;</span><br><span class="line">  redirect_uri=CALLBACK_URL&amp;</span><br><span class="line">  scope=read</span><br></pre></td></tr></table></figure></div>
<p>上面 URL 中，response_type参数为token，表示要求直接返回令牌。</p>
<p>第二步，用户跳转到 B 网站，登录后同意给予 A 网站授权。这时，B 网站就会跳回redirect_uri参数指定的跳转网址，并且把令牌作为 URL 参数，传给 A 网站。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="TEXT"><figure class="iseeu highlight /text"><table><tr><td class="code"><pre><span class="line">https://a.com/callback#token=ACCESS_TOKEN</span><br></pre></td></tr></table></figure></div>
<p>上面 URL 中，token参数就是令牌，A 网站因此直接在前端拿到令牌。</p>
<p>注意，令牌的位置是 URL 锚点（fragment），而不是查询字符串（querystring），这是因为 OAuth 2.0 允许跳转网址是 HTTP 协议，因此存在”中间人攻击”的风险，而浏览器跳转时，锚点不会发到服务器，就减少了泄漏令牌的风险。<br><img src="/2022/07/18/uncatalog/cl5qed6p700001cr78iu9hcbm/bg2019040906.jpg" alt="img"></p>
<p>这种方式把令牌直接传给前端，是很不安全的。因此，只能用于一些安全要求不高的场景，并且令牌的有效期必须非常短，通常就是会话期间（session）有效，浏览器关掉，令牌就失效了。</p>
<h2 id="第三种方式：密码式"><a href="#第三种方式：密码式" class="headerlink" title="第三种方式：密码式"></a>第三种方式：密码式</h2><p>如果你高度信任某个应用，RFC 6749 也允许用户把用户名和密码，直接告诉该应用。该应用就使用你的密码，申请令牌，这种方式称为”密码式”（password）。</p>
<p>第一步，A 网站要求用户提供 B 网站的用户名和密码。拿到以后，A 就直接向 B 请求令牌。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="TEXT"><figure class="iseeu highlight /text"><table><tr><td class="code"><pre><span class="line">https://oauth.b.com/token?</span><br><span class="line">  grant_type=password&amp;</span><br><span class="line">  username=USERNAME&amp;</span><br><span class="line">  password=PASSWORD&amp;</span><br><span class="line">  client_id=CLIENT_ID</span><br><span class="line">  </span><br></pre></td></tr></table></figure></div>

<p>上面 URL 中，grant_type参数是授权方式，这里的password表示”密码式”，username和password是 B 的用户名和密码。</p>
<p>第二步，B 网站验证身份通过后，直接给出令牌。注意，这时不需要跳转，而是把令牌放在 JSON 数据里面，作为 HTTP 回应，A 因此拿到令牌。</p>
<p>这种方式需要用户给出自己的用户名/密码，显然风险很大，因此只适用于其他授权方式都无法采用的情况，而且必须是用户高度信任的应用。</p>
<h2 id="第四种方式：凭证式"><a href="#第四种方式：凭证式" class="headerlink" title="第四种方式：凭证式"></a>第四种方式：凭证式</h2><p>最后一种方式是凭证式（client credentials），适用于没有前端的命令行应用，即在命令行下请求令牌。</p>
<p>第一步，A 应用在命令行向 B 发出请求。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="TEXT"><figure class="iseeu highlight /text"><table><tr><td class="code"><pre><span class="line">https://oauth.b.com/token?</span><br><span class="line">  grant_type=client_credentials&amp;</span><br><span class="line">  client_id=CLIENT_ID&amp;</span><br><span class="line">  client_secret=CLIENT_SECRET</span><br></pre></td></tr></table></figure></div>
<p>上面 URL 中，grant_type参数等于client_credentials表示采用凭证式，client_id和client_secret用来让 B 确认 A 的身份。</p>
<p>第二步，B 网站验证通过以后，直接返回令牌。</p>
<p>这种方式给出的令牌，是针对第三方应用的，而不是针对用户的，即有可能多个用户共享同一个令牌。</p>
<h2 id="令牌的使用"><a href="#令牌的使用" class="headerlink" title="令牌的使用"></a>令牌的使用</h2><p>A 网站拿到令牌以后，就可以向 B 网站的 API 请求数据了。</p>
<p>此时，每个发到 API 的请求，都必须带有令牌。具体做法是在请求的头信息，加上一个Authorization字段，令牌就放在这个字段里面。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">curl -H &quot;Authorization: Bearer ACCESS_TOKEN&quot; \</span><br><span class="line">&quot;https://api.b.com&quot;</span><br></pre></td></tr></table></figure></div>
<p>上面命令中，ACCESS_TOKEN就是拿到的令牌。</p>
<h2 id="更新令牌"><a href="#更新令牌" class="headerlink" title="更新令牌"></a>更新令牌</h2><p>令牌的有效期到了，如果让用户重新走一遍上面的流程，再申请一个新的令牌，很可能体验不好，而且也没有必要。OAuth 2.0 允许用户自动更新令牌。</p>
<p>具体方法是，B 网站颁发令牌的时候，一次性颁发两个令牌，一个用于获取数据，另一个用于获取新的令牌（refresh token 字段）。令牌到期前，用户使用 refresh token 发一个请求，去更新令牌。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="TEXT"><figure class="iseeu highlight /text"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">https://b.com/oauth/token?</span><br><span class="line">  grant_type=refresh_token&amp;</span><br><span class="line">  client_id=CLIENT_ID&amp;</span><br><span class="line">  client_secret=CLIENT_SECRET&amp;</span><br><span class="line">  refresh_token=REFRESH_TOKEN</span><br></pre></td></tr></table></figure></div>
<p>上面 URL 中，grant_type参数为refresh_token表示要求更新令牌，client_id参数和client_secret参数用于确认身份，refresh_token参数就是用于更新令牌的令牌。</p>
<p>B 网站验证通过以后，就会颁发新的令牌。</p>
<p>写到这里，颁发令牌的四种方式就介绍完了。下一篇文章会编写一个真实的 Demo，演示如何通过 OAuth 2.0 向 GitHub 的 API 申请令牌，然后再用令牌获取数据。</p>
]]></content>
      <tags>
        <tag>架构设计那些事儿</tag>
      </tags>
  </entry>
  <entry>
    <title>架构设计那些事儿--登录认证那些事儿(二)，JSON Web Token</title>
    <url>/2022/07/18/uncatalog/cl5qf74ul000040r73q1jfruf/</url>
    <content><![CDATA[<hr>
<span id="more"></span>
<p>JSON Web Token（缩写 JWT）是目前最流行的跨域认证解决方案，本文介绍它的原理和用法。</p>
<h2 id="一、跨域认证的问题"><a href="#一、跨域认证的问题" class="headerlink" title="一、跨域认证的问题"></a>一、跨域认证的问题</h2><p>互联网服务离不开用户认证。一般流程是下面这样。</p>
<ul>
<li><p>1、用户向服务器发送用户名和密码。</p>
</li>
<li><p>2、服务器验证通过后，在当前对话（session）里面保存相关数据，比如用户角色、登录时间等等。</p>
</li>
<li><p>3、服务器向用户返回一个 session_id，写入用户的 Cookie。</p>
</li>
<li><p>4、用户随后的每一次请求，都会通过 Cookie，将 session_id 传回服务器。</p>
</li>
<li><p>5、服务器收到 session_id，找到前期保存的数据，由此得知用户的身份。</p>
</li>
</ul>
<p>这种模式的问题在于，扩展性（scaling）不好。单机当然没有问题，如果是服务器集群，或者是跨域的服务导向架构，就要求 session 数据共享，每台服务器都能够读取 session。</p>
<p>举例来说，A 网站和 B 网站是同一家公司的关联服务。现在要求，用户只要在其中一个网站登录，再访问另一个网站就会自动登录，请问怎么实现？</p>
<p>一种解决方案是 session 数据持久化，写入数据库或别的持久层。各种服务收到请求后，都向持久层请求数据。这种方案的优点是架构清晰，缺点是工程量比较大。另外，持久层万一挂了，就会单点失败。</p>
<p>另一种方案是服务器索性不保存 session 数据了，所有数据都保存在客户端，每次请求都发回服务器。JWT 就是这种方案的一个代表。</p>
<h2 id="二、JWT-的原理"><a href="#二、JWT-的原理" class="headerlink" title="二、JWT 的原理"></a>二、JWT 的原理</h2><p>JWT 的原理是，服务器认证以后，生成一个 JSON 对象，发回给用户，就像下面这样。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="JSON"><figure class="iseeu highlight /json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line"><span class="attr">&quot;姓名&quot;</span>: <span class="string">&quot;张三&quot;</span>,</span><br><span class="line"><span class="attr">&quot;角色&quot;</span>: <span class="string">&quot;管理员&quot;</span>,</span><br><span class="line"><span class="attr">&quot;到期时间&quot;</span>: <span class="string">&quot;2018年7月1日0点0分&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<p>以后，用户与服务端通信的时候，都要发回这个 JSON 对象。服务器完全只靠这个对象认定用户身份。为了防止用户篡改数据，服务器在生成这个对象的时候，会加上签名（详见后文）。</p>
<p>服务器就不保存任何 session 数据了，也就是说，服务器变成无状态了，从而比较容易实现扩展。</p>
<h2 id="三、JWT-的数据结构"><a href="#三、JWT-的数据结构" class="headerlink" title="三、JWT 的数据结构"></a>三、JWT 的数据结构</h2><p>实际的 JWT 大概就像下面这样。</p>
<p><img src="/2022/07/18/uncatalog/cl5qf74ul000040r73q1jfruf/bg2018072304.jpg" alt="img"><br>它是一个很长的字符串，中间用点（.）分隔成三个部分。注意，JWT 内部是没有换行的，这里只是为了便于展示，将它写成了几行。</p>
<p>JWT 的三个部分依次如下。</p>
<ul>
<li>Header（头部）</li>
<li>Payload（负载）</li>
<li>Signature（签名）</li>
</ul>
<p>写成一行，就是下面的样子。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="TEXT"><figure class="iseeu highlight /text"><table><tr><td class="code"><pre><span class="line">Header.Payload.Signature</span><br></pre></td></tr></table></figure></div>
<p><img src="/2022/07/18/uncatalog/cl5qf74ul000040r73q1jfruf/bg2018072303.jpg" alt="img"><br>下面依次介绍这三个部分。</p>
<h3 id="3-1-Header"><a href="#3-1-Header" class="headerlink" title="3.1 Header"></a>3.1 Header</h3><p>Header 部分是一个 JSON 对象，描述 JWT 的元数据，通常是下面的样子。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="JSON"><figure class="iseeu highlight /json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">&quot;alg&quot;</span>: <span class="string">&quot;HS256&quot;</span>,</span><br><span class="line">  <span class="attr">&quot;typ&quot;</span>: <span class="string">&quot;JWT&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<p>上面代码中，alg属性表示签名的算法（algorithm），默认是 HMAC SHA256（写成 HS256）；typ属性表示这个令牌（token）的类型（type），JWT 令牌统一写为JWT。</p>
<p>最后，将上面的 JSON 对象使用 Base64URL 算法（详见后文）转成字符串。</p>
<h3 id="3-2-Payload"><a href="#3-2-Payload" class="headerlink" title="3.2 Payload"></a>3.2 Payload</h3><p>Payload 部分也是一个 JSON 对象，用来存放实际需要传递的数据。JWT 规定了7个官方字段，供选用。</p>
<ul>
<li>iss (issuer)：签发人</li>
<li>exp (expiration time)：过期时间</li>
<li>sub (subject)：主题</li>
<li>aud (audience)：受众</li>
<li>nbf (Not Before)：生效时间</li>
<li>iat (Issued At)：签发时间</li>
<li>jti (JWT ID)：编号</li>
</ul>
<p>除了官方字段，你还可以在这个部分定义私有字段，下面就是一个例子。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="JSON"><figure class="iseeu highlight /json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">&quot;sub&quot;</span>: <span class="string">&quot;1234567890&quot;</span>,</span><br><span class="line">  <span class="attr">&quot;name&quot;</span>: <span class="string">&quot;John Doe&quot;</span>,</span><br><span class="line">  <span class="attr">&quot;admin&quot;</span>: <span class="literal">true</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>注意，JWT 默认是不加密的，任何人都可以读到，所以不要把秘密信息放在这个部分。</p>
<p>这个 JSON 对象也要使用 Base64URL 算法转成字符串。</p>
<h3 id="3-3-Signature"><a href="#3-3-Signature" class="headerlink" title="3.3 Signature"></a>3.3 Signature</h3><p>Signature 部分是对前两部分的签名，防止数据篡改。</p>
<p>首先，需要指定一个密钥（secret）。这个密钥只有服务器才知道，不能泄露给用户。然后，使用 Header 里面指定的签名算法（默认是 HMAC SHA256），按照下面的公式产生签名。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="TEXT"><figure class="iseeu highlight /text"><table><tr><td class="code"><pre><span class="line">HMACSHA256(</span><br><span class="line">  base64UrlEncode(header) + &quot;.&quot; +</span><br><span class="line">  base64UrlEncode(payload),</span><br><span class="line">  secret)</span><br></pre></td></tr></table></figure></div>

<p>算出签名以后，把 Header、Payload、Signature 三个部分拼成一个字符串，每个部分之间用”点”（.）分隔，就可以返回给用户。</p>
<h3 id="3-4-Base64URL"><a href="#3-4-Base64URL" class="headerlink" title="3.4 Base64URL"></a>3.4 Base64URL</h3><p>前面提到，Header 和 Payload 串型化的算法是 Base64URL。这个算法跟 Base64 算法基本类似，但有一些小的不同。</p>
<p>JWT 作为一个令牌（token），有些场合可能会放到 URL（比如 api.example.com/?token=xxx）。Base64 有三个字符+、/和=，在 URL 里面有特殊含义，所以要被替换掉：=被省略、+替换成-，/替换成_ 。这就是 Base64URL 算法。</p>
<h2 id="四、JWT-的使用方式"><a href="#四、JWT-的使用方式" class="headerlink" title="四、JWT 的使用方式"></a>四、JWT 的使用方式</h2><p>客户端收到服务器返回的 JWT，可以储存在 Cookie 里面，也可以储存在 localStorage。</p>
<p>此后，客户端每次与服务器通信，都要带上这个 JWT。你可以把它放在 Cookie 里面自动发送，但是这样不能跨域，所以更好的做法是放在 HTTP 请求的头信息Authorization字段里面。</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="TEXT"><figure class="iseeu highlight /text"><table><tr><td class="code"><pre><span class="line">Authorization: Bearer &lt;token&gt;</span><br></pre></td></tr></table></figure></div>
<p>另一种做法是，跨域的时候，JWT 就放在 POST 请求的数据体里面。</p>
<h2 id="五、JWT-的几个特点"><a href="#五、JWT-的几个特点" class="headerlink" title="五、JWT 的几个特点"></a>五、JWT 的几个特点</h2><p>（1）JWT 默认是不加密，但也是可以加密的。生成原始 Token 以后，可以用密钥再加密一次。</p>
<p>（2）JWT 不加密的情况下，不能将秘密数据写入 JWT。</p>
<p>（3）JWT 不仅可以用于认证，也可以用于交换信息。有效使用 JWT，可以降低服务器查询数据库的次数。</p>
<p>（4）JWT 的最大缺点是，由于服务器不保存 session 状态，因此无法在使用过程中废止某个 token，或者更改 token 的权限。也就是说，一旦 JWT 签发了，在到期之前就会始终有效，除非服务器部署额外的逻辑。</p>
<p>（5）JWT 本身包含了认证信息，一旦泄露，任何人都可以获得该令牌的所有权限。为了减少盗用，JWT 的有效期应该设置得比较短。对于一些比较重要的权限，使用时应该再次对用户进行认证。</p>
<p>（6）为了减少盗用，JWT 不应该使用 HTTP 协议明码传输，要使用 HTTPS 协议传输。</p>
]]></content>
      <tags>
        <tag>架构设计那些事儿</tag>
      </tags>
  </entry>
  <entry>
    <title>玩转git三剑客</title>
    <url>/2022/09/05/uncatalog/cl7oebs5q0000f0r7e0oq9fnk/</url>
    <content><![CDATA[<hr>
<span id="more"></span>

<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>官方安装包下载地址:<a href="https://git-scm.com/download/win">https://git-scm.com/download/win</a><br>验证是否安装成功：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> git --version</span></span><br><span class="line">git version 2.37.3.windows.1</span><br></pre></td></tr></table></figure></div>

<p>(建议使用比较高的版本，旧版本可能会在<code>git log --all</code>这些结果展示上有些不太友好的差异)</p>
<h2 id="git使用之前要做的最小配置"><a href="#git使用之前要做的最小配置" class="headerlink" title="git使用之前要做的最小配置"></a>git使用之前要做的最小配置</h2><ol>
<li>配置全局用户信息</li>
</ol>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">git config --global user.name &#x27;your_name&#x27;</span><br><span class="line">git config --global user.email &#x27;your_email@domain.com&#x27;</span><br></pre></td></tr></table></figure></div>

<ol start="2">
<li>配置某个git仓库的用户信息</li>
</ol>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">git config --local user.name &#x27;your_name&#x27;</span><br><span class="line">git config --local user.email &#x27;your_email@domain.com&#x27;</span><br></pre></td></tr></table></figure></div>

<ol start="3">
<li>config的三个作用域(优先级从高到低)</li>
</ol>
<table>
<thead>
<tr>
<th>作用域</th>
<th>用法</th>
<th>效果</th>
</tr>
</thead>
<tbody><tr>
<td>local</td>
<td>git config –local</td>
<td>只对某个仓库有效</td>
</tr>
<tr>
<td>global</td>
<td>git config –global</td>
<td>对当前用户所有仓库有效</td>
</tr>
<tr>
<td>system</td>
<td>git config –system</td>
<td>对系统所有登录的用户有效</td>
</tr>
<tr>
<td>4. 查看git配置</td>
<td></td>
<td></td>
</tr>
</tbody></table>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">git config --list --local</span><br><span class="line">git config --list --global</span><br><span class="line">git config --list --system</span><br></pre></td></tr></table></figure></div>

<h2 id="git项目初始化"><a href="#git项目初始化" class="headerlink" title="git项目初始化"></a>git项目初始化</h2><ol>
<li>把已有的项目代码纳入git管理</li>
</ol>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">cd 项目代码所在文件夹</span><br><span class="line">git init</span><br></pre></td></tr></table></figure></div>

<ol start="2">
<li>新建的项目直接用git管理</li>
</ol>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">cd 某个文件夹</span><br><span class="line">git init your_project_name # 会自动创建文件夹</span><br><span class="line">cd your_project_name</span><br></pre></td></tr></table></figure></div>

<h2 id="了解工作区和暂存区"><a href="#了解工作区和暂存区" class="headerlink" title="了解工作区和暂存区"></a>了解工作区和暂存区</h2><p><img src="/2022/09/05/uncatalog/cl7oebs5q0000f0r7e0oq9fnk/add.jpg"></p>
<h2 id="通过git-log查看版本演变历史"><a href="#通过git-log查看版本演变历史" class="headerlink" title="通过git log查看版本演变历史"></a>通过<code>git log</code>查看版本演变历史</h2><ol>
<li>基本命令<code>git log</code></li>
</ol>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> git <span class="built_in">log</span></span></span><br><span class="line">commit a0b98ea6769a71901895c5f879b4b23383ba6bcd</span><br><span class="line">Author: xxx</span><br><span class="line">Date:   Wed Sep 7 11:20:39 xxx</span><br><span class="line"></span><br><span class="line">    Move readme.md to readme</span><br><span class="line"></span><br><span class="line">commit 63ca73303c196401d6f0312186a11d517c51f749</span><br><span class="line">Author: xxx</span><br><span class="line">Date:   Tue Sep 6 11:10:01 xxx</span><br><span class="line"></span><br><span class="line">    Add refering projects</span><br><span class="line"></span><br><span class="line">commit f77ad615d0a091ac22f78f892c4d50077b43096a</span><br><span class="line">Author: xxx</span><br><span class="line">Date:   Tue Sep 6 11:01:34 xxx</span><br><span class="line"></span><br><span class="line">    Add js</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>

<ol start="2">
<li>简洁命令命令<code>git log</code>。(这条命令可以帮助你以简洁的方式查看提交记录。它把提交记录浓缩在了一行，而且只保留类似较短的提交哈希值和提交信息)</li>
</ol>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> git <span class="built_in">log</span> --oneline</span></span><br><span class="line">a0b98ea Move readme.md to readme</span><br><span class="line">63ca733 Add refering projects</span><br><span class="line">f77ad61 Add js</span><br></pre></td></tr></table></figure></div>

<ol start="3">
<li>查看指定的最近m个commit，在上面的两个命令里面添加 <code>-nm</code>即可</li>
</ol>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">最近的四次提交</span> </span><br><span class="line"><span class="meta">$</span><span class="bash"> git <span class="built_in">log</span> -n4</span> </span><br><span class="line"><span class="meta">$</span><span class="bash"> git <span class="built_in">log</span> -n4 --oneline</span></span><br></pre></td></tr></table></figure></div>

<ol start="4">
<li>图形化查看各个分支的<code>git log</code></li>
</ol>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> git <span class="built_in">log</span> --all --graph</span></span><br><span class="line">* commit fee6bacc33f975bdb0f9ecd7edc7db5acd5429de (HEAD -&gt; main)</span><br><span class="line">| Author: BugKillerPro &lt;511808895@qq.com&gt;</span><br><span class="line">| Date:   Wed Sep 7 15:05:37 2022 +0800</span><br><span class="line">|</span><br><span class="line">|     Modify style.css on branch main</span><br><span class="line">|</span><br><span class="line">| * commit 97b461a6abd2c7700cc063b5795ec192d6d7d1c3 (tmp)</span><br><span class="line">|/  Author: BugKillerPro &lt;511808895@qq.com&gt;</span><br><span class="line">|   Date:   Wed Sep 7 14:46:59 2022 +0800</span><br><span class="line">|</span><br><span class="line">|       Add test to branch tmp</span><br><span class="line">|</span><br><span class="line">* commit a0b98ea6769a71901895c5f879b4b23383ba6bcd</span><br><span class="line">| Author: BugKillerPro &lt;511808895@qq.com&gt;</span><br><span class="line">| Date:   Wed Sep 7 11:20:39 2022 +0800</span><br><span class="line">|</span><br><span class="line">|     Move readme.md to readme</span><br><span class="line">|</span><br><span class="line">* commit 63ca73303c196401d6f0312186a11d517c51f749</span><br><span class="line">| Author: BugKillerPro &lt;511808895@qq.com&gt;</span><br><span class="line">| Date:   Tue Sep 6 11:10:01 2022 +0800</span><br><span class="line">|</span><br><span class="line">|     Add refering projects</span><br><span class="line">|</span><br><span class="line">* commit f77ad615d0a091ac22f78f892c4d50077b43096a (tag: js01)</span><br><span class="line">| Author: BugKillerPro &lt;511808895@qq.com&gt;</span><br><span class="line">| Date:   Tue Sep 6 11:01:34 2022 +0800</span><br><span class="line">|</span><br><span class="line">|     Add js</span><br><span class="line">|</span><br><span class="line">* commit 78be6970adb1671a56e4536b7ea2170a4aa0a7cf</span><br><span class="line">| Author: BugKillerPro &lt;511808895@qq.com&gt;</span><br><span class="line">| Date:   Tue Sep 6 10:59:30 2022 +0800</span><br><span class="line">|</span><br><span class="line">|     Add style.css</span><br><span class="line">|</span><br><span class="line">* commit f51e1172b2dca4aea588ec756f630f5ad803212d</span><br><span class="line">| Author: BugKillerPro &lt;511808895@qq.com&gt;</span><br><span class="line">| Date:   Tue Sep 6 10:55:52 2022 +0800</span><br><span class="line">|</span><br><span class="line">|     Add index _ log</span><br><span class="line">|</span><br><span class="line">* commit 97ad72879455e51a3529a52806f2ec07f67bc8bd (origin/main, origin/HEAD)</span><br><span class="line">  Author: bugmakerprox &lt;112847253+bugmakerprox@users.noreply.github.com&gt;</span><br><span class="line">  Date:   Mon Sep 5 14:02:11 2022 +0800</span><br><span class="line"></span><br><span class="line">      Initial commit</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure></div>

<p>同样也可以加上<code>--oneline</code>查看简洁化的log，也可以加上<code>-nm</code>，查看所有分支的最近m条log</p>
<h2 id="通过图形化界面工具查看版本演变历史"><a href="#通过图形化界面工具查看版本演变历史" class="headerlink" title="通过图形化界面工具查看版本演变历史"></a>通过图形化界面工具查看版本演变历史</h2><p>输入<code>gitk</code>命令，会弹出图形化工具界面</p>
<h2 id="探秘-git文件夹"><a href="#探秘-git文件夹" class="headerlink" title="探秘.git文件夹"></a>探秘<code>.git</code>文件夹</h2><ol>
<li>查看所有文件</li>
</ol>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> ls -al</span></span><br><span class="line">drwxr-xr-x  7 root root 222 9月   7 15:30 .</span><br><span class="line">drwxr-xr-x  3 root root  18 9月   7 16:26 ..</span><br><span class="line">-rw-r--r--  1 root root  32 9月   7 15:05 COMMIT_EDITMSG</span><br><span class="line">-rw-r--r--  1 root root 360 9月   7 14:44 config</span><br><span class="line">-rw-r--r--  1 root root  73 9月   5 14:04 description</span><br><span class="line">-rw-r--r--  1 root root 103 9月   7 10:54 FETCH_HEAD</span><br><span class="line">-rw-r--r--  1 root root 546 9月   7 15:30 gitk.cache</span><br><span class="line">-rw-r--r--  1 root root  21 9月   7 14:52 HEAD</span><br><span class="line">drwxr-xr-x  2 root root 268 9月   5 14:04 hooks</span><br><span class="line">-rw-r--r--  1 root root 554 9月   7 15:05 index</span><br><span class="line">drwxr-xr-x  2 root root  21 9月   5 14:04 info</span><br><span class="line">drwxr-xr-x  3 root root  30 9月   5 14:04 logs</span><br><span class="line">drwxr-xr-x 32 root root 310 9月   7 16:03 objects</span><br><span class="line">-rw-r--r--  1 root root  41 9月   7 10:59 ORIG_HEAD</span><br><span class="line">-rw-r--r--  1 root root 105 9月   5 14:04 packed-refs</span><br><span class="line">drwxr-xr-x  5 root root  46 9月   5 14:04 refs</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>

<ol start="2">
<li>几个文件的说明</li>
</ol>
<p>2.1 <code>refs/</code>文件夹</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> tree refs</span></span><br><span class="line">refs/</span><br><span class="line">├── heads</span><br><span class="line">│ ├── main</span><br><span class="line">│ └── tmp</span><br><span class="line">├── remotes</span><br><span class="line">│ └── origin</span><br><span class="line">│     └── HEAD</span><br><span class="line">└── tags</span><br><span class="line">    └── js01</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>

<p>2.1.1  <code>heads</code>文件夹– 仓库的分支情况</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> cat main</span></span><br><span class="line">fee6bacc33f975bdb0f9ecd7edc7db5acd5429de</span><br><span class="line"><span class="meta">$</span><span class="bash"> cat tmp</span></span><br><span class="line">97b461a6abd2c7700cc063b5795ec192d6d7d1c3</span><br></pre></td></tr></table></figure></div>

<p>通过对比上面讲到的“图形化查看各个分支”，可以发现，<code>main</code>和<code>tmp</code>文件里存放的分别是这两个分支当前指向的<code>commit</code>，也就是每个分支的最后一个<code>commit</code>。<br>另外，可以通过<code>git cat-file -t</code>查看对象的信息，关于<code>git cat-file</code>的用法，详见<a href="https://cloud.tencent.com/developer/section/1138770">cat-file</a></p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> git cat-file -t fee6bacc33f975bdb0f9ecd7edc7db5acd5429de</span></span><br><span class="line">commit</span><br></pre></td></tr></table></figure></div>

<p>所以，<code>refs/heads/</code>目录下的文件内容是<code>commit</code>对象信息。</p>
<p>2.1.2 <code>tags</code> 文件夹 – 仓库的tag信息</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> cat tags/js01</span></span><br><span class="line">db9cd1f2ba810d45ab0c214326ad50fc026dd65d</span><br></pre></td></tr></table></figure></div>

<p>同样，通过<code>git cat-file -t</code>查看对象信息</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> git cat-file -t db9cd1f2ba810d45ab0c214326ad50fc026dd65d</span></span><br><span class="line">tag</span><br></pre></td></tr></table></figure></div>

<p>所以，<code>refs/tags/</code>目录下的文件内容是<code>tag</code>对象信息，再通过<code>git cat-file -p</code>查看一下详细信息</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> git cat-file -p db9cd1f2ba810d45ab0c214326ad50fc026dd65d</span></span><br><span class="line">object f77ad615d0a091ac22f78f892c4d50077b43096a</span><br><span class="line">type commit</span><br><span class="line">tag js01</span><br><span class="line">tagger xxx &lt;email&gt; 1662537810 +0800</span><br><span class="line"></span><br><span class="line">js01</span><br><span class="line"></span><br><span class="line"><span class="meta">$</span><span class="bash"> git cat-file -t f77ad615d0a091ac22f78f892c4d50077b43096a</span></span><br><span class="line">commit</span><br></pre></td></tr></table></figure></div>

<p>可以看出，<code>js01</code>这个tag是打在<code>f77ad615d0a091ac22f78f892c4d50077b43096a</code>这次<code>commit</code>上的，和上面“图形化查看各个分支”看到的信息一致。</p>
<p>2.2 <code>HEAD</code>文件<br>表示当前仓库工作所在的分支，文件内容<code>ref: refs/heads/main</code> ，指向refs/heads下的分支文件</p>
<p>2.3 <code>config</code>文件<br>表示和本地仓库相关的配置信息，local作用域的信息会写在这里面；同样，编辑该文件，信息也可以从<code>git config --local --list</code>看到</p>
<p>2.4 <code>objects</code>文件夹</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> tree objects</span></span><br><span class="line">objects/</span><br><span class="line">├── 06</span><br><span class="line">│   └── cdcb31ac08c3da684741bd9e576d806c02c509</span><br><span class="line">├── 17</span><br><span class="line">│   └── 3e0e863d31a6977e6bea2f5433172c302c7827</span><br><span class="line">├── 2c</span><br><span class="line">│   └── 8d044b64097ced0e003b9bded8ed5397767080</span><br><span class="line">├── 2e</span><br><span class="line">│   └── a71f7370e32c9ab44a475cccbc289f65b2c11d</span><br><span class="line">├── 37</span><br><span class="line">│   └── 809d45bb8f6e7699bc3216a4529b965831280f</span><br><span class="line">├── 50</span><br><span class="line">│   └── b9f19afa5ffe2199377d70208207e692417f9d</span><br><span class="line">├── 63</span><br><span class="line">│   └── ca73303c196401d6f0312186a11d517c51f749</span><br><span class="line">├── 6a</span><br><span class="line">│   └── d4c68d567a1a5b415dcfce2010fce1a60b245f</span><br><span class="line">├── 74</span><br><span class="line">│   └── ce54a5c285bebca10869bfde5a61183f37960d</span><br><span class="line">├── 78</span><br><span class="line">│   └── be6970adb1671a56e4536b7ea2170a4aa0a7cf</span><br><span class="line">├── 7c</span><br><span class="line">│   └── fe3376c0cc252bed22271480b06b642f960f48</span><br><span class="line">├── 87</span><br><span class="line">│   └── b3e92f70e7dfa555f141afeae28a2bc4a343b6</span><br><span class="line">├── 96</span><br><span class="line">│   └── b67e399c8496ec36cbbbcb776eb924fad7f9a7</span><br><span class="line">├── 97</span><br><span class="line">│   ├── ad72879455e51a3529a52806f2ec07f67bc8bd</span><br><span class="line">│   └── b461a6abd2c7700cc063b5795ec192d6d7d1c3</span><br><span class="line">├── a0</span><br><span class="line">│   └── b98ea6769a71901895c5f879b4b23383ba6bcd</span><br><span class="line">├── a3</span><br><span class="line">│   └── 461553e40ba4259a40287239b5c38fb2fb76a7</span><br><span class="line">├── ab</span><br><span class="line">│   └── 80565b73e7d2f0a2b5b9667c0b3470238b0fc0</span><br><span class="line">├── ac</span><br><span class="line">│   └── c1c738d00c0c937ce5d630ef096199f8d8d73f</span><br><span class="line">├── ae</span><br><span class="line">│   └── e37060401d19e7bd9f80b7b33920a000e96b5b</span><br><span class="line">├── b0</span><br><span class="line">│   └── eb6f806441b634f3591e7e3abd87a7754d305a</span><br><span class="line">├── cc</span><br><span class="line">│   └── b7b203933b7f1065b3a338eb321ba55112912f</span><br><span class="line">├── d6</span><br><span class="line">│   └── 5a3bef25228c256c49b2ddf5bac2f367cb75f9</span><br><span class="line">├── da</span><br><span class="line">│   └── f480669aa9256fa18b5c28e467af816f16482d</span><br><span class="line">├── db</span><br><span class="line">│   └── 9cd1f2ba810d45ab0c214326ad50fc026dd65d</span><br><span class="line">├── ef</span><br><span class="line">│   ├── 3f137d8af338a8604544a3e482090684321d93</span><br><span class="line">│   └── b66cbd5ffbfe9578e4aaf7629402a9d943205a</span><br><span class="line">├── f5</span><br><span class="line">│   └── 1e1172b2dca4aea588ec756f630f5ad803212d</span><br><span class="line">├── f7</span><br><span class="line">│   └── 7ad615d0a091ac22f78f892c4d50077b43096a</span><br><span class="line">├── fe</span><br><span class="line">│   └── e6bacc33f975bdb0f9ecd7edc7db5acd5429de</span><br><span class="line">├── info</span><br><span class="line">└── pack</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>

<p>详见<a href="https://git-scm.com/book/zh/v2/Git-%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86-Git-%E5%AF%B9%E8%B1%A1">Git 内部原理 - Git 对象</a></p>
<h2 id="commit、tree和blob三个对象之间的关系"><a href="#commit、tree和blob三个对象之间的关系" class="headerlink" title="commit、tree和blob三个对象之间的关系"></a>commit、tree和blob三个对象之间的关系</h2><blockquote>
<p>了解<br><img src="/2022/09/05/uncatalog/cl7oebs5q0000f0r7e0oq9fnk/12.png" alt="12"></p>
</blockquote>
<h2 id="分离头指针-detached-HEAD-情况下的注意事项"><a href="#分离头指针-detached-HEAD-情况下的注意事项" class="headerlink" title="分离头指针(detached HEAD)情况下的注意事项"></a>分离头指针(detached HEAD)情况下的注意事项</h2><p>常见产生分离头指针的情况：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> git <span class="built_in">log</span> --all --graph --oneline</span></span><br><span class="line">* fee6bac (HEAD -&gt; main) Modify style.css on branch main</span><br><span class="line">| * 97b461a (tmp) Add test to branch tmp</span><br><span class="line">|/</span><br><span class="line">* a0b98ea Move readme.md to readme</span><br><span class="line">* 63ca733 Add refering projects</span><br><span class="line">* f77ad61 (tag: js01) Add js</span><br><span class="line">* 78be697 Add style.css</span><br><span class="line">* f51e117 Add index _ log</span><br><span class="line">* 97ad728 (origin/main, origin/HEAD) Initial commit</span><br><span class="line"></span><br><span class="line">jw.xu@hz-jw-xu-n MINGW64 /d/github/gitPractice (main)</span><br><span class="line"><span class="meta">$</span><span class="bash"> git checkout 78be697 <span class="comment"># 该操作会产生分离头指针现象</span></span></span><br><span class="line">Note: switching to &#x27;78be697&#x27;.</span><br><span class="line"></span><br><span class="line">You are in &#x27;detached HEAD&#x27; state. You can look around, make experimental</span><br><span class="line">changes and commit them, and you can discard any commits you make in this</span><br><span class="line">state without impacting any branches by switching back to a branch.</span><br><span class="line"></span><br><span class="line">If you want to create a new branch to retain commits you create, you may</span><br><span class="line">do so (now or later) by using -c with the switch command. Example:</span><br><span class="line"></span><br><span class="line">  git switch -c &lt;new-branch-name&gt;</span><br><span class="line"></span><br><span class="line">Or undo this operation with:</span><br><span class="line"></span><br><span class="line">  git switch -</span><br><span class="line"></span><br><span class="line">Turn off this advice by setting config variable advice.detachedHead to false</span><br><span class="line"></span><br><span class="line">HEAD is now at 78be697 Add style.css</span><br><span class="line"></span><br><span class="line"><span class="meta">$</span><span class="bash"> git <span class="built_in">log</span> --all --graph --oneline</span></span><br><span class="line">* fee6bac (main) Modify style.css on branch main</span><br><span class="line">| * 97b461a (tmp) Add test to branch tmp</span><br><span class="line">|/</span><br><span class="line">* a0b98ea Move readme.md to readme</span><br><span class="line">* 63ca733 Add refering projects</span><br><span class="line">* f77ad61 (tag: js01) Add js</span><br><span class="line">* 78be697 (HEAD) Add style.css</span><br><span class="line">* f51e117 Add index _ log</span><br><span class="line">* 97ad728 (origin/main, origin/HEAD) Initial commit</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>

<p>分离头指针是指当前正在工作在一个没有分支的状态下，即没有指向任何<code>branch</code>。如果在这种情况下做了变更，然后又切换到其他分支，变更将被清理掉。<br>当然，也可以利用好分离头指针这个特性，比如我们仅仅需要在某个commit上做一些尝试代码，并不需要记录和提交，尝试完之后，直接切换到其他分支即可，尝试代码会被清理掉。<br>如果在这种情况下，做了变更，又做了commit，则会出现以下情况:</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> git status</span></span><br><span class="line">HEAD detached at 78be697</span><br><span class="line">Changes not staged for commit:</span><br><span class="line">  (use &quot;git add &lt;file&gt;...&quot; to update what will be committed)</span><br><span class="line">  (use &quot;git restore &lt;file&gt;...&quot; to discard changes in working directory)</span><br><span class="line">        modified:   styles/style.css</span><br><span class="line"></span><br><span class="line">no changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;)</span><br><span class="line"><span class="meta">$</span><span class="bash"> git add -u</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> git commit -m <span class="string">&quot;Background to yellow&quot;</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> git <span class="built_in">log</span> --all --graph --oneline</span></span><br><span class="line">* a5a8831 (HEAD) Background to yellow</span><br><span class="line">| * fee6bac (main) Modify style.css on branch main</span><br><span class="line">| | * 97b461a (tmp) Add test to branch tmp</span><br><span class="line">| |/</span><br><span class="line">| * a0b98ea Move readme.md to readme</span><br><span class="line">| * 63ca733 Add refering projects</span><br><span class="line">| * f77ad61 (tag: js01) Add js</span><br><span class="line">|/</span><br><span class="line">* 78be697 Add style.css</span><br><span class="line">* f51e117 Add index _ log</span><br><span class="line">* 97ad728 (origin/main, origin/HEAD) Initial commit</span><br><span class="line"></span><br><span class="line"><span class="meta">$</span><span class="bash"> git branch</span></span><br><span class="line">* (HEAD detached from 78be697)</span><br><span class="line">  main</span><br><span class="line">  tmp</span><br></pre></td></tr></table></figure></div>

<p>可以看到头指针(HEAD)没有指向任何分支(main或者tmp),如果此时切换到了其他分支:</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> git checkout main</span></span><br><span class="line">Warning: you are leaving 1 commit behind, not connected to</span><br><span class="line">any of your branches:</span><br><span class="line"></span><br><span class="line">  a5a8831 Background to yellow</span><br><span class="line"></span><br><span class="line">If you want to keep it by creating a new branch, this may be a good time</span><br><span class="line">to do so with:</span><br><span class="line"></span><br><span class="line"> git branch &lt;new-branch-name&gt; a5a8831</span><br><span class="line"></span><br><span class="line">Switched to branch &#x27;main&#x27;</span><br><span class="line">Your branch is ahead of &#x27;origin/main&#x27; by 6 commits.</span><br><span class="line">  (use &quot;git push&quot; to publish your local commits)</span><br><span class="line">  </span><br><span class="line"><span class="meta">$</span><span class="bash"> git <span class="built_in">log</span> --all --graph --oneline</span></span><br><span class="line">* fee6bac (HEAD -&gt; main) Modify style.css on branch main</span><br><span class="line">| * 97b461a (tmp) Add test to branch tmp</span><br><span class="line">|/</span><br><span class="line">* a0b98ea Move readme.md to readme</span><br><span class="line">* 63ca733 Add refering projects</span><br><span class="line">* f77ad61 (tag: js01) Add js</span><br><span class="line">* 78be697 Add style.css</span><br><span class="line">* f51e117 Add index _ log</span><br><span class="line">* 97ad728 (origin/main, origin/HEAD) Initial commit </span><br></pre></td></tr></table></figure></div>
<p>发现，之前的<code>a5a8831 (HEAD) Background to yellow</code>消失了。如果觉得<code>a5a8831</code>很重要，此时还有补救办法，就是上面提示的那样<code>git branch &lt;new-branch-name&gt; a5a8831</code>操作：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> git branch fix_css a5a8831</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> git branch</span></span><br><span class="line">  fix_css</span><br><span class="line">* main</span><br><span class="line">  tmp</span><br><span class="line"><span class="meta">$</span><span class="bash"> git <span class="built_in">log</span> --all --graph --oneline</span></span><br><span class="line">* a5a8831 (fix_css) Background to yellow</span><br><span class="line">| * fee6bac (HEAD -&gt; main) Modify style.css on branch main</span><br><span class="line">| | * 97b461a (tmp) Add test to branch tmp</span><br><span class="line">| |/</span><br><span class="line">| * a0b98ea Move readme.md to readme</span><br><span class="line">| * 63ca733 Add refering projects</span><br><span class="line">| * f77ad61 (tag: js01) Add js</span><br><span class="line">|/</span><br><span class="line">* 78be697 Add style.css</span><br><span class="line">* f51e117 Add index _ log</span><br><span class="line">* 97ad728 (origin/main, origin/HEAD) Initial commit</span><br></pre></td></tr></table></figure></div>
<p>新建了一个<code>fix_css</code>分支，之前的提交<code>a5a8831</code>又回来了。</p>
<h2 id="进一步理解HEAD和branch"><a href="#进一步理解HEAD和branch" class="headerlink" title="进一步理解HEAD和branch"></a>进一步理解HEAD和branch</h2><p>HEAD 可以指向branch也可以指向commit</p>
<h2 id="怎么删除不需要的分支"><a href="#怎么删除不需要的分支" class="headerlink" title="怎么删除不需要的分支"></a>怎么删除不需要的分支</h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> git branch -d 分支名 <span class="comment">#</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> git branch -D 分支名</span></span><br></pre></td></tr></table></figure></div>
<p>区别：</p>
<blockquote>
<p>-d<br>–delete<br>Delete a branch. The branch must be fully merged in its upstream branch, or in HEAD if no upstream was set with –track or –set-upstream-to.<br>-D<br>Shortcut for –delete –force</p>
</blockquote>
<h2 id="怎么修改最新commit的message"><a href="#怎么修改最新commit的message" class="headerlink" title="怎么修改最新commit的message"></a>怎么修改最新commit的message</h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> git <span class="built_in">log</span> --all --graph --oneline -n2</span></span><br><span class="line">* a5a8831 (fix_css) Background to yellow</span><br><span class="line">| * fee6bac (HEAD -&gt; main) Modify style.css on branch main</span><br><span class="line"></span><br><span class="line"><span class="meta">$</span><span class="bash"> git commit --amend <span class="comment"># 弹出vim修改框</span></span></span><br><span class="line">[main 7f04fb2] Modify style.css on branch main amend</span><br><span class="line"> Date: Wed Sep 7 15:05:37 2022 +0800</span><br><span class="line"> 1 file changed, 5 insertions(+)</span><br><span class="line"></span><br><span class="line"><span class="meta">$</span><span class="bash"> git <span class="built_in">log</span> --all --graph --oneline -n2</span></span><br><span class="line">* 7f04fb2 (HEAD -&gt; main) Modify style.css on branch main amend</span><br><span class="line">| * a5a8831 (fix_css) Background to yellow</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>

<h2 id="怎么修改老旧的commit的message"><a href="#怎么修改老旧的commit的message" class="headerlink" title="怎么修改老旧的commit的message"></a>怎么修改老旧的commit的message</h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> git <span class="built_in">log</span> --all --graph --oneline -n6</span></span><br><span class="line">* fb1ece1 (HEAD -&gt; main) Add div class style</span><br><span class="line">* 167491f Add green style.css</span><br><span class="line">* f51e117 Add index _ log</span><br><span class="line">* 97ad728 (origin/main, origin/HEAD) Initial commit</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>
<p>如果我想变更<code>167491f Add green style.css</code>这一次commit的message,从“Add green style.css”变更为“Add red style.css”，可以使用它的父commit<code>f51e117</code>做<code>rebase</code>操作：<br>(tips:如果该commit没有父commit，即是第一个commit，我们可以对选用它的commitID做rebase操作，然后在下面的弹出内容里，把该commit添加进去即可，然后再选择对应的commands)</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> git rebase -i f51e117  <span class="comment"># -i 交互模式</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 弹出以下内容</span></span><br><span class="line">pick 167491f Add green style.css</span><br><span class="line">pick fb1ece1 Add div class style</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Rebase 97ad728..63ca733 onto 97ad728 (4 commands)</span></span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="bash"><span class="comment"># Commands:</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> p, pick &lt;commit&gt; = use commit</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> r, reword &lt;commit&gt; = use commit, but edit the commit message</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> e, edit &lt;commit&gt; = use commit, but stop <span class="keyword">for</span> amending</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> s, squash &lt;commit&gt; = use commit, but meld into previous commit</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> f, fixup [-C | -c] &lt;commit&gt; = like <span class="string">&quot;squash&quot;</span> but keep only the previous</span></span><br><span class="line"><span class="meta">#</span><span class="bash">                    commit<span class="string">&#x27;s log message, unless -C is used, in which case</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash">                    keep only this commit<span class="string">&#x27;s message; -c is same as -C but</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash">                    opens the editor</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> x, <span class="built_in">exec</span> &lt;<span class="built_in">command</span>&gt; = run <span class="built_in">command</span> (the rest of the line) using shell</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> b, <span class="built_in">break</span> = stop here (<span class="built_in">continue</span> rebase later with <span class="string">&#x27;git rebase --continue&#x27;</span>)</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> d, drop &lt;commit&gt; = remove commit</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> l, label &lt;label&gt; = label current HEAD with a name</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> t, reset &lt;label&gt; = reset HEAD to a label</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> m, merge [-C &lt;commit&gt; | -c &lt;commit&gt;] &lt;label&gt; [<span class="comment"># &lt;oneline&gt;]</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> .       create a merge commit using the original merge commit<span class="string">&#x27;s</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> .       message (or the oneline, <span class="keyword">if</span> no original merge commit was</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> .       specified); use -c &lt;commit&gt; to reword the commit message</span></span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="bash"><span class="comment"># These lines can be re-ordered; they are executed from top to bottom.</span></span></span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="bash"><span class="comment"># If you remove a line here THAT COMMIT WILL BE LOST.</span></span></span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="bash"><span class="comment"># However, if you remove everything, the rebase will be aborted.</span></span></span><br><span class="line"></span><br></pre></td></tr></table></figure></div>
<p>接下来就是编写对应commit的commands，常见的commands解析如下:</p>
<table>
<thead>
<tr>
<th>commands</th>
<th>解析</th>
</tr>
</thead>
<tbody><tr>
<td>pick(简写p)</td>
<td>rebase过程中保留这次commit</td>
</tr>
<tr>
<td>reword(简写r)</td>
<td>rebase过程中保留这次commit,但是需要重新编辑这次commit的message，使用了这个命令之后，保存退出，将会弹出修改message界面</td>
</tr>
<tr>
<td>edit(简写e)</td>
<td>rebase过程中保留这次commit,保留commit，但rebase操作执行到该commit时会暂停，用户在此commit基础上进行内容修改（当然，也可以不修改）后，执行git add 目标文件和git commit –amend更新message，然后执行git rebase –continue继续未完成的rebase工作 。这个命令的使用场景是，需要对之前的某一个commit上做内容修改</td>
</tr>
<tr>
<td>squash(简写s)</td>
<td>rebase过程中保留这次commit, 但将其合并至前一个commit，合并时，自动汇总该commit与上一个commit的message，用户可进行二次编辑message</td>
</tr>
<tr>
<td>fixup(简写f)</td>
<td>与squash功能类似，保留commit，将其合并至前一个commit，但是丢弃该commit的message，使用上一个commit的message</td>
</tr>
</tbody></table>
<p>这里我们把<code>pick 167491f Add green style.css</code>修改为<code>r 167491f Add green style.css</code>，保存退出之后，弹出修改message页面:</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">Add red style.css</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Please enter the commit message <span class="keyword">for</span> your changes. Lines starting</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> with <span class="string">&#x27;#&#x27;</span> will be ignored, and an empty message aborts the commit.</span></span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="bash"><span class="comment"># Date:      Wed Sep 7 11:20:39 2022 +0800</span></span></span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="bash"><span class="comment"># interactive rebase in progress; onto 63ca733</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Last <span class="built_in">command</span> <span class="keyword">done</span> (1 <span class="built_in">command</span> <span class="keyword">done</span>):</span></span><br><span class="line"><span class="meta">#</span><span class="bash">    reword a0b98ea Move readme.md to readme</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Next <span class="built_in">command</span> to <span class="keyword">do</span> (1 remaining <span class="built_in">command</span>):</span></span><br><span class="line"><span class="meta">#</span><span class="bash">    pick 7f04fb2 Modify style.css on branch main amend</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> You are currently editing a commit <span class="keyword">while</span> rebasing branch <span class="string">&#x27;main&#x27;</span> on <span class="string">&#x27;63ca733&#x27;</span>.</span></span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="bash"><span class="comment"># Changes to be committed:</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash">       renamed:    README.md -&gt; README</span></span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="bash"><span class="comment"># Untracked files:</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash">       .gitignore</span></span><br><span class="line"><span class="meta">#</span></span><br></pre></td></tr></table></figure></div>
<p>message修改完之后，再次保存退出，将自动弹出:</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> git rebase -i f51e117</span></span><br><span class="line">[detached HEAD 68c45d1] Add red style.css</span><br><span class="line"> Date: Tue Sep 6 10:59:30 2022 +0800</span><br><span class="line"> 1 file changed, 50 insertions(+)</span><br><span class="line"> create mode 100644 styles/style.css</span><br><span class="line">Successfully rebased and updated refs/heads/main.</span><br></pre></td></tr></table></figure></div>
<p>我们再次查看log:</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">git log --all --graph --oneline -n6</span><br><span class="line">* 7db15bd (HEAD -&gt; main) Add div class style</span><br><span class="line">* 68c45d1 Add red style.css</span><br><span class="line">* f51e117 Add index _ log</span><br><span class="line">* 97ad728 (origin/main, origin/HEAD) Initial commit</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>
<p>对比开始之前的log，已经完成了message的修改，只不过commit的ID发生了变更。<br>(注意，当存在多个分支时，修改多个分支共同路径上的commit的message，将从该commit的父commit开始发生裂变，当前分支该commit的message发生了修改，其他分支该commit的message保持不变)<br>修改<code>f51e117 Add index _ log</code>前:</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">* fd46298 (HEAD -&gt; b1) Add style to b1</span><br><span class="line">| * 72c72b5 (main) Add li to index</span><br><span class="line">|/</span><br><span class="line">* 7db15bd Add div class style</span><br><span class="line">* 68c45d1 Add red style.css</span><br><span class="line">* f51e117 Add index _ log</span><br><span class="line">* 97ad728 (origin/main, origin/HEAD) Initial commit</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>
<p>修改<code>f51e117 Add index _ log</code>后:</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">* 6f4263f (HEAD -&gt; b1) Add style to b1</span><br><span class="line">* 29ec5c3 Add div class style</span><br><span class="line">* f3f7003 Add red style.css</span><br><span class="line">* 8128f86 Add index _ log after init</span><br><span class="line">| * 72c72b5 (main) Add li to index</span><br><span class="line">| * 7db15bd Add div class style</span><br><span class="line">| * 68c45d1 Add red style.css</span><br><span class="line">| * f51e117 Add index _ log</span><br><span class="line">|/</span><br><span class="line">* 97ad728 (origin/main, origin/HEAD) Initial commit</span><br></pre></td></tr></table></figure></div>
<p><code>git rebase</code>变基操作应该只在自己开发的分支上进行，所以通过<code>git rebase -i commitID </code>修改旧的commit的message应该仅限于自己分支，不要对团队集成路径上/共同路径上的commit的message做变更，以免出现不可预期的trouble. </p>
<h2 id="怎么把多个连续的commit合并成一个commit"><a href="#怎么把多个连续的commit合并成一个commit" class="headerlink" title="怎么把多个连续的commit合并成一个commit"></a>怎么把多个连续的commit合并成一个commit</h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> git <span class="built_in">log</span> --all --graph --oneline</span></span><br><span class="line">* a3d26dc (HEAD -&gt; main) Add 3 div to index</span><br><span class="line">* bac9977 Add 2 div to index</span><br><span class="line">* 2fab0c5 Add 1 div to index</span><br><span class="line">* 7db15bd Add div class style</span><br><span class="line">* 68c45d1 Add red style.css</span><br><span class="line">* f51e117 Add index _ log</span><br><span class="line">* 97ad728 (origin/main, origin/HEAD) Initial commit</span><br></pre></td></tr></table></figure></div>
<p>最近的三次comimt都是对index文件的操作，我们可以考虑把它们合并一下:</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> git rebase -i 7db15bd</span> </span><br></pre></td></tr></table></figure></div>
<p>弹出页面:</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">pick 2fab0c5 Add 1 div to index</span><br><span class="line">pick bac9977 Add 2 div to index</span><br><span class="line">pick a3d26dc Add 3 div to index</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Rebase 7db15bd..a3d26dc onto 7db15bd (3 commands)</span></span><br></pre></td></tr></table></figure></div>
<p>修改为:</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">pick 2fab0c5 Add 1 div to index</span><br><span class="line">s bac9977 Add 2 div to index</span><br><span class="line">s a3d26dc Add 3 div to index</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Rebase 7db15bd..a3d26dc onto 7db15bd (3 commands)</span></span><br></pre></td></tr></table></figure></div>
<p>保存退出，弹出页面:</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> This is a combination of 3 commits.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> This is the 1st commit message:</span></span><br><span class="line"></span><br><span class="line">Add 1 div to index</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> This is the commit message <span class="comment">#2:</span></span></span><br><span class="line"></span><br><span class="line">Add 2 div to index</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> This is the commit message <span class="comment">#3:</span></span></span><br><span class="line"></span><br><span class="line">Add 3 div to index</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Please enter the commit message <span class="keyword">for</span> your changes. Lines starting</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> with <span class="string">&#x27;#&#x27;</span> will be ignored, and an empty message aborts the commit.</span></span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="bash"><span class="comment"># Date:      Fri Sep 9 14:13:08 2022 +0800</span></span></span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="bash"><span class="comment"># interactive rebase in progress; onto 7db15bd</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Last commands <span class="keyword">done</span> (3 commands <span class="keyword">done</span>):</span></span><br><span class="line"><span class="meta">#</span><span class="bash">    squash bac9977 Add 2 div to index</span></span><br><span class="line"><span class="meta">#</span><span class="bash">    squash a3d26dc Add 3 div to index</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> No commands remaining.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> You are currently rebasing branch <span class="string">&#x27;main&#x27;</span> on <span class="string">&#x27;7db15bd&#x27;</span>.</span></span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="bash"><span class="comment"># Changes to be committed:</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash">       modified:   index.html</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></div>
<p>在<code># This is a combination of 3 commits.</code>下面添加合并成一个commit的message：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> This is a combination of 3 commits.</span></span><br><span class="line">Add total 3 div to index,a combination commit message</span><br><span class="line"><span class="meta">#</span><span class="bash"> This is the 1st commit message:</span></span><br><span class="line"></span><br><span class="line">Add 1 div to index</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> This is the commit message <span class="comment">#2:</span></span></span><br><span class="line"></span><br><span class="line">Add 2 div to index</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> This is the commit message <span class="comment">#3:</span></span></span><br><span class="line"></span><br><span class="line">Add 3 div to index</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Please enter the commit message <span class="keyword">for</span> your changes. Lines starting</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> with <span class="string">&#x27;#&#x27;</span> will be ignored, and an empty message aborts the commit.</span></span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="bash"><span class="comment"># Date:      Fri Sep 9 14:13:08 2022 +0800</span></span></span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="bash"><span class="comment"># interactive rebase in progress; onto 7db15bd</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Last commands <span class="keyword">done</span> (3 commands <span class="keyword">done</span>):</span></span><br><span class="line"><span class="meta">#</span><span class="bash">    squash bac9977 Add 2 div to index</span></span><br><span class="line"><span class="meta">#</span><span class="bash">    squash a3d26dc Add 3 div to index</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> No commands remaining.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> You are currently rebasing branch <span class="string">&#x27;main&#x27;</span> on <span class="string">&#x27;7db15bd&#x27;</span>.</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></div>
<p>保存退出:</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> git rebase -i 7db15bd</span></span><br><span class="line">[detached HEAD 35a3dea] Add total 3 div to index,a combination commit message</span><br><span class="line"> Date: Fri Sep 9 14:13:08 2022 +0800</span><br><span class="line"> 1 file changed, 15 insertions(+)</span><br><span class="line">Successfully rebased and updated refs/heads/main.</span><br></pre></td></tr></table></figure></div>
<p>查看log，完成commit合并:</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> git <span class="built_in">log</span> --all --graph --oneline</span></span><br><span class="line">* 35a3dea (HEAD -&gt; main) Add total 3 div to index,a combination commit message</span><br><span class="line">* 7db15bd Add div class style</span><br><span class="line">* 68c45d1 Add red style.css</span><br><span class="line">* f51e117 Add index _ log</span><br><span class="line">* 97ad728 (origin/main, origin/HEAD) Initial commit</span><br></pre></td></tr></table></figure></div>

<h2 id="怎么把多个不连续的commit合并成一个commit"><a href="#怎么把多个不连续的commit合并成一个commit" class="headerlink" title="怎么把多个不连续的commit合并成一个commit"></a>怎么把多个不连续的commit合并成一个commit</h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> git <span class="built_in">log</span> --all --graph --oneline</span></span><br><span class="line">* 6e38539 (HEAD -&gt; main) Add new annotation to index.html</span><br><span class="line">* b7e7353 Add gree style.css</span><br><span class="line">* 35a3dea Add total 3 div to index,a combination commit message</span><br><span class="line">* 7db15bd Add div class style</span><br><span class="line">* 68c45d1 Add red style.css</span><br><span class="line">* f51e117 Add index _ log</span><br><span class="line">* 97ad728 (origin/main, origin/HEAD) Initial commit</span><br></pre></td></tr></table></figure></div>
<p><code>b7e7353 Add gree style.css</code>和<code>68c45d1 Add red style.css</code>都是对<code>style.css</code>的修改，考虑合并成一个commit：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> git rebase -i f51e117</span></span><br></pre></td></tr></table></figure></div>
<p>弹出:</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">pick 68c45d1 Add red style.css</span><br><span class="line">pick 7db15bd Add div class style</span><br><span class="line">pick 35a3dea Add total 3 div to index,a combination commit message</span><br><span class="line">pick b7e7353 Add gree style.css</span><br><span class="line">pick 6e38539 Add new annotation to index.html</span><br></pre></td></tr></table></figure></div>
<p>修改为:</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">pick 68c45d1 Add red style.css</span><br><span class="line">s b7e7353 Add gree style.css</span><br><span class="line">pick 7db15bd Add div class style</span><br><span class="line">pick 35a3dea Add total 3 div to index,a combination commit message</span><br><span class="line">pick 6e38539 Add new annotation to index.html</span><br></pre></td></tr></table></figure></div>
<p>保存退出(对于不连续的commit做合并，大概率会遇到冲突，如果有冲突，则解决完文件冲突后使用<code>git add -u</code> 和<code>git rebase --continue</code>)，弹出:</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> This is a combination of 2 commits.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 在此处添加合并后的message</span></span><br><span class="line">Add some color style.css,combination message of 2 commits</span><br><span class="line"><span class="meta">#</span><span class="bash"> This is the 1st commit message:</span></span><br><span class="line"></span><br><span class="line">Add red style.css</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> This is the commit message <span class="comment">#2:</span></span></span><br><span class="line"></span><br><span class="line">Add gree style.css</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Please enter the commit message <span class="keyword">for</span> your changes. Lines starting</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> with <span class="string">&#x27;#&#x27;</span> will be ignored, and an empty message aborts the commit.</span></span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="bash"><span class="comment"># Date:      Tue Sep 6 10:59:30 2022 +0800</span></span></span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="bash"><span class="comment"># interactive rebase in progress; onto f51e117</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Last commands <span class="keyword">done</span> (2 commands <span class="keyword">done</span>):</span></span><br><span class="line"><span class="meta">#</span><span class="bash">    pick 68c45d1 Add red style.css</span></span><br><span class="line"><span class="meta">#</span><span class="bash">    squash b7e7353 Add gree style.css</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Next commands to <span class="keyword">do</span> (3 remaining commands):</span></span><br><span class="line"><span class="meta">#</span><span class="bash">    pick 7db15bd Add div class style</span></span><br><span class="line"><span class="meta">#</span><span class="bash">    pick 35a3dea Add total 3 div to index,a combination commit message</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> You are currently rebasing branch <span class="string">&#x27;main&#x27;</span> on <span class="string">&#x27;f51e117&#x27;</span>.</span></span><br></pre></td></tr></table></figure></div>
<p>查看合并结果:</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> git <span class="built_in">log</span> --all --graph --oneline</span></span><br><span class="line">* d3a8e50 (HEAD -&gt; main) Add new annotation to index.html</span><br><span class="line">* ad7fa4c Add total 3 div to index,a combination commit message</span><br><span class="line">* 6a384dd Add div class style</span><br><span class="line">* ebd0755 Add some color style.css,combination message of 2 commits</span><br><span class="line">* f51e117 Add index _ log</span><br><span class="line">* 97ad728 (origin/main, origin/HEAD) Initial commit</span><br></pre></td></tr></table></figure></div>

<h2 id="消除最近的几次提交"><a href="#消除最近的几次提交" class="headerlink" title="消除最近的几次提交"></a>消除最近的几次提交</h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> git <span class="built_in">log</span> --all --graph --oneline</span></span><br><span class="line">* e4eb5dd (HEAD -&gt; temp) Add images/wall_paper.jpg</span><br><span class="line">* ad147cf Remove style/style.css</span><br><span class="line">* 67626bb Add some comments</span><br><span class="line">| * 0007ea8 (main) Change styles/style.css to 版本库</span><br><span class="line">| * d3a8e50 Add new annotation to index.html</span><br><span class="line">| * ad7fa4c Add total 3 div to index,a combination commit message</span><br><span class="line">| * 6a384dd Add div class style</span><br><span class="line">|/</span><br><span class="line">* ebd0755 Add some color style.css,combination message of 2 commits</span><br><span class="line">* f51e117 Add index _ log</span><br><span class="line">* 97ad728 (origin/main, origin/HEAD) Initial commit</span><br><span class="line"></span><br><span class="line"><span class="meta">$</span><span class="bash"> git reset --hard 67626bb</span></span><br><span class="line">HEAD is now at 67626bb Add some comments</span><br><span class="line"></span><br><span class="line"><span class="meta">$</span><span class="bash"> git <span class="built_in">log</span> --all --graph --oneline</span></span><br><span class="line">* 67626bb (HEAD -&gt; temp) Add some comments</span><br><span class="line">| * 0007ea8 (main) Change styles/style.css to 版本库</span><br><span class="line">| * d3a8e50 Add new annotation to index.html</span><br><span class="line">| * ad7fa4c Add total 3 div to index,a combination commit message</span><br><span class="line">| * 6a384dd Add div class style</span><br><span class="line">|/</span><br><span class="line">* ebd0755 Add some color style.css,combination message of 2 commits</span><br><span class="line">* f51e117 Add index _ log</span><br><span class="line">* 97ad728 (origin/main, origin/HEAD) Initial commit</span><br></pre></td></tr></table></figure></div>
<p><code>git reset --hard commitID</code>，HEAD会指向<code>comitID</code>，并且暂存区和工作区都会恢复到指定<code>commitID</code>的内容。</p>
<h2 id="怎么比较暂存区和HEAD所含文件的差异"><a href="#怎么比较暂存区和HEAD所含文件的差异" class="headerlink" title="怎么比较暂存区和HEAD所含文件的差异"></a>怎么比较暂存区和HEAD所含文件的差异</h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 工作区文件修改后，添加到暂存区</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> git add -u</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 比较暂存区和HEAD所含文件的差异</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> git diff --cached</span></span><br></pre></td></tr></table></figure></div>

<h2 id="如何让暂存区恢复成和HEAD的一样"><a href="#如何让暂存区恢复成和HEAD的一样" class="headerlink" title="如何让暂存区恢复成和HEAD的一样"></a>如何让暂存区恢复成和HEAD的一样</h2><blockquote>
<p>即放弃已经add到暂存区的变更</p>
</blockquote>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 恢复</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> git reset HEAD</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看差异，验证恢复</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> git diff --cached</span></span><br></pre></td></tr></table></figure></div>
<p>执行之后，从上一次commit到现在，add到暂存区的变更将会清除，但是本地工作区不会被清除</p>
<h2 id="怎样取消暂存区部分文件的更改"><a href="#怎样取消暂存区部分文件的更改" class="headerlink" title="怎样取消暂存区部分文件的更改"></a>怎样取消暂存区部分文件的更改</h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> git status</span></span><br><span class="line">On branch main</span><br><span class="line">Your branch is ahead of &#x27;origin/main&#x27; by 6 commits.</span><br><span class="line">  (use &quot;git push&quot; to publish your local commits)</span><br><span class="line"></span><br><span class="line">Changes to be committed:</span><br><span class="line">  (use &quot;git restore --staged &lt;file&gt;...&quot; to unstage)</span><br><span class="line">        modified:   index.html</span><br><span class="line">        modified:   styles/style.css</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>
<p><code>index.html</code>和<code>styles/style.css</code>两个文件都做了修改，并且已经add到暂存区，同样可以使用<code>git reset</code>命令来取消暂存区某个文件的更改，即把这个文件从上一次commit到现在，add到暂存区的变更将会清除，但是本地工作区不会被清除</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> git reset HEAD -- index.html</span></span><br></pre></td></tr></table></figure></div>
<p>执行之后，暂存区的<code>index.html</code>文件将和上一次commit时保持一致，如果此时再<code>git commit</code>操作,将会把暂存区<code>styles/style.css</code>的变更提交到版本库。</p>
<h2 id="怎么比较工作区和暂存区所含文件的差异"><a href="#怎么比较工作区和暂存区所含文件的差异" class="headerlink" title="怎么比较工作区和暂存区所含文件的差异"></a>怎么比较工作区和暂存区所含文件的差异</h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 工作区文件修改之后，添加到暂存区之前，比较工作区和暂存区所含文件的差异</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> git diff [-- filename(多个空格隔开) ]</span></span><br></pre></td></tr></table></figure></div>

<h2 id="如何让工作区的文件恢复为和暂存区一样"><a href="#如何让工作区的文件恢复为和暂存区一样" class="headerlink" title="如何让工作区的文件恢复为和暂存区一样"></a>如何让工作区的文件恢复为和暂存区一样</h2><blockquote>
<p>即放弃从上次add到目前，在工作区的变更</p>
</blockquote>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 恢复指定文件</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> git checkout -- filename</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 恢复当前目录下所有</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> git checkout .</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看差异，验证恢复</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> git diff</span></span><br></pre></td></tr></table></figure></div>
<p>总结:<br><img src="/2022/09/05/uncatalog/cl7oebs5q0000f0r7e0oq9fnk/add.jpg"></p>
<h2 id="查看不同提交的指定文件的差异"><a href="#查看不同提交的指定文件的差异" class="headerlink" title="查看不同提交的指定文件的差异"></a>查看不同提交的指定文件的差异</h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 分之间文件差异</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> git diff branch1 branch2 -- filename</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> commit间文件差异(commitID1和commitID2可以在不同的分支上)</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> git diff commitID1 commitID2 -- filename</span></span><br></pre></td></tr></table></figure></div>

<h2 id="正确删除文件的方法"><a href="#正确删除文件的方法" class="headerlink" title="正确删除文件的方法"></a>正确删除文件的方法</h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> git rm filename</span></span><br></pre></td></tr></table></figure></div>

<h2 id="如何指定不需要git管理的文件"><a href="#如何指定不需要git管理的文件" class="headerlink" title="如何指定不需要git管理的文件"></a>如何指定不需要git管理的文件</h2><p>详见<a href="https://www.w3schools.com/git/git_ignore.asp">.gitignore</a></p>
<h2 id="如何将git仓库备份到本地"><a href="#如何将git仓库备份到本地" class="headerlink" title="如何将git仓库备份到本地"></a>如何将git仓库备份到本地</h2><ol>
<li>哑协议和智能协议<br><img src="/2022/09/05/uncatalog/cl7oebs5q0000f0r7e0oq9fnk/protocal.png" alt="protocal"></li>
</ol>
<p><img src="/2022/09/05/uncatalog/cl7oebs5q0000f0r7e0oq9fnk/protocal_diff.png" alt="protocal_diff"></p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">pwd</span></span></span><br><span class="line">/d/github/gitPractice</span><br><span class="line"></span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">cd</span> ..</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建哑协议备份仓库目录</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> mkdir gitPracticeBackUpYa</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建只能协议备份仓库目录</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> mkdir gitPracticeBackUpZhiNeng</span></span><br><span class="line"></span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">cd</span> gitPracticeBackUpYa/</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 通过哑协议备份到gitPracticeBackUpYa目录</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> git <span class="built_in">clone</span> --bare /d/github/gitPractice/.git/ ya_xie_yi.git</span></span><br><span class="line">Cloning into bare repository &#x27;ya_xie_yi.git&#x27;...</span><br><span class="line">done.</span><br><span class="line"></span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">cd</span> ../gitPracticeBackUpZhiNeng/</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 通过智能协议备份到gitPracticeBackUpYa目录，--bare不包含工作区</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> git <span class="built_in">clone</span> --bare file:///d/github/gitPractice/.git zhi_neng.git</span></span><br><span class="line">Cloning into bare repository &#x27;zhi_neng.git&#x27;...</span><br><span class="line">remote: Enumerating objects: 29, done.</span><br><span class="line">remote: Counting objects: 100% (29/29), done.</span><br><span class="line">remote: Compressing objects: 100% (23/23), done.</span><br><span class="line">remote: Total 29 (delta 10), reused 0 (delta 0), pack-reused 0</span><br><span class="line">Receiving objects: 100% (29/29), 22.51 KiB | 5.63 MiB/s, done.</span><br><span class="line">Resolving deltas: 100% (10/10), done.</span><br><span class="line"></span><br><span class="line"><span class="meta">$</span><span class="bash"> ls</span></span><br><span class="line">zhi_neng.git/</span><br><span class="line"></span><br><span class="line"><span class="meta">$</span><span class="bash"> ls ../gitPracticeBackUpYa/</span></span><br><span class="line">ya_xie_yi.git/</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>

<ol start="2">
<li>备份<br><img src="/2022/09/05/uncatalog/cl7oebs5q0000f0r7e0oq9fnk/backup.png" alt="backup"></li>
</ol>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">/d/github/gitPractice (temp)</span><br><span class="line"><span class="meta">$</span><span class="bash"> git remote -v <span class="comment"># 显示需要读写远程仓库使用的 Git 保存的简写与其对应的 URL</span></span></span><br><span class="line">origin  https://github.com/bugmakerprox/gitPractice.git (fetch)</span><br><span class="line">origin  https://github.com/bugmakerprox/gitPractice.git (push)</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> git remote add &lt;shortname&gt; &lt;url&gt; 添加一个新的远程 Git 仓库</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> git remote add zhineng file:///d/github/gitPracticeBackUpZhiNeng/zhi_neng.git</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></div>
<p>在备份仓库(gitPracticeBackUpZhiNeng)查看</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">pwd</span></span></span><br><span class="line">/d/github/gitPracticeBackUpZhiNeng/zhi_neng.git</span><br><span class="line"></span><br><span class="line">jw.xu@hz-jw-xu-n MINGW64 /d/github/gitPracticeBackUpZhiNeng/zhi_neng.git (BARE:temp)</span><br><span class="line"><span class="meta">$</span><span class="bash"> git branch -av</span></span><br><span class="line">  main 0007ea8 Change styles/style.css to 版本库</span><br><span class="line">* temp 67626bb Add some comments</span><br><span class="line"></span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">cd</span> ..</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> ls</span></span><br><span class="line">zhi_neng.git/</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>
<p>在本地仓库推送到远程仓库</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">/d/github/gitPractice (temp)</span><br><span class="line"><span class="meta">$</span><span class="bash"> git remote -v</span></span><br><span class="line">origin  https://github.com/bugmakerprox/gitPractice.git (fetch)</span><br><span class="line">origin  https://github.com/bugmakerprox/gitPractice.git (push)</span><br><span class="line">zhineng file:///d/github/gitPracticeBackUpZhiNeng/zhi_neng.git (fetch)</span><br><span class="line">zhineng file:///d/github/gitPracticeBackUpZhiNeng/zhi_neng.git (push)</span><br><span class="line"></span><br><span class="line"><span class="meta">$</span><span class="bash"> git add .</span></span><br><span class="line"></span><br><span class="line"><span class="meta">$</span><span class="bash"> git commit -m <span class="string">&quot;Add to zhineng&quot;</span></span></span><br><span class="line">[temp aa50d7b] Add to zhineng</span><br><span class="line"> 4 files changed, 31 insertions(+)</span><br><span class="line"> create mode 100644 .idea/.gitignore</span><br><span class="line"> create mode 100644 .idea/gitPractice.iml</span><br><span class="line"> create mode 100644 .idea/modules.xml</span><br><span class="line"> create mode 100644 .idea/vcs.xml</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>

<p>在备份仓库(gitPracticeBackUpZhiNeng)查看</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">pwd</span></span></span><br><span class="line">/d/github/gitPracticeBackUpZhiNeng/zhi_neng.git</span><br><span class="line"></span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">cd</span> ..</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> ls</span></span><br><span class="line">zhi_neng.git/</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>

<ol start="3">
<li>恢复<br>恢复这部分内容，教程里面没有涉及，而且前面两步讲的比较笼统，虽然上面<code>gitPracticeBackUpZhiNeng</code>和<code>gitPracticeBackUpYa</code>目录并没有工程代码，只备份了.git文件，备份恢复来说已经足够了，下面就讲一下如何利用<code>zhi_neng.git</code>做恢复  </li>
</ol>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 任意目录</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> git <span class="built_in">clone</span> file:///d/github/gitPracticeBackUpZhiNeng/zhi_neng.git</span></span><br><span class="line">Cloning into &#x27;zhi_neng&#x27;...</span><br><span class="line">remote: Enumerating objects: 36, done.</span><br><span class="line">remote: Counting objects: 100% (36/36), done.</span><br><span class="line">remote: Compressing objects: 100% (20/20), done.</span><br><span class="line">remote: Total 36 (delta 11), reused 28 (delta 10), pack-reused 0</span><br><span class="line">Receiving objects: 100% (36/36), 23.54 KiB | 3.92 MiB/s, done.</span><br><span class="line">Resolving deltas: 100% (11/11), done.</span><br><span class="line"></span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">cd</span> zhi_neng/</span></span><br><span class="line"></span><br><span class="line"><span class="meta">$</span><span class="bash"> ls</span></span><br><span class="line">README.md  images/  index.html  styles/</span><br><span class="line"></span><br><span class="line"><span class="meta">$</span><span class="bash"> git branch -av</span></span><br><span class="line">* temp                aa50d7b Add to zhineng</span><br><span class="line">  remotes/origin/HEAD -&gt; origin/temp</span><br><span class="line">  remotes/origin/main 0007ea8 Change styles/style.css to 版本库</span><br><span class="line">  remotes/origin/temp aa50d7b Add to zhineng</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>

<h2 id="把本地仓库同步到github"><a href="#把本地仓库同步到github" class="headerlink" title="把本地仓库同步到github"></a>把本地仓库同步到github</h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> git remote add &lt;shortname&gt; &lt;url&gt; 添加一个新的远程 Git 仓库</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> git remote add github git@github.com:bugmakerprox/gitPractice.git</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> git remote -v</span></span><br><span class="line">github  git@github.com:bugmakerprox/gitPractice.git (fetch)</span><br><span class="line">github  git@github.com:bugmakerprox/gitPractice.git (push)</span><br><span class="line">origin  https://github.com/bugmakerprox/gitPractice.git (fetch)</span><br><span class="line">origin  https://github.com/bugmakerprox/gitPractice.git (push)</span><br><span class="line">zhineng file:///d/github/gitPracticeBackUpZhiNeng/zhi_neng.git (fetch)</span><br><span class="line">zhineng file:///d/github/gitPracticeBackUpZhiNeng/zhi_neng.git (push)</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> push</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> git push github --all</span></span><br><span class="line">Enumerating objects: 34, done.</span><br><span class="line">Counting objects: 100% (34/34), done.</span><br><span class="line">Delta compression using up to 4 threads</span><br><span class="line">Compressing objects: 100% (29/29), done.</span><br><span class="line">Writing objects: 100% (33/33), 22.97 KiB | 1.35 MiB/s, done.</span><br><span class="line">Total 33 (delta 11), reused 0 (delta 0), pack-reused 0</span><br><span class="line">remote: Resolving deltas: 100% (11/11), done.</span><br><span class="line">To github.com:bugmakerprox/gitPractice.git</span><br><span class="line">   97ad728..0007ea8  main -&gt; main</span><br><span class="line"> * [new branch]      temp -&gt; temp</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>

<h2 id="不同人修改了不同文件或者不同人修改了同文件的不同区域如何处理"><a href="#不同人修改了不同文件或者不同人修改了同文件的不同区域如何处理" class="headerlink" title="不同人修改了不同文件或者不同人修改了同文件的不同区域如何处理"></a>不同人修改了不同文件或者不同人修改了同文件的不同区域如何处理</h2><p>先<code>git pull</code>，和远程仓库做个同步(拉去其他人的变更)，再<code>git push</code>自己的变更到远程仓库</p>
<blockquote>
<p>git pull = git fetch + git merge <a href="https://www.zhihu.com/question/38305012">详情</a></p>
</blockquote>
<h2 id="不同人同文件的同区域如何处理"><a href="#不同人同文件的同区域如何处理" class="headerlink" title="不同人同文件的同区域如何处理"></a>不同人同文件的同区域如何处理</h2><ul>
<li>先<code>git pull</code>，和远程仓库做个同步(拉取其他人的变更)</li>
<li>这时会提示发生了<code>CONFLICT</code>，需要先解决冲突，编辑产生冲突的文件(建议通过编译器如Goland自带的Git –&gt; Resolve Conflict来解决)</li>
<li>再通过<code>git status</code>查看冲突是否完全解决</li>
<li>如果是，则通过<code>git commit</code>提交即可完成冲突合并，如果要放弃merge，需要使用<code>git merge --abort</code>来实现。</li>
</ul>
<h2 id="同时变更了文件名和文件内容如何处理"><a href="#同时变更了文件名和文件内容如何处理" class="headerlink" title="同时变更了文件名和文件内容如何处理"></a>同时变更了文件名和文件内容如何处理</h2><p>场景：</p>
<ul>
<li>甲把文件<code>A.html</code>变更为了<code>B.html</code>，并<code>git push</code>提交到了远程仓库</li>
<li>同时乙在本地对<code>A.html</code>文件内容进行了修改，<code>git push</code>提交到远程仓库，此时会发生<code>! [rejected]</code>提示<br><img src="/2022/09/05/uncatalog/cl7oebs5q0000f0r7e0oq9fnk/rename.png" alt="img"></li>
</ul>
<p>解决：<br> 乙需要先<code>git pull</code>，如果有冲突需要和上一步一样解决冲突，如果没有冲突，会发现本地文件<code>A.html</code>变更为了<code>B.html</code>，并且之前在本地对<code>A.html</code>文件内容的修改也会出现在<code>B.html</code>文件，即git智能的帮我们完成了合并，接下来继续<code>commit</code>和<code>push</code>提交到远程仓库即可。</p>
<h2 id="多人修改同一文件的文件名如何处理"><a href="#多人修改同一文件的文件名如何处理" class="headerlink" title="多人修改同一文件的文件名如何处理"></a>多人修改同一文件的文件名如何处理</h2><p>场景：</p>
<ul>
<li>甲把文件<code>index.htm</code>变更为了<code>index2.htm</code>，并<code>commit</code>和<code>push</code>提交到了远程仓库</li>
<li>乙把文件<code>index.htm</code>变更为了<code>index1.htm</code>，并通过<code>commit</code>和<code>push</code>做提交，此时会发生<code>! [rejected]</code>提示<br><img src="/2022/09/05/uncatalog/cl7oebs5q0000f0r7e0oq9fnk/rename1.png" alt="img"></li>
</ul>
<p>解决：<br>乙需要先<code>git pull</code>，会提示冲突:<br><img src="/2022/09/05/uncatalog/cl7oebs5q0000f0r7e0oq9fnk/re3.png" alt="img"><br>查看本地文件，会发现同时出现了<code>index1.htm</code>和<code>index2.htm</code>两个文件，通过<code>git status</code>查看一下:<br><img src="/2022/09/05/uncatalog/cl7oebs5q0000f0r7e0oq9fnk/3.png" alt="img"><br>提示非常详细：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">both deleted: index.htm</span><br><span class="line">added by us : index1.htm</span><br><span class="line">added by them : index2.htm</span><br></pre></td></tr></table></figure></div>
<p>同时也给出了操作建议：</p>
<div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="true"data-rel="SHELL"><figure class="iseeu highlight /shell"><table><tr><td class="code"><pre><span class="line">Unmerged pahts:</span><br><span class="line">   (use &quot;git add/rm &lt;file&gt;...&quot; as appropriate to mark resolution)</span><br></pre></td></tr></table></figure></div>
<p>甲和乙协商<code>index.htm</code>最终需要确定的名称之后，比如<code>index1.htm</code>，进行如下操作</p>
<ul>
<li><code>git rm index.htm</code></li>
<li><code>git rm index2.htm</code></li>
<li><code>git add index1.htm</code><br>查看<code>git status</code>:<br><img src="/2022/09/05/uncatalog/cl7oebs5q0000f0r7e0oq9fnk/4.png" alt="img"></li>
</ul>
<p>冲突已经解决，接下来<code>git commit</code>和<code>git push</code>即可。</p>
<h2 id="禁止向集成分支执行git-push-f操作"><a href="#禁止向集成分支执行git-push-f操作" class="headerlink" title="禁止向集成分支执行git push -f操作"></a>禁止向集成分支执行<code>git push -f</code>操作</h2><h2 id="禁止向集成分支执行变更历史的操作"><a href="#禁止向集成分支执行变更历史的操作" class="headerlink" title="禁止向集成分支执行变更历史的操作"></a>禁止向集成分支执行变更历史的操作</h2><h2 id="Some-tips"><a href="#Some-tips" class="headerlink" title="Some tips"></a>Some tips</h2><ol>
<li>windows系统中，<code>git commit -m &quot;Add file or files&quot;</code> 提交说明建议用双引号，以免出现不可预知的错误</li>
<li><code>git commit -m &quot;Add file or files&quot;</code>，提交说明，建议第一个单词(<code>Add</code>)的首字母大写</li>
<li>对于git已经跟踪的文件，文件内容变更后，建议使用<code>git add -u</code></li>
<li>对于git已经跟踪的文件，如果要对其进行重命名，建议使用<code>git mv oldName newName</code>,然后直接commit</li>
<li><code>git add</code> 和<code>git commit -m </code>可以合并为一个命令<code>git commit -am</code></li>
</ol>
]]></content>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
</search>
